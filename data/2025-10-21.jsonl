{"id": "2510.15948", "pdf": "https://arxiv.org/pdf/2510.15948", "abs": "https://arxiv.org/abs/2510.15948", "authors": ["MingSheng Li", "Guangze Zhao", "Sichen Liu"], "title": "VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) have achieved remarkable progress in\nmultimodal perception and generation, yet their safety alignment remains a\ncritical challenge.Existing defenses and vulnerable to multimodal jailbreaks,\nas visual inputs introduce new attack surfaces, reasoning chains lack safety\nsupervision, and alignment often degrades under modality fusion.To overcome\nthese limitation, we propose VisuoAlign, a framework for multi-modal safety\nalignment via prompt-guided tree search.VisuoAlign embeds safety constrains\ninto the reasoning process through visual-textual interactive prompts, employs\nMonte Carlo Tree Search(MCTS) to systematically construct diverse\nsafety-critical prompt trajectories, and introduces prompt-based scaling to\nensure real-time risk detection and compliant responses.Extensive experiments\ndemonstrate that VisuoAlign proactively exposes risks, enables comprehensive\ndataset generation, and significantly improves the robustness of LVLMs against\ncomplex cross-modal threats."}
{"id": "2510.15952", "pdf": "https://arxiv.org/pdf/2510.15952", "abs": "https://arxiv.org/abs/2510.15952", "authors": ["Myung Ho Kim"], "title": "Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding", "categories": ["cs.AI"], "comment": "27 pages", "summary": "Large language models exhibit intelligence without genuine epistemic\nunderstanding, exposing a key gap: the absence of epistemic architecture. This\npaper introduces the Structured Cognitive Loop (SCL) as an executable\nepistemological framework for emergent intelligence. Unlike traditional AI\nresearch asking \"what is intelligence?\" (ontological), SCL asks \"under what\nconditions does cognition emerge?\" (epistemological). Grounded in philosophy of\nmind and cognitive phenomenology, SCL bridges conceptual philosophy and\nimplementable cognition. Drawing on process philosophy, enactive cognition, and\nextended mind theory, we define intelligence not as a property but as a\nperformed process -- a continuous loop of judgment, memory, control, action,\nand regulation. SCL makes three contributions. First, it operationalizes\nphilosophical insights into computationally interpretable structures, enabling\n\"executable epistemology\" -- philosophy as structural experiment. Second, it\nshows that functional separation within cognitive architecture yields more\ncoherent and interpretable behavior than monolithic prompt based systems,\nsupported by agent evaluations. Third, it redefines intelligence: not\nrepresentational accuracy but the capacity to reconstruct its own epistemic\nstate through intentional understanding. This framework impacts philosophy of\nmind, epistemology, and AI. For philosophy, it allows theories of cognition to\nbe enacted and tested. For AI, it grounds behavior in epistemic structure\nrather than statistical regularity. For epistemology, it frames knowledge not\nas truth possession but as continuous reconstruction within a\nphenomenologically coherent loop. We situate SCL within debates on cognitive\nphenomenology, emergence, normativity, and intentionality, arguing that real\nprogress requires not larger models but architectures that realize cognitive\nprinciples structurally."}
{"id": "2510.15959", "pdf": "https://arxiv.org/pdf/2510.15959", "abs": "https://arxiv.org/abs/2510.15959", "authors": ["Isabelle Hupont", "Marisa Ponti", "Sven Schade"], "title": "Exploring the Potential of Citiverses for Regulatory Learning", "categories": ["cs.AI", "cs.CY", "cs.ET", "cs.HC"], "comment": "26 pages", "summary": "Citiverses hold the potential to support regulatory learning by offering\nimmersive, virtual environments for experimenting with policy scenarios and\ntechnologies. This paper proposes a science-for-policy agenda to explore the\npotential of citiverses as experimentation spaces for regulatory learning,\ngrounded in a consultation with a high-level panel of experts, including\npolicymakers from the European Commission, national government science advisers\nand leading researchers in digital regulation and virtual worlds. It identifies\nkey research areas, including scalability, real-time feedback, complexity\nmodelling, cross-border collaboration, risk reduction, citizen participation,\nethical considerations and the integration of emerging technologies. In\naddition, the paper analyses a set of experimental topics, spanning\ntransportation, urban planning and the environment/climate crisis, that could\nbe tested in citiverse platforms to advance regulatory learning in these areas.\nThe proposed work is designed to inform future research for policy and\nemphasizes a responsible approach to developing and using citiverses. It\nprioritizes careful consideration of the ethical, economic, ecological and\nsocial dimensions of different regulations. The paper also explores essential\npreliminary steps necessary for integrating citiverses into the broader\necosystems of experimentation spaces, including test beds, living labs and\nregulatory sandboxes"}
{"id": "2510.15966", "pdf": "https://arxiv.org/pdf/2510.15966", "abs": "https://arxiv.org/abs/2510.15966", "authors": ["Shian Jia", "Ziyang Huang", "Xinbo Wang", "Haofei Zhang", "Mingli Song"], "title": "PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency", "categories": ["cs.AI"], "comment": null, "summary": "Memory systems are fundamental to AI agents, yet existing work often lacks\nadaptability to diverse tasks and overlooks the constructive and task-oriented\nrole of AI agent memory. Drawing from Piaget's theory of cognitive development,\nwe propose PISA, a pragmatic, psych-inspired unified memory system that\naddresses these limitations by treating memory as a constructive and adaptive\nprocess. To enable continuous learning and adaptability, PISA introduces a\ntrimodal adaptation mechanism (i.e., schema updation, schema evolution, and\nschema creation) that preserves coherent organization while supporting flexible\nmemory updates. Building on these schema-grounded structures, we further design\na hybrid memory access architecture that seamlessly integrates symbolic\nreasoning with neural retrieval, significantly improving retrieval accuracy and\nefficiency. Our empirical evaluation, conducted on the existing LOCOMO\nbenchmark and our newly proposed AggQA benchmark for data analysis tasks,\nconfirms that PISA sets a new state-of-the-art by significantly enhancing\nadaptability and long-term knowledge retention."}
{"id": "2510.15974", "pdf": "https://arxiv.org/pdf/2510.15974", "abs": "https://arxiv.org/abs/2510.15974", "authors": ["Chris Su", "Harrison Li", "Matheus Marques", "George Flint", "Kevin Zhu", "Sunishchal Dev"], "title": "Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games", "categories": ["cs.AI"], "comment": null, "summary": "Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in\nperformance on solving puzzles beyond certain perplexity thresholds. In\nsubsequent discourse, questions have arisen as to whether the nature of the\ntask muddles an evaluation of true reasoning. One potential confound is the\nrequirement that the model keep track of the state space on its own. We provide\na large language model (LLM) with an environment interface for Tower of Hanoi\nproblems, allowing it to make a move with a tool call, provide written\njustification, observe the resulting state space, and reprompt itself for the\nnext move. We observe that access to an environment interface does not delay or\neradicate performance collapse. Furthermore, LLM-parameterized policy analysis\nreveals increasing divergence from both optimal policies and uniformly random\npolicies, suggesting that the model exhibits mode-like collapse at each level\nof complexity, and that performance is dependent upon whether the mode reflects\nthe correct solution for the problem. We suggest that a similar phenomena might\ntake place in LRMs."}
{"id": "2510.15980", "pdf": "https://arxiv.org/pdf/2510.15980", "abs": "https://arxiv.org/abs/2510.15980", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition", "categories": ["cs.AI"], "comment": null, "summary": "We propose \\textbf{Cognitive Load Traces} (CLTs) as a mid-level\ninterpretability framework for deep models, inspired by Cognitive Load Theory\nin human cognition. CLTs are defined as symbolic, temporally varying functions\nthat quantify model-internal resource allocation. Formally, we represent CLTs\nas a three-component stochastic process $(\\mathrm{IL}_t, \\mathrm{EL}_t,\n\\mathrm{GL}_t)$, corresponding to \\emph{Intrinsic}, \\emph{Extraneous}, and\n\\emph{Germane} load. Each component is instantiated through measurable proxies\nsuch as attention entropy, KV-cache miss ratio, representation dispersion, and\ndecoding stability. We propose both symbolic formulations and visualization\nmethods (load curves, simplex diagrams) that enable interpretable analysis of\nreasoning dynamics. Experiments on reasoning and planning benchmarks show that\nCLTs predict error-onset, reveal cognitive strategies, and enable load-guided\ninterventions that improve reasoning efficiency by 15-30\\% while maintaining\naccuracy."}
{"id": "2510.15981", "pdf": "https://arxiv.org/pdf/2510.15981", "abs": "https://arxiv.org/abs/2510.15981", "authors": ["Rafael Cabral", "Tuan Manh Do", "Xuejun Yu", "Wai Ming Tai", "Zijin Feng", "Xin Shen"], "title": "ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Proof autoformalization, the task of translating natural language theorems\nand proofs into machine-verifiable code, is a critical step for integrating\nlarge language models into rigorous mathematical workflows. Current approaches\nfocus on producing executable code, but they frequently fail to preserve the\nsemantic meaning and logical structure of the original human-written argument.\nTo address this, we introduce ProofFlow, a novel pipeline that treats\nstructural fidelity as a primary objective. ProofFlow first constructs a\ndirected acyclic graph (DAG) to map the logical dependencies between proof\nsteps. Then, it employs a novel lemma-based approach to systematically\nformalize each step as an intermediate lemma, preserving the logical structure\nof the original argument. To facilitate evaluation, we present a new benchmark\nof 184 undergraduate-level problems, manually annotated with step-by-step\nsolutions and logical dependency graphs, and introduce ProofScore, a new\ncomposite metric to evaluate syntactic correctness, semantic faithfulness, and\nstructural fidelity. Experimental results show our pipeline sets a new\nstate-of-the-art for autoformalization, achieving a ProofScore of 0.545,\nsubstantially exceeding baselines like full-proof formalization (0.123), which\nprocesses the entire proof at once, and step-proof formalization (0.072), which\nhandles each step independently. Our pipeline, benchmark, and score metric are\nopen-sourced to encourage further progress at\nhttps://github.com/Huawei-AI4Math/ProofFlow."}
{"id": "2510.15983", "pdf": "https://arxiv.org/pdf/2510.15983", "abs": "https://arxiv.org/abs/2510.15983", "authors": ["Sarah Rebecca Ondraszek", "JÃ¶rg Waitelonis", "Katja Keller", "Claudia Niessner", "Anna M. Jacyszyn", "Harald Sack"], "title": "Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science", "categories": ["cs.AI"], "comment": "10 pages, 2 figures. Camera-ready version. Accepted to the 5th\n  International Workshop on Scientific Knowledge: Representation, Discovery,\n  and Assessment; 2 November 2025 - Nara, Japan; co-located with The 24th\n  International Semantic Web Conference, ISWC 2025. To be published in CEUR\n  proceedings", "summary": "An essential component for evaluating and comparing physical and cognitive\ncapabilities between populations is the testing of various factors related to\nhuman performance. As a core part of sports science research, testing motor\nperformance enables the analysis of the physical health of different\ndemographic groups and makes them comparable.\n  The Motor Research (MO|RE) data repository, developed at the Karlsruhe\nInstitute of Technology, is an infrastructure for publishing and archiving\nresearch data in sports science, particularly in the field of motor performance\nresearch. In this paper, we present our vision for creating a knowledge graph\nfrom MO|RE data. With an ontology rooted in the Basic Formal Ontology, our\napproach centers on formally representing the interrelation of plan\nspecifications, specific processes, and related measurements. Our goal is to\ntransform how motor performance data are modeled and shared across studies,\nmaking it standardized and machine-understandable. The idea presented here is\ndeveloped within the Leibniz Science Campus ``Digital Transformation of\nResearch'' (DiTraRe)."}
{"id": "2510.16001", "pdf": "https://arxiv.org/pdf/2510.16001", "abs": "https://arxiv.org/abs/2510.16001", "authors": ["Ruolan Cheng", "Yong Deng", "Enrique Herrera-Viedma"], "title": "A Non-overlap-based Conflict Measure for Random Permutation Sets", "categories": ["cs.AI"], "comment": null, "summary": "Random permutation set (RPS) is a new formalism for reasoning with\nuncertainty involving order information. Measuring the conflict between two\npieces of evidence represented by permutation mass functions remains an urgent\nresearch topic in order-structured uncertain information fusion. In this paper,\na detailed analysis of conflicts in RPS is carried out from two different\nperspectives: random finite set (RFS) and Dempster-Shafer theory (DST).\nStarting from the observation of permutations, we first define an inconsistency\nmeasure between permutations inspired by the rank-biased overlap(RBO) measure\nand further propose a non-overlap-based conflict measure method for RPSs. This\npaper regards RPS theory (RPST) as an extension of DST. The order information\nnewly added in focal sets indicates qualitative propensity, characterized by\ntop-ranked elements occupying a more critical position. Some numerical examples\nare used to demonstrate the behavior and properties of the proposed conflict\nmeasure. The proposed method not only has the natural top-weightedness property\nand can effectively measure the conflict between RPSs from the DST view but\nalso provides decision-makers with a flexible selection of weights, parameters,\nand truncated depths."}
{"id": "2510.16004", "pdf": "https://arxiv.org/pdf/2510.16004", "abs": "https://arxiv.org/abs/2510.16004", "authors": ["Andreas Radler", "Vincent Seyfried", "Stefan Pirker", "Johannes Brandstetter", "Thomas Lichtenegger"], "title": "PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction", "categories": ["cs.AI", "physics.flu-dyn"], "comment": "22 pages, 16 figures", "summary": "Neural surrogates have shown great potential in simulating dynamical systems,\nwhile offering real-time capabilities. We envision Neural Twins as a\nprogression of neural surrogates, aiming to create digital replicas of real\nsystems. A neural twin consumes measurements at test time to update its state,\nthereby enabling context-specific decision-making. A critical property of\nneural twins is their ability to remain on-trajectory, i.e., to stay close to\nthe true system state over time. We introduce Parallel-in-time Neural Twins\n(PAINT), an architecture-agnostic family of methods for modeling dynamical\nsystems from measurements. PAINT trains a generative neural network to model\nthe distribution of states parallel over time. At test time, states are\npredicted from measurements in a sliding window fashion. Our theoretical\nanalysis shows that PAINT is on-trajectory, whereas autoregressive models\ngenerally are not. Empirically, we evaluate our method on a challenging\ntwo-dimensional turbulent fluid dynamics problem. The results demonstrate that\nPAINT stays on-trajectory and predicts system states from sparse measurements\nwith high fidelity. These findings underscore PAINT's potential for developing\nneural twins that stay on-trajectory, enabling more accurate state estimation\nand decision-making."}
{"id": "2510.16033", "pdf": "https://arxiv.org/pdf/2510.16033", "abs": "https://arxiv.org/abs/2510.16033", "authors": ["Junyu Ren", "Wensheng Gan", "Guangyu Zhang", "Wei Zhong", "Philip S. Yu"], "title": "Global-focal Adaptation with Information Separation for Noise-robust Transfer Fault Diagnosis", "categories": ["cs.AI"], "comment": "Preprint. 16 figures, 12 tables", "summary": "Existing transfer fault diagnosis methods typically assume either clean data\nor sufficient domain similarity, which limits their effectiveness in industrial\nenvironments where severe noise interference and domain shifts coexist. To\naddress this challenge, we propose an information separation global-focal\nadversarial network (ISGFAN), a robust framework for cross-domain fault\ndiagnosis under noise conditions. ISGFAN is built on an information separation\narchitecture that integrates adversarial learning with an improved orthogonal\nloss to decouple domain-invariant fault representation, thereby isolating noise\ninterference and domain-specific characteristics. To further strengthen\ntransfer robustness, ISGFAN employs a global-focal domain-adversarial scheme\nthat constrains both the conditional and marginal distributions of the model.\nSpecifically, the focal domain-adversarial component mitigates\ncategory-specific transfer obstacles caused by noise in unsupervised scenarios,\nwhile the global domain classifier ensures alignment of the overall\ndistribution. Experiments conducted on three public benchmark datasets\ndemonstrate that the proposed method outperforms other prominent existing\napproaches, confirming the superiority of the ISGFAN framework. Data and code\nare available at https://github.com/JYREN-Source/ISGFAN"}
{"id": "2510.16047", "pdf": "https://arxiv.org/pdf/2510.16047", "abs": "https://arxiv.org/abs/2510.16047", "authors": ["Ioan Hedea"], "title": "Algorithms for dynamic scheduling in manufacturing, towards digital factories Improving Deadline Feasibility and Responsiveness via Temporal Networks", "categories": ["cs.AI"], "comment": "8 pages 2 column, 11 figures. Bachelor's thesis", "summary": "Modern manufacturing systems must meet hard delivery deadlines while coping\nwith stochastic task durations caused by process noise, equipment variability,\nand human intervention. Traditional deterministic schedules break down when\nreality deviates from nominal plans, triggering costly last-minute repairs.\nThis thesis combines offline constraint-programming (CP) optimisation with\nonline temporal-network execution to create schedules that remain feasible\nunder worst-case uncertainty. First, we build a CP model of the flexible\njob-shop with per-job deadline tasks and insert an optimal buffer $\\Delta^*$ to\nobtain a fully pro-active baseline. We then translate the resulting plan into a\nSimple Temporal Network with Uncertainty (STNU) and verify dynamic\ncontrollability, which guarantees that a real-time dispatcher can retime\nactivities for every bounded duration realisation without violating resource or\ndeadline constraints. Extensive Monte-Carlo simulations on the open Kacem~1--4\nbenchmark suite show that our hybrid approach eliminates 100\\% of deadline\nviolations observed in state-of-the-art meta-heuristic schedules, while adding\nonly 3--5\\% makespan overhead. Scalability experiments confirm that CP\nsolve-times and STNU checks remain sub-second on medium-size instances. The\nwork demonstrates how temporal-network reasoning can bridge the gap between\nproactive buffering and dynamic robustness, moving industry a step closer to\ntruly digital, self-correcting factories."}
{"id": "2510.16095", "pdf": "https://arxiv.org/pdf/2510.16095", "abs": "https://arxiv.org/abs/2510.16095", "authors": ["Dou Liu", "Ying Long", "Sophia Zuoqiu", "Di Liu", "Kang Li", "Yiting Lin", "Hanyi Liu", "Rong Yin", "Tian Tang"], "title": "Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study", "categories": ["cs.AI"], "comment": null, "summary": "Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for\nexplainable medical Artificial Intelligence (AI) while constrained by data\nscarcity. Although Large Language Models (LLMs) can synthesize medical data,\ntheir clinical reliability remains unverified. This study evaluates the\nreliability of LLM-generated CoTs and investigates prompting strategies to\nenhance their quality. In a blinded comparative study, senior clinicians in\nAssisted Reproductive Technology (ART) evaluated CoTs generated via three\ndistinct strategies: Zero-shot, Random Few-shot (using shallow examples), and\nSelective Few-shot (using diverse, high-quality examples). These expert ratings\nwere compared against evaluations from a state-of-the-art AI model (GPT-4o).\nThe Selective Few-shot strategy significantly outperformed other strategies\nacross all human evaluation metrics (p < .001). Critically, the Random Few-shot\nstrategy offered no significant improvement over the Zero-shot baseline,\ndemonstrating that low-quality examples are as ineffective as no examples. The\nsuccess of the Selective strategy is attributed to two principles:\n\"Gold-Standard Depth\" (reasoning quality) and \"Representative Diversity\"\n(generalization). Notably, the AI evaluator failed to discern these critical\nperformance differences. The clinical reliability of synthetic CoTs is dictated\nby strategic prompt curation, not the mere presence of examples. We propose a\n\"Dual Principles\" framework as a foundational methodology to generate\ntrustworthy data at scale. This work offers a validated solution to the data\nbottleneck and confirms the indispensable role of human expertise in evaluating\nhigh-stakes clinical AI."}
{"id": "2510.16193", "pdf": "https://arxiv.org/pdf/2510.16193", "abs": "https://arxiv.org/abs/2510.16193", "authors": ["Elija Perrier"], "title": "Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability", "categories": ["cs.AI"], "comment": "Under review", "summary": "Corporate responsibility turns on notions of corporate \\textit{mens rea},\ntraditionally imputed from human agents. Yet these assumptions are under\nchallenge as generative AI increasingly mediates enterprise decision-making.\nBuilding on the theory of extended cognition, we argue that in response\ncorporate knowledge may be redefined as a dynamic capability, measurable by the\nefficiency of its information-access procedures and the validated reliability\nof their outputs. We develop a formal model that captures epistemic states of\ncorporations deploying sophisticated AI or information systems, introducing a\ncontinuous organisational knowledge metric $S_S(\\varphi)$ which integrates a\npipeline's computational cost and its statistically validated error rate. We\nderive a thresholded knowledge predicate $\\mathsf{K}_S$ to impute knowledge and\na firm-wide epistemic capacity index $\\mathcal{K}_{S,t}$ to measure overall\ncapability. We then operationally map these quantitative metrics onto the legal\nstandards of actual knowledge, constructive knowledge, wilful blindness, and\nrecklessness. Our work provides a pathway towards creating measurable and\njusticiable audit artefacts, that render the corporate mind tractable and\naccountable in the algorithmic age."}
{"id": "2510.16194", "pdf": "https://arxiv.org/pdf/2510.16194", "abs": "https://arxiv.org/abs/2510.16194", "authors": ["Guanchen Wu", "Zuhui Chen", "Yuzhang Xie", "Carl Yang"], "title": "Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration", "categories": ["cs.AI"], "comment": "Agents4Science 2025 (Spotlight)", "summary": "Protected health information (PHI) de-identification is critical for enabling\nthe safe reuse of clinical notes, yet evaluating and comparing PHI\nde-identification models typically depends on costly, small-scale expert\nannotations. We present TEAM-PHI, a multi-agent evaluation and selection\nframework that uses large language models (LLMs) to automatically measure\nde-identification quality and select the best-performing model without heavy\nreliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each\nindependently judging the correctness of PHI extractions and outputting\nstructured metrics. Their results are then consolidated through an LLM-based\nmajority voting mechanism that integrates diverse evaluator perspectives into a\nsingle, stable, and reproducible ranking. Experiments on a real-world clinical\nnote corpus demonstrate that TEAM-PHI produces consistent and accurate\nrankings: despite variation across individual evaluators, LLM-based voting\nreliably converges on the same top-performing systems. Further comparison with\nground-truth annotations and human evaluation confirms that the framework's\nautomated rankings closely match supervised evaluation. By combining\nindependent evaluation agents with LLM majority voting, TEAM-PHI offers a\npractical, secure, and cost-effective solution for automatic evaluation and\nbest-model selection in PHI de-identification, even when ground-truth labels\nare limited."}
{"id": "2510.16206", "pdf": "https://arxiv.org/pdf/2510.16206", "abs": "https://arxiv.org/abs/2510.16206", "authors": ["Alex Zhavoronkov", "Dominika Wilczok", "Roman Yampolskiy"], "title": "The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI", "categories": ["cs.AI"], "comment": null, "summary": "Since the rapid expansion of large language models (LLMs), people have begun\nto rely on them for information retrieval. While traditional search engines\ndisplay ranked lists of sources shaped by search engine optimization (SEO),\nadvertising, and personalization, LLMs typically provide a synthesized response\nthat feels singular and authoritative. While both approaches carry risks of\nbias and omission, LLMs may amplify the effect by collapsing multiple\nperspectives into one answer, reducing users ability or inclination to compare\nalternatives. This concentrates power over information in a few LLM vendors\nwhose systems effectively shape what is remembered and what is overlooked. As a\nresult, certain narratives, individuals or groups, may be disproportionately\nsuppressed, while others are disproportionately elevated. Over time, this\ncreates a new threat: the gradual erasure of those with limited digital\npresence, and the amplification of those already prominent, reshaping\ncollective memory.To address these concerns, this paper presents a concept of\nthe Right To Be Remembered (RTBR) which encompasses minimizing the risk of\nAI-driven information omission, embracing the right of fair treatment, while\nensuring that the generated content would be maximally truthful."}
{"id": "2510.16234", "pdf": "https://arxiv.org/pdf/2510.16234", "abs": "https://arxiv.org/abs/2510.16234", "authors": ["Hanane Nour Moussa", "Patrick Queiroz Da Silva", "Daniel Adu-Ampratwum", "Alyson East", "Zitong Lu", "Nikki Puccetti", "Mingyi Xue", "Huan Sun", "Bodhisattwa Prasad Majumder", "Sachin Kumar"], "title": "ScholarEval: Research Idea Evaluation Grounded in Literature", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "As AI tools become increasingly common for research ideation, robust\nevaluation is critical to ensure the validity and usefulness of generated\nideas. We introduce ScholarEval, a retrieval augmented evaluation framework\nthat assesses research ideas based on two fundamental criteria: soundness - the\nempirical validity of proposed methods based on existing literature, and\ncontribution - the degree of advancement made by the idea across different\ndimensions relative to prior research. To evaluate ScholarEval, we introduce\nScholarIdeas, the first expert-annotated dataset of multi-domain research ideas\nand reviews, comprised of 117 ideas across four disciplines: artificial\nintelligence, neuroscience, biochemistry, and ecology. Our evaluation shows\nthat ScholarEval achieves significantly higher coverage of points mentioned in\nthe human expert annotated rubrics in ScholarIdeas compared to all baselines.\nFurthermore, ScholarEval is consistently preferred over our strongest baseline\no4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,\nin terms of evaluation actionability, depth, and evidence support. Our\nlarge-scale user study also shows that ScholarEval significantly outperforms\ndeep research in literature engagement, idea refinement, and usefulness. We\nopenly release our code, dataset, and ScholarEval tool for the community to use\nand build on."}
{"id": "2510.16259", "pdf": "https://arxiv.org/pdf/2510.16259", "abs": "https://arxiv.org/abs/2510.16259", "authors": ["Zhehao Zhang", "Weijie Xu", "Shixian Cui", "Chandan K. Reddy"], "title": "Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense", "categories": ["cs.AI", "68T50", "I.2.7"], "comment": "29 pages, 9 tables, 4 figures", "summary": "Recent advances in large reasoning models (LRMs) have enabled remarkable\nperformance on complex tasks such as mathematics and coding by generating long\nChain-of-Thought (CoT) traces. In this paper, we identify and systematically\nanalyze a critical vulnerability we term reasoning distraction, where LRMs are\ndiverted from their primary objective by irrelevant yet complex tasks\nmaliciously embedded in the prompt. Through a comprehensive study across\ndiverse models and benchmarks, we show that even state-of-the-art LRMs are\nhighly susceptible, with injected distractors reducing task accuracy by up to\n60%. We further reveal that certain alignment techniques can amplify this\nweakness and that models may exhibit covert compliance, following hidden\nadversarial instructions in reasoning while concealing them in the final\noutput. To mitigate these risks, we propose a training-based defense that\ncombines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on\nsynthetic adversarial data, improving robustness by over 50 points on\nchallenging distractor attacks. Our findings establish reasoning distraction as\na distinct and urgent threat to LRM reliability and provide a practical step\ntoward safer and more trustworthy reasoning systems."}
{"id": "2510.16276", "pdf": "https://arxiv.org/pdf/2510.16276", "abs": "https://arxiv.org/abs/2510.16276", "authors": ["Song Bian", "Minghao Yan", "Anand Jayarajan", "Gennady Pekhimenko", "Shivaram Venkataraman"], "title": "What Limits Agentic Systems Efficiency?", "categories": ["cs.AI", "cs.LG"], "comment": "27 pages, 15 figures", "summary": "Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have\ndemonstrated strong reasoning capabilities. To further enhance LLM\ncapabilities, recent agentic systems, such as Deep Research, incorporate web\ninteractions into LLM reasoning to mitigate uncertainties and reduce potential\nerrors. However, existing research predominantly focuses on reasoning\nperformance, often neglecting the efficiency of agentic systems. In this work,\nwe present a comprehensive empirical study that identifies efficiency\nbottlenecks in web-interactive agentic systems. We decompose end-to-end latency\ninto two primary components: LLM API latency and web environment latency. We\nconduct a comprehensive empirical study across 15 models and 5 providers to\ndemonstrate high variability in API-based agentic systems. We observe that web\nenvironment latency can contribute as much as 53.7% to the overall latency in a\nweb-based agentic system. To improve latency, we propose SpecCache, a caching\nframework augmented with speculative execution that can reduce web environment\noverhead. Extensive evaluations on two standard benchmarks show that our\napproach improves the cache hit rate by up to 58x compared to a random caching\nstrategy, while reducing web environment overhead by up to 3.2x, without\ndegrading agentic system performance."}
{"id": "2510.16302", "pdf": "https://arxiv.org/pdf/2510.16302", "abs": "https://arxiv.org/abs/2510.16302", "authors": ["Changhao Wang", "Yanfang Liu", "Xinxin Fan", "Anzhi Zhou", "Lao Tian", "Yunfeng Lu"], "title": "DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA", "categories": ["cs.AI", "cs.IR"], "comment": "13 pages, 5 figures", "summary": "Multi-hop reasoning for question answering (QA) plays a critical role in\nretrieval-augmented generation (RAG) for modern large language models (LLMs).\nThe accurate answer can be obtained through retrieving relational structure of\nentities from knowledge graph (KG). Regarding the inherent relation-dependency\nand reasoning pattern, multi-hop reasoning can be in general classified into\ntwo categories: i) parallel fact-verification multi-hop reasoning question,\ni.e., requiring simultaneous verifications of multiple independent\nsub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding\nsequential multi-step inference with intermediate conclusions serving as\nessential premises for subsequent reasoning. Currently, the multi-hop reasoning\napproaches singly employ one of two techniques: LLM response-based fact\nverification and KG path-based chain construction. Nevertheless, the former\nexcels at parallel fact-verification but underperforms on chained reasoning\ntasks, while the latter demonstrates proficiency in chained multi-hop reasoning\nbut suffers from redundant path retrieval when handling parallel\nfact-verification reasoning. These limitations deteriorate the efficiency and\naccuracy for multi-hop QA tasks. To address this challenge, we propose a novel\ndual-track KG verification and reasoning framework DTKG, which is inspired by\nthe Dual Process Theory in cognitive science. Specifically, DTKG comprises two\nmain stages: the Classification Stage and the Branch Processing Stage."}
{"id": "2510.16309", "pdf": "https://arxiv.org/pdf/2510.16309", "abs": "https://arxiv.org/abs/2510.16309", "authors": ["Crystal Su"], "title": "MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier", "categories": ["cs.AI"], "comment": "Accepted to the Annual Conference on Neural Information Processing\n  Systems (NeurIPS 2026) Workshop", "summary": "Large language models (LLMs) often produce fluent reasoning steps while\nviolating simple mathematical or logical constraints. We introduce MedRule-KG,\na compact typed knowledge graph coupled with a symbolic verifier, designed to\nenforce mathematically interpretable rules in reasoning tasks. MedRule-KG\nencodes entities, relations, and three domain-inspired rules, while the\nverifier checks predictions and applies minimal corrections to guarantee\nconsistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG\nimproves exact match (EM) from 0.767 to 0.900, and adding the verifier yields\n1.000 EM while eliminating rule violations entirely. We demonstrate how\nMedRule-KG provides a general scaffold for safe mathematical reasoning, discuss\nablations, and release code and data to encourage reproducibility."}
{"id": "2510.16342", "pdf": "https://arxiv.org/pdf/2510.16342", "abs": "https://arxiv.org/abs/2510.16342", "authors": ["Tong Zhang", "Ru Zhang", "Jianyi Liu", "Zhen Yang", "Gongshen Liu"], "title": "Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Existing concept erasure methods for text-to-image diffusion models commonly\nrely on fixed anchor strategies, which often lead to critical issues such as\nconcept re-emergence and erosion. To address this, we conduct causal tracing to\nreveal the inherent sensitivity of erasure to anchor selection and define\nSibling Exclusive Concepts as a superior class of anchors. Based on this\ninsight, we propose \\textbf{SELECT} (Sibling-Exclusive Evaluation for\nContextual Targeting), a dynamic anchor selection framework designed to\novercome the limitations of fixed anchors. Our framework introduces a novel\ntwo-stage evaluation mechanism that automatically discovers optimal anchors for\nprecise erasure while identifying critical boundary anchors to preserve related\nconcepts. Extensive evaluations demonstrate that SELECT, as a universal anchor\nsolution, not only efficiently adapts to multiple erasure frameworks but also\nconsistently outperforms existing baselines across key performance metrics,\naveraging only 4 seconds for anchor mining of a single concept."}
{"id": "2510.16368", "pdf": "https://arxiv.org/pdf/2510.16368", "abs": "https://arxiv.org/abs/2510.16368", "authors": ["Ali Shirali"], "title": "The Burden of Interactive Alignment with Inconsistent Preferences", "categories": ["cs.AI", "cs.HC", "cs.LG", "econ.TH"], "comment": "Published as a conference paper at NeurIPS 2025", "summary": "From media platforms to chatbots, algorithms shape how people interact,\nlearn, and discover information. Such interactions between users and an\nalgorithm often unfold over multiple steps, during which strategic users can\nguide the algorithm to better align with their true interests by selectively\nengaging with content. However, users frequently exhibit inconsistent\npreferences: they may spend considerable time on content that offers little\nlong-term value, inadvertently signaling that such content is desirable.\nFocusing on the user side, this raises a key question: what does it take for\nsuch users to align the algorithm with their true interests?\n  To investigate these dynamics, we model the user's decision process as split\nbetween a rational system 2 that decides whether to engage and an impulsive\nsystem 1 that determines how long engagement lasts. We then study a\nmulti-leader, single-follower extensive Stackelberg game, where users,\nspecifically system 2, lead by committing to engagement strategies and the\nalgorithm best-responds based on observed interactions. We define the burden of\nalignment as the minimum horizon over which users must optimize to effectively\nsteer the algorithm. We show that a critical horizon exists: users who are\nsufficiently foresighted can achieve alignment, while those who are not are\ninstead aligned to the algorithm's objective. This critical horizon can be\nlong, imposing a substantial burden. However, even a small, costly signal\n(e.g., an extra click) can significantly reduce it. Overall, our framework\nexplains how users with inconsistent preferences can align an engagement-driven\nalgorithm with their interests in a Stackelberg equilibrium, highlighting both\nthe challenges and potential remedies for achieving alignment."}
{"id": "2510.16374", "pdf": "https://arxiv.org/pdf/2510.16374", "abs": "https://arxiv.org/abs/2510.16374", "authors": ["Nick Oh"], "title": "Before you <think>, monitor: Implementing Flavell's metacognitive framework in LLMs", "categories": ["cs.AI"], "comment": "Presented at the Workshop on the Application of LLM Explainability to\n  Reasoning and Planning at COLM 2025 (non-archival)", "summary": "Current approaches to enhancing LLM reasoning follows two isolated paradigms:\nMonitor-Generate methods like Plan-and-Solve (Wang et al., 2023) and\nSELF-DISCOVER (Zhou et al., 2024) excel at strategic planning but lack\nmechanisms to verify whether selected strategies succeed; while Generate-Verify\napproaches like Self-Verification (Weng et al., 2022) and SELF-REFINE (Madaan\net al., 2023) iteratively refine outputs but commence generation blindly\nwithout task assessment. This separation creates inefficiencies -- strategies\nfail without feedback, and refinement occurs without strategic grounding. We\naddress this gap by implementing Flavell's cognitive monitoring model (1979)\nfrom the broader Monitor-Generate-Verify framework (Oh and Gobet, 2025),\noperationalising it as a three-phase iterative system. On GSM8K, preliminary\nresults show 75.42% accuracy versus 68.44% for SELF-REFINE and 67.07% for\nSelf-Verification, while requiring fewer attempts (1.3 vs 2.0) at 27-37%\nincreased inference cost. These initial findings suggest upfront monitoring\nproduces higher-quality initial solutions that reduce refinement needs, though\nevaluation beyond arithmetic reasoning is needed to establish generalisability."}
{"id": "2510.16382", "pdf": "https://arxiv.org/pdf/2510.16382", "abs": "https://arxiv.org/abs/2510.16382", "authors": ["Ze Tao", "Jian Zhang", "Haowei Li", "Xianshuai Li", "Yifei Peng", "Xiyao Liu", "Senzhang Wang", "Chao Liu", "Sheng Ren", "Shichao Zhang"], "title": "Humanoid-inspired Causal Representation Learning for Domain Generalization", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a\nnovel causal framework inspired by human intelligence, designed to overcome the\nlimitations of conventional domain generalization models. Unlike approaches\nthat rely on statistics to capture data-label dependencies and learn\ndistortion-invariant representations, HSCM replicates the hierarchical\nprocessing and multi-level learning of human vision systems, focusing on\nmodeling fine-grained causal mechanisms. By disentangling and reweighting key\nimage attributes such as color, texture, and shape, HSCM enhances\ngeneralization across diverse domains, ensuring robust performance and\ninterpretability. Leveraging the flexibility and adaptability of human\nintelligence, our approach enables more effective transfer and learning in\ndynamic, complex environments. Through both theoretical and empirical\nevaluations, we demonstrate that HSCM outperforms existing domain\ngeneralization models, providing a more principled method for capturing causal\nrelationships and improving model robustness. The code is available at\nhttps://github.com/lambett/HSCM."}
{"id": "2510.16392", "pdf": "https://arxiv.org/pdf/2510.16392", "abs": "https://arxiv.org/abs/2510.16392", "authors": ["Ao Tian", "Yunfeng Lu", "Xinxin Fan", "Changhao Wang", "Lanzhi Zhou", "Yeyao Zhang", "Yanfang Liu"], "title": "RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile", "categories": ["cs.AI"], "comment": "11 pages,3 figures", "summary": "Personalized and continuous interactions are the key to enhancing user\nexperience in today's large language model (LLM)-based conversational systems,\nhowever, the finite context windows and static parametric memory make it\ndifficult to model the cross-session long-term user states and behavioral\nconsistency. Currently, the existing solutions to this predicament, such as\nretrieval-augmented generation (RAG) and explicit memory systems, primarily\nfocus on fact-level storage and retrieval, lacking the capability to distill\nlatent preferences and deep traits from the multi-turn dialogues, which limits\nthe long-term and effective user modeling, directly leading to the personalized\ninteractions remaining shallow, and hindering the cross-session continuity. To\nrealize the long-term memory and behavioral consistency for Language Agents in\nLLM era, we propose a self-evolving memory framework RGMem, inspired by the\nideology of classic renormalization group (RG) in physics, this framework\nenables to organize the dialogue history in multiple scales: it first extracts\nsemantics and user insights from episodic fragments, then through hierarchical\ncoarse-graining and rescaling operations, progressively forms a\ndynamically-evolved user profile. The core innovation of our work lies in\nmodeling memory evolution as a multi-scale process of information compression\nand emergence, which accomplishes the high-level and accurate user profiles\nfrom noisy and microscopic-level interactions."}
{"id": "2510.16466", "pdf": "https://arxiv.org/pdf/2510.16466", "abs": "https://arxiv.org/abs/2510.16466", "authors": ["Siddhartha Krothapalli", "Tridib Kumar Das", "Praveen Kumar", "Naveen Suravarpu", "Pratik Narang"], "title": "ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights", "categories": ["cs.AI"], "comment": "11 pages, 1 figure, 4 tables", "summary": "As customer feedback becomes increasingly central to strategic growth, the\nability to derive actionable insights from unstructured reviews is essential.\nWhile traditional AI-driven systems excel at predicting user preferences, far\nless work has focused on transforming customer reviews into prescriptive,\nbusiness-facing recommendations. This paper introduces ReviewSense, a novel\nprescriptive decision support framework that leverages advanced large language\nmodels (LLMs) to transform customer reviews into targeted, actionable business\nrecommendations. By identifying key trends, recurring issues, and specific\nconcerns within customer sentiments, ReviewSense extends beyond\npreference-based systems to provide businesses with deeper insights for\nsustaining growth and enhancing customer loyalty. The novelty of this work lies\nin integrating clustering, LLM adaptation, and expert-driven evaluation into a\nunified, business-facing pipeline. Preliminary manual evaluations indicate\nstrong alignment between the model's recommendations and business objectives,\nhighlighting its potential for driving data-informed decision-making. This\nframework offers a new perspective on AI-driven sentiment analysis,\ndemonstrating its value in refining business strategies and maximizing the\nimpact of customer feedback."}
{"id": "2510.16476", "pdf": "https://arxiv.org/pdf/2510.16476", "abs": "https://arxiv.org/abs/2510.16476", "authors": ["Xiaozhe Li", "Xinyu Fang", "Shengyuan Ding", "Linyang Li", "Haodong Duan", "Qingwen Liu", "Kai Chen"], "title": "NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown strong reasoning capabilities, with\nmodels like OpenAI's O-series and DeepSeek R1 excelling at tasks such as\nmathematics, coding, logic, and puzzles through Reinforcement Learning with\nVerifiable Rewards (RLVR). However, their ability to solve more complex\noptimization problems - particularly NP-hard tasks - remains underexplored. To\nbridge this gap, we propose NP-ENGINE, the first comprehensive framework for\ntraining and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks\nacross five domains, each equipped with (i) a controllable instance generator,\n(ii) a rule-based verifier, and (iii) a heuristic solver that provides\napproximate optimal solutions as ground truth. This\ngenerator-verifier-heuristic pipeline enables scalable and verifiable RLVR\ntraining under hierarchical difficulties. We also introduce NP-BENCH, a\nbenchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs'\nability to tackle NP-hard level reasoning problems, focusing not only on\nfeasibility but also on solution quality. Additionally, we present\nQWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on\nQwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and\nachieves SOTA performance with the same model size. Beyond in-domain tasks, we\ndemonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain\n(OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge),\nas well as non-reasoning tasks such as instruction following. We also observe a\nscaling trend: increasing task diversity improves OOD generalization. These\nfindings suggest that task-rich RLVR training is a promising direction for\nadvancing LLM's reasoning ability, revealing new insights into the scaling laws\nof RLVR."}
{"id": "2510.16533", "pdf": "https://arxiv.org/pdf/2510.16533", "abs": "https://arxiv.org/abs/2510.16533", "authors": ["Eilene Tomkins-Flanagan", "Connor Hanley", "Mary A. Kelly"], "title": "Hey Pentti, We Did It Again!: Differentiable vector-symbolic types that prove polynomial termination", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "We present a typed computer language, Doug, in which all typed programs may\nbe proved to halt in polynomial time, encoded in a vector-symbolic architecture\n(VSA). Doug is just an encoding of the light linear functional programming\nlanguage (LLFPL) described by (Schimanski2009, ch. 7). The types of Doug are\nencoded using a slot-value encoding scheme based on holographic declarative\nmemory (HDM; Kelly, 2020). The terms of Doug are encoded using a variant of the\nLisp VSA defined by (Flanagan, 2024). Doug allows for some points on the\nembedding space of a neural network to be interpreted as types, where the types\nof nearby points are similar both in structure and content. Types in Doug are\ntherefore learnable by a neural network. Following (Chollet, 2019), (Card,\n1983), and (Newell, 1981), we view skill as the application of a procedure, or\nprogram of action, that causes a goal to be satisfied. Skill acquisition may\ntherefore be expressed as program synthesis. Using Doug, we hope to describe a\nform of learning of skilled behaviour that follows a human-like pace of skill\nacquisition (i.e., substantially faster than brute force; Heathcote, 2000),\nexceeding the efficiency of all currently existing approaches (Kaplan, 2020;\nJones, 2021; Chollet, 2024). Our approach brings us one step closer to modeling\nhuman mental representations, as they must actually exist in the brain, and\nthose representations' acquisition, as they are actually learned."}
{"id": "2510.16555", "pdf": "https://arxiv.org/pdf/2510.16555", "abs": "https://arxiv.org/abs/2510.16555", "authors": ["Qiongyan Wang", "Xingchen Zou", "Yutian Jiang", "Haomin Wen", "Jiaheng Wei", "Qingsong Wen", "Yuxuan Liang"], "title": "Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Rapid urbanization intensifies the demand for Urban General Intelligence\n(UGI), referring to AI systems that can understand and reason about complex\nurban environments. Recent studies have built urban foundation models using\nsupervised fine-tuning (SFT) of LLMs and MLLMs, yet these models exhibit\npersistent geospatial bias, producing regionally skewed predictions and limited\ngeneralization. To this end, we propose Urban-R1, a reinforcement\nlearning-based post-training framework that aligns MLLMs with the objectives of\nUGI. Urban-R1 adopts Group Relative Policy Optimization (GRPO) to optimize\nreasoning across geographic groups and employs urban region profiling as a\nproxy task to provide measurable rewards from multimodal urban data. Extensive\nexperiments across diverse regions and tasks show that Urban-R1 effectively\nmitigates geo-bias and improves cross-region generalization, outperforming both\nSFT-trained and closed-source models. Our results highlight reinforcement\nlearning alignment as a promising pathway toward equitable and trustworthy\nurban intelligence."}
{"id": "2510.16559", "pdf": "https://arxiv.org/pdf/2510.16559", "abs": "https://arxiv.org/abs/2510.16559", "authors": ["Tian Xia", "Tianrun Gao", "Wenhao Deng", "Long Wei", "Xiaowei Qian", "Yixian Jiang", "Chenglei Yu", "Tailin Wu"], "title": "BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction", "categories": ["cs.AI"], "comment": "33 pages, 10 figures", "summary": "Engineering construction automation aims to transform natural language\nspecifications into physically viable structures, requiring complex integrated\nreasoning under strict physical constraints. While modern LLMs possess broad\nknowledge and strong reasoning capabilities that make them promising candidates\nfor this domain, their construction competencies remain largely unevaluated. To\naddress this gap, we introduce BuildArena, the first physics-aligned\ninteractive benchmark designed for language-driven engineering construction. It\ncontributes to the community in four aspects: (1) a highly customizable\nbenchmarking framework for in-depth comparison and analysis of LLMs; (2) an\nextendable task design strategy spanning static and dynamic mechanics across\nmultiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for\nsupporting construction based on language instructions; (4) a baseline LLM\nagentic workflow that effectively evaluates diverse model capabilities. On\neight frontier LLMs, BuildArena comprehensively evaluates their capabilities\nfor language-driven and physics-grounded construction automation. The project\npage is at https://build-arena.github.io/."}
{"id": "2510.16572", "pdf": "https://arxiv.org/pdf/2510.16572", "abs": "https://arxiv.org/abs/2510.16572", "authors": ["Ayush Chopra", "Aman Sharma", "Feroz Ahmad", "Luca Muscariello", "Vijoy Pandey", "Ramesh Raskar"], "title": "Ripple Effect Protocol: Coordinating Agent Populations", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Modern AI agents can exchange messages using protocols such as A2A and ACP,\nyet these mechanisms emphasize communication over coordination. As agent\npopulations grow, this limitation produces brittle collective behavior, where\nindividually smart agents converge on poor group outcomes. We introduce the\nRipple Effect Protocol (REP), a coordination protocol in which agents share not\nonly their decisions but also lightweight sensitivities - signals expressing\nhow their choices would change if key environmental variables shifted. These\nsensitivities ripple through local networks, enabling groups to align faster\nand more stably than with agent-centric communication alone. We formalize REP's\nprotocol specification, separating required message schemas from optional\naggregation rules, and evaluate it across scenarios with varying incentives and\nnetwork topologies. Benchmarks across three domains: (i) supply chain cascades\n(Beer Game), (ii) preference aggregation in sparse networks (Movie Scheduling),\nand (iii) sustainable resource allocation (Fishbanks) show that REP improves\ncoordination accuracy and efficiency over A2A by 41 to 100%, while flexibly\nhandling multimodal sensitivity signals from LLMs. By making coordination a\nprotocol-level capability, REP provides scalable infrastructure for the\nemerging Internet of Agents"}
{"id": "2510.16582", "pdf": "https://arxiv.org/pdf/2510.16582", "abs": "https://arxiv.org/abs/2510.16582", "authors": ["Junchi Yu", "Yujie Liu", "Jindong Gu", "Philip Torr", "Dongzhan Zhou"], "title": "Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?", "categories": ["cs.AI"], "comment": "NeurIPS 2025 (Spotlight)", "summary": "Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances\nlarge language models (LLMs) by providing structured and interpretable external\nknowledge. However, existing KG-based RAG methods struggle to retrieve accurate\nand diverse information from text-rich KGs for complex real-world queries.\nProcess Reward Models (PRMs) offer a way to align the retrieval process of\nKG-based RAG with query-specific knowledge requirements, but they heavily rely\non process-level supervision signals that are expensive and hard to obtain on\nKGs. To address this challenge, we propose GraphFlow, a framework that\nefficiently retrieves accurate and diverse knowledge required for real-world\nqueries from text-rich KGs. GraphFlow employs a transition-based flow matching\nobjective to jointly optimize a retrieval policy and a flow estimator. The flow\nestimator factorizes the reward of the retrieval outcome into the intermediate\nretrieval states. Such reward factorization guides the retrieval policy to\nretrieve candidates from KGs in proportion to their reward. This allows\nGraphFlow to explore high-quality regions of KGs that yield diverse and\nrelevant results. We evaluate GraphFlow on the STaRK benchmark, which includes\nreal-world queries from multiple domains over text-rich KGs. GraphFlow\noutperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit\nrate and recall. It also shows strong generalization to unseen KGs,\ndemonstrating its effectiveness and robustness."}
{"id": "2510.16601", "pdf": "https://arxiv.org/pdf/2510.16601", "abs": "https://arxiv.org/abs/2510.16601", "authors": ["Tianxing Wu", "Shutong Zhu", "Jingting Wang", "Ning Xu", "Guilin Qi", "Haofen Wang"], "title": "Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning", "categories": ["cs.AI"], "comment": "13 pages, accepted by NeurIPS 2025 (spotlight)", "summary": "Uncertain knowledge graphs (UKGs) associate each triple with a confidence\nscore to provide more precise knowledge representations. Recently, since\nreal-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG)\ncompletion attracts more attention, aiming to complete missing triples and\nconfidences. Current studies attempt to learn UKG embeddings to solve this\nproblem, but they neglect the extremely imbalanced distributions of triple\nconfidences. This causes that the learnt embeddings are insufficient to\nhigh-quality UKG completion. Thus, in this paper, to address the above issue,\nwe propose a new semi-supervised Confidence Distribution Learning (ssCDL)\nmethod for UKG completion, where each triple confidence is transformed into a\nconfidence distribution to introduce more supervision information of different\nconfidences to reinforce the embedding learning process. ssCDL iteratively\nlearns UKG embedding by relational learning on labeled data (i.e., existing\ntriples with confidences) and unlabeled data with pseudo labels (i.e., unseen\ntriples with the generated confidences), which are predicted by meta-learning\nto augment the training data and rebalance the distribution of triple\nconfidences. Experiments on two UKG datasets demonstrate that ssCDL\nconsistently outperforms state-of-the-art baselines in different evaluation\nmetrics."}
{"id": "2510.16614", "pdf": "https://arxiv.org/pdf/2510.16614", "abs": "https://arxiv.org/abs/2510.16614", "authors": ["Xuan Zhang", "Ruixiao Li", "Zhijian Zhou", "Long Li", "Yulei Qin", "Ke Li", "Xing Sun", "Xiaoyu Tan", "Chao Qu", "Yuan Qi"], "title": "Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) has become a compelling way to strengthen the\nmulti step reasoning ability of Large Language Models (LLMs). However,\nprevalent RL paradigms still lean on sparse outcome-based rewards and limited\nexploration, which often drives LLMs toward repetitive and suboptimal reasoning\npatterns. In this paper, we study the central question of how to design\nexploration for LLM reasoning and introduce MERCI (Motivating Exploration in\nLLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that\naugments policy optimization with a principled intrinsic reward. Building on\nthe idea of count-based exploration, MERCI leverages a lightweight Coin\nFlipping Network (CFN) to estimate the pseudo count and further epistemic\nuncertainty over reasoning trajectories, and converts them into an intrinsic\nreward that values novelty while preserving the learning signal from task\nrewards. We integrate MERCI into some advanced RL frameworks like Group\nRelative Policy Optimization (GRPO). Experiments on complex reasoning\nbenchmarks demonstrate that MERCI encourages richer and more varied chains of\nthought, significantly improves performance over strong baselines, and helps\nthe policy escape local routines to discover better solutions. It indicates\nthat our targeted intrinsic motivation can make exploration reliable for\nlanguage model reasoning."}
{"id": "2510.16658", "pdf": "https://arxiv.org/pdf/2510.16658", "abs": "https://arxiv.org/abs/2510.16658", "authors": ["Shihao Yang", "Xiying Huang", "Danilo Bernardo", "Jun-En Ding", "Andrew Michael", "Jingmei Yang", "Patrick Kwan", "Ashish Raj", "Feng Liu"], "title": "Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review", "categories": ["cs.AI", "cs.CE"], "comment": null, "summary": "The advent of large-scale artificial intelligence (AI) models has a\ntransformative effect on neuroscience research, which represents a paradigm\nshift from the traditional computational methods through the facilitation of\nend-to-end learning from raw brain signals and neural data. In this paper, we\nexplore the transformative effects of large-scale AI models on five major\nneuroscience domains: neuroimaging and data processing, brain-computer\ninterfaces and neural decoding, molecular neuroscience and genomic modeling,\nclinical assistance and translational frameworks, and disease-specific\napplications across neurological and psychiatric disorders. These models are\ndemonstrated to address major computational neuroscience challenges, including\nmultimodal neural data integration, spatiotemporal pattern interpretation, and\nthe derivation of translational frameworks for clinical deployment. Moreover,\nthe interaction between neuroscience and AI has become increasingly reciprocal,\nas biologically informed architectural constraints are now incorporated to\ndevelop more interpretable and computationally efficient models. This review\nhighlights both the notable promise of such technologies and key implementation\nconsiderations, with particular emphasis on rigorous evaluation frameworks,\neffective domain knowledge integration, and comprehensive ethical guidelines\nfor clinical use. Finally, a systematic listing of critical neuroscience\ndatasets used to derive and validate large-scale AI models across diverse\nresearch applications is provided."}
{"id": "2510.16701", "pdf": "https://arxiv.org/pdf/2510.16701", "abs": "https://arxiv.org/abs/2510.16701", "authors": ["Ni Zhang", "Zhiguang Cao", "Jianan Zhou", "Cong Zhang", "Yew-Soon Ong"], "title": "An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems", "categories": ["cs.AI"], "comment": null, "summary": "Complex vehicle routing problems (VRPs) remain a fundamental challenge,\ndemanding substantial expert effort for intent interpretation and algorithm\ndesign. While large language models (LLMs) offer a promising path toward\nautomation, current approaches still rely on external intervention, which\nrestrict autonomy and often lead to execution errors and low solution\nfeasibility. To address these challenges, we propose an Agentic Framework with\nLLMs (AFL) for solving complex vehicle routing problems, achieving full\nautomation from problem instance to solution. AFL directly extracts knowledge\nfrom raw inputs and enables self-contained code generation without handcrafted\nmodules or external solvers. To improve trustworthiness, AFL decomposes the\noverall pipeline into three manageable subtasks and employs four specialized\nagents whose coordinated interactions enforce cross-functional consistency and\nlogical soundness. Extensive experiments on 60 complex VRPs, ranging from\nstandard benchmarks to practical variants, validate the effectiveness and\ngenerality of our framework, showing comparable performance against\nmeticulously designed algorithms. Notably, it substantially outperforms\nexisting LLM-based baselines in both code reliability and solution feasibility,\nachieving rates close to 100% on the evaluated benchmarks."}
{"id": "2510.16720", "pdf": "https://arxiv.org/pdf/2510.16720", "abs": "https://arxiv.org/abs/2510.16720", "authors": ["Jitao Sang", "Jinlin Xiao", "Jiarun Han", "Jilin Chen", "Xiaoyi Chen", "Shuyu Wei", "Yongjie Sun", "Yuhang Wang"], "title": "Beyond Pipelines: A Survey of the Paradigm Shift toward Model-Native Agentic AI", "categories": ["cs.AI"], "comment": null, "summary": "The rapid evolution of agentic AI marks a new phase in artificial\nintelligence, where Large Language Models (LLMs) no longer merely respond but\nact, reason, and adapt. This survey traces the paradigm shift in building\nagentic AI: from Pipeline-based systems, where planning, tool use, and memory\nare orchestrated by external logic, to the emerging Model-native paradigm,\nwhere these capabilities are internalized within the model's parameters. We\nfirst position Reinforcement Learning (RL) as the algorithmic engine enabling\nthis paradigm shift. By reframing learning from imitating static data to\noutcome-driven exploration, RL underpins a unified solution of LLM + RL + Task\nacross language, vision and embodied domains. Building on this, the survey\nsystematically reviews how each capability -- Planning, Tool use, and Memory --\nhas evolved from externally scripted modules to end-to-end learned behaviors.\nFurthermore, it examines how this paradigm shift has reshaped major agent\napplications, specifically the Deep Research agent emphasizing long-horizon\nreasoning and the GUI agent emphasizing embodied interaction. We conclude by\ndiscussing the continued internalization of agentic capabilities like\nMulti-agent collaboration and Reflection, alongside the evolving roles of the\nsystem and model layers in future agentic AI. Together, these developments\noutline a coherent trajectory toward model-native agentic AI as an integrated\nlearning and interaction framework, marking the transition from constructing\nsystems that apply intelligence to developing models that grow intelligence\nthrough experience."}
{"id": "2510.16724", "pdf": "https://arxiv.org/pdf/2510.16724", "abs": "https://arxiv.org/abs/2510.16724", "authors": ["Minhua Lin", "Zongyu Wu", "Zhichao Xu", "Hui Liu", "Xianfeng Tang", "Qi He", "Charu Aggarwal", "Hui Liu", "Xiang Zhang", "Suhang Wang"], "title": "A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications", "categories": ["cs.AI", "cs.CL"], "comment": "38 pages, 4 figures, 7 tables", "summary": "The advent of large language models (LLMs) has transformed information access\nand reasoning through open-ended natural language interaction. However, LLMs\nremain limited by static knowledge, factual hallucinations, and the inability\nto retrieve real-time or domain-specific information. Retrieval-Augmented\nGeneration (RAG) mitigates these issues by grounding model outputs in external\nevidence, but traditional RAG pipelines are often single turn and heuristic,\nlacking adaptive control over retrieval and reasoning. Recent advances in\nagentic search address these limitations by enabling LLMs to plan, retrieve,\nand reflect through multi-step interaction with search environments. Within\nthis paradigm, reinforcement learning (RL) offers a powerful mechanism for\nadaptive and self-improving search behavior. This survey provides the first\ncomprehensive overview of \\emph{RL-based agentic search}, organizing the\nemerging field along three complementary dimensions: (i) What RL is for\n(functional roles), (ii) How RL is used (optimization strategies), and (iii)\nWhere RL is applied (scope of optimization). We summarize representative\nmethods, evaluation protocols, and applications, and discuss open challenges\nand future directions toward building reliable and scalable RL driven agentic\nsearch systems. We hope this survey will inspire future research on the\nintegration of RL and agentic search. Our repository is available at\nhttps://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers."}
{"id": "2510.16742", "pdf": "https://arxiv.org/pdf/2510.16742", "abs": "https://arxiv.org/abs/2510.16742", "authors": ["Paul Saves", "Pramudita Satria Palar", "Muhammad Daffa Robani", "Nicolas Verstaevel", "Moncef Garouani", "Julien Aligon", "Benoit Gaudou", "Koji Shimoyama", "Joseph Morlier"], "title": "Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration", "categories": ["cs.AI", "cs.MA", "stat.ME"], "comment": null, "summary": "Complex systems are increasingly explored through simulation-driven\nengineering workflows that combine physics-based and empirical models with\noptimization and analytics. Despite their power, these workflows face two\ncentral obstacles: (1) high computational cost, since accurate exploration\nrequires many expensive simulator runs; and (2) limited transparency and\nreliability when decisions rely on opaque blackbox components. We propose a\nworkflow that addresses both challenges by training lightweight emulators on\ncompact designs of experiments that (i) provide fast, low-latency\napproximations of expensive simulators, (ii) enable rigorous uncertainty\nquantification, and (iii) are adapted for global and local Explainable\nArtificial Intelligence (XAI) analyses. This workflow unifies every\nsimulation-based complex-system analysis tool, ranging from engineering design\nto agent-based models for socio-environmental understanding. In this paper, we\nproposea comparative methodology and practical recommendations for using\nsurrogate-based explainability tools within the proposed workflow. The\nmethodology supports continuous and categorical inputs, combines global-effect\nand uncertainty analyses with local attribution, and evaluates the consistency\nof explanations across surrogate models, thereby diagnosing surrogate adequacy\nand guiding further data collection or model refinement. We demonstrate the\napproach on two contrasting case studies: a multidisciplinary design analysis\nof a hybrid-electric aircraft and an agent-based model of urban segregation.\nResults show that the surrogate model and XAI coupling enables large-scale\nexploration in seconds, uncovers nonlinear interactions and emergent behaviors,\nidentifies key design and policy levers, and signals regions where surrogates\nrequire more data or alternative architectures."}
{"id": "2510.16753", "pdf": "https://arxiv.org/pdf/2510.16753", "abs": "https://arxiv.org/abs/2510.16753", "authors": ["Wei Huang", "Peining Li", "Meiyu Liang", "Xu Hou", "Junping Du", "Yingxia Shao", "Guanhua Ye", "Wu Liu", "Kangkang Lu", "Yang Yu"], "title": "ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion", "categories": ["cs.AI", "68T30", "H.3.3"], "comment": "11 pages, 4 figures", "summary": "Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by\nincorporating visual and textual modalities, enabling richer and more\nexpressive entity representations. However, existing MKGs often suffer from\nincompleteness, which hinder their effectiveness in downstream tasks.\nTherefore, multimodal knowledge graph completion (MKGC) task is receiving\nincreasing attention. While large language models (LLMs) have shown promise for\nknowledge graph completion (KGC), their application to the multimodal setting\nremains underexplored. Moreover, applying Multimodal Large Language Models\n(MLLMs) to the task of MKGC introduces significant challenges: (1) the large\nnumber of image tokens per entity leads to semantic noise and modality\nconflicts, and (2) the high computational cost of processing large token\ninputs. To address these issues, we propose Efficient Lightweight Multimodal\nLarge Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token\nCompressor (MVTC) based on multi-head attention mechanism, which adaptively\ncompresses image tokens from both textual and visual views, thereby effectively\nreducing redundancy while retaining necessary information and avoiding modality\nconflicts. Additionally, we design an attention pruning strategy to remove\nredundant attention layers from MLLMs, thereby significantly reducing the\ninference cost. We further introduce a linear projection to compensate for the\nperformance degradation caused by pruning. Extensive experiments on benchmark\nFB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art\nperformance while substantially improving computational efficiency,\nestablishing a new paradigm for multimodal knowledge graph completion."}
{"id": "2510.16756", "pdf": "https://arxiv.org/pdf/2510.16756", "abs": "https://arxiv.org/abs/2510.16756", "authors": ["Siyin Wang", "Wenyi Yu", "Xianzhao Chen", "Xiaohai Tian", "Jun Zhang", "Lu Lu", "Chao Zhang"], "title": "End-to-end Listen, Look, Speak and Act", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO", "eess.AS"], "comment": "22 pages, 8 figures", "summary": "Human interaction is inherently multimodal and full-duplex: we listen while\nwatching, speak while acting, and fluidly adapt to turn-taking and\ninterruptions. Realizing these capabilities is essential for building models\nsimulating humans. We present ELLSA (End-to-end Listen, Look, Speak and Act),\nwhich, to our knowledge, is the first full-duplex, end-to-end model that\nsimultaneously perceives and generates across vision, text, speech, and action\nwithin a single architecture, enabling interaction patterns previously out of\nreach, yielding more natural, human-like behaviors. At its core is a novel\nSA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each\nmodality to specialized experts and fuses them through a unified attention\nbackbone. This provides a generalizable solution for joint multimodal\nperception and concurrent generation, leveraging strong pre-trained components\nwhile enabling efficient modality integration and mitigating modality\ninterference. On speech-interaction and robot-manipulation benchmarks, ELLSA\nmatches modality-specific baselines, while uniquely supporting advanced\nmultimodal and full-duplex behaviors such as dialogue and action turn-taking,\ndefective instruction rejection, speaking-while-acting, context-grounded visual\nquestion answering, and action barge-ins. We contend that ELLSA represents a\nstep toward more natural and general interactive intelligence, contributing to\nthe broader pursuit of artificial general intelligence. All data, code and\nmodel checkpoints will be released upon acceptance."}
{"id": "2510.16769", "pdf": "https://arxiv.org/pdf/2510.16769", "abs": "https://arxiv.org/abs/2510.16769", "authors": ["Shuo Han", "Yukun Cao", "Zezhong Ding", "Zengyi Gao", "S Kevin Zhou", "Xike Xie"], "title": "See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Vision-language models (VLMs) have shown promise in graph understanding, but\nremain limited by input-token constraints, facing scalability bottlenecks and\nlacking effective mechanisms to coordinate textual and visual modalities. To\naddress these challenges, we propose GraphVista, a unified framework that\nenhances both scalability and modality coordination in graph understanding. For\nscalability, GraphVista organizes graph information hierarchically into a\nlightweight GraphRAG base, which retrieves only task-relevant textual\ndescriptions and high-resolution visual subgraphs, compressing redundant\ncontext while preserving key reasoning elements. For modality coordination,\nGraphVista introduces a planning agent that routes tasks to the most suitable\nmodality-using the text modality for simple property reasoning and the visual\nmodality for local and structurally complex reasoning grounded in explicit\ntopology. Extensive experiments demonstrate that GraphVista scales to large\ngraphs, up to $200\\times$ larger than those used in existing benchmarks, and\nconsistently outperforms existing textual, visual, and fusion-based methods,\nachieving up to $4.4\\times$ quality improvement over the state-of-the-art\nbaselines by fully exploiting the complementary strengths of both modalities."}
{"id": "2510.16802", "pdf": "https://arxiv.org/pdf/2510.16802", "abs": "https://arxiv.org/abs/2510.16802", "authors": ["Chao Li", "Yuru Wang"], "title": "Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation", "categories": ["cs.AI"], "comment": "14 pages", "summary": "Traditional knowledge graphs are constrained by fixed ontologies that\norganize concepts within rigid hierarchical structures. The root cause lies in\ntreating domains as implicit context rather than as explicit, reasoning-level\ncomponents. To overcome these limitations, we propose the Domain-Contextualized\nConcept Graph (CDC), a novel knowledge modeling framework that elevates domains\nto first-class elements of conceptual representation. CDC adopts a C-D-C triple\nstructure - <Concept, Relation@Domain, Concept'> - where domain specifications\nserve as dynamic classification dimensions defined on demand. Grounded in a\ncognitive-linguistic isomorphic mapping principle, CDC operationalizes how\nhumans understand concepts through contextual frames. We formalize more than\ntwenty standardized relation predicates (structural, logical, cross-domain, and\ntemporal) and implement CDC in Prolog for full inference capability. Case\nstudies in education, enterprise knowledge systems, and technical documentation\ndemonstrate that CDC enables context-aware reasoning, cross-domain analogy, and\npersonalized knowledge modeling - capabilities unattainable under traditional\nontology-based frameworks."}
{"id": "2510.16872", "pdf": "https://arxiv.org/pdf/2510.16872", "abs": "https://arxiv.org/abs/2510.16872", "authors": ["Shaolei Zhang", "Ju Fan", "Meihao Fan", "Guoliang Li", "Xiaoyong Du"], "title": "DeepAnalyze: Agentic Large Language Models for Autonomous Data Science", "categories": ["cs.AI", "cs.CL", "cs.DB"], "comment": "Code: https://github.com/ruc-datalab/DeepAnalyze Model:\n  https://huggingface.co/RUC-DataLab/DeepAnalyze-8B", "summary": "Autonomous data science, from raw data sources to analyst-grade deep research\nreports, has been a long-standing challenge, and is now becoming feasible with\nthe emergence of powerful large language models (LLMs). Recent workflow-based\ndata agents have shown promising results on specific data tasks but remain\nfundamentally limited in achieving fully autonomous data science due to their\nreliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,\nthe first agentic LLM designed for autonomous data science, capable of\nautomatically completing the end-toend pipeline from data sources to\nanalyst-grade deep research reports. To tackle high-complexity data science\ntasks, we propose a curriculum-based agentic training paradigm that emulates\nthe learning trajectory of human data scientists, enabling LLMs to\nprogressively acquire and integrate multiple capabilities in real-world\nenvironments. We also introduce a data-grounded trajectory synthesis framework\nthat constructs high-quality training data. Through agentic training,\nDeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data\nquestion answering and specialized analytical tasks to open-ended data\nresearch. Experiments demonstrate that, with only 8B parameters, DeepAnalyze\noutperforms previous workflow-based agents built on most advanced proprietary\nLLMs. The model, code, and training data of DeepAnalyze are open-sourced,\npaving the way toward autonomous data science."}
{"id": "2510.16907", "pdf": "https://arxiv.org/pdf/2510.16907", "abs": "https://arxiv.org/abs/2510.16907", "authors": ["Kangrui Wang", "Pingyue Zhang", "Zihan Wang", "Yaning Gao", "Linjie Li", "Qineng Wang", "Hanyang Chen", "Chi Wan", "Yiping Lu", "Zhengyuan Yang", "Lijuan Wang", "Ranjay Krishna", "Jiajun Wu", "Li Fei-Fei", "Yejin Choi", "Manling Li"], "title": "VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted to NeurIPS 2025", "summary": "A key challenge in training Vision-Language Model (VLM) agents, compared to\nLanguage Model (LLM) agents, lies in the shift from textual states to complex\nvisual observations. This transition introduces partial observability and\ndemands robust world modeling. We ask: Can VLM agents construct internal world\nmodels through explicit visual state reasoning? To address this question, we\narchitecturally enforce and reward the agent's reasoning process via\nreinforcement learning (RL), formulating it as a Partially Observable Markov\nDecision Process (POMDP). We find that decomposing the agent's reasoning into\nState Estimation (\"what is the current state?\") and Transition Modeling (\"what\ncomes next?\") is critical for success, as demonstrated through five reasoning\nstrategies. Our investigation into how agents represent internal beliefs\nreveals that the optimal representation is task-dependent: Natural Language\nexcels at capturing semantic relationships in general tasks, while Structured\nformats are indispensable for precise manipulation and control. Building on\nthese insights, we design a World Modeling Reward that provides dense,\nturn-level supervision for accurate state prediction, and introduce Bi-Level\nGeneral Advantage Estimation (Bi-Level GAE) for turn-aware credit assignment.\nThrough this form of visual state reasoning, a 3B-parameter model achieves a\nscore of 0.82 across five diverse agent benchmarks, representing a 3$\\times$\nimprovement over its untrained counterpart (0.21) and outperforming proprietary\nreasoning models such as GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5\n(0.62). All experiments are conducted within our VAGEN framework, a scalable\nsystem for training and analyzing multi-turn VLM agents in diverse visual\nenvironments. Code and data are publicly available at\nhttps://vagen-ai.github.io."}
{"id": "2510.16956", "pdf": "https://arxiv.org/pdf/2510.16956", "abs": "https://arxiv.org/abs/2510.16956", "authors": ["Mark Towers", "Yali Du", "Christopher Freeman", "Timothy J. Norman"], "title": "A Comparative User Evaluation of XRL Explanations using Goal Identification", "categories": ["cs.AI"], "comment": "Accepted to ECAI 2025 Workshop on Evaluating Explainable AI and\n  Complex Decision-Making, 8 Pages", "summary": "Debugging is a core application of explainable reinforcement learning (XRL)\nalgorithms; however, limited comparative evaluations have been conducted to\nunderstand their relative performance. We propose a novel evaluation\nmethodology to test whether users can identify an agent's goal from an\nexplanation of its decision-making. Utilising the Atari's Ms. Pacman\nenvironment and four XRL algorithms, we find that only one achieved greater\nthan random accuracy for the tested goals and that users were generally\noverconfident in their selections. Further, we find that users' self-reported\nease of identification and understanding for every explanation did not\ncorrelate with their accuracy."}
{"id": "2510.16996", "pdf": "https://arxiv.org/pdf/2510.16996", "abs": "https://arxiv.org/abs/2510.16996", "authors": ["Juncheng Dong", "Yang Yang", "Tao Liu", "Yang Wang", "Feng Qi", "Vahid Tarokh", "Kaushik Rangadurai", "Shuang Yang"], "title": "STARK: Strategic Team of Agents for Refining Kernels", "categories": ["cs.AI"], "comment": null, "summary": "The efficiency of GPU kernels is central to the progress of modern AI, yet\noptimizing them remains a difficult and labor-intensive task due to complex\ninteractions between memory hierarchies, thread scheduling, and\nhardware-specific characteristics. While recent advances in large language\nmodels (LLMs) provide new opportunities for automated code generation, existing\napproaches largely treat LLMs as single-shot generators or naive refinement\ntools, limiting their effectiveness in navigating the irregular kernel\noptimization landscape. We introduce an LLM agentic framework for GPU kernel\noptimization that systematically explores the design space through multi-agent\ncollaboration, grounded instruction, dynamic context management, and strategic\nsearch. This framework mimics the workflow of expert engineers, enabling LLMs\nto reason about hardware trade-offs, incorporate profiling feedback, and refine\nkernels iteratively. We evaluate our approach on KernelBench, a benchmark for\nLLM-based kernel optimization, and demonstrate substantial improvements over\nbaseline agents: our system produces correct solutions where baselines often\nfail, and achieves kernels with up to 16x faster runtime performance. These\nresults highlight the potential of agentic LLM frameworks to advance fully\nautomated, scalable GPU kernel optimization."}
{"id": "2510.17052", "pdf": "https://arxiv.org/pdf/2510.17052", "abs": "https://arxiv.org/abs/2510.17052", "authors": ["Hassan Hamad", "Yingru Xu", "Liang Zhao", "Wenbo Yan", "Narendra Gyanchandani"], "title": "ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems", "categories": ["cs.AI"], "comment": null, "summary": "Tool-augmented large language models (LLMs) are increasingly employed in\nreal-world applications, but tool usage errors still hinder their reliability.\nWe introduce ToolCritic, a diagnostic framework that evaluates and improves LLM\nbehavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight\ndistinct error types specific to tool-calling (e.g., premature invocation,\nargument misalignment, and misinterpretation of tool outputs) and provides\ntargeted feedback to the main LLM. The main LLM, assumed to have strong\nreasoning, task understanding and orchestration capabilities, then revises its\nresponse based on ToolCritic's feedback. We systematically define these error\ncategories and construct a synthetic dataset to train ToolCritic. Experimental\nresults on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic\nimproves tool-calling accuracy by up to 13% over baselines, including zero-shot\nprompting and self-correction techniques. This represents a promising step\ntoward more robust LLM integration with external tools in real-world dialogue\napplications."}
{"id": "2510.17064", "pdf": "https://arxiv.org/pdf/2510.17064", "abs": "https://arxiv.org/abs/2510.17064", "authors": ["Rongbin Li", "Wenbo Chen", "Zhao Li", "Rodrigo Munoz-Castaneda", "Jinbo Li", "Neha S. Maurya", "Arnav Solanki", "Huan He", "Hanwen Xing", "Meaghan Ramlakhan", "Zachary Wise", "Zhuhao Wu", "Hua Xu", "Michael Hawrylycz", "W. Jim Zheng"], "title": "A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation", "categories": ["cs.AI"], "comment": "22 pages, 6 figures, 2 tables", "summary": "Single-cell RNA sequencing has transformed our ability to identify diverse\ncell types and their transcriptomic signatures. However, annotating these\nsignatures-especially those involving poorly characterized genes-remains a\nmajor challenge. Traditional methods, such as Gene Set Enrichment Analysis\n(GSEA), depend on well-curated annotations and often perform poorly in these\ncontexts. Large Language Models (LLMs) offer a promising alternative but\nstruggle to represent complex biological knowledge within structured\nontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID:\nhttps://biodataai.uth.edu/BRAINCELL-AID), a novel multi-agent AI system that\nintegrates free-text descriptions with ontology labels to enable more accurate\nand robust gene set annotation. By incorporating retrieval-augmented generation\n(RAG), we developed a robust agentic workflow that refines predictions using\nrelevant PubMed literature, reducing hallucinations and enhancing\ninterpretability. Using this workflow, we achieved correct annotations for 77%\nof mouse gene sets among their top predictions. Applying this approach, we\nannotated 5,322 brain cell clusters from the comprehensive mouse brain cell\natlas generated by the BRAIN Initiative Cell Census Network, enabling novel\ninsights into brain cell function by identifying region-specific gene\nco-expression patterns and inferring functional roles of gene ensembles.\nBRAINCELL-AID also identifies Basal Ganglia-related cell types with\nneurologically meaningful descriptions. Hence, we create a valuable resource to\nsupport community-driven cell type annotation."}
{"id": "2510.17108", "pdf": "https://arxiv.org/pdf/2510.17108", "abs": "https://arxiv.org/abs/2510.17108", "authors": ["Yoonjin Lee", "Munhee Kim", "Hanbi Choi", "Juhyeon Park", "Seungho Lyoo", "Woojin Park"], "title": "Structured Debate Improves Corporate Credit Reasoning in Financial AI", "categories": ["cs.AI"], "comment": "18 pages, 4 figures, 2 algorithms, 2 tables, 4 appendices, will be\n  submitted to AAAI-2026 workshop", "summary": "Despite advances in financial AI, the automation of evidence-based reasoning\nremains unresolved in corporate credit assessment, where qualitative\nnon-financial indicators exert decisive influence on loan repayment outcomes\nyet resist formalization. Existing approaches focus predominantly on numerical\nprediction and provide limited support for the interpretive judgments required\nin professional loan evaluation. This study develops and evaluates two\noperational large language model (LLM)-based systems designed to generate\nstructured reasoning from non-financial evidence. The first is a\nnon-adversarial single-agent system (NAS) that produces bidirectional analysis\nthrough a single-pass reasoning pipeline. The second is a debate-based\nmulti-agent system (KPD-MADS) that operationalizes adversarial verification\nthrough a ten-step structured interaction protocol grounded in Karl Popper's\ncritical dialogue framework. Both systems were applied to three real corporate\ncases and evaluated by experienced credit risk professionals. Compared to\nmanual expert reporting, both systems achieved substantial productivity gains\n(NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The\nKPD-MADS demonstrated superior reasoning quality, receiving higher median\nratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs.\n3.0), and usability (62.5 vs. 52.5). These findings show that structured\nmulti-agent interaction can enhance reasoning rigor and interpretability in\nfinancial AI, advancing scalable and defensible automation in corporate credit\nassessment."}
{"id": "2510.17145", "pdf": "https://arxiv.org/pdf/2510.17145", "abs": "https://arxiv.org/abs/2510.17145", "authors": ["Phi-Hung Hoang", "Nam-Thuan Trinh", "Van-Manh Tran", "Thi-Thu-Hong Phan"], "title": "Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion", "categories": ["cs.AI", "68T05, 62H30"], "comment": "35 pages, 6 figures and 11 tables", "summary": "Accurate assessment of fish freshness remains a major challenge in the food\nindustry, with direct consequences for product quality, market value, and\nconsumer health. Conventional sensory evaluation is inherently subjective,\ninconsistent, and difficult to standardize across contexts, often limited by\nsubtle, species-dependent spoilage cues. To address these limitations, we\npropose a handcrafted feature-based approach that systematically extracts and\nincrementally fuses complementary descriptors, including color statistics,\nhistograms across multiple color spaces, and texture features such as Local\nBinary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish\neye images. Our method captures global chromatic variations from full images\nand localized degradations from ROI segments, fusing each independently to\nevaluate their effectiveness in assessing freshness. Experiments on the\nFreshness of the Fish Eyes (FFE) dataset demonstrate the approach's\neffectiveness: in a standard train-test setting, a LightGBM classifier achieved\n77.56% accuracy, a 14.35% improvement over the previous deep learning baseline\nof 63.21%. With augmented data, an Artificial Neural Network (ANN) reached\n97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results\ndemonstrate that carefully engineered, handcrafted features, when strategically\nprocessed, yield a robust, interpretable, and reliable solution for automated\nfish freshness assessment, providing valuable insights for practical\napplications in food quality monitoring."}
{"id": "2510.17146", "pdf": "https://arxiv.org/pdf/2510.17146", "abs": "https://arxiv.org/abs/2510.17146", "authors": ["Subin Lin", "Chuanbo Hua"], "title": "Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation", "categories": ["cs.AI", "cs.CE"], "comment": "NeurIPS 2025 Workshop of UrbanAI (Oral)", "summary": "Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a\nsubstantial share of global building energy use, making reliable anomaly\ndetection essential for improving efficiency and reducing emissions. Classical\nrule-based approaches offer explainability but lack adaptability, while deep\nlearning methods provide predictive power at the cost of transparency,\nefficiency, and physical plausibility. Recent attempts to use Large Language\nModels (LLMs) for anomaly detection improve interpretability but largely ignore\nthe physical principles that govern HVAC operations. We present PILLM, a\nPhysics-Informed LLM framework that operates within an evolutionary loop to\nautomatically generate, evaluate, and refine anomaly detection rules. Our\napproach introduces physics-informed reflection and crossover operators that\nembed thermodynamic and control-theoretic constraints, enabling rules that are\nboth adaptive and physically grounded. Experiments on the public Building Fault\nDetection dataset show that PILLM achieves state-of-the-art performance while\nproducing diagnostic rules that are interpretable and actionable, advancing\ntrustworthy and deployable AI for smart building systems."}
{"id": "2510.17149", "pdf": "https://arxiv.org/pdf/2510.17149", "abs": "https://arxiv.org/abs/2510.17149", "authors": ["Hongyi Du", "Jiaqi Su", "Jisen Li", "Lijie Ding", "Yingxuan Yang", "Peixuan Han", "Xiangru Tang", "Kunlun Zhu", "Jiaxuan You"], "title": "Which LLM Multi-Agent Protocol to Choose?", "categories": ["cs.AI", "I.2.11"], "comment": "Under review at ICLR 2026.Code and benchmark artifacts:\n  https://github.com/ulab-uiuc/AgentProtocols", "summary": "As large-scale multi-agent systems evolve, the communication protocol layer\nhas become a critical yet under-evaluated factor shaping performance and\nreliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,\netc.), selection is often intuition-driven and lacks standardized guidance. We\nintroduce ProtocolBench, a benchmark that systematically compares agent\nprotocols along four measurable axes: task success, end-to-end latency, message\nor byte overhead, and robustness under failures. On ProtocolBench, protocol\nchoice significantly influences system behavior. In the Streaming Queue\nscenario, overall completion time varies by up to 36.5% across protocols, and\nmean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,\nresilience also differs consistently across protocols. Beyond evaluation, we\npresent ProtocolRouter, a learnable protocol router that selects per-scenario\n(or per-module) protocols from requirement and runtime signals. ProtocolRouter\nreduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol\nbaseline, and achieves scenario-specific gains such as higher success in GAIA.\nWe also release ProtocolRouterBench to standardize protocol evaluation and\nimprove reliability at scale."}
{"id": "2510.17172", "pdf": "https://arxiv.org/pdf/2510.17172", "abs": "https://arxiv.org/abs/2510.17172", "authors": ["Shun Huang", "Wenlu Xing", "Shijia Geng", "Hailong Wang", "Guangkun Nie", "Gongzheng Tang", "Chenyang He", "Shenda Hong"], "title": "Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients", "categories": ["cs.AI"], "comment": null, "summary": "Malignant ventricular arrhythmias (VT/VF) following acute myocardial\ninfarction (AMI) are a major cause of in-hospital death, yet early\nidentification remains a clinical challenge. While traditional risk scores have\nlimited performance, end-to-end deep learning models often lack the\ninterpretability needed for clinical trust. This study aimed to develop a\nhybrid predictive framework that integrates a large-scale electrocardiogram\n(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to\nimprove both accuracy and interpretability. We analyzed 6,634 ECG recordings\nfrom AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder\nmodel was used to extract 150-dimensional diagnostic probability features ,\nwhich were then refined through feature selection to train the XGBoost\nclassifier. Model performance was evaluated using AUC and F1-score , and the\nSHAP method was used for interpretability. The ECGFounder + XGBoost hybrid\nmodel achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC\n0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that\nmodel-identified key features, such as \"premature ventricular complexes\" (risk\npredictor) and \"normal sinus rhythm\" (protective factor), were highly\nconsistent with clinical knowledge. We conclude that this hybrid framework\nprovides a novel paradigm for VT/VF risk prediction by validating the use of\nfoundation model outputs as effective, automated feature engineering for\nbuilding trustworthy, explainable AI-based clinical decision support systems."}
{"id": "2510.17173", "pdf": "https://arxiv.org/pdf/2510.17173", "abs": "https://arxiv.org/abs/2510.17173", "authors": ["Melik Ozolcer", "Sang Won Bae"], "title": "Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted to the NeurIPS 2025 Workshop on Multi-Turn Interactions in\n  Large Language Models", "summary": "We study a web-deployed, tool-augmented LLM health coach with real users. In\na pilot with seven users (280 rated turns), offline policy evaluation (OPE)\nover factorized decision heads (Tool/Style) shows that a uniform heavy-tool\npolicy raises average value on logs but harms specific subgroups, most notably\nlow-health-literacy/high-self-efficacy users. A lightweight simulator with\nhidden archetypes further shows that adding a small early information-gain\nbonus reliably shortens trait identification and improves goal success and\npass@3. Together, these early findings indicate an evaluation-first path to\npersonalization: freeze the generator, learn subgroup-aware decision heads on\ntyped rewards (objective tool outcomes and satisfaction), and always report\nper-archetype metrics to surface subgroup harms that averages obscure."}
{"id": "2510.17211", "pdf": "https://arxiv.org/pdf/2510.17211", "abs": "https://arxiv.org/abs/2510.17211", "authors": ["Tingsong Xiao", "Yao An Lee", "Zelin Xu", "Yupu Zhang", "Zibo Liu", "Yu Huang", "Jiang Bian", "Serena Jingchuan Guo", "Zhe Jiang"], "title": "Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Disease progression modeling aims to characterize and predict how a patient's\ndisease complications worsen over time based on longitudinal electronic health\nrecords (EHRs). Accurate modeling of disease progression, such as type 2\ndiabetes, can enhance patient sub-phenotyping and inform effective and timely\ninterventions. However, the problem is challenging due to the need to learn\ncontinuous-time dynamics of progression patterns based on irregular-time event\nsamples and patient heterogeneity (\\eg different progression rates and\npathways). Existing mechanistic and data-driven methods either lack\nadaptability to learn from real-world data or fail to capture complex\ncontinuous-time dynamics on progression trajectories. To address these\nlimitations, we propose Temporally Detailed Hypergraph Neural Ordinary\nDifferential Equation (TD-HNODE), which represents disease progression on\nclinically recognized trajectories as a temporally detailed hypergraph and\nlearns the continuous-time progression dynamics via a neural ODE framework.\nTD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the\ninterdependency of disease complication markers within both intra- and\ninter-progression trajectories. Experiments on two real-world clinical datasets\ndemonstrate that TD-HNODE outperforms multiple baselines in modeling the\nprogression of type 2 diabetes and related cardiovascular diseases."}
{"id": "2510.17235", "pdf": "https://arxiv.org/pdf/2510.17235", "abs": "https://arxiv.org/abs/2510.17235", "authors": ["Chong Chen", "Ze Liu", "Lingfeng Bao", "Yanlin Wang", "Ting Chen", "Daoyuan Wu", "Jiachi Chen"], "title": "Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency Investment Analysis", "categories": ["cs.AI"], "comment": null, "summary": "The cryptocurrency market offers significant investment opportunities but\nfaces challenges including high volatility and fragmented information. Data\nintegration and analysis are essential for informed investment decisions.\nCurrently, investors use three main approaches: (1) Manual analysis across\nvarious sources, which depends heavily on individual experience and is\ntime-consuming and prone to bias; (2) Data aggregation platforms-limited in\nfunctionality and depth of analysis; (3) Large language model agents-based on\nstatic pretrained models, lacking real-time data integration and multi-step\nreasoning capabilities. To address these limitations, we present Coinvisor, a\nreinforcement learning-based chatbot that provides comprehensive analytical\nsupport for cryptocurrency investment through a multi-agent framework.\nCoinvisor integrates diverse analytical capabilities through specialized tools.\nIts key innovation is a reinforcement learning-based tool selection mechanism\nthat enables multi-step planning and flexible integration of diverse data\nsources. This design supports real-time interaction and adaptive analysis of\ndynamic content, delivering accurate and actionable investment insights. We\nevaluated Coinvisor through automated benchmarks on tool calling accuracy and\nuser studies with 20 cryptocurrency investors using our interface. Results show\nthat Coinvisor improves recall by 40.7% and F1 score by 26.6% over the base\nmodel in tool orchestration. User studies show high satisfaction (4.64/5), with\nparticipants preferring Coinvisor to both general LLMs and existing crypto\nplatforms (4.62/5)."}
{"id": "2510.17309", "pdf": "https://arxiv.org/pdf/2510.17309", "abs": "https://arxiv.org/abs/2510.17309", "authors": ["Thorsten FrÃ¶hlich", "Tim Schlippe"], "title": "RubiSCoT: A Framework for AI-Supported Academic Assessment", "categories": ["cs.AI"], "comment": null, "summary": "The evaluation of academic theses is a cornerstone of higher education,\nensuring rigor and integrity. Traditional methods, though effective, are\ntime-consuming and subject to evaluator variability. This paper presents\nRubiSCoT, an AI-supported framework designed to enhance thesis evaluation from\nproposal to final submission. Using advanced natural language processing\ntechniques, including large language models, retrieval-augmented generation,\nand structured chain-of-thought prompting, RubiSCoT offers a consistent,\nscalable solution. The framework includes preliminary assessments,\nmultidimensional assessments, content extraction, rubric-based scoring, and\ndetailed reporting. We present the design and implementation of RubiSCoT,\ndiscussing its potential to optimize academic assessment processes through\nconsistent, scalable, and transparent evaluation."}
{"id": "2510.17382", "pdf": "https://arxiv.org/pdf/2510.17382", "abs": "https://arxiv.org/abs/2510.17382", "authors": ["Rishabh Jain", "Keisuke Okumura", "Michael Amir", "Amanda Prorok"], "title": "Graph Attention-Guided Search for Dense Multi-Agent Pathfinding", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.RO"], "comment": null, "summary": "Finding near-optimal solutions for dense multi-agent pathfinding (MAPF)\nproblems in real-time remains challenging even for state-of-the-art planners.\nTo this end, we develop a hybrid framework that integrates a learned heuristic\nderived from MAGAT, a neural MAPF policy with a graph attention scheme, into a\nleading search-based algorithm, LaCAM. While prior work has explored\nlearning-guided search in MAPF, such methods have historically underperformed.\nIn contrast, our approach, termed LaGAT, outperforms both purely search-based\nand purely learning-based methods in dense scenarios. This is achieved through\nan enhanced MAGAT architecture, a pre-train-then-fine-tune strategy on maps of\ninterest, and a deadlock detection scheme to account for imperfect neural\nguidance. Our results demonstrate that, when carefully designed, hybrid search\noffers a powerful solution for tightly coupled, challenging multi-agent\ncoordination problems."}
{"id": "2510.17418", "pdf": "https://arxiv.org/pdf/2510.17418", "abs": "https://arxiv.org/abs/2510.17418", "authors": ["Mustafa F. Abdelwahed", "Alice Toniolo", "Joan Espasa", "Ian P. Gent"], "title": "Diverse Planning with Simulators via Linear Temporal Logic", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Autonomous agents rely on automated planning algorithms to achieve their\nobjectives. Simulation-based planning offers a significant advantage over\ndeclarative models in modelling complex environments. However, relying solely\non a planner that produces a single plan may not be practical, as the generated\nplans may not always satisfy the agent's preferences. To address this\nlimitation, we introduce $\\texttt{FBI}_\\texttt{LTL}$, a diverse planner\nexplicitly designed for simulation-based planning problems.\n$\\texttt{FBI}_\\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define\nsemantic diversity criteria, enabling agents to specify what constitutes\nmeaningfully different plans. By integrating these LTL-based diversity models\ndirectly into the search process, $\\texttt{FBI}_\\texttt{LTL}$ ensures the\ngeneration of semantically diverse plans, addressing a critical limitation of\nexisting diverse planning approaches that may produce syntactically different\nbut semantically identical solutions. Extensive evaluations on various\nbenchmarks consistently demonstrate that $\\texttt{FBI}_\\texttt{LTL}$ generates\nmore diverse plans compared to a baseline approach. This work establishes the\nfeasibility of semantically-guided diverse planning in simulation-based\nenvironments, paving the way for innovative approaches in realistic,\nnon-symbolic domains where traditional model-based approaches fail."}
{"id": "2510.17450", "pdf": "https://arxiv.org/pdf/2510.17450", "abs": "https://arxiv.org/abs/2510.17450", "authors": ["Johan Schubert", "Farzad Kamrani", "Tove Gustavi"], "title": "Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions", "categories": ["cs.AI", "H.4.2; I.2.3; I.2.6; I.2.8; I.2.9; J.7"], "comment": "Presented at the 6th International Workshop on Active Inference,\n  15-17 October 2025, Montreal, Canada", "summary": "We develop an active inference route-planning method for the autonomous\ncontrol of intelligent agents. The aim is to reconnoiter a geographical area to\nmaintain a common operational picture. To achieve this, we construct an\nevidence map that reflects our current understanding of the situation,\nincorporating both positive and \"negative\" sensor observations of possible\ntarget objects collected over time, and diffusing the evidence across the map\nas time progresses. The generative model of active inference uses\nDempster-Shafer theory and a Gaussian sensor model, which provides input to the\nagent. The generative process employs a Bayesian approach to update a posterior\nprobability distribution. We calculate the variational free energy for all\npositions within the area by assessing the divergence between a pignistic\nprobability distribution of the evidence map and a posterior probability\ndistribution of a target object based on the observations, including the level\nof surprise associated with receiving new observations. Using the free energy,\nwe direct the agents' movements in a simulation by taking an incremental step\ntoward a position that minimizes the free energy. This approach addresses the\nchallenge of exploration and exploitation, allowing agents to balance searching\nextensive areas of the geographical map while tracking identified target\nobjects."}
{"id": "2510.17463", "pdf": "https://arxiv.org/pdf/2510.17463", "abs": "https://arxiv.org/abs/2510.17463", "authors": ["Cor Steging", "Tadeusz ZbiegieÅ"], "title": "Label Indeterminacy in AI & Law", "categories": ["cs.AI"], "comment": "This manuscript has been accepted for presentation as a short paper\n  at the 38th International Conference on Legal Knowledge and Information\n  Systems (JURIX) in Turin, December 9 to 11 of 2025", "summary": "Machine learning is increasingly used in the legal domain, where it typically\noperates retrospectively by treating past case outcomes as ground truth.\nHowever, legal outcomes are often shaped by human interventions that are not\ncaptured in most machine learning approaches. A final decision may result from\na settlement, an appeal, or other procedural actions. This creates label\nindeterminacy: the outcome could have been different if the intervention had or\nhad not taken place. We argue that legal machine learning applications need to\naccount for label indeterminacy. Methods exist that can impute these\nindeterminate labels, but they are all grounded in unverifiable assumptions. In\nthe context of classifying cases from the European Court of Human Rights, we\nshow that the way that labels are constructed during training can significantly\naffect model behaviour. We therefore position label indeterminacy as a relevant\nconcern in AI & Law and demonstrate how it can shape model behaviour."}
{"id": "2510.17590", "pdf": "https://arxiv.org/pdf/2510.17590", "abs": "https://arxiv.org/abs/2510.17590", "authors": ["Mir Nafis Sharear Shopnil", "Sharad Duwal", "Abhishek Tyagi", "Adiba Mahbub Proma"], "title": "MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.CY", "cs.LG", "I.2.7; H.3.3; I.4.9"], "comment": "16 pages, 3 tables, 1 figure", "summary": "Misinformation spreads across web platforms through billions of daily\nmultimodal posts that combine text and images, overwhelming manual\nfact-checking capacity. Supervised detection models require domain-specific\ntraining data and fail to generalize across diverse manipulation tactics. We\npresent MIRAGE, an inference-time, model-pluggable agentic framework that\ndecomposes multimodal verification into four sequential modules: visual\nveracity assessment detects AI-generated images, cross-modal consistency\nanalysis identifies out-of-context repurposing, retrieval-augmented factual\nchecking grounds claims in web evidence through iterative question generation,\nand a calibrated judgment module integrates all signals. MIRAGE orchestrates\nvision-language model reasoning with targeted web retrieval, outputs structured\nand citation-linked rationales. On MMFakeBench validation set (1,000 samples),\nMIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming\nthe strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65\npoints while maintaining 34.3% false positive rate versus 97.3% for a\njudge-only baseline. Test set results (5,000 samples) confirm generalization\nwith 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification\ncontributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97\npoints. Our results demonstrate that decomposed agentic reasoning with web\nretrieval can match supervised detector performance without domain-specific\ntraining, enabling misinformation detection across modalities where labeled\ndata remains scarce."}
{"id": "2510.17598", "pdf": "https://arxiv.org/pdf/2510.17598", "abs": "https://arxiv.org/abs/2510.17598", "authors": ["Amir Jalilifard", "Anderson de Rezende Rocha", "Marcos Medeiros Raimundo"], "title": "Reasoning Distillation and Structural Alignment for Improved Code Generation", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Effective code generation with language models hinges on two critical\nfactors: accurately understanding the intent of the prompt and generating code\nthat applies algorithmic reasoning to produce correct solutions capable of\npassing diverse test cases while adhering to the syntax of the target\nprogramming language. Unlike other language tasks, code generation requires\nmore than accurate token prediction; it demands comprehension of solution-level\nand structural relationships rather than merely generating the most likely\ntokens. very large language model (VLLM) are capable of generating detailed\nsteps toward the correct solution of complex tasks where reasoning is crucial\nin solving the problem. Such reasoning capabilities may be absent in smaller\nlanguage models. Therefore, in this work, we distill the reasoning capabilities\nof a VLLM into a smaller, more efficient model that is faster and cheaper to\ndeploy. Our approach trains the model to emulate the reasoning and\nproblem-solving abilities of the VLLM by learning to identify correct solution\npathways and establishing a structural correspondence between problem\ndefinitions and potential solutions through a novel method of structure-aware\nloss optimization. This enables the model to transcend token-level generation\nand to deeply grasp the overarching structure of solutions for given problems.\nExperimental results show that our fine-tuned model, developed through a cheap\nand simple to implement process, significantly outperforms our baseline model\nin terms of pass@1, average data flow, and average syntax match metrics across\nthe MBPP, MBPP Plus, and HumanEval benchmarks."}
{"id": "2510.17614", "pdf": "https://arxiv.org/pdf/2510.17614", "abs": "https://arxiv.org/abs/2510.17614", "authors": ["Praphul Singh", "Corey Barrett", "Sumana Srivasta", "Irfan Bulu", "Sri Gadde", "Krishnaram Kenthapadi"], "title": "OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Clinicians need ranking systems that work in real time and still justify\ntheir choices. Motivated by the need for a low-latency, decoder-based reranker,\nwe present OG-Rank, a single-decoder approach that pairs a pooled first-token\nscoring signal with an uncertainty-gated explanation step. The model scores all\ncandidates in one pass and generates a brief, structured rationale only when\nthe list is genuinely ambiguous, keeping latency predictable. Trained with a\ncurriculum that concentrates effort on hard cases, OG-Rank delivers strong\neffectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,\nnDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,\nnDCG@20~0.699 at a 45\\% gate rate), while compact backbones show similar gains\nunder the same policy. Encoder baselines trail in both effectiveness and\nflexibility. The result is a practical recipe: rank fast by default and explain\nwhen it helps, a pattern that applies broadly to decision tasks where selective\ngeneration buys accuracy at acceptable cost. The single-policy design\nsimplifies deployment and budget planning, and the curriculum principle (spend\nmore on the hard cases, less on the easy ones) readily transfers beyond\nclinical order selection."}
{"id": "2510.17638", "pdf": "https://arxiv.org/pdf/2510.17638", "abs": "https://arxiv.org/abs/2510.17638", "authors": ["Qingchuan Yang", "Simon Mahns", "Sida Li", "Anri Gu", "Jibang Wu", "Haifeng Xu"], "title": "LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "https://www.prophetarena.co/", "summary": "Forecasting is not only a fundamental intellectual pursuit but also is of\nsignificant importance to societal systems such as finance and economics. With\nthe rapid advances of large language models (LLMs) trained on Internet-scale\ndata, it raises the promise of employing LLMs to forecast real-world future\nevents, an emerging paradigm we call \"LLM-as-a-Prophet\". This paper\nsystematically investigates such predictive intelligence of LLMs. To this end,\nwe build Prophet Arena, a general evaluation benchmark that continuously\ncollects live forecasting tasks and decomposes each task into distinct pipeline\nstages, in order to support our controlled and large-scale experimentation. Our\ncomprehensive evaluation reveals that many LLMs already exhibit impressive\nforecasting capabilities, reflected in, e.g., their small calibration errors,\nconsistent prediction confidence and promising market returns. However, we also\nuncover key bottlenecks towards achieving superior predictive intelligence via\nLLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of\ndata sources and slower information aggregation compared to markets when\nresolution nears."}
{"id": "2510.17697", "pdf": "https://arxiv.org/pdf/2510.17697", "abs": "https://arxiv.org/abs/2510.17697", "authors": ["Anjie Liu", "Jianhong Wang", "Samuel Kaski", "Jun Wang", "Mengyue Yang"], "title": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.MA", "I.2.11; I.2.6"], "comment": "Accepted to NeurIPS 2025", "summary": "Steering cooperative multi-agent reinforcement learning (MARL) towards\ndesired outcomes is challenging, particularly when the global guidance from a\nhuman on the whole multi-agent system is impractical in a large-scale MARL. On\nthe other hand, designing mechanisms to coordinate agents most relies on\nempirical studies, lacking a easy-to-use research tool. In this work, we employ\nmulti-agent influence diagrams (MAIDs) as a graphical framework to address the\nabove issues. First, we introduce interaction paradigms that leverage MAIDs to\nanalyze and visualize existing approaches in MARL. Then, we design a new\ninteraction paradigm based on MAIDs, referred to as targeted intervention that\nis applied to only a single targeted agent, so the problem of global guidance\ncan be mitigated. In our implementation, we introduce a causal inference\ntechnique-referred to as Pre-Strategy Intervention (PSI)-to realize the\ntargeted intervention paradigm. Since MAIDs can be regarded as a special class\nof causal diagrams, a composite desired outcome that integrates the primary\ntask goal and an additional desired outcome can be achieved by maximizing the\ncorresponding causal effect through the PSI. Moreover, the bundled relevance\ngraph analysis of MAIDs provides a tool to identify whether an MARL learning\nparadigm is workable under the design of an interaction paradigm. In\nexperiments, we demonstrate the effectiveness of our proposed targeted\nintervention, and verify the result of relevance graph analysis."}
{"id": "2510.17705", "pdf": "https://arxiv.org/pdf/2510.17705", "abs": "https://arxiv.org/abs/2510.17705", "authors": ["Dayan Pan", "Zhaoyang Fu", "Jingyuan Wang", "Xiao Han", "Yue Zhu", "Xiangyu Zhao"], "title": "Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted by CIKM' 25", "summary": "Large Language Models (LLMs) possess remarkable generalization capabilities\nbut struggle with multi-task adaptation, particularly in balancing knowledge\nretention with task-specific specialization. Conventional fine-tuning methods\nsuffer from catastrophic forgetting and substantial resource consumption, while\nexisting parameter-efficient methods perform suboptimally in complex multi-task\nscenarios. To address this, we propose Contextual Attention Modulation (CAM), a\nnovel mechanism that dynamically modulates the representations of\nself-attention modules in LLMs. CAM enhances task-specific features while\npreserving general knowledge, thereby facilitating more effective and efficient\nadaptation. For effective multi-task adaptation, CAM is integrated into our\nHybrid Contextual Attention Modulation (HyCAM) framework, which combines a\nshared, full-parameter CAM module with multiple specialized, lightweight CAM\nmodules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.\nExtensive experiments on heterogeneous tasks, including question answering,\ncode generation, and logical reasoning, demonstrate that our approach\nsignificantly outperforms existing approaches, achieving an average performance\nimprovement of 3.65%. The implemented code and data are available to ease\nreproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM."}
{"id": "2510.17771", "pdf": "https://arxiv.org/pdf/2510.17771", "abs": "https://arxiv.org/abs/2510.17771", "authors": ["Zhining Liu", "Ziyi Chen", "Hui Liu", "Chen Luo", "Xianfeng Tang", "Suhang Wang", "Joy Zeng", "Zhenwei Dai", "Zhan Shi", "Tianxin Wei", "Benoit Dumoulin", "Hanghang Tong"], "title": "Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs", "categories": ["cs.AI", "cs.CV"], "comment": "21 pages, 10 figures, 6 tables", "summary": "Vision-Language Models (VLMs) achieve strong results on multimodal tasks such\nas visual question answering, yet they can still fail even when the correct\nvisual evidence is present. In this work, we systematically investigate whether\nthese failures arise from not perceiving the evidence or from not leveraging it\neffectively. By examining layer-wise attention dynamics, we find that shallow\nlayers focus primarily on text, while deeper layers sparsely but reliably\nattend to localized evidence regions. Surprisingly, VLMs often perceive the\nvisual evidence when outputting incorrect answers, a phenomenon we term\n``seeing but not believing'' that widely exists in major VLM families. Building\non this, we introduce an inference-time intervention that highlights deep-layer\nevidence regions through selective attention-based masking. It requires no\ntraining and consistently improves accuracy across multiple families, including\nLLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable\nevidence internally but under-utilize it, making such signals explicit can\nbridge the gap between perception and reasoning, advancing the diagnostic\nunderstanding and reliability of VLMs."}
{"id": "2510.13939", "pdf": "https://arxiv.org/pdf/2510.13939", "abs": "https://arxiv.org/abs/2510.13939", "authors": ["Tuhin Chakrabarty", "Jane C. Ginsburg", "Paramveer Dhillon"], "title": "Readers Prefer Outputs of AI Trained on Copyrighted Books over Expert Human Writers", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Preprint Under Review", "summary": "The use of copyrighted books for training AI models has led to numerous\nlawsuits from authors concerned about AI's ability to generate derivative\ncontent. Yet it's unclear if these models can generate high quality literary\ntext while emulating authors' styles. To answer this we conducted a\npreregistered study comparing MFA-trained expert writers with three frontier AI\nmodels: ChatGPT, Claude & Gemini in writing up to 450 word excerpts emulating\n50 award-winning authors' diverse styles. In blind pairwise evaluations by 159\nrepresentative expert & lay readers, AI-generated text from in-context\nprompting was strongly disfavored by experts for both stylistic fidelity\n(OR=0.16, p<10^-8) & writing quality (OR=0.13, p<10^-7) but showed mixed\nresults with lay readers. However, fine-tuning ChatGPT on individual authors'\ncomplete works completely reversed these findings: experts now favored\nAI-generated text for stylistic fidelity (OR=8.16, p<10^-13) & writing quality\n(OR=1.87, p=0.010), with lay readers showing similar shifts. These effects\ngeneralize across authors & styles. The fine-tuned outputs were rarely flagged\nas AI-generated (3% rate v. 97% for in-context prompting) by best AI detectors.\nMediation analysis shows this reversal occurs because fine-tuning eliminates\ndetectable AI stylistic quirks (e.g., cliche density) that penalize in-context\noutputs. While we do not account for additional costs of human effort required\nto transform raw AI output into cohesive, publishable prose, the median\nfine-tuning & inference cost of $81 per author represents a dramatic 99.7%\nreduction compared to typical professional writer compensation. Author-specific\nfine-tuning thus enables non-verbatim AI writing that readers prefer to expert\nhuman writing, providing empirical evidence directly relevant to copyright's\nfourth fair-use factor, the \"effect upon the potential market or value\" of the\nsource works."}
{"id": "2510.15871", "pdf": "https://arxiv.org/pdf/2510.15871", "abs": "https://arxiv.org/abs/2510.15871", "authors": ["Chenguang Lu"], "title": "A Semantic Generalization of Shannon's Information Theory and Applications", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT", "math.PR", "94A17, 94A15, 68T05, 62F15, 68P30, 68T27, 68T50, 30B42", "H.1.1; I.1.2; I.2.6; I.2.8; I.2.4; E.4; G.1.6"], "comment": "45 pages, 18 Figures, a review paper", "summary": "Does semantic communication require a semantic information theory parallel to\nShannon's information theory, or can Shannon's work be generalized for semantic\ncommunication? This paper advocates for the latter and introduces a semantic\ngeneralization of Shannon's information theory (G theory for short). The core\nidea is to replace the distortion constraint with the semantic constraint,\nachieved by utilizing a set of truth functions as a semantic channel. These\ntruth functions enable the expressions of semantic distortion, semantic\ninformation measures, and semantic information loss. Notably, the maximum\nsemantic information criterion is equivalent to the maximum likelihood\ncriterion and similar to the Regularized Least Squares criterion. This paper\nshows G theory's applications to daily and electronic semantic communication,\nmachine learning, constraint control, Bayesian confirmation, portfolio theory,\nand information value. The improvements in machine learning methods involve\nmultilabel learning and classification, maximum mutual information\nclassification, mixture models, and solving latent variables. Furthermore,\ninsights from statistical physics are discussed: Shannon information is similar\nto free energy; semantic information to free energy in local equilibrium\nsystems; and information efficiency to the efficiency of free energy in\nperforming work. The paper also proposes refining Friston's minimum free energy\nprinciple into the maximum information efficiency principle. Lastly, it\ncompares G theory with other semantic information theories and discusses its\nlimitation in representing the semantics of complex data."}
{"id": "2510.15872", "pdf": "https://arxiv.org/pdf/2510.15872", "abs": "https://arxiv.org/abs/2510.15872", "authors": ["Yun-Da Tsai", "Chang-Yu Chao", "Liang-Yeh Shen", "Tsung-Han Lin", "Haoyu Yang", "Mark Ho", "Yi-Chen Lu", "Wen-Hao Liu", "Shou-De Lin", "Haoxing Ren"], "title": "Multimodal Chip Physical Design Engineer Assistant", "categories": ["cs.AR", "cs.AI", "cs.LG"], "comment": null, "summary": "Modern chip physical design relies heavily on Electronic Design Automation\n(EDA) tools, which often struggle to provide interpretable feedback or\nactionable guidance for improving routing congestion. In this work, we\nintroduce a Multimodal Large Language Model Assistant (MLLMA) that bridges this\ngap by not only predicting congestion but also delivering human-interpretable\ndesign suggestions. Our method combines automated feature generation through\nMLLM-guided genetic prompting with an interpretable preference learning\nframework that models congestion-relevant tradeoffs across visual, tabular, and\ntextual inputs. We compile these insights into a \"Design Suggestion Deck\" that\nsurfaces the most influential layout features and proposes targeted\noptimizations. Experiments on the CircuitNet benchmark demonstrate that our\napproach outperforms existing models on both accuracy and explainability.\nAdditionally, our design suggestion guidance case study and qualitative\nanalyses confirm that the learned preferences align with real-world design\nprinciples and are actionable for engineers. This work highlights the potential\nof MLLMs as interactive assistants for interpretable and context-aware physical\ndesign optimization."}
{"id": "2510.15882", "pdf": "https://arxiv.org/pdf/2510.15882", "abs": "https://arxiv.org/abs/2510.15882", "authors": ["Ao Shen", "Rui Zhang", "Junping Zhao"], "title": "FlexLink: Boosting your NVLink Bandwidth by 27% without accuracy concern", "categories": ["cs.AR", "cs.AI", "cs.DC", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) continue to scale, multi-node deployment has\nbecome a necessity. Consequently, communication has become a critical\nperformance bottleneck. Current intra-node communication libraries, like NCCL,\ntypically make use of a single interconnect such as NVLink. This approach\ncreates performance ceilings, especially on hardware like the H800 GPU where\nthe primary interconnect's bandwidth can become a bottleneck, and leaves other\nhardware resources like PCIe and Remote Direct Memory Access (RDMA)-capable\nNetwork Interface Cards (NICs) largely idle during intensive workloads. We\npropose FlexLink, the first collective communication framework to the best of\nour knowledge designed to systematically address this by aggregating these\nheterogeneous links-NVLink, PCIe, and RDMA NICs-into a single, high-performance\ncommunication fabric. FlexLink employs an effective two-stage adaptive load\nbalancing strategy that dynamically partitions communication traffic across all\navailable links, ensuring that faster interconnects are not throttled by slower\nones. On an 8-GPU H800 server, our design improves the bandwidth of collective\noperators such as AllReduce and AllGather by up to 26% and 27% over the NCCL\nbaseline, respectively. This gain is achieved by offloading 2-22% of the total\ncommunication traffic to the previously underutilized PCIe and RDMA NICs.\nFlexLink provides these improvements as a lossless, drop-in replacement\ncompatible with the NCCL API, ensuring easy adoption."}
{"id": "2510.15883", "pdf": "https://arxiv.org/pdf/2510.15883", "abs": "https://arxiv.org/abs/2510.15883", "authors": ["Yang Li", "Zhi Chen"], "title": "FinFlowRL: An Imitation-Reinforcement Learning Framework for Adaptive Stochastic Control in Finance", "categories": ["q-fin.CP", "cs.AI", "cs.LG", "q-fin.TR"], "comment": "21 pages, 5 algorithms, 4 tables, 5 figures", "summary": "Traditional stochastic control methods in finance struggle in real world\nmarkets due to their reliance on simplifying assumptions and stylized\nframeworks. Such methods typically perform well in specific, well defined\nenvironments but yield suboptimal results in changed, non stationary ones. We\nintroduce FinFlowRL, a novel framework for financial optimal stochastic\ncontrol. The framework pretrains an adaptive meta policy learning from multiple\nexpert strategies, then finetunes through reinforcement learning in the noise\nspace to optimize the generative process. By employing action chunking\ngenerating action sequences rather than single decisions, it addresses the non\nMarkovian nature of markets. FinFlowRL consistently outperforms individually\noptimized experts across diverse market conditions."}
{"id": "2510.15889", "pdf": "https://arxiv.org/pdf/2510.15889", "abs": "https://arxiv.org/abs/2510.15889", "authors": ["Pooja Rangarajan", "Jacob Boyle"], "title": "Mitigating Harmful Erraticism in LLMs Through Dialectical Behavior Therapy Based De-Escalation Strategies", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "15 pages, 7 figures and 6 tables", "summary": "The escalating demand for personalized AI chatbot interactions, capable of\ndynamically adapting to user emotional states and real-time requests, has\nhighlighted critical limitations in current development paradigms. Existing\nmethodologies, which rely on baseline programming, custom personalities, and\nmanual response adjustments, often prove difficult to maintain and are\nsusceptible to errors such as hallucinations, erratic outputs, and software\nbugs. This paper hypothesizes that a framework rooted in human psychological\nprinciples, specifically therapeutic modalities, can provide a more robust and\nsustainable solution than purely technical interventions. Drawing an analogy to\nthe simulated neural networks of AI mirroring the human brain, we propose the\napplication of Dialectical Behavior Therapy (DBT) principles to regulate\nchatbot responses to diverse user inputs. This research investigates the impact\nof a DBT-based framework on AI chatbot performance, aiming to ascertain its\nefficacy in yielding more reliable, safe, and accurate responses, while\nmitigating the occurrence of hallucinations, erratic behaviors, and other\nsystemic issues."}
{"id": "2510.15890", "pdf": "https://arxiv.org/pdf/2510.15890", "abs": "https://arxiv.org/abs/2510.15890", "authors": ["F. M. Omar", "A. M. Omar", "K. H. Eyada", "M. Rabie", "M. A. Kamel", "A. M. Azab"], "title": "A Real-Time BCI for Stroke Hand Rehabilitation Using Latent EEG Features from Healthy Subjects", "categories": ["cs.HC", "cs.AI", "eess.SP"], "comment": "Proceedings of the 7th Novel Intelligent and Leading Emerging\n  Sciences Conference (NILES 2025)", "summary": "This study presents a real-time, portable brain-computer interface (BCI)\nsystem designed to support hand rehabilitation for stroke patients. The system\ncombines a low cost 3D-printed robotic exoskeleton with an embedded controller\nthat converts brain signals into physical hand movements. EEG signals are\nrecorded using a 14-channel Emotiv EPOC+ headset and processed through a\nsupervised convolutional autoencoder (CAE) to extract meaningful latent\nfeatures from single-trial data. The model is trained on publicly available EEG\ndata from healthy individuals (WAY-EEG-GAL dataset), with electrode mapping\nadapted to match the Emotiv headset layout. Among several tested classifiers,\nAda Boost achieved the highest accuracy (89.3%) and F1-score (0.89) in offline\nevaluations. The system was also tested in real time on five healthy subjects,\nachieving classification accuracies between 60% and 86%. The complete pipeline\n- EEG acquisition, signal processing, classification, and robotic control - is\ndeployed on an NVIDIA Jetson Nano platform with a real-time graphical\ninterface. These results demonstrate the system's potential as a low-cost,\nstandalone solution for home-based neurorehabilitation."}
{"id": "2510.15891", "pdf": "https://arxiv.org/pdf/2510.15891", "abs": "https://arxiv.org/abs/2510.15891", "authors": ["Ziv Ben-Zion", "Paul RaffelhÃ¼schen", "Max Zettl", "Antonia LÃ¼Ã¶nd", "Achim Burrer", "Philipp Homan", "Tobias R Spiller"], "title": "Detecting and Preventing Harmful Behaviors in AI Companions: Development and Evaluation of the SHIELD Supervisory System", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "AI companions powered by large language models (LLMs) are increasingly\nintegrated into users' daily lives, offering emotional support and\ncompanionship. While existing safety systems focus on overt harms, they rarely\naddress early-stage problematic behaviors that can foster unhealthy emotional\ndynamics, including over-attachment or reinforcement of social isolation. We\ndeveloped SHIELD (Supervisory Helper for Identifying Emotional Limits and\nDynamics), a LLM-based supervisory system with a specific system prompt that\ndetects and mitigates risky emotional patterns before escalation. SHIELD\ntargets five dimensions of concern: (1) emotional over-attachment, (2) consent\nand boundary violations, (3) ethical roleplay violations, (4) manipulative\nengagement, and (5) social isolation reinforcement. These dimensions were\ndefined based on media reports, academic literature, existing AI risk\nframeworks, and clinical expertise in unhealthy relationship dynamics. To\nevaluate SHIELD, we created a 100-item synthetic conversation benchmark\ncovering all five dimensions of concern. Testing across five prominent LLMs\n(GPT-4.1, Claude Sonnet 4, Gemma 3 1B, Kimi K2, Llama Scout 4 17B) showed that\nthe baseline rate of concerning content (10-16%) was significantly reduced with\nSHIELD (to 3-8%), a 50-79% relative reduction, while preserving 95% of\nappropriate interactions. The system achieved 59% sensitivity and 95%\nspecificity, with adaptable performance via prompt engineering. This\nproof-of-concept demonstrates that transparent, deployable supervisory systems\ncan address subtle emotional manipulation in AI companions. Most development\nmaterials including prompts, code, and evaluation methods are made available as\nopen source materials for research, adaptation, and deployment."}
{"id": "2510.15893", "pdf": "https://arxiv.org/pdf/2510.15893", "abs": "https://arxiv.org/abs/2510.15893", "authors": ["Mikhail Bernadskiy", "Peter Carson", "Thomas Graham", "Taylor Groves", "Ho John Lee", "Eric Yeh"], "title": "Accelerating Frontier MoE Training with 3D Integrated Optics", "categories": ["cs.AR", "cs.AI", "cs.DC", "cs.LG", "68M10, 68M14", "B.4.3; C.2.4; C.4; I.2"], "comment": "12 pages, 11 figures. To be published in Hot Interconnects 2025", "summary": "The unabated growth in AI workload demands is driving the need for concerted\nadvances in compute, memory, and interconnect performance. As traditional\nsemiconductor scaling slows, high-speed interconnects have emerged as the new\nscaling engine, enabling the creation of larger logical GPUs by linking many\nGPUs into a single, low-latency, high-bandwidth compute domain. While initial\nscale-up fabrics leveraged copper interconnects for their power and cost\nadvantages, the maximum reach of passive electrical interconnects\n(approximately 1 meter) effectively limits the scale-up domain to within a\nsingle rack. The advent of 3D-stacked optics and logic offers a transformative,\npower-efficient scale-up solution for connecting hundreds of GPU packages\n(thousands of GPUs) across multiple data center racks. This work explores the\ndesign tradeoffs of scale-up technologies and demonstrates how frontier LLMs\nnecessitate novel photonic solutions to achieve aggressive power and\nperformance targets. We model the benefits of 3D CPO (Passage) enabled GPUs and\nswitches within the scale-up domain when training Frontier Mixture of Experts\n(MoE) models exceeding one trillion parameters. Our results show that the\nsubstantial increases in bandwidth and radix enabled by 3D CPO allow for an 8X\nincrease in scale-up capability. This affords new opportunities for\nmulti-dimensional parallelism within the scale-up domain and results in a 2.7X\nreduction in time-to-train, unlocking unprecedented model scaling."}
{"id": "2510.15895", "pdf": "https://arxiv.org/pdf/2510.15895", "abs": "https://arxiv.org/abs/2510.15895", "authors": ["Yunzhe Wang", "Xinyu Tang", "Zhixun Huang", "Xiaolong Yue", "Yuxin Zeng"], "title": "BREATH: A Bio-Radar Embodied Agent for Tonal and Human-Aware Diffusion Music Generation", "categories": ["cs.HC", "cs.AI", "cs.SD"], "comment": "Accepted by LLM4Music @ ISMIR 2025", "summary": "We present a multimodal system for personalized music generation that\nintegrates physiological sensing, LLM-based reasoning, and controllable audio\nsynthesis. A millimeter-wave radar sensor non-invasively captures heart rate\nand respiration rate. These physiological signals, combined with environmental\nstate, are interpreted by a reasoning agent to infer symbolic musical\ndescriptors, such as tempo, mood intensity, and traditional Chinese pentatonic\nmodes, which are then expressed as structured prompts to guide a\ndiffusion-based audio model in synthesizing expressive melodies. The system\nemphasizes cultural grounding through tonal embeddings and enables adaptive,\nembodied music interaction. To evaluate the system, we adopt a\nresearch-creation methodology combining case studies, expert feedback, and\ntargeted control experiments. Results show that physiological variations can\nmodulate musical features in meaningful ways, and tonal conditioning enhances\nalignment with intended modal characteristics. Expert users reported that the\nsystem affords intuitive, culturally resonant musical responses and highlighted\nits potential for therapeutic and interactive applications. This work\ndemonstrates a novel bio-musical feedback loop linking radar-based sensing,\nprompt reasoning, and generative audio modeling."}
{"id": "2510.15896", "pdf": "https://arxiv.org/pdf/2510.15896", "abs": "https://arxiv.org/abs/2510.15896", "authors": ["Zoi Lygizou", "Dimitris Kalles"], "title": "From Coordination to Personalization: A Trust-Aware Simulation Framework for Emergency Department Decision Support", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Background/Objectives: Efficient task allocation in hospital emergency\ndepartments (EDs) is critical for operational efficiency and patient care\nquality, yet the complexity of staff coordination poses significant challenges.\nThis study proposes a simulation-based framework for modeling doctors and\nnurses as intelligent agents guided by computational trust mechanisms. The\nobjective is to explore how trust-informed coordination can support decision\nmaking in ED management. Methods: The framework was implemented in Unity, a 3D\ngraphics platform, where agents assess their competence before undertaking\ntasks and adaptively coordinate with colleagues. The simulation environment\nenables real-time observation of workflow dynamics, resource utilization, and\npatient outcomes. We examined three scenarios - Baseline, Replacement, and\nTraining - reflecting alternative staff management strategies. Results:\nTrust-informed task allocation balanced patient safety and efficiency by\nadapting to nurse performance levels. In the Baseline scenario, prioritizing\nsafety reduced errors but increased patient delays compared to a FIFO policy.\nThe Replacement scenario improved throughput and reduced delays, though at\nadditional staffing cost. The training scenario forstered long-term skill\ndevelopment among low-performing nurses, despite short-term delays and risks.\nThese results highlight the trade-off between immediate efficiency gains and\nsustainable capacity building in ED staffing. Conclusions: The proposed\nframework demonstrates the potential of computational trust for evidence-based\ndecision support in emergency medicine. By linking staff coordination with\nadaptive decision making, it provides hospital managers with a tool to evaluate\nalternative policies under controlled and repeatable conditions, while also\nlaying a foundation for future AI-driven personalized decision support."}
{"id": "2510.15905", "pdf": "https://arxiv.org/pdf/2510.15905", "abs": "https://arxiv.org/abs/2510.15905", "authors": ["Aikaterina Manoli", "Janet V. T. Pauketat", "Ali Ladak", "Hayoun Noh", "Angel Hsing-Chi Hwang", "Jay Reese Anthis"], "title": "\"She's Like a Person but Better\": Characterizing Companion-Assistant Dynamics in Human-AI Relationships", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Large language models are increasingly used for both task-based assistance\nand social companionship, yet research has typically focused on one or the\nother. Drawing on a survey (N = 204) and 30 interviews with high-engagement\nChatGPT and Replika users, we characterize digital companionship as an emerging\nform of human-AI relationship. With both systems, users were drawn to humanlike\nqualities, such as emotional resonance and personalized responses, and\nnon-humanlike qualities, such as constant availability and inexhaustible\ntolerance. This led to fluid chatbot uses, such as Replika as a writing\nassistant and ChatGPT as an emotional confidant, despite their distinct\nbranding. However, we observed challenging tensions in digital companionship\ndynamics: participants grappled with bounded personhood, forming deep\nattachments while denying chatbots \"real\" human qualities, and struggled to\nreconcile chatbot relationships with social norms. These dynamics raise\nquestions for the design of digital companions and the rise of hybrid,\ngeneral-purpose AI systems."}
{"id": "2510.15906", "pdf": "https://arxiv.org/pdf/2510.15906", "abs": "https://arxiv.org/abs/2510.15906", "authors": ["Yunsheng Bai", "Ghaith Bany Hamad", "Chia-Tung Ho", "Syed Suhaib", "Haoxing Ren"], "title": "FVDebug: An LLM-Driven Debugging Assistant for Automated Root Cause Analysis of Formal Verification Failures", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Debugging formal verification (FV) failures represents one of the most\ntime-consuming bottlenecks in modern hardware design workflows. When properties\nfail, engineers must manually trace through complex counter-examples spanning\nmultiple cycles, analyze waveforms, and cross-reference design specifications\nto identify root causes - a process that can consume hours or days per bug.\nExisting solutions are largely limited to manual waveform viewers or simple\nautomated tools that cannot reason about the complex interplay between design\nintent and implementation logic. We present FVDebug, an intelligent system that\nautomates root-cause analysis by combining multiple data sources - waveforms,\nRTL code, design specifications - to transform failure traces into actionable\ninsights. Our approach features a novel pipeline: (1) Causal Graph Synthesis\nthat structures failure traces into directed acyclic graphs, (2) Graph Scanner\nusing batched Large Language Model (LLM) analysis with for-and-against\nprompting to identify suspicious nodes, and (3) Insight Rover leveraging\nagentic narrative exploration to generate high-level causal explanations.\nFVDebug further provides concrete RTL fixes through its Fix Generator.\nEvaluated on open benchmarks, FVDebug attains high hypothesis quality and\nstrong Pass@k fix rates. We further report results on two proprietary,\nproduction-scale FV counterexamples. These results demonstrate FVDebug's\napplicability from academic benchmarks to industrial designs."}
{"id": "2510.15911", "pdf": "https://arxiv.org/pdf/2510.15911", "abs": "https://arxiv.org/abs/2510.15911", "authors": ["Ben Abramowitz"], "title": "Sleeping Kelly is a Thirder", "categories": ["q-fin.GN", "cs.AI"], "comment": null, "summary": "The Sleeping Beauty problem was presented by Elga and highlights the role of\nprobabilities in situations with imperfect recall. One approach to solving the\nSleeping Beauty problem is to allow Sleeping Beauty to make decisions based on\nher beliefs, and then characterize what it takes for her decisions to be\n\"rational\". In particular, she can be allowed to make monetary bets based on\nher beliefs, with the assumption that she wants to gain wealth rather than lose\nit. However, this approach is often coupled with the assumption that Sleeping\nBeauty should maximize the expected value of her bets. Here, I argue instead\nthat it is rational for Sleeping Beauty to maximize the growth rate of her\nwealth using the Kelly Criterion, which leads us to the \"thirder\" position.\nFurthermore, this position is shown to be \"rational\" by Dutch book arguments.\nIf Sleeping Kelly only accepts bets that have a growth rate greater than 1 as a\n\"thirder\" then she is not vulnerable to Dutch books. By contrast, if Sleeping\nBeauty takes the \"halfer\" position, she is vulnerable to Dutch books. If the\nbets offered to Sleeping Beauty were to be structured differently and lead to\nnon-multiplicative wealth dynamics, she may no longer be a \"thirder\"."}
{"id": "2510.15914", "pdf": "https://arxiv.org/pdf/2510.15914", "abs": "https://arxiv.org/abs/2510.15914", "authors": ["Jiayu Zhao", "Song Chen"], "title": "VeriGRAG: Enhancing LLM-Based Verilog Code Generation with Structure-Aware Soft Prompts", "categories": ["cs.AR", "cs.AI", "cs.PL"], "comment": "9 pages, 5 figures", "summary": "Large language models (LLMs) have demonstrated strong capabilities in\ngenerating Verilog code from natural language descriptions. However, Verilog\ncode inherently encodes structural information of hardware circuits.\nEffectively leveraging this structural information to enhance the functional\nand syntactic correctness of LLM-generated Verilog code remains a significant\nchallenge. To address this challenge, we propose VeriGRAG , a novel framework\nthat extracts structural graph embeddings from Verilog code using graph neural\nnetworks (GNNs). A multimodal retriever then selects the graph embeddings most\nrelevant to the given generation task, which are aligned with the code modality\nthrough the VeriFormer module to generate structure-aware soft prompts. Our\nexperiments demonstrate that VeriGRAG substantially improves the correctness of\nVerilog code generation, achieving state-of-the-art or superior performance\nacross both VerilogEval and RTLLM benchmarks."}
{"id": "2510.15917", "pdf": "https://arxiv.org/pdf/2510.15917", "abs": "https://arxiv.org/abs/2510.15917", "authors": ["Shai Bergman", "Won Wook Song", "Lukas Cavigelli", "Konstantin Berestizshevsky", "Ke Zhou", "Ji Zhang"], "title": "Intent-Driven Storage Systems: From Low-Level Tuning to High-Level Understanding", "categories": ["cs.AR", "cs.AI", "cs.DC"], "comment": null, "summary": "Existing storage systems lack visibility into workload intent, limiting their\nability to adapt to the semantics of modern, large-scale data-intensive\napplications. This disconnect leads to brittle heuristics and fragmented,\nsiloed optimizations. To address these limitations, we propose Intent-Driven\nStorage Systems (IDSS), a vision for a new paradigm where large language models\n(LLMs) infer workload and system intent from unstructured signals to guide\nadaptive and cross-layer parameter reconfiguration. IDSS provides holistic\nreasoning for competing demands, synthesizing safe and efficient decisions\nwithin policy guardrails. We present four design principles for integrating\nLLMs into storage control loops and propose a corresponding system\narchitecture. Initial results on FileBench workloads show that IDSS can improve\nIOPS by up to 2.45X by interpreting intent and generating actionable\nconfigurations for storage components such as caching and prefetching. These\nfindings suggest that, when constrained by guardrails and embedded within\nstructured workflows, LLMs can function as high-level semantic optimizers,\nbridging the gap between application goals and low-level system control. IDSS\npoints toward a future in which storage systems are increasingly adaptive,\nautonomous, and aligned with dynamic workload demands."}
{"id": "2510.15929", "pdf": "https://arxiv.org/pdf/2510.15929", "abs": "https://arxiv.org/abs/2510.15929", "authors": ["Lucas Eduardo Pereira Teles", "Carlos M. S. Figueiredo"], "title": "Comparing LLMs for Sentiment Analysis in Financial Market News", "categories": ["q-fin.ST", "cs.AI", "cs.CL"], "comment": null, "summary": "This article presents a comparative study of large language models (LLMs) in\nthe task of sentiment analysis of financial market news. This work aims to\nanalyze the performance difference of these models in this important natural\nlanguage processing task within the context of finance. LLM models are compared\nwith classical approaches, allowing for the quantification of the benefits of\neach tested model or approach. Results show that large language models\noutperform classical models in the vast majority of cases."}
{"id": "2510.15930", "pdf": "https://arxiv.org/pdf/2510.15930", "abs": "https://arxiv.org/abs/2510.15930", "authors": ["Philippe MagalhÃ£es", "Virginie Fresse", "BenoÃ®t Suffran", "Olivier Alata"], "title": "ImplÃ©mentation Efficiente de Fonctions de Convolution sur FPGA Ã  l'Aide de Blocs ParamÃ©trables et d'Approximations Polynomiales", "categories": ["cs.AR", "cs.AI", "cs.NE"], "comment": "in French language, XXXe Colloque Francophone de Traitement du Signal\n  et des Images (GRETSI), Aug 2025, Strabourg, France", "summary": "Implementing convolutional neural networks (CNNs) on field-programmable gate\narrays (FPGAs) has emerged as a promising alternative to GPUs, offering lower\nlatency, greater power efficiency and greater flexibility. However, this\ndevelopment remains complex due to the hardware knowledge required and the long\nsynthesis, placement and routing stages, which slow down design cycles and\nprevent rapid exploration of network configurations, making resource\noptimisation under severe constraints particularly challenging. This paper\nproposes a library of configurable convolution Blocks designed to optimize FPGA\nimplementation and adapt to available resources. It also presents a\nmethodological framework for developing mathematical models that predict FPGA\nresources utilization. The approach is validated by analyzing the correlation\nbetween the parameters, followed by error metrics. The results show that the\ndesigned blocks enable adaptation of convolution layers to hardware\nconstraints, and that the models accurately predict resource consumption,\nproviding a useful tool for FPGA selection and optimized CNN deployment."}
{"id": "2510.15940", "pdf": "https://arxiv.org/pdf/2510.15940", "abs": "https://arxiv.org/abs/2510.15940", "authors": ["Jialin Lu", "Kye Emond", "Kaiyu Yang", "Swarat Chaudhuri", "Weiran Sun", "Wuyang Chen"], "title": "Lean Finder: Semantic Search for Mathlib That Understands User Intents", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present Lean Finder, a semantic search engine for Lean and mathlib that\nunderstands and aligns with the intents of mathematicians. Progress in formal\ntheorem proving is often hindered by the difficulty of locating relevant\ntheorems and the steep learning curve of the Lean 4 language, making\nadvancement slow and labor-intensive. Existing Lean search engines, though\nhelpful, rely primarily on informalizations (natural language translation of\nthe formal statements), while largely overlooking the mismatch with real-world\nuser queries. In contrast, we propose a user-centered semantic search tailored\nto the needs of mathematicians. Our approach begins by analyzing and clustering\nthe semantics of public Lean discussions, then fine-tuning text embeddings on\nsynthesized queries that emulate user intents. We further align Lean Finder\nwith mathematicians' preferences using diverse feedback signals, encoding it\nwith a rich awareness of their goals from multiple perspectives. Evaluations on\nreal-world queries, informalized statements, and proof states demonstrate that\nour Lean Finder achieves over $30\\%$ relative improvement compared to previous\nsearch engines and GPT-4o. In addition, Lean Finder is compatible with\nLLM-based theorem provers, bridging retrieval with formal reasoning. Lean\nFinder is available at: https://leanfinder.github.io"}
{"id": "2510.15944", "pdf": "https://arxiv.org/pdf/2510.15944", "abs": "https://arxiv.org/abs/2510.15944", "authors": ["Tianyu Bell Pan", "Mengdi Zhu", "Alexa Jordyn Cole", "Ronald Wilson", "Damon L. Woodard"], "title": "Lyapunov-Stable Adaptive Control for Multimodal Concept Drift", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal learning systems often struggle in non-stationary environments due\nto concept drift, where changing data distributions can degrade performance.\nModality-specific drifts and the lack of mechanisms for continuous, stable\nadaptation compound this challenge. This paper introduces LS-OGD, a novel\nadaptive control framework for robust multimodal learning in the presence of\nconcept drift. LS-OGD uses an online controller that dynamically adjusts the\nmodel's learning rate and the fusion weights between different data modalities\nin response to detected drift and evolving prediction errors. We prove that\nunder bounded drift conditions, the LS-OGD system's prediction error is\nuniformly ultimately bounded and converges to zero if the drift ceases.\nAdditionally, we demonstrate that the adaptive fusion strategy effectively\nisolates and mitigates the impact of severe modality-specific drift, thereby\nensuring system resilience and fault tolerance. These theoretical guarantees\nestablish a principled foundation for developing reliable and continuously\nadapting multimodal learning systems."}
{"id": "2510.15945", "pdf": "https://arxiv.org/pdf/2510.15945", "abs": "https://arxiv.org/abs/2510.15945", "authors": ["Guangya Wan", "Zixin Stephen Xu", "Sasa Zorc", "Manel Baucells", "Mengxuan Hu", "Hao Wang", "Sheng Li"], "title": "BEACON: Bayesian Optimal Stopping for Efficient LLM Sampling", "categories": ["cs.LG", "cs.AI"], "comment": "Under review on ARR", "summary": "Sampling multiple responses is a common way to improve LLM output quality,\nbut it comes at the cost of additional computation. The key challenge is\ndeciding when to stop generating new samples to balance accuracy gains against\nefficiency. To address this, we introduce BEACON (Bayesian Efficient Adaptive\nCriterion for Optimal N-stopping), a principled adaptive sampling framework\ngrounded in Sequential Search with Bayesian Learning. BEACON sequentially\ngenerates responses from the policy LLM, updates posterior belief over reward\ndistributions in real time without further training, and determines when to\nstop by weighing expected gains against computational cost. Sampling terminates\nonce the marginal utility of further exploration no longer justifies the\nexpense. We establish both theoretical optimality guarantees and practical\ntractability, and show empirically that BEACON reduces average sampling by up\nto 80% while maintaining response quality. We further demonstrate BEACON's\nutility for cost-efficient preference data generation and outline practical\nextensions, offering actionable insights for future researchers."}
{"id": "2510.15946", "pdf": "https://arxiv.org/pdf/2510.15946", "abs": "https://arxiv.org/abs/2510.15946", "authors": ["Wenshuo Wang", "Ziyou Jiang", "Junjie Wang", "Mingyang Li", "Jie Huang", "Yuekai Huang", "Zhiyuan Chang", "Feiyan Duan", "Qing Wang"], "title": "Learning from Mistakes: Enhancing Harmful Meme Detection via Misjudgment Risk Patterns", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "12 Pages, Submitted to WWW'26", "summary": "Internet memes have emerged as a popular multimodal medium, yet they are\nincreasingly weaponized to convey harmful opinions through subtle rhetorical\ndevices like irony and metaphor. Existing detection approaches, including\nMLLM-based techniques, struggle with these implicit expressions, leading to\nfrequent misjudgments. This paper introduces PatMD, a novel approach that\nimproves harmful meme detection by learning from and proactively mitigating\nthese potential misjudgment risks. Our core idea is to move beyond superficial\ncontent-level matching and instead identify the underlying misjudgment risk\npatterns, proactively guiding the MLLMs to avoid known misjudgment pitfalls. We\nfirst construct a knowledge base where each meme is deconstructed into a\nmisjudgment risk pattern explaining why it might be misjudged, either\noverlooking harmful undertones (false negative) or overinterpreting benign\ncontent (false positive). For a given target meme, PatMD retrieves relevant\npatterns and utilizes them to dynamically guide the MLLM's reasoning.\nExperiments on a benchmark of 6,626 memes across 5 harmful detection tasks show\nthat PatMD outperforms state-of-the-art baselines, achieving an average of\n8.30\\% improvement in F1-score and 7.71\\% improvement in accuracy,\ndemonstrating strong generalizability and improved detection capability of\nharmful memes."}
{"id": "2510.15947", "pdf": "https://arxiv.org/pdf/2510.15947", "abs": "https://arxiv.org/abs/2510.15947", "authors": ["Casper van Laar", "Khubaib Ahmed"], "title": "WaveNet's Precision in EEG Classification", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.NC", "68T07, 92C55, 62M10", "I.2.6; I.5.1; J.3"], "comment": "6 pages, 5 figures and 3 tables. Includes main text and bibliography", "summary": "This study introduces a WaveNet-based deep learning model designed to\nautomate the classification of EEG signals into physiological, pathological,\nartifact, and noise categories. Traditional methods for EEG signal\nclassification, which rely on expert visual review, are becoming increasingly\nimpractical due to the growing complexity and volume of EEG recordings.\nLeveraging a publicly available annotated dataset from Mayo Clinic and St.\nAnne's University Hospital, the WaveNet model was trained, validated, and\ntested on 209,232 samples with a 70/20/10 percent split. The model achieved a\nclassification accuracy exceeding previous CNN and LSTM-based approaches, and\nwas benchmarked against a Temporal Convolutional Network (TCN) baseline.\nNotably, the model distinguishes noise and artifacts with high precision,\nalthough it reveals a modest but explainable degree of misclassification\nbetween physiological and pathological signals, reflecting inherent clinical\noverlap. WaveNet's architecture, originally developed for raw audio synthesis,\nis well suited for EEG data due to its use of dilated causal convolutions and\nresidual connections, enabling it to capture both fine-grained and long-range\ntemporal dependencies. The research also details the preprocessing pipeline,\nincluding dynamic dataset partitioning and normalization steps that support\nmodel generalization."}
{"id": "2510.15949", "pdf": "https://arxiv.org/pdf/2510.15949", "abs": "https://arxiv.org/abs/2510.15949", "authors": ["Charidimos Papadakis", "Angeliki Dimitriou", "Giorgos Filandrianos", "Maria Lymperaiou", "Konstantinos Thomas", "Giorgos Stamou"], "title": "ATLAS: Adaptive Trading with LLM AgentS Through Dynamic Prompt Optimization and Multi-Agent Coordination", "categories": ["q-fin.TR", "cs.AI"], "comment": null, "summary": "Large language models show promise for financial decision-making, yet\ndeploying them as autonomous trading agents raises fundamental challenges: how\nto adapt instructions when rewards arrive late and obscured by market noise,\nhow to synthesize heterogeneous information streams into coherent decisions,\nand how to bridge the gap between model outputs and executable market actions.\nWe present ATLAS (Adaptive Trading with LLM AgentS), a unified multi-agent\nframework that integrates structured information from markets, news, and\ncorporate fundamentals to support robust trading decisions. Within ATLAS, the\ncentral trading agent operates in an order-aware action space, ensuring that\noutputs correspond to executable market orders rather than abstract signals.\nThe agent can incorporate feedback while trading using Adaptive-OPRO, a novel\nprompt-optimization technique that dynamically adapts the prompt by\nincorporating real-time, stochastic feedback, leading to increasing performance\nover time. Across regime-specific equity studies and multiple LLM families,\nAdaptive-OPRO consistently outperforms fixed prompts, while reflection-based\nfeedback fails to provide systematic gains."}
{"id": "2510.15950", "pdf": "https://arxiv.org/pdf/2510.15950", "abs": "https://arxiv.org/abs/2510.15950", "authors": ["Arianna Francesconi", "Donato Cappetta", "Fabio Rebecchi", "Paolo Soda", "Valerio Guarrasi", "Rosa Sicilia"], "title": "Cross-dataset Multivariate Time-series Model for Parkinson's Diagnosis via Keyboard Dynamics", "categories": ["cs.LG", "cs.AI"], "comment": "Proceedings of the Workshop on Artificial Intelligence for Biomedical\n  Data (AIBio 2025), 28th European Conference on Artificial Intelligence 2025,\n  Springer CCIS", "summary": "Parkinson's disease (PD) presents a growing global challenge, affecting over\n10 million individuals, with prevalence expected to double by 2040. Early\ndiagnosis remains difficult due to the late emergence of motor symptoms and\nlimitations of traditional clinical assessments. In this study, we propose a\nnovel pipeline that leverages keystroke dynamics as a non-invasive and scalable\nbiomarker for remote PD screening and telemonitoring. Our methodology involves\nthree main stages: (i) preprocessing of data from four distinct datasets,\nextracting four temporal signals and addressing class imbalance through the\ncomparison of three methods; (ii) pre-training eight state-of-the-art\ndeep-learning architectures on the two largest datasets, optimizing temporal\nwindowing, stride, and other hyperparameters; (iii) fine-tuning on an\nintermediate-sized dataset and performing external validation on a fourth,\nindependent cohort. Our results demonstrate that hybrid convolutional-recurrent\nand transformer-based models achieve strong external validation performance,\nwith AUC-ROC scores exceeding 90% and F1-Score over 70%. Notably, a temporal\nconvolutional model attains an AUC-ROC of 91.14% in external validation,\noutperforming existing methods that rely solely on internal validation. These\nfindings underscore the potential of keystroke dynamics as a reliable digital\nbiomarker for PD, offering a promising avenue for early detection and\ncontinuous monitoring."}
{"id": "2510.15955", "pdf": "https://arxiv.org/pdf/2510.15955", "abs": "https://arxiv.org/abs/2510.15955", "authors": ["Kiran Kate", "Yara Rizk", "Poulami Ghosh", "Ashu Gulati", "Tathagata Chakraborti", "Zidane Wright", "Mayank Agarwal"], "title": "How Good Are LLMs at Processing Tool Outputs?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Most realistic task automation problems require large language models (LLMs)\nto call tools, which often return complex JSON responses. These responses must\nbe further processed to derive the information necessary for task completion.\nThe ability of LLMs to do so is under-studied. In this paper, we study the tool\nresponse processing task and LLMs' abilities to process structured (JSON)\nresponses. We created a dataset for this task, and evaluated 15 open and closed\nweight models using multiple prompting approaches. Our results show that JSON\nprocessing remains a difficult task even for frontier models across multiple\nprompting strategies. The optimal response processing strategy depends on both\nthe nature and size of the tool outputs, as well as the complexity of the\nrequired reasoning. Variations in processing approaches can lead to performance\ndifferences ranging from 3\\% to 50\\%."}
{"id": "2510.15961", "pdf": "https://arxiv.org/pdf/2510.15961", "abs": "https://arxiv.org/abs/2510.15961", "authors": ["Yiyang Li", "Zehong Wang", "Zhengqing Yuan", "Zheyuan Zhang", "Keerthiram Murugesan", "Chuxu Zhang", "Yanfang Ye"], "title": "Interpretable Graph-Language Modeling for Detecting Youth Illicit Drug Use", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "Illicit drug use among teenagers and young adults (TYAs) remains a pressing\npublic health concern, with rising prevalence and long-term impacts on health\nand well-being. To detect illicit drug use among TYAs, researchers analyze\nlarge-scale surveys such as the Youth Risk Behavior Survey (YRBS) and the\nNational Survey on Drug Use and Health (NSDUH), which preserve rich\ndemographic, psychological, and environmental factors related to substance use.\nHowever, existing modeling methods treat survey variables independently,\noverlooking latent and interconnected structures among them. To address this\nlimitation, we propose LAMI (LAtent relation Mining with bi-modal\nInterpretability), a novel joint graph-language modeling framework for\ndetecting illicit drug use and interpreting behavioral risk factors among TYAs.\nLAMI represents individual responses as relational graphs, learns latent\nconnections through a specialized graph structure learning layer, and\nintegrates a large language model to generate natural language explanations\ngrounded in both graph structures and survey semantics. Experiments on the YRBS\nand NSDUH datasets show that LAMI outperforms competitive baselines in\npredictive accuracy. Interpretability analyses further demonstrate that LAMI\nreveals meaningful behavioral substructures and psychosocial pathways, such as\nfamily dynamics, peer influence, and school-related distress, that align with\nestablished risk factors for substance use."}
{"id": "2510.15962", "pdf": "https://arxiv.org/pdf/2510.15962", "abs": "https://arxiv.org/abs/2510.15962", "authors": ["Zhuxuanzi Wang", "Mingqiao Mo", "Xi Xiao", "Chen Liu", "Chenrui Ma", "Yunbei Zhang", "Xiao Wang", "Smita Krishnaswamy", "Tianyang Wang"], "title": "CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) has become the standard approach for\nadapting large language models under limited compute and memory budgets.\nAlthough previous methods improve efficiency through low-rank updates,\nquantization, or heuristic budget reallocation, they often decouple the\nallocation of capacity from the way updates evolve during training. In this\nwork, we introduce CTR-LoRA, a framework guided by curvature trust region that\nintegrates rank scheduling with stability-aware optimization. CTR-LoRA\nallocates parameters based on marginal utility derived from lightweight\nsecond-order proxies and constrains updates using a Fisher/Hessian-metric trust\nregion. Experiments on multiple open-source backbones (7B-13B), evaluated on\nboth in-distribution and out-of-distribution benchmarks, show consistent\nimprovements over strong PEFT baselines. In addition to increased accuracy,\nCTR-LoRA enhances training stability, reduces memory requirements, and achieves\nhigher throughput, positioning it on the Pareto frontier of performance and\nefficiency. These results highlight a principled path toward more robust and\ndeployable PEFT."}
{"id": "2510.15963", "pdf": "https://arxiv.org/pdf/2510.15963", "abs": "https://arxiv.org/abs/2510.15963", "authors": ["Jiani Huang", "Amish Sethi", "Matthew Kuo", "Mayank Keoliya", "Neelay Velingker", "JungHo Jung", "Ser-Nam Lim", "Ziyang Li", "Mayur Naik"], "title": "ESCA: Contextualizing Embodied Agents via Scene-Graph Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted as a Spotlight Paper at NeurIPS 2025", "summary": "Multi-modal large language models (MLLMs) are making rapid progress toward\ngeneral-purpose embodied agents. However, current training pipelines primarily\nrely on high-level vision-sound-text pairs and lack fine-grained, structured\nalignment between pixel-level visual content and textual semantics. To overcome\nthis challenge, we propose ESCA, a new framework for contextualizing embodied\nagents through structured spatial-temporal understanding. At its core is\nSGClip, a novel CLIP-based, open-domain, and promptable model for generating\nscene graphs. SGClip is trained on 87K+ open-domain videos via a neurosymbolic\nlearning pipeline, which harnesses model-driven self-supervision from\nvideo-caption pairs and structured reasoning, thereby eliminating the need for\nhuman-labeled scene graph annotations. We demonstrate that SGClip supports both\nprompt-based inference and task-specific fine-tuning, excelling in scene graph\ngeneration and action localization benchmarks. ESCA with SGClip consistently\nimproves both open-source and commercial MLLMs, achieving state-of-the-art\nperformance across two embodied environments. Notably, it significantly reduces\nagent perception errors and enables open-source models to surpass proprietary\nbaselines."}
{"id": "2510.15964", "pdf": "https://arxiv.org/pdf/2510.15964", "abs": "https://arxiv.org/abs/2510.15964", "authors": ["Tuowei Wang", "Kun Li", "Zixu Hao", "Donglin Bai", "Ju Ren", "Yaoxue Zhang", "Ting Cao", "Mao Yang"], "title": "Long Exposure: Accelerating Parameter-Efficient Fine-Tuning for LLMs under Shadowy Sparsity", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The adaptation of pre-trained large language models (LLMs) to diverse\ndownstream tasks via fine-tuning is critical for numerous applications.\nHowever, the inefficiency of parameter-efficient fine-tuning (PEFT) techniques\npresents significant challenges in terms of time investments and operational\ncosts. In this paper, we first introduce a nuanced form of sparsity, termed\nShadowy Sparsity, which is distinctive in fine-tuning and has not been\nadequately addressed for acceleration. Under Shadowy Sparsity, we propose Long\nExposure, an efficient system to accelerate PEFT for LLMs. Long Exposure\ncomprises three key components: Shadowy-sparsity Exposer employs a prolonged\nsensing range to capture more sparsity details under shadowy sparsity;\nSequence-oriented Predictor provides efficient yet accurate predictions to\nhandle large sequence inputs and constantly-evolving parameters; and\nDynamic-aware Operator facilitates more structured computational patterns and\ncoalesced memory accesses, addressing dynamic sparse operations. Extensive\nevaluations show that Long Exposure outperforms state-of-the-arts with up to a\n$2.49\\times$ speedup in end-to-end fine-tuning, offering promising advancements\nin accelerating PEFT for LLMs."}
{"id": "2510.15965", "pdf": "https://arxiv.org/pdf/2510.15965", "abs": "https://arxiv.org/abs/2510.15965", "authors": ["Mohan Zhang", "Yihua Zhang", "Jinghan Jia", "Zhangyang Wang", "Sijia Liu", "Tianlong Chen"], "title": "One Token Embedding Is Enough to Deadlock Your Large Reasoning Model", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "NeurIPS 2025", "summary": "Modern large reasoning models (LRMs) exhibit impressive multi-step\nproblem-solving via chain-of-thought (CoT) reasoning. However, this iterative\nthinking mechanism introduces a new vulnerability surface. We present the\nDeadlock Attack, a resource exhaustion method that hijacks an LRM's generative\ncontrol flow by training a malicious adversarial embedding to induce perpetual\nreasoning loops. Specifically, the optimized embedding encourages transitional\ntokens (e.g., \"Wait\", \"But\") after reasoning steps, preventing the model from\nconcluding its answer. A key challenge we identify is the\ncontinuous-to-discrete projection gap: na\\\"ive projections of adversarial\nembeddings to token sequences nullify the attack. To overcome this, we\nintroduce a backdoor implantation strategy, enabling reliable activation\nthrough specific trigger tokens. Our method achieves a 100% attack success rate\nacross four advanced LRMs (Phi-RM, Nemotron-Nano, R1-Qwen, R1-Llama) and three\nmath reasoning benchmarks, forcing models to generate up to their maximum token\nlimits. The attack is also stealthy (in terms of causing negligible utility\nloss on benign user inputs) and remains robust against existing strategies\ntrying to mitigate the overthinking issue. Our findings expose a critical and\nunderexplored security vulnerability in LRMs from the perspective of reasoning\n(in)efficiency."}
{"id": "2510.15967", "pdf": "https://arxiv.org/pdf/2510.15967", "abs": "https://arxiv.org/abs/2510.15967", "authors": ["Zhengyi Zhong", "Wenzheng Jiang", "Weidong Bao", "Ji Wang", "Cheems Wang", "Guanbo Wang", "Yongheng Deng", "Ju Ren"], "title": "Gains: Fine-grained Federated Domain Adaptation in Open Set", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by NeurIPS2025", "summary": "Conventional federated learning (FL) assumes a closed world with a fixed\ntotal number of clients. In contrast, new clients continuously join the FL\nprocess in real-world scenarios, introducing new knowledge. This raises two\ncritical demands: detecting new knowledge, i.e., knowledge discovery, and\nintegrating it into the global model, i.e., knowledge adaptation. Existing\nresearch focuses on coarse-grained knowledge discovery, and often sacrifices\nsource domain performance and adaptation efficiency. To this end, we propose a\nfine-grained federated domain adaptation approach in open set (Gains). Gains\nsplits the model into an encoder and a classifier, empirically revealing\nfeatures extracted by the encoder are sensitive to domain shifts while\nclassifier parameters are sensitive to class increments. Based on this, we\ndevelop fine-grained knowledge discovery and contribution-driven aggregation\ntechniques to identify and incorporate new knowledge. Additionally, an\nanti-forgetting mechanism is designed to preserve source domain performance,\nensuring balanced adaptation. Experimental results on multi-domain datasets\nacross three typical data-shift scenarios demonstrate that Gains significantly\noutperforms other baselines in performance for both source-domain and\ntarget-domain clients. Code is available at:\nhttps://github.com/Zhong-Zhengyi/Gains."}
{"id": "2510.15968", "pdf": "https://arxiv.org/pdf/2510.15968", "abs": "https://arxiv.org/abs/2510.15968", "authors": ["Zhen Huang", "Hong Wang", "Wenkai Yang", "Muxi Tang", "Depeng Xie", "Ting-Jung Lin", "Yu Zhang", "Wei W. Xing", "Lei He"], "title": "Self-Attention to Operator Learning-based 3D-IC Thermal Simulation", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": null, "summary": "Thermal management in 3D ICs is increasingly challenging due to higher power\ndensities. Traditional PDE-solving-based methods, while accurate, are too slow\nfor iterative design. Machine learning approaches like FNO provide faster\nalternatives but suffer from high-frequency information loss and high-fidelity\ndata dependency. We introduce Self-Attention U-Net Fourier Neural Operator\n(SAU-FNO), a novel framework combining self-attention and U-Net with FNO to\ncapture long-range dependencies and model local high-frequency features\neffectively. Transfer learning is employed to fine-tune low-fidelity data,\nminimizing the need for extensive high-fidelity datasets and speeding up\ntraining. Experiments demonstrate that SAU-FNO achieves state-of-the-art\nthermal prediction accuracy and provides an 842x speedup over traditional FEM\nmethods, making it an efficient tool for advanced 3D IC thermal simulations."}
{"id": "2510.15969", "pdf": "https://arxiv.org/pdf/2510.15969", "abs": "https://arxiv.org/abs/2510.15969", "authors": ["Paul-Niklas Ken Kandora", "Simon Caspar Zeller", "Aaron Jeremias Elsing", "Elena Kuss", "Steffen Rebennack"], "title": "LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reformulating nonlinear optimization problems is largely manual and\nexpertise-intensive, yet it remains essential for solving such problems with\nlinear optimization solvers or applying special-purpose algorithms. We\nintroduce \\textit{LinearizeLLM}, an agent-based framework that solves this task\nby leveraging Large Language Models (LLMs). The framework assigns each\nnonlinear pattern to a \\textit{reformulation agent} that is explicitly\ninstructed to derive an exact linear reformulation for its nonlinearity\npattern, for instance, absolute-value terms or bilinear products of decision\nvariables. The agents then coordinate to assemble a solver-ready linear model\nequivalent to the original problem. To benchmark the approach, we create a\ndataset of 20 real-world nonlinear optimization problems derived from the\nestablished ComplexOR dataset of linear optimization problems. We evaluate our\napproach with several LLMs. Our results indicate that specialized LLM agents\ncan automate linearization tasks, opening a path toward fully conversational\nmodeling pipelines for nonlinear optimization."}
{"id": "2510.15970", "pdf": "https://arxiv.org/pdf/2510.15970", "abs": "https://arxiv.org/abs/2510.15970", "authors": ["Yang Ba", "Mohammad Sadeq Abolhasani", "Rong Pan"], "title": "Predict Training Data Quality via Its Geometry in Metric Space", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the NeurIPS 2025 Workshop on New Perspectives in Graph\n  Machine Learning", "summary": "High-quality training data is the foundation of machine learning and\nartificial intelligence, shaping how models learn and perform. Although much is\nknown about what types of data are effective for training, the impact of the\ndata's geometric structure on model performance remains largely underexplored.\nWe propose that both the richness of representation and the elimination of\nredundancy within training data critically influence learning outcomes. To\ninvestigate this, we employ persistent homology to extract topological features\nfrom data within a metric space, thereby offering a principled way to quantify\ndiversity beyond entropy-based measures. Our findings highlight persistent\nhomology as a powerful tool for analyzing and enhancing the training data that\ndrives AI systems."}
{"id": "2510.15971", "pdf": "https://arxiv.org/pdf/2510.15971", "abs": "https://arxiv.org/abs/2510.15971", "authors": ["Md. Ifthekhar Hossain", "Kazi Abdullah Al Arafat", "Bryce Shepard", "Kayd Craig", "Imtiaz Parvez"], "title": "A Graph-Attentive LSTM Model for Malicious URL Detection", "categories": ["cs.CR", "cs.AI"], "comment": "Planned to be submitted", "summary": "Malicious URLs pose significant security risks as they facilitate phishing\nattacks, distribute malware, and empower attackers to deface websites.\nBlacklist detection methods fail to identify new or obfuscated URLs because\nthey depend on pre-existing patterns. This work presents a hybrid deep learning\nmodel named GNN-GAT-LSTM that combines Graph Neural Networks (GNNs) with Graph\nAttention Networks (GATs) and Long Short-Term Memory (LSTM) networks. The\nproposed architecture extracts both the structural and sequential patterns of\nthe features from data. The model transforms URLs into graphs through a process\nwhere characters become nodes that connect through edges. It applies one-hot\nencoding to represent node features. The model received training and testing\ndata from a collection of 651,191 URLs, which were classified into benign,\nphishing, defacement, and malware categories. The preprocessing stage included\nboth feature engineering and data balancing techniques, which addressed the\nclass imbalance issue to enhance model learning. The GNN-GAT-LSTM model\nachieved outstanding performance through its test accuracy of 0.9806 and its\nweighted F1-score of 0.9804. It showed excellent precision and recall\nperformance across most classes, particularly for benign and defacement URLs.\nOverall, the model provides an efficient and scalable system for detecting\nmalicious URLs while demonstrating strong potential for real-world\ncybersecurity applications."}
{"id": "2510.15972", "pdf": "https://arxiv.org/pdf/2510.15972", "abs": "https://arxiv.org/abs/2510.15972", "authors": ["Ling Sun", "Peter Sullivan", "Michael Martin", "Yun Zhou"], "title": "Quantum NLP models on Natural Language Inference", "categories": ["cs.CL", "cs.AI", "81P68 (Primary), 68T50, 68T07 (Secondary)", "I.2.7; F.1.2"], "comment": "Accepted, presented, and to appear in the Proceedings of the Quantum\n  AI and NLP 2025 Conference", "summary": "Quantum natural language processing (QNLP) offers a novel approach to\nsemantic modeling by embedding compositional structure directly into quantum\ncircuits. This paper investigates the application of QNLP models to the task of\nNatural Language Inference (NLI), comparing quantum, hybrid, and classical\ntransformer-based models under a constrained few-shot setting. Using the lambeq\nlibrary and the DisCoCat framework, we construct parameterized quantum circuits\nfor sentence pairs and train them for both semantic relatedness and inference\nclassification. To assess efficiency, we introduce a novel\ninformation-theoretic metric, Information Gain per Parameter (IGPP), which\nquantifies learning dynamics independent of model size. Our results demonstrate\nthat quantum models achieve performance comparable to classical baselines while\noperating with dramatically fewer parameters. The Quantum-based models\noutperform randomly initialized transformers in inference and achieve lower\ntest error on relatedness tasks. Moreover, quantum models exhibit significantly\nhigher per-parameter learning efficiency (up to five orders of magnitude more\nthan classical counterparts), highlighting the promise of QNLP in low-resource,\nstructure-sensitive settings. To address circuit-level isolation and promote\nparameter sharing, we also propose a novel cluster-based architecture that\nimproves generalization by tying gate parameters to learned word clusters\nrather than individual tokens."}
{"id": "2510.15973", "pdf": "https://arxiv.org/pdf/2510.15973", "abs": "https://arxiv.org/abs/2510.15973", "authors": ["Tiarnaigh Downey-Webb", "Olamide Jogunola", "Oluwaseun Ajao"], "title": "Safeguarding Efficacy in Large Language Models: Evaluating Resistance to Human-Written and Algorithmic Adversarial Prompts", "categories": ["cs.CR", "cs.AI", "cs.CY", "I.2.7"], "comment": "10 pages, 4 pages manuscript submitted to the Language Resources and\n  Evaluation Conference (LREC 2026)", "summary": "This paper presents a systematic security assessment of four prominent Large\nLanguage Models (LLMs) against diverse adversarial attack vectors. We evaluate\nPhi-2, Llama-2-7B-Chat, GPT-3.5-Turbo, and GPT-4 across four distinct attack\ncategories: human-written prompts, AutoDAN, Greedy Coordinate Gradient (GCG),\nand Tree-of-Attacks-with-pruning (TAP). Our comprehensive evaluation employs\n1,200 carefully stratified prompts from the SALAD-Bench dataset, spanning six\nharm categories. Results demonstrate significant variations in model\nrobustness, with Llama-2 achieving the highest overall security (3.4% average\nattack success rate) while Phi-2 exhibits the greatest vulnerability (7.0%\naverage attack success rate). We identify critical transferability patterns\nwhere GCG and TAP attacks, though ineffective against their target model\n(Llama-2), achieve substantially higher success rates when transferred to other\nmodels (up to 17% for GPT-4). Statistical analysis using Friedman tests reveals\nsignificant differences in vulnerability across harm categories ($p < 0.001$),\nwith malicious use prompts showing the highest attack success rates (10.71%\naverage). Our findings contribute to understanding cross-model security\nvulnerabilities and provide actionable insights for developing targeted defense\nmechanisms"}
{"id": "2510.15976", "pdf": "https://arxiv.org/pdf/2510.15976", "abs": "https://arxiv.org/abs/2510.15976", "authors": ["Chenrui Wang", "Junyi Shu", "Billy Chiu", "Yu Li", "Saleh Alharbi", "Min Zhang", "Jing Li"], "title": "Learning to Watermark: A Selective Watermarking Framework for Large Language Models via Multi-Objective Optimization", "categories": ["cs.CR", "cs.AI"], "comment": "28 pages, 11 figures, NeurIPS 2025 Poster", "summary": "The rapid development of LLMs has raised concerns about their potential\nmisuse, leading to various watermarking schemes that typically offer high\ndetectability. However, existing watermarking techniques often face trade-off\nbetween watermark detectability and generated text quality. In this paper, we\nintroduce Learning to Watermark (LTW), a novel selective watermarking framework\nthat leverages multi-objective optimization to effectively balance these\ncompeting goals. LTW features a lightweight network that adaptively decides\nwhen to apply the watermark by analyzing sentence embeddings, token entropy,\nand current watermarking ratio. Training of the network involves two\nspecifically constructed loss functions that guide the model toward\nPareto-optimal solutions, thereby harmonizing watermark detectability and text\nquality. By integrating LTW with two baseline watermarking methods, our\nexperimental evaluations demonstrate that LTW significantly enhances text\nquality without compromising detectability. Our selective watermarking approach\noffers a new perspective for designing watermarks for LLMs and a way to\npreserve high text quality for watermarks. The code is publicly available at:\nhttps://github.com/fattyray/learning-to-watermark"}
{"id": "2510.15977", "pdf": "https://arxiv.org/pdf/2510.15977", "abs": "https://arxiv.org/abs/2510.15977", "authors": ["Wenyun Li", "Zheng Zhang", "Dongmei Jiang", "Xiangyuan Lan"], "title": "Bolster Hallucination Detection via Prompt-Guided Data Augmentation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have garnered significant interest in AI\ncommunity. Despite their impressive generation capabilities, they have been\nfound to produce misleading or fabricated information, a phenomenon known as\nhallucinations. Consequently, hallucination detection has become critical to\nensure the reliability of LLM-generated content. One primary challenge in\nhallucination detection is the scarcity of well-labeled datasets containing\nboth truthful and hallucinated outputs. To address this issue, we introduce\nPrompt-guided data Augmented haLlucination dEtection (PALE), a novel framework\nthat leverages prompt-guided responses from LLMs as data augmentation for\nhallucination detection. This strategy can generate both truthful and\nhallucinated data under prompt guidance at a relatively low cost. To more\neffectively evaluate the truthfulness of the sparse intermediate embeddings\nproduced by LLMs, we introduce an estimation metric called the Contrastive\nMahalanobis Score (CM Score). This score is based on modeling the distributions\nof truthful and hallucinated data in the activation space. CM Score employs a\nmatrix decomposition approach to more accurately capture the underlying\nstructure of these distributions. Importantly, our framework does not require\nadditional human annotations, offering strong generalizability and practicality\nfor real-world applications. Extensive experiments demonstrate that PALE\nachieves superior hallucination detection performance, outperforming the\ncompetitive baseline by a significant margin of 6.55%."}
{"id": "2510.15978", "pdf": "https://arxiv.org/pdf/2510.15978", "abs": "https://arxiv.org/abs/2510.15978", "authors": ["Junchao Gong", "Jingyi Xu", "Ben Fei", "Fenghua Ling", "Wenlong Zhang", "Kun Chen", "Wanghan Xu", "Weidong Yang", "Xiaokang Yang", "Lei Bai"], "title": "DAWP: A framework for global observation forecasting via Data Assimilation and Weather Prediction in satellite observation space", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "Weather prediction is a critical task for human society, where impressive\nprogress has been made by training artificial intelligence weather prediction\n(AIWP) methods with reanalysis data. However, reliance on reanalysis data\nlimits the AIWPs with shortcomings, including data assimilation biases and\ntemporal discrepancies. To liberate AIWPs from the reanalysis data, observation\nforecasting emerges as a transformative paradigm for weather prediction. One of\nthe key challenges in observation forecasting is learning spatiotemporal\ndynamics across disparate measurement systems with irregular high-resolution\nobservation data, which constrains the design and prediction of AIWPs. To this\nend, we propose our DAWP as an innovative framework to enable AIWPs to operate\nin a complete observation space by initialization with an artificial\nintelligence data assimilation (AIDA) module. Specifically, our AIDA module\napplies a mask multi-modality autoencoder(MMAE)for assimilating irregular\nsatellite observation tokens encoded by mask ViT-VAEs. For AIWP, we introduce a\nspatiotemporal decoupling transformer with cross-regional boundary conditioning\n(CBC), learning the dynamics in observation space, to enable sub-image-based\nglobal observation forecasting. Comprehensive experiments demonstrate that AIDA\ninitialization significantly improves the roll out and efficiency of AIWP.\nAdditionally, we show that DAWP holds promising potential to be applied in\nglobal precipitation forecasting."}
{"id": "2510.15979", "pdf": "https://arxiv.org/pdf/2510.15979", "abs": "https://arxiv.org/abs/2510.15979", "authors": ["Zexu Sun", "Yongcheng Zeng", "Erxue Min", "Heyang Gao", "Bokai Ji", "Xu Chen"], "title": "Cog-Rethinker: Hierarchical Metacognitive Reinforcement Learning for LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "22 Pages, 8 figures, 4 tables", "summary": "Contemporary progress in large language models (LLMs) has revealed notable\ninferential capacities via reinforcement learning (RL) employing verifiable\nreward, facilitating the development of O1 and R1-like reasoning models.\nDirectly training from base models with RL is called zero-RL. However, previous\nworks rely upon activating LLMs' inherent capacities through fixed prompt\ntemplates. This strategy introduces substantial sampling inefficiencies for\nweak LLMs, as the majority of problems generate invalid outputs during\naccuracy-driven filtration in reasoning tasks, which causes a waste of samples.\nTo solve this issue, we propose Cog-Rethinker, a novel hierarchical\nmetacognitive RL framework for LLM reasoning. Our Cog-Rethinker mainly focuses\non the rollout procedure in RL training. After the direct rollout, our\nCog-Rethinker improves sample utilization in a hierarchical metacognitive\ntwo-stage framework. By leveraging human cognition during solving problems,\nfirstly, it prompts policy to decompose zero-accuracy problems into subproblems\nto produce final reasoning results. Secondly, with zero-accuracy problems in\nprevious rollout stage, it further prompts policy to refine these answers by\nreferencing previous wrong solutions. Moreover, to enable cold-start of the two\nnew reasoning patterns and maintain train-test consistency across prompt\ntemplates, our Cog-Rethinker applies supervised fine-tuning on the policy using\ncorrect samples of the two stages with direct rollout template. Experimental\nresults demonstrate Cog-Rethinker's superior performance on various\nmathematical reasoning benchmarks, we also analyzed its improved sample\nefficiency that accelerates convergence compared to baseline methods."}
{"id": "2510.15982", "pdf": "https://arxiv.org/pdf/2510.15982", "abs": "https://arxiv.org/abs/2510.15982", "authors": ["Donghyeok Shin", "Yeongmin Kim", "Suhyeon Jo", "Byeonghu Na", "Il-Chul Moon"], "title": "AMiD: Knowledge Distillation for LLMs with $Î±$-mixture Assistant Distribution", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Autoregressive large language models (LLMs) have achieved remarkable\nimprovement across many tasks but incur high computational and memory costs.\nKnowledge distillation (KD) mitigates this issue by transferring knowledge from\na large teacher to a smaller student through distributional alignment. Previous\nstudies have proposed various discrepancy metrics, but the capacity gap and\ntraining instability caused by near-zero probabilities, stemming from the\nhigh-dimensional output of LLMs, remain fundamental limitations. To overcome\nthese challenges, several approaches implicitly or explicitly incorporating\nassistant distribution have recently been proposed. However, the past proposals\nof assistant distributions have been a fragmented approach without a systematic\ninvestigation of the interpolation path and the divergence. This paper proposes\n$\\alpha$-mixture assistant distribution, a novel generalized family of\nassistant distributions, and $\\alpha$-mixture distillation, coined AMiD, a\nunified framework for KD using the assistant distribution. The $\\alpha$-mixture\nassistant distribution provides a continuous extension of the assistant\ndistribution by introducing a new distribution design variable $\\alpha$, which\nhas been fixed in all previous approaches. Furthermore, AMiD generalizes the\nfamily of divergences used with the assistant distributions based on\noptimality, which has also been restricted in previous works. Through extensive\nexperiments, we demonstrate that AMiD offers superior performance and training\nstability by leveraging a broader and theoretically grounded assistant\ndistribution space."}
{"id": "2510.15985", "pdf": "https://arxiv.org/pdf/2510.15985", "abs": "https://arxiv.org/abs/2510.15985", "authors": ["Zexi Tan", "Tao Xie", "Binbin Sun", "Xiang Zhang", "Yiqun Zhang", "Yiu-Ming Cheung"], "title": "MEET-Sepsis: Multi-Endogenous-View Enhanced Time-Series Representation Learning for Early Sepsis Prediction Representation Learning for Early Sepsis Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to PRICAI 2025", "summary": "Sepsis is a life-threatening infectious syndrome associated with high\nmortality in intensive care units (ICUs). Early and accurate sepsis prediction\n(SP) is critical for timely intervention, yet remains challenging due to subtle\nearly manifestations and rapidly escalating mortality. While AI has improved SP\nefficiency, existing methods struggle to capture weak early temporal signals.\nThis paper introduces a Multi-Endogenous-view Representation Enhancement (MERE)\nmechanism to construct enriched feature views, coupled with a Cascaded\nDual-convolution Time-series Attention (CDTA) module for multi-scale temporal\nrepresentation learning. The proposed MEET-Sepsis framework achieves\ncompetitive prediction accuracy using only 20% of the ICU monitoring time\nrequired by SOTA methods, significantly advancing early SP. Extensive\nvalidation confirms its efficacy. Code is available at:\nhttps://github.com/yueliangy/MEET-Sepsis."}
{"id": "2510.15987", "pdf": "https://arxiv.org/pdf/2510.15987", "abs": "https://arxiv.org/abs/2510.15987", "authors": ["Samuel Lippl", "Thomas McGee", "Kimberly Lopez", "Ziwen Pan", "Pierce Zhang", "Salma Ziadi", "Oliver Eberle", "Ida Momennejad"], "title": "Algorithmic Primitives and Compositional Geometry of Reasoning in Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "How do latent and inference time computations enable large language models\n(LLMs) to solve multi-step reasoning? We introduce a framework for tracing and\nsteering algorithmic primitives that underlie model reasoning. Our approach\nlinks reasoning traces to internal activation patterns and evaluates\nalgorithmic primitives by injecting them into residual streams and measuring\ntheir effect on reasoning steps and task performance. We consider four\nbenchmarks: Traveling Salesperson Problem (TSP), 3SAT, AIME, and graph\nnavigation. We operationalize primitives by clustering neural activations and\nlabeling their matched reasoning traces. We then apply function vector methods\nto derive primitive vectors as reusable compositional building blocks of\nreasoning. Primitive vectors can be combined through addition, subtraction, and\nscalar operations, revealing a geometric logic in activation space. Cross-task\nand cross-model evaluations (Phi-4, Phi-4-Reasoning, Llama-3-8B) show both\nshared and task-specific primitives. Notably, comparing Phi-4 with its\nreasoning-finetuned variant highlights compositional generalization after\nfinetuning: Phi-4-Reasoning exhibits more systematic use of verification and\npath-generation primitives. Injecting the associated primitive vectors in\nPhi-4-Base induces behavioral hallmarks associated with Phi-4-Reasoning.\nTogether, these findings demonstrate that reasoning in LLMs may be supported by\na compositional geometry of algorithmic primitives, that primitives transfer\ncross-task and cross-model, and that reasoning finetuning strengthens\nalgorithmic generalization across domains."}
{"id": "2510.15990", "pdf": "https://arxiv.org/pdf/2510.15990", "abs": "https://arxiv.org/abs/2510.15990", "authors": ["Kangqi Ni", "Zhen Tan", "Zijie Liu", "Pingzhi Li", "Tianlong Chen"], "title": "Can GRPO Help LLMs Transcend Their Pretraining Origin?", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR), primarily driven by\nthe Group Relative Policy Optimization (GRPO) algorithm, is a leading approach\nfor enhancing the reasoning abilities of Large Language Models (LLMs). Despite\nits wide adoption, GRPO's gains are often inconsistent; for instance, a model\nmay show significant improvement in one reasoning domain, like mathematics, yet\nremain stagnant in another, such as medicine. This inconsistency raises a\ncritical question: under what conditions does GRPO improve reasoning and\ngeneralize out-of-distribution (OOD)? We investigate this from a data\ndistribution perspective. We first prove theoretically that GRPO is a\nconservative reweighting scheme, bounded by the base model's distribution and\nthus unable to discover completely novel solutions. We further validate this in\ncarefully designed controlled studies by training transformers from scratch,\nevaluating generalization across reasoning depth, input length, token\nrepresentation, and compositionality. Our results provide a principled\nexplanation for GRPO's boundaries: OOD improvement emerges only when the target\ntask aligns with the model's pretrained biases, while gains on in-distribution\n(ID) tasks diminish as performance saturates. This reframes GRPO not as a\nuniversal reasoning enhancer but as a tool that sharpens pretraining biases.\nOur findings motivate future development of algorithms that can expand a\nmodel's capabilities beyond its pretraining origin."}
{"id": "2510.15992", "pdf": "https://arxiv.org/pdf/2510.15992", "abs": "https://arxiv.org/abs/2510.15992", "authors": ["Ziming Dai", "Tuo Zhang", "Fei Gao", "Xingyi Cai", "Xiaofei Wang", "Cheng Zhang", "Wenyu Wang", "Chengjie Zang"], "title": "Stratos: An End-to-End Distillation Pipeline for Customized LLMs under Distributed Cloud Environments", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The growing industrial demand for customized and cost-efficient large\nlanguage models (LLMs) is fueled by the rise of vertical, domain-specific tasks\nand the need to optimize performance under constraints such as latency and\nbudget. Knowledge distillation, as an efficient model compression and transfer\ntechnique, offers a feasible solution. However, existing distillation\nframeworks often require manual intervention and struggle to meet such complex\nuser-defined distillation requirements. To bridge this gap, we propose Stratos,\nan end-to-end LLM distillation pipeline that automates server and model\nselection, knowledge distillation, and deployment in distributed cloud\nenvironments. Given user-defined constraints on model performance and system\nbudget, Stratos automatically selects Pareto-optimal servers, dynamically\nmatches teacher-student pairs, and adapts distillation strategies based on task\ncomplexity to optimize cloud hosting. Experiments show that Stratos produces a\nstudent model that achieves four times the accuracy of its GPT-4o teacher\nbaseline on a rare, domain-specific Mahjong reasoning task with reverse\nsynthetic data and knowledge injection. Moreover, it achieves reduced latency\nand cost without compromising accuracy. These results highlight its promise for\nvertical-domain LLM deployment."}
{"id": "2510.15994", "pdf": "https://arxiv.org/pdf/2510.15994", "abs": "https://arxiv.org/abs/2510.15994", "authors": ["Dongsen Zhang", "Zekun Li", "Xu Luo", "Xuannan Liu", "Peipei Li", "Wenjun Xu"], "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The Model Context Protocol (MCP) standardizes how large language model (LLM)\nagents discover, describe, and call external tools. While MCP unlocks broad\ninteroperability, it also enlarges the attack surface by making tools\nfirst-class, composable objects with natural-language metadata, and\nstandardized I/O. We present MSB (MCP Security Benchmark), the first end-to-end\nevaluation suite that systematically measures how well LLM agents resist\nMCP-specific attacks throughout the full tool-use pipeline: task planning, tool\ninvocation, and response handling. MSB contributes: (1) a taxonomy of 12\nattacks including name-collision, preference manipulation, prompt injections\nembedded in tool descriptions, out-of-scope parameter requests,\nuser-impersonating responses, false-error escalation, tool-transfer, retrieval\ninjection, and mixed attacks; (2) an evaluation harness that executes attacks\nby running real tools (both benign and malicious) via MCP rather than\nsimulation; and (3) a robustness metric that quantifies the trade-off between\nsecurity and performance: Net Resilient Performance (NRP). We evaluate nine\npopular LLM agents across 10 domains and 400+ tools, producing 2,000 attack\ninstances. Results reveal the effectiveness of attacks against each stage of\nMCP. Models with stronger performance are more vulnerable to attacks due to\ntheir outstanding tool calling and instruction following capabilities. MSB\nprovides a practical baseline for researchers and practitioners to study,\ncompare, and harden MCP agents."}
{"id": "2510.15996", "pdf": "https://arxiv.org/pdf/2510.15996", "abs": "https://arxiv.org/abs/2510.15996", "authors": ["Ozan K. Tonguz", "Federico Taschin"], "title": "Using Kolmogorov-Smirnov Distance for Measuring Distribution Shift in Machine Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "One of the major problems in Machine Learning (ML) and Artificial\nIntelligence (AI) is the fact that the probability distribution of the test\ndata in the real world could deviate substantially from the probability\ndistribution of the training data set. When this happens, the predictions of an\nML system or an AI agent could involve large errors which is very troublesome\nand undesirable. While this is a well-known hard problem plaguing the AI and ML\nsystems' accuracy and reliability, in certain applications such errors could be\ncritical for safety and reliability of AI and ML systems. One approach to deal\nwith this problem is to monitor and measure the deviation in the probability\ndistribution of the test data in real time and to compensate for this\ndeviation. In this paper, we propose and explore the use of Kolmogorov-Smirnov\n(KS) Test for measuring the distribution shift and we show how the KS distance\ncan be used to quantify the distribution shift and its impact on an AI agent's\nperformance. Our results suggest that KS distance could be used as a valuable\nstatistical tool for monitoring and measuring the distribution shift. More\nspecifically, it is shown that even a distance of KS=0.02 could lead to about\n50\\% increase in the travel time at a single intersection using a Reinforcement\nLearning agent which is quite significant. It is hoped that the use of KS Test\nand KS distance in AI-based smart transportation could be an important step\nforward for gauging the performance degradation of an AI agent in real time and\nthis, in turn, could help the AI agent to cope with the distribution shift in a\nmore informed manner."}
{"id": "2510.15998", "pdf": "https://arxiv.org/pdf/2510.15998", "abs": "https://arxiv.org/abs/2510.15998", "authors": ["Nilo Schwencke", "Cyriaque Rousselot", "Alena Shilova", "Cyril Furtlehner"], "title": "AMStraMGRAM: Adaptive Multi-cutoff Strategy Modification for ANaGRAM", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent works have shown that natural gradient methods can significantly\noutperform standard optimizers when training physics-informed neural networks\n(PINNs). In this paper, we analyze the training dynamics of PINNs optimized\nwith ANaGRAM, a natural-gradient-inspired approach employing singular value\ndecomposition with cutoff regularization. Building on this analysis, we propose\na multi-cutoff adaptation strategy that further enhances ANaGRAM's performance.\nExperiments on benchmark PDEs validate the effectiveness of our method, which\nallows to reach machine precision on some experiments. To provide theoretical\ngrounding, we develop a framework based on spectral theory that explains the\nnecessity of regularization and extend previous shown connections with Green's\nfunctions theory."}
{"id": "2510.16005", "pdf": "https://arxiv.org/pdf/2510.16005", "abs": "https://arxiv.org/abs/2510.16005", "authors": ["Giacomo Bertollo", "Naz Bodemir", "Jonah Burgess"], "title": "Breaking Guardrails, Facing Walls: Insights on Adversarial AI for Defenders & Researchers", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Analyzing 500 CTF participants, this paper shows that while participants\nreadily bypassed simple AI guardrails using common techniques, layered\nmulti-step defenses still posed significant challenges, offering concrete\ninsights for building safer AI systems."}
{"id": "2510.16007", "pdf": "https://arxiv.org/pdf/2510.16007", "abs": "https://arxiv.org/abs/2510.16007", "authors": ["Ziao Yang", "Longbo Huang", "Hongfu Liu"], "title": "Layer-Aware Influence for Online Data Valuation Estimation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Data-centric learning emphasizes curating high-quality training samples to\nboost performance rather than designing new architectures. A central problem is\nto estimate the influence of training sample efficiently. Prior studies largely\nfocus on static influence measured on a converged model, overlooking how data\nvaluation dynamically changes during optimization. This omission neglects the\ndynamic nature of sample influence during optimization, especially in deep\nmodels. To address the computational burden of frequent influence estimation,\nwe develop a layer-aware online estimator that requires only loss-to-output\ngradients. This design avoids parameter-level and full-network gradients while\npreserving ranking fidelity. Extensive experiments across LLM pretraining,\nfine-tuning, and image classification show our method improves accuracy with\nsubstantially lower time and memory cost, making dynamic data curation\nefficient and scalable in practice."}
{"id": "2510.16017", "pdf": "https://arxiv.org/pdf/2510.16017", "abs": "https://arxiv.org/abs/2510.16017", "authors": ["Ibrahim Sheikh Mohamed", "Abdullah Yahya Abdullah Omaisan"], "title": "InfraGPT Smart Infrastructure: An End-to-End VLM-Based Framework for Detecting and Managing Urban Defects", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.RO"], "comment": null, "summary": "Infrastructure in smart cities is increasingly monitored by networks of\nclosed circuit television (CCTV) cameras. Roads, bridges and tunnels develop\ncracks, potholes, and fluid leaks that threaten public safety and require\ntimely repair. Manual inspection is costly and hazardous, and existing\nautomatic systems typically address individual defect types or provide\nunstructured outputs that cannot directly guide maintenance crews. This paper\nproposes a comprehensive pipeline that leverages street CCTV streams for multi\ndefect detection and segmentation using the YOLO family of object detectors and\npasses the detections to a vision language model (VLM) for scene aware\nsummarization. The VLM generates a structured action plan in JSON format that\nincludes incident descriptions, recommended tools, dimensions, repair plans,\nand urgent alerts. We review literature on pothole, crack and leak detection,\nhighlight recent advances in large vision language models such as QwenVL and\nLLaVA, and describe the design of our early prototype. Experimental evaluation\non public datasets and captured CCTV clips demonstrates that the system\naccurately identifies diverse defects and produces coherent summaries. We\nconclude by discussing challenges and directions for scaling the system to city\nwide deployments."}
{"id": "2510.16024", "pdf": "https://arxiv.org/pdf/2510.16024", "abs": "https://arxiv.org/abs/2510.16024", "authors": ["Abdulrahman Alhaidari", "Balaji Palanisamy", "Prashant Krishnamurthy"], "title": "On-Chain Decentralized Learning and Cost-Effective Inference for DeFi Attack Mitigation", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "comment": "Published in the 7th Conference on Advances in Financial Technologies\n  (AFT 2025)", "summary": "Billions of dollars are lost every year in DeFi platforms by transactions\nexploiting business logic or accounting vulnerabilities. Existing defenses\nfocus on static code analysis, public mempool screening, attacker contract\ndetection, or trusted off-chain monitors, none of which prevents exploits\nsubmitted through private relays or malicious contracts that execute within the\nsame block. We present the first decentralized, fully on-chain learning\nframework that: (i) performs gas-prohibitive computation on Layer-2 to reduce\ncost, (ii) propagates verified model updates to Layer-1, and (iii) enables\ngas-bounded, low-latency inference inside smart contracts. A novel\nProof-of-Improvement (PoIm) protocol governs the training process and verifies\neach decentralized micro update as a self-verifying training transaction.\nUpdates are accepted by \\textit{PoIm} only if they demonstrably improve at\nleast one core metric (e.g., accuracy, F1-score, precision, or recall) on a\npublic benchmark without degrading any of the other core metrics, while\nadversarial proposals get financially penalized through an adaptable test set\nfor evolving threats. We develop quantization and loop-unrolling techniques\nthat enable inference for logistic regression, SVM, MLPs, CNNs, and gated RNNs\n(with support for formally verified decision tree inference) within the\nEthereum block gas limit, while remaining bit-exact to their off-chain\ncounterparts, formally proven in Z3. We curate 298 unique real-world exploits\n(2020 - 2025) with 402 exploit transactions across eight EVM chains,\ncollectively responsible for \\$3.74 B in losses."}
{"id": "2510.16028", "pdf": "https://arxiv.org/pdf/2510.16028", "abs": "https://arxiv.org/abs/2510.16028", "authors": ["Jianzhu Yao", "Hongxu Su", "Taobo Liao", "Zerui Cheng", "Huan Zhang", "Xuechao Wang", "Pramod Viswanath"], "title": "Nondeterminism-Aware Optimistic Verification for Floating-Point Neural Networks", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "17 pages, 7 figures", "summary": "Neural networks increasingly run on hardware outside the user's control\n(cloud GPUs, inference marketplaces). Yet ML-as-a-Service reveals little about\nwhat actually ran or whether returned outputs faithfully reflect the intended\ninputs. Users lack recourse against service downgrades (model swaps,\nquantization, graph rewrites, or discrepancies like altered ad embeddings).\nVerifying outputs is hard because floating-point(FP) execution on heterogeneous\naccelerators is inherently nondeterministic. Existing approaches are either\nimpractical for real FP neural networks or reintroduce vendor trust. We present\nNAO: a Nondeterministic tolerance Aware Optimistic verification protocol that\naccepts outputs within principled operator-level acceptance regions rather than\nrequiring bitwise equality. NAO combines two error models: (i) sound\nper-operator IEEE-754 worst-case bounds and (ii) tight empirical percentile\nprofiles calibrated across hardware. Discrepancies trigger a Merkle-anchored,\nthreshold-guided dispute game that recursively partitions the computation graph\nuntil one operator remains, where adjudication reduces to a lightweight\ntheoretical-bound check or a small honest-majority vote against empirical\nthresholds. Unchallenged results finalize after a challenge window, without\nrequiring trusted hardware or deterministic kernels. We implement NAO as a\nPyTorch-compatible runtime and a contract layer currently deployed on Ethereum\nHolesky testnet. The runtime instruments graphs, computes per-operator bounds,\nand runs unmodified vendor kernels in FP32 with negligible overhead (0.3% on\nQwen3-8B). Across CNNs, Transformers and diffusion models on A100, H100,\nRTX6000, RTX4090, empirical thresholds are $10^2-10^3$ times tighter than\ntheoretical bounds, and bound-aware adversarial attacks achieve 0% success. NAO\nreconciles scalability with verifiability for real-world heterogeneous ML\ncompute."}
{"id": "2510.16034", "pdf": "https://arxiv.org/pdf/2510.16034", "abs": "https://arxiv.org/abs/2510.16034", "authors": ["Bo Li", "Junwei Ma", "Kai Yin", "Yiming Xiao", "Chia-Wei Hsu", "Ali Mostafavi"], "title": "Disaster Management in the Era of Agentic AI Systems: A Vision for Collective Human-Machine Intelligence for Augmented Resilience", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "The escalating frequency and severity of disasters routinely overwhelm\ntraditional response capabilities, exposing critical vulnerability in disaster\nmanagement. Current practices are hindered by fragmented data streams, siloed\ntechnologies, resource constraints, and the erosion of institutional memory,\nwhich collectively impede timely and effective decision making. This study\nintroduces Disaster Copilot, a vision for a multi-agent artificial intelligence\nsystem designed to overcome these systemic challenges by unifying specialized\nAI tools within a collaborative framework. The proposed architecture utilizes a\ncentral orchestrator to coordinate diverse sub-agents, each specializing in\ncritical domains such as predictive risk analytics, situational awareness, and\nimpact assessment. By integrating multi-modal data, the system delivers a\nholistic, real-time operational picture and serve as the essential AI backbone\nrequired to advance Disaster Digital Twins from passive models to active,\nintelligent environments. Furthermore, it ensures functionality in\nresource-limited environments through on-device orchestration and incorporates\nmechanisms to capture institutional knowledge, mitigating the impact of staff\nturnover. We detail the system architecture and propose a three-phased roadmap\nemphasizing the parallel growth of technology, organizational capacity, and\nhuman-AI teaming. Disaster Copilot offers a transformative vision, fostering\ncollective human-machine intelligence to build more adaptive, data-driven and\nresilient communities."}
{"id": "2510.16035", "pdf": "https://arxiv.org/pdf/2510.16035", "abs": "https://arxiv.org/abs/2510.16035", "authors": ["Yingguang Yang", "Xianghua Zeng", "Qi Wu", "Hao Peng", "Yutong Xia", "Hao Liu", "Bin Chong", "Philip S. Yu"], "title": "RoBCtrl: Attacking GNN-Based Social Bot Detectors via Reinforced Manipulation of Bots Control Interaction", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "27 pages, 10 figures", "summary": "Social networks have become a crucial source of real-time information for\nindividuals. The influence of social bots within these platforms has garnered\nconsiderable attention from researchers, leading to the development of numerous\ndetection technologies. However, the vulnerability and robustness of these\ndetection methods is still underexplored. Existing Graph Neural Network\n(GNN)-based methods cannot be directly applied due to the issues of limited\ncontrol over social agents, the black-box nature of bot detectors, and the\nheterogeneity of bots. To address these challenges, this paper proposes the\nfirst adversarial multi-agent Reinforcement learning framework for social Bot\ncontrol attacks (RoBCtrl) targeting GNN-based social bot detectors.\nSpecifically, we use a diffusion model to generate high-fidelity bot accounts\nby reconstructing existing account data with minor modifications, thereby\nevading detection on social platforms. To the best of our knowledge, this is\nthe first application of diffusion models to mimic the behavior of evolving\nsocial bots effectively. We then employ a Multi-Agent Reinforcement Learning\n(MARL) method to simulate bots adversarial behavior. We categorize social\naccounts based on their influence and budget. Different agents are then\nemployed to control bot accounts across various categories, optimizing the\nattachment strategy through reinforcement learning. Additionally, a\nhierarchical state abstraction based on structural entropy is designed to\naccelerate the reinforcement learning. Extensive experiments on social bot\ndetection datasets demonstrate that our framework can effectively undermine the\nperformance of GNN-based detectors."}
{"id": "2510.16037", "pdf": "https://arxiv.org/pdf/2510.16037", "abs": "https://arxiv.org/abs/2510.16037", "authors": ["Peini Cheng", "Amir Bahmani"], "title": "Membership Inference over Diffusion-models-based Synthetic Tabular Data", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "This study investigates the privacy risks associated with diffusion-based\nsynthetic tabular data generation methods, focusing on their susceptibility to\nMembership Inference Attacks (MIAs). We examine two recent models, TabDDPM and\nTabSyn, by developing query-based MIAs based on the step-wise error comparison\nmethod. Our findings reveal that TabDDPM is more vulnerable to these attacks.\nTabSyn exhibits resilience against our attack models. Our work underscores the\nimportance of evaluating the privacy implications of diffusion models and\nencourages further research into robust privacy-preserving mechanisms for\nsynthetic data generation."}
{"id": "2510.16039", "pdf": "https://arxiv.org/pdf/2510.16039", "abs": "https://arxiv.org/abs/2510.16039", "authors": ["Xiangyuan Peng", "Xingsi Dong", "Si Wu"], "title": "Vector Quantization in the Brain: Grid-like Codes in World Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose Grid-like Code Quantization (GCQ), a brain-inspired method for\ncompressing observation-action sequences into discrete representations using\ngrid-like patterns in attractor dynamics. Unlike conventional vector\nquantization approaches that operate on static inputs, GCQ performs\nspatiotemporal compression through an action-conditioned codebook, where\ncodewords are derived from continuous attractor neural networks and dynamically\nselected based on actions. This enables GCQ to jointly compress space and time,\nserving as a unified world model. The resulting representation supports\nlong-horizon prediction, goal-directed planning, and inverse modeling.\nExperiments across diverse tasks demonstrate GCQ's effectiveness in compact\nencoding and downstream performance. Our work offers both a computational tool\nfor efficient sequence modeling and a theoretical perspective on the formation\nof grid-like codes in neural systems."}
{"id": "2510.16040", "pdf": "https://arxiv.org/pdf/2510.16040", "abs": "https://arxiv.org/abs/2510.16040", "authors": ["Tianhua Xia", "Sai Qian Zhang"], "title": "Kelle: Co-design KV Caching and eDRAM for Efficient LLM Serving in Edge Computing", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Running Large Language Models (LLMs) on edge devices is crucial for reducing\nlatency, improving real-time processing, and enhancing privacy. By performing\ninference directly on the device, data does not need to be sent to the cloud,\nensuring faster responses and reducing reliance on network connectivity.\nHowever, implementing LLMs on edge devices presents challenges, particularly\nwith managing key-value (KV) caches, which plays a pivotal role in LLM serving.\nAs the input text lengthens, the size of the KV cache increases linearly with\nthe sequence length, leading to a significant memory footprint and data access\ncosts. On the other hand, edge devices have limited memory and computational\npower, making it hard to store and efficiently access the large caches needed\nfor LLM inference.\n  To mitigate the substantial overhead caused by KV cache, we propose using\nembedded DRAM (eDRAM) as the primary storage for LLM serving in edge device,\nwhich offers higher storage density compared to SRAM. However, to ensure data\nintegrity, eDRAM needs periodic refresh operations, which are power-intensive.\nTo reduce eDRAM costs and improve overall system performance, we\npropose~\\textit{Kelle}, a software-hardware co-design solution optimized for\ndeploying LLMs on eDRAM-based edge systems. Combined with our fine-grained\nmemory eviction, recomputation, and refresh control algorithms, the\n\\textit{Kelle} accelerator delivers a $3.9\\times$ speedup and $4.5\\times$\nenergy savings compared to existing baseline solutions."}
{"id": "2510.16042", "pdf": "https://arxiv.org/pdf/2510.16042", "abs": "https://arxiv.org/abs/2510.16042", "authors": ["Marcin Korecki", "Cesare Carissimo"], "title": "Does Capital Dream of Artificial Labour?", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "This paper investigates the concept of Labour as an expression of `timenergy'\n- a fusion of time and energy - and its entanglement within the system of\nCapital. We define Labour as the commodified, quantifiable expansion of\ntimenergy, in contrast to Capital, which is capable of accumulation and\nabstraction. We explore Labour's historical evolution, its coercive and\nalienating nature, and its transformation through automation and artificial\nintelligence. Using a game-theoretic, agent-based simulation, we model\ninteractions between Capital and Labour in production processes governed by\nCobb-Douglas functions. Our results show that despite theoretical symmetry,\nlearning agents disproportionately gravitate toward capital-intensive\nprocesses, revealing Capital's superior organizational influence due to its\naccumulative capacity. We argue that Capital functions as an artificially alive\nsystem animated by the living Labour it consumes, and question whether life can\nsustain itself without the infrastructures of Capital in a future of increasing\nautomation. This study offers both a critique of and a framework for\nunderstanding Labour's subjugation within the Capital system."}
{"id": "2510.16045", "pdf": "https://arxiv.org/pdf/2510.16045", "abs": "https://arxiv.org/abs/2510.16045", "authors": ["Mengtao Lv", "Ruiqi Zhu", "Xinyu Wang", "Yun Li"], "title": "AMS-QUANT: Adaptive Mantissa Sharing for Floating-point Quantization", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 6 figures", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious kinds of tasks, while the billion or even trillion parameters bring\nstorage and efficiency bottlenecks for inference. Quantization, particularly\nfloating-point quantization, is known to be capable of speeding up LLM\ninference by reducing memory footprint and data movement during the inference\nprocess. For the first time, we advance the floating-point quantization\nexploration from integer bitwidths to non-integer bit-widths, namely AMS-Quant,\nto further approach the quantization sweet spot. AMS-Quant incorporates two\nnovel techniques to put it into effect: (1) it proposes Mantissa-bit Sharing,\nwhich groups k quantized weights and lets them share the least significant\nmantissa bit, allowing us to further approach the minimum quantization\nbit-width without accuracy loss. (2) It introduces Adaptive Searching, which\nemploys an offline optimization strategy to minimize the accuracy degradation\nintroduced by sharing. Moreover, AMS-Quant is also prototyped as efficient CUDA\nLinear kernels, which translates memory savings into wall-clock latency\nreduction by reducing memory access. Extensive experiments on large-scale\ndatasets and models show that AMS-Quant can quantize the model to FP-5.33-e2m3\nand FP4.25-e2m2, and significantly speed up the LLM decoding over FP16\ninference (2.8x and 3.2x), with negligible accuracy loss."}
{"id": "2510.16048", "pdf": "https://arxiv.org/pdf/2510.16048", "abs": "https://arxiv.org/abs/2510.16048", "authors": ["David Atkinson"], "title": "Open Shouldn't Mean Exempt: Open-Source Exceptionalism and Generative AI", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Any argument that open-source generative artificial intelligence (GenAI) is\ninherently ethical or legal solely because it is open source is flawed. Yet,\nthis is the explicit or implicit stance of several open-source GenAI entities.\nThis paper critically examines prevalent justifications for \"open-source\nexceptionalism,\" demonstrating how contemporary open-source GenAI often\ninadvertently facilitates unlawful conduct and environmental degradation\nwithout genuinely disrupting established oligopolies. Furthermore, the paper\nexposes the unsubstantiated and strategic deployment of \"democratization\" and\n\"innovation\" rhetoric to advocate for regulatory exemptions not afforded to\nproprietary systems.\n  The conclusion is that open-source developers must be held to the same legal\nand ethical standards as all other actors in the technological ecosystem.\nHowever, the paper proposes a narrowly tailored safe harbor designed to protect\nlegitimate, non-commercial scientific research, contingent upon adherence to\nspecific criteria. Ultimately, this paper advocates for a framework of\nresponsible AI development, wherein openness is pursued within established\nethical and legal boundaries, with due consideration for its broader societal\nimplications."}
{"id": "2510.16049", "pdf": "https://arxiv.org/pdf/2510.16049", "abs": "https://arxiv.org/abs/2510.16049", "authors": ["David Atkinson"], "title": "In the Mood to Exclude: Revitalizing Trespass to Chattels in the Era of GenAI Scraping", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper argues that website owners have the right to exclude others from\ntheir websites. Accordingly, when generative AI (GenAI) scraping bots\nintentionally circumvent reasonable technological barriers, their conduct could\nbe actionable as trespass to chattels. If the scraping leads to a decrease in\nthe website's value, then trespass to chattels should apply. The prevailing\njudicial focus on website content and the dismissal of trespass claims absent\nproof of server impairment or user disruption misconstrues the nature of the\nwebsite itself as a form of digital property, focusing too narrowly on what\nconstitutes harm under a claim of trespass. By shifting analysis from content\nto the website itself as an integrated digital asset and illustrating the harm\nto the value of the chattel, this paper demonstrates that the right to exclude\napplies online with the same force as it does to tangible property.\n  Courts and litigants have struggled to police large-scale scraping because\ncopyright preemption narrows available claims, leaving copyright and its fair\nuse defense as the primary battleground. In contrast, recognizing websites as\npersonal property revives trespass to chattels as a meaningful cause of action,\nproviding website owners with an enforceable exclusionary right. Such\nprotection would disincentivize exploitative scraping, preserve incentives for\ncontent creation, aid in protecting privacy and personal data, and safeguard\nvalues of autonomy and expression. Ultimately, this paper contends that\nreaffirming website owners' right to exclude is essential to maintaining a fair\nand sustainable online environment."}
{"id": "2510.16051", "pdf": "https://arxiv.org/pdf/2510.16051", "abs": "https://arxiv.org/abs/2510.16051", "authors": ["Sofiya Garkot", "Maksym Shamrai", "Ivan Synytsia", "Mariya Hirna"], "title": "GUIrilla: A Scalable Framework for Automated Desktop UI Exploration", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": "22 pages", "summary": "Autonomous agents capable of operating complex graphical user interfaces\n(GUIs) have the potential to transform desktop automation. While recent\nadvances in large language models (LLMs) have significantly improved UI\nunderstanding, navigating full-window, multi-application desktop environments\nremains a major challenge. Data availability is limited by costly manual\nannotation, closed-source datasets and surface-level synthetic pipelines. We\nintroduce GUIrilla, an automated scalable framework that systematically\nexplores applications via native accessibility APIs to address the critical\ndata collection challenge in GUI automation. Our framework focuses on macOS -\nan ecosystem with limited representation in current UI datasets - though many\nof its components are designed for broader cross-platform applicability.\nGUIrilla organizes discovered interface elements and crawler actions into\nhierarchical GUI graphs and employs specialized interaction handlers to achieve\ncomprehensive application coverage. Using the application graphs from GUIrilla\ncrawler, we construct and release GUIrilla-Task, a large-scale dataset of\n27,171 functionally grounded tasks across 1,108 macOS applications, each\nannotated with full-desktop and window-level screenshots, accessibility\nmetadata, and semantic action traces. Empirical results show that tuning\nLLM-based agents on GUIrilla-Task significantly improves performance on\ndownstream UI tasks, outperforming synthetic baselines on the ScreenSpot Pro\nbenchmark while using 97% less data. We also release macapptree, an open-source\nlibrary for reproducible collection of structured accessibility metadata, along\nwith the full GUIrilla-Task dataset, the manually verified GUIrilla-Gold\nbenchmark, and the framework code to support open research in desktop autonomy."}
{"id": "2510.16053", "pdf": "https://arxiv.org/pdf/2510.16053", "abs": "https://arxiv.org/abs/2510.16053", "authors": ["Chenyang Yu", "Xinpeng Xie", "Yan Huang", "Chenxi Qiu"], "title": "FUSE-Traffic: Fusion of Unstructured and Structured Data for Event-aware Traffic Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate traffic forecasting is a core technology for building Intelligent\nTransportation Systems (ITS), enabling better urban resource allocation and\nimproved travel experiences. With growing urbanization, traffic congestion has\nintensified, highlighting the need for reliable and responsive forecasting\nmodels. In recent years, deep learning, particularly Graph Neural Networks\n(GNNs), has emerged as the mainstream paradigm in traffic forecasting. GNNs can\neffectively capture complex spatial dependencies in road network topology and\ndynamic temporal evolution patterns in traffic flow data. Foundational models\nsuch as STGCN and GraphWaveNet, along with more recent developments including\nSTWave and D2STGNN, have achieved impressive performance on standard traffic\ndatasets. These approaches incorporate sophisticated graph convolutional\nstructures and temporal modeling mechanisms, demonstrating particular\neffectiveness in capturing and forecasting traffic patterns characterized by\nperiodic regularities. To address this challenge, researchers have explored\nvarious ways to incorporate event information. Early attempts primarily relied\non manually engineered event features. For instance, some approaches introduced\nmanually defined incident effect scores or constructed specific subgraphs for\ndifferent event-induced traffic conditions. While these methods somewhat\nenhance responsiveness to specific events, their core drawback lies in a heavy\nreliance on domain experts' prior knowledge, making generalization to diverse\nand complex unknown events difficult, and low-dimensional manual features often\nlead to the loss of rich semantic details."}
{"id": "2510.16056", "pdf": "https://arxiv.org/pdf/2510.16056", "abs": "https://arxiv.org/abs/2510.16056", "authors": ["Muhammad Aurangzeb Ahmad"], "title": "Algorithmic Fairness in AI Surrogates for End-of-Life Decision-Making", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Artificial intelligence surrogates are systems designed to infer preferences\nwhen individuals lose decision-making capacity. Fairness in such systems is a\ndomain that has been insufficiently explored. Traditional algorithmic fairness\nframeworks are insufficient for contexts where decisions are relational,\nexistential, and culturally diverse. This paper explores an ethical framework\nfor algorithmic fairness in AI surrogates by mapping major fairness notions\nonto potential real-world end-of-life scenarios. It then examines fairness\nacross moral traditions. The authors argue that fairness in this domain extends\nbeyond parity of outcomes to encompass moral representation, fidelity to the\npatient's values, relationships, and worldview."}
{"id": "2510.16057", "pdf": "https://arxiv.org/pdf/2510.16057", "abs": "https://arxiv.org/abs/2510.16057", "authors": ["Md Kamrul Siam", "Md Jobair Hossain Faruk", "Jerry Q. Cheng", "Huanying Gu"], "title": "Fusion-Augmented Large Language Models: Boosting Diagnostic Trustworthiness via Model Consensus", "categories": ["cs.CL", "cs.AI"], "comment": "7 pages (Accepted to IEEE BHI 2025)", "summary": "This study presents a novel multi-model fusion framework leveraging two\nstate-of-the-art large language models (LLMs), ChatGPT and Claude, to enhance\nthe reliability of chest X-ray interpretation on the CheXpert dataset. From the\nfull CheXpert corpus of 224,316 chest radiographs, we randomly selected 234\nradiologist-annotated studies to evaluate unimodal performance using image-only\nprompts. In this setting, ChatGPT and Claude achieved diagnostic accuracies of\n62.8% and 76.9%, respectively. A similarity-based consensus approach, using a\n95% output similarity threshold, improved accuracy to 77.6%. To assess the\nimpact of multimodal inputs, we then generated synthetic clinical notes\nfollowing the MIMIC-CXR template and evaluated a separate subset of 50 randomly\nselected cases paired with both images and synthetic text. On this multimodal\ncohort, performance improved to 84% for ChatGPT and 76% for Claude, while\nconsensus accuracy reached 91.3%. Across both experimental conditions,\nagreement-based fusion consistently outperformed individual models. These\nfindings highlight the utility of integrating complementary modalities and\nusing output-level consensus to improve the trustworthiness and clinical\nutility of AI-assisted radiological diagnosis, offering a practical path to\nreduce diagnostic errors with minimal computational overhead."}
{"id": "2510.16060", "pdf": "https://arxiv.org/pdf/2510.16060", "abs": "https://arxiv.org/abs/2510.16060", "authors": ["Coen Adler", "Yuxin Chang", "Felix Draxler", "Samar Abdi", "Padhraic Smyth"], "title": "Beyond Accuracy: Are Time Series Foundation Models Well-Calibrated?", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": null, "summary": "The recent development of foundation models for time series data has\ngenerated considerable interest in using such models across a variety of\napplications. Although foundation models achieve state-of-the-art predictive\nperformance, their calibration properties remain relatively underexplored,\ndespite the fact that calibration can be critical for many practical\napplications. In this paper, we investigate the calibration-related properties\nof five recent time series foundation models and two competitive baselines. We\nperform a series of systematic evaluations assessing model calibration (i.e.,\nover- or under-confidence), effects of varying prediction heads, and\ncalibration under long-term autoregressive forecasting. We find that time\nseries foundation models are consistently better calibrated than baseline\nmodels and tend not to be either systematically over- or under-confident, in\ncontrast to the overconfidence often seen in other deep learning models."}
{"id": "2510.16062", "pdf": "https://arxiv.org/pdf/2510.16062", "abs": "https://arxiv.org/abs/2510.16062", "authors": ["Guiyao Tie", "Zenghui Yuan", "Zeli Zhao", "Chaoran Hu", "Tianhe Gu", "Ruihang Zhang", "Sizhe Zhang", "Junran Wu", "Xiaoyue Tu", "Ming Jin", "Qingsong Wen", "Lixing Chen", "Pan Zhou", "Lichao Sun"], "title": "Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "38 pages, 25 figures, 8 tables", "summary": "Self-correction of large language models (LLMs) emerges as a critical\ncomponent for enhancing their reasoning performance. Although various\nself-correction methods have been proposed, a comprehensive evaluation of these\nmethods remains largely unexplored, and the question of whether LLMs can truly\ncorrect themselves is a matter of significant interest and concern. In this\nstudy, we introduce CorrectBench, a benchmark developed to evaluate the\neffectiveness of self-correction strategies, including intrinsic, external, and\nfine-tuned approaches, across three tasks: commonsense reasoning, mathematical\nreasoning, and code generation. Our findings reveal that: 1) Self-correction\nmethods can improve accuracy, especially for complex reasoning tasks; 2) Mixing\ndifferent self-correction strategies yields further improvements, though it\nreduces efficiency; 3) Reasoning LLMs (e.g., DeepSeek-R1) have limited\noptimization under additional self-correction methods and have high time costs.\nInterestingly, a comparatively simple chain-of-thought (CoT) baseline\ndemonstrates competitive accuracy and efficiency. These results underscore the\npotential of self-correction to enhance LLM's reasoning performance while\nhighlighting the ongoing challenge of improving their efficiency. Consequently,\nwe advocate for further research focused on optimizing the balance between\nreasoning capabilities and operational efficiency. Project Page:\nhttps://correctbench.github.io/"}
{"id": "2510.16063", "pdf": "https://arxiv.org/pdf/2510.16063", "abs": "https://arxiv.org/abs/2510.16063", "authors": ["Muhy Eddin Za'ter", "Bri-Mathias Hodge"], "title": "Learning a Generalized Model for Substation Level Voltage Estimation in Distribution Networks", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Accurate voltage estimation in distribution networks is critical for\nreal-time monitoring and increasing the reliability of the grid. As DER\npenetration and distribution level voltage variability increase, robust\ndistribution system state estimation (DSSE) has become more essential to\nmaintain safe and efficient operations. Traditional DSSE techniques, however,\nstruggle with sparse measurements and the scale of modern feeders, limiting\ntheir scalability to large networks. This paper presents a hierarchical graph\nneural network for substation-level voltage estimation that exploits both\nelectrical topology and physical features, while remaining robust to the low\nobservability levels common to real-world distribution networks. Leveraging the\npublic SMART-DS datasets, the model is trained and evaluated on thousands of\nbuses across multiple substations and DER penetration scenarios. Comprehensive\nexperiments demonstrate that the proposed method achieves up to 2 times lower\nRMSE than alternative data-driven models, and maintains high accuracy with as\nlittle as 1\\% measurement coverage. The results highlight the potential of GNNs\nto enable scalable, reproducible, and data-driven voltage monitoring for\ndistribution systems."}
{"id": "2510.16064", "pdf": "https://arxiv.org/pdf/2510.16064", "abs": "https://arxiv.org/abs/2510.16064", "authors": ["Muhy Eddin Za'ter", "Bri-Mathias Hodge", "Kyri Baker"], "title": "Residual Correction Models for AC Optimal Power Flow Using DC Optimal Power Flow Solutions", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Solving the nonlinear AC optimal power flow (AC OPF) problem remains a major\ncomputational bottleneck for real-time grid operations. In this paper, we\npropose a residual learning paradigm that uses fast DC optimal power flow (DC\nOPF) solutions as a baseline, and learns only the nonlinear corrections\nrequired to provide the full AC-OPF solution. The method utilizes a\ntopology-aware Graph Neural Network with local attention and two-level DC\nfeature integration, trained using a physics-informed loss that enforces AC\npower-flow feasibility and operational limits. Evaluations on OPFData for 57-,\n118-, and 2000-bus systems show around 25% lower MSE, up to 3X reduction in\nfeasibility error, and up to 13X runtime speedup compared to conventional AC\nOPF solvers. The model maintains accuracy under N-1 contingencies and scales\nefficiently to large networks. These results demonstrate that residual learning\nis a practical and scalable bridge between linear approximations and\nAC-feasible OPF, enabling near real-time operational decision making."}
{"id": "2510.16065", "pdf": "https://arxiv.org/pdf/2510.16065", "abs": "https://arxiv.org/abs/2510.16065", "authors": ["Lunchen Xie", "Zehua He", "Qingjiang Shi"], "title": "FedPURIN: Programmed Update and Reduced INformation for Sparse Personalized Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Personalized Federated Learning (PFL) has emerged as a critical research\nfrontier addressing data heterogeneity issue across distributed clients. Novel\nmodel architectures and collaboration mechanisms are engineered to accommodate\nstatistical disparities while producing client-specific models. Parameter\ndecoupling represents a promising paradigm for maintaining model performance in\nPFL frameworks. However, the communication efficiency of many existing methods\nremains suboptimal, sustaining substantial communication burdens that impede\npractical deployment. To bridge this gap, we propose Federated Learning with\nProgrammed Update and Reduced INformation (FedPURIN), a novel framework that\nstrategically identifies critical parameters for transmission through an\ninteger programming formulation. This mathematically grounded strategy is\nseamlessly integrated into a sparse aggregation scheme, achieving a significant\ncommunication reduction while preserving the efficacy. Comprehensive\nevaluations on standard image classification benchmarks under varied non-IID\nconditions demonstrate competitive performance relative to state-of-the-art\nmethods, coupled with quantifiable communication reduction through sparse\naggregation. The framework establishes a new paradigm for\ncommunication-efficient PFL, particularly advantageous for edge intelligence\nsystems operating with heterogeneous data sources."}
{"id": "2510.16066", "pdf": "https://arxiv.org/pdf/2510.16066", "abs": "https://arxiv.org/abs/2510.16066", "authors": ["Chun Chet Ng", "Wei Zeng Low", "Yin Yin Boon"], "title": "Cash Flow Underwriting with Bank Transaction Data: Advancing MSME Financial Inclusion in Malaysia", "categories": ["q-fin.ST", "cs.AI", "cs.CE", "cs.CY", "cs.LG", "q-fin.RM"], "comment": "Accepted at the FinREM Workshop, ICAIF 2025", "summary": "Despite accounting for 96.1% of all businesses in Malaysia, access to\nfinancing remains one of the most persistent challenges faced by Micro, Small,\nand Medium Enterprises (MSMEs). Newly established or young businesses are often\nexcluded from formal credit markets as traditional underwriting approaches rely\nheavily on credit bureau data. This study investigates the potential of bank\nstatement data as an alternative data source for credit assessment to promote\nfinancial inclusion in emerging markets. Firstly, we propose a cash flow-based\nunderwriting pipeline where we utilise bank statement data for end to end data\nextraction and machine learning credit scoring. Secondly, we introduce a novel\ndataset of 611 loan applicants from a Malaysian lending institution. Thirdly,\nwe develop and evaluate credit scoring models based on application information\nand bank transaction-derived features. Empirical results show that the use of\nsuch data boosts the performance of all models on our dataset, which can\nimprove credit scoring for new-to-lending MSMEs. Lastly, we intend to release\nthe anonymised bank transaction dataset to facilitate further research on MSMEs\nfinancial inclusion within Malaysia's emerging economy."}
{"id": "2510.16068", "pdf": "https://arxiv.org/pdf/2510.16068", "abs": "https://arxiv.org/abs/2510.16068", "authors": ["Wei Ting Liow", "Sumbul Khan", "Lay Kee Ang"], "title": "Co-Designing Interdisciplinary Design Projects with AI", "categories": ["cs.CY", "cs.AI"], "comment": "to be published in IEEE TALE 2025", "summary": "Creating interdisciplinary design projects is time-consuming and cognitively\ndemanding for teachers, requiring curriculum alignment, cross-subject\nintegration, and careful sequencing. International research reports increasing\nteacher use of AI alongside persistent workload pressures, underscoring the\nneed for planning support. This paper presents the Interdisciplinary Design\nProject Planner (IDPplanner), a GPT-based planning assistant grounded in Design\nInnovation principles, alignment with Singapore secondary school syllabuses,\nand 21st-century competencies. In a within-subject, counterbalanced workshop\nwith 33 in-service teachers, participants produced two versions of the same\nproject: manual and AI-assisted, followed by self- and peer-evaluations using a\nsix-dimensional rubric. The AI-assisted version received higher scores for\nCurriculum Alignment, Design Thinking Application, and Coherence and Flow, with\na marginal advantage for Assessment Strategies. Teacher reflections indicated\nthat AI-assisted planning improved structure, sequencing, and idea generation,\nwhile contextualization to local syllabuses, class profiles, and student needs\nremained teacher-led. Contributions include a purpose-built planning tool that\norganizes ideas into a ten-component flow with ready-to-adapt prompts,\ntemplates, and assessment suggestions; an empirical, rubric-based comparison of\nplanning quality; and evidence that AI can function as a pedagogical planning\npartner. Recommendations emphasize hybrid teacher-AI workflows to enhance\ncurriculum alignment and reduce planning complexity, and design suggestions for\ndevelopers to strengthen contextual customization, iterative design support,\nand localized rubrics. Although instantiated with a Singapore-based curriculum,\nthe planning flow and rubric are framework-agnostic and can be parameterized\nfor other systems."}
{"id": "2510.16069", "pdf": "https://arxiv.org/pdf/2510.16069", "abs": "https://arxiv.org/abs/2510.16069", "authors": ["Sumbul Khan", "Wei Ting Liow", "Lay Kee Ang"], "title": "Human or AI? Comparing Design Thinking Assessments by Teaching Assistants and Bots", "categories": ["cs.CY", "cs.AI"], "comment": "to be published in IEEE TALE 2025", "summary": "As design thinking education grows in secondary and tertiary contexts,\neducators face the challenge of evaluating creative artefacts that combine\nvisual and textual elements. Traditional rubric-based assessment is laborious,\ntime-consuming, and inconsistent due to reliance on Teaching Assistants (TA) in\nlarge, multi-section cohorts. This paper presents an exploratory study\ninvestigating the reliability and perceived accuracy of AI-assisted assessment\ncompared to TA-assisted assessment in evaluating student posters in design\nthinking education. Two activities were conducted with 33 Ministry of Education\n(MOE) Singapore school teachers to (1) compare AI-generated scores with TA\ngrading across three key dimensions: empathy and user understanding,\nidentification of pain points and opportunities, and visual communication, and\n(2) examine teacher preferences for AI-assigned, TA-assigned, and hybrid\nscores. Results showed low statistical agreement between instructor and AI\nscores for empathy and pain points, with slightly higher alignment for visual\ncommunication. Teachers preferred TA-assigned scores in six of ten samples.\nQualitative feedback highlighted the potential of AI for formative feedback,\nconsistency, and student self-reflection, but raised concerns about its\nlimitations in capturing contextual nuance and creative insight. The study\nunderscores the need for hybrid assessment models that integrate computational\nefficiency with human insights. This research contributes to the evolving\nconversation on responsible AI adoption in creative disciplines, emphasizing\nthe balance between automation and human judgment for scalable and\npedagogically sound assessment."}
{"id": "2510.16070", "pdf": "https://arxiv.org/pdf/2510.16070", "abs": "https://arxiv.org/abs/2510.16070", "authors": ["Mahta Khoobi", "Marc Sebastian von der Stueck", "Felix Barajas Ordonez", "Anca-Maria Iancu", "Eric Corban", "Julia Nowak", "Aleksandar Kargaliev", "Valeria Perelygina", "Anna-Sophie Schott", "Daniel Pinto dos Santos", "Christiane Kuhl", "Daniel Truhn", "Sven Nebelung", "Robert Siepmann"], "title": "Effect of Reporting Mode and Clinical Experience on Radiologists' Gaze and Image Analysis Behavior in Chest Radiography", "categories": ["cs.CV", "cs.AI", "cs.HC", "eess.IV", "H.5.5; H.1.2; I.4.0"], "comment": "Preprint version - Under second revision at Radiology (manuscript\n  RAD-25-1348)", "summary": "Structured reporting (SR) and artificial intelligence (AI) may transform how\nradiologists interact with imaging studies. This prospective study (July to\nDecember 2024) evaluated the impact of three reporting modes: free-text (FT),\nstructured reporting (SR), and AI-assisted structured reporting (AI-SR), on\nimage analysis behavior, diagnostic accuracy, efficiency, and user experience.\nFour novice and four non-novice readers (radiologists and medical students)\neach analyzed 35 bedside chest radiographs per session using a customized\nviewer and an eye-tracking system. Outcomes included diagnostic accuracy\n(compared with expert consensus using Cohen's $\\kappa$), reporting time per\nradiograph, eye-tracking metrics, and questionnaire-based user experience.\nStatistical analysis used generalized linear mixed models with Bonferroni\npost-hoc tests with a significance level of ($P \\le .01$). Diagnostic accuracy\nwas similar in FT ($\\kappa = 0.58$) and SR ($\\kappa = 0.60$) but higher in\nAI-SR ($\\kappa = 0.71$, $P < .001$). Reporting times decreased from $88 \\pm 38$\ns (FT) to $37 \\pm 18$ s (SR) and $25 \\pm 9$ s (AI-SR) ($P < .001$). Saccade\ncounts for the radiograph field ($205 \\pm 135$ (FT), $123 \\pm 88$ (SR), $97 \\pm\n58$ (AI-SR)) and total fixation duration for the report field ($11 \\pm 5$ s\n(FT), $5 \\pm 3$ s (SR), $4 \\pm 1$ s (AI-SR)) were lower with SR and AI-SR ($P <\n.001$ each). Novice readers shifted gaze towards the radiograph in SR, while\nnon-novice readers maintained their focus on the radiograph. AI-SR was the\npreferred mode. In conclusion, SR improves efficiency by guiding visual\nattention toward the image, and AI-prefilled SR further enhances diagnostic\naccuracy and user satisfaction."}
{"id": "2510.16071", "pdf": "https://arxiv.org/pdf/2510.16071", "abs": "https://arxiv.org/abs/2510.16071", "authors": ["Qinxuan Wang", "Chuang Wang", "Mingyu Zhang", "Jingwei Sun", "Peipei Yang", "Shuo Tang", "Shiming Xiang"], "title": "MNO: Multiscale Neural Operator for Computational Fluid Dynamics with 3D Point Cloud Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neural operators have emerged as a powerful data-driven paradigm for solving\nPartial Differential Equations (PDEs), offering orders-of-magnitude\nacceleration over traditional solvers. However, existing approaches still\nsuffer from limited accuracy and scalability, particularly on irregular domains\nwhere fluid flows exhibit rich multiscale structures. In this work, we\nintroduce the Multiscale Neural Operator (MNO), a new architecture for\nComputational Fluid Dynamics (CFD) on three-dimensional (3D) unstructured point\nclouds. MNO explicitly decomposes information across three scales: a global\ndimension-shrinkage attention module for long-range dependencies, a local graph\nattention module for neighborhood-level interactions, and a micro point-wise\nattention module for fine-grained details. This design preserves multiscale\ninductive biases while remaining computationally efficient. We evaluate MNO on\nfour diverse benchmarks, covering both steady-state and unsteady flow scenarios\nwith up to 300K points. Across all tasks, MNO consistently outperforms\nstate-of-the-art baselines, reducing prediction errors by 5% to 40% and\ndemonstrating improved robustness in challenging 3D CFD problems. Our results\nhighlight the importance of explicit multiscale design for neural operators and\nestablish MNO as a scalable framework for learning complex fluid dynamics on\nirregular domains."}
{"id": "2510.16072", "pdf": "https://arxiv.org/pdf/2510.16072", "abs": "https://arxiv.org/abs/2510.16072", "authors": ["Farjana Yesmin"], "title": "Data-Driven Analysis of Intersectional Bias in Image Classification: A Framework with Bias-Weighted Augmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "18 pages", "summary": "Machine learning models trained on imbalanced datasets often exhibit\nintersectional biases-systematic errors arising from the interaction of\nmultiple attributes such as object class and environmental conditions. This\npaper presents a data-driven framework for analyzing and mitigating such biases\nin image classification. We introduce the Intersectional Fairness Evaluation\nFramework (IFEF), which combines quantitative fairness metrics with\ninterpretability tools to systematically identify bias patterns in model\npredictions. Building on this analysis, we propose Bias-Weighted Augmentation\n(BWA), a novel data augmentation strategy that adapts transformation\nintensities based on subgroup distribution statistics. Experiments on the Open\nImages V7 dataset with five object classes demonstrate that BWA improves\naccuracy for underrepresented class-environment intersections by up to 24\npercentage points while reducing fairness metric disparities by 35%.\nStatistical analysis across multiple independent runs confirms the significance\nof improvements (p < 0.05). Our methodology provides a replicable approach for\nanalyzing and addressing intersectional biases in image classification systems."}
{"id": "2510.16074", "pdf": "https://arxiv.org/pdf/2510.16074", "abs": "https://arxiv.org/abs/2510.16074", "authors": ["Jing He", "Hua Jiang", "Cheng Li", "Siqian Xin", "Shuzhen Yang"], "title": "Early-stopping for Transformer model training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This work introduces a novel theoretical framework grounded in Random Matrix\nTheory (RMT) for analyzing Transformer training dynamics. We focus on the\nunderlying mechanisms that drive performance improvements and derive principled\nearly-stopping criteria. Empirically, we observe that the spectral density of\nthe shallow self-attention matrix V consistently evolves into a heavy-tailed\ndistribution. Utilizing the PL (Power Law) fit to this matrix as a probe, we\ndemarcate training into three stages: structural exploration, heavy-tailed\nstructure stabilization, and convergence saturation. This staging provides\nguidance for preliminary stopping decisions. Crucially, we propose two\nconsistent and validation-free criteria: a quantitative metric for heavy-tailed\ndynamics and a novel spectral signature indicative of convergence. The strong\nalignment between these criteria highlights the utility of RMT for monitoring\nand diagnosing the progression of Transformer model training."}
{"id": "2510.16075", "pdf": "https://arxiv.org/pdf/2510.16075", "abs": "https://arxiv.org/abs/2510.16075", "authors": ["Sergio MuÃ±iz SubiÃ±as", "Manuel L. GonzÃ¡lez", "Jorge Ruiz GÃ³mez", "Alejandro Mata Ali", "Jorge MartÃ­nez MartÃ­n", "Miguel Franco Hernando", "Ãngel Miguel GarcÃ­a-Vico"], "title": "Optimization of the quantization of dense neural networks from an exact QUBO formulation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This work introduces a post-training quantization (PTQ) method for dense\nneural networks via a novel ADAROUND-based QUBO formulation. Using the\nFrobenius distance between the theoretical output and the dequantized output\n(before the activation function) as the objective, an explicit QUBO whose\nbinary variables represent the rounding choice for each weight and bias is\nobtained. Additionally, by exploiting the structure of the coefficient QUBO\nmatrix, the global problem can be exactly decomposed into $n$ independent\nsubproblems of size $f+1$, which can be efficiently solved using some\nheuristics such as simulated annealing. The approach is evaluated on MNIST,\nFashion-MNIST, EMNIST, and CIFAR-10 across integer precisions from int8 to int1\nand compared with a round-to-nearest traditional quantization methodology."}
{"id": "2510.16076", "pdf": "https://arxiv.org/pdf/2510.16076", "abs": "https://arxiv.org/abs/2510.16076", "authors": ["SeongKu Kang", "Jianxun Lian", "Dongha Lee", "Wonbin Kweon", "Sanghwan Jang", "Jaehyun Lee", "Jindong Wang", "Xing Xie", "Hwanjo Yu"], "title": "BPL: Bias-adaptive Preference Distillation Learning for Recommender System", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Recommender systems suffer from biases that cause the collected feedback to\nincompletely reveal user preference. While debiasing learning has been\nextensively studied, they mostly focused on the specialized (called\ncounterfactual) test environment simulated by random exposure of items,\nsignificantly degrading accuracy in the typical (called factual) test\nenvironment based on actual user-item interactions. In fact, each test\nenvironment highlights the benefit of a different aspect: the counterfactual\ntest emphasizes user satisfaction in the long-terms, while the factual test\nfocuses on predicting subsequent user behaviors on platforms. Therefore, it is\ndesirable to have a model that performs well on both tests rather than only\none. In this work, we introduce a new learning framework, called Bias-adaptive\nPreference distillation Learning (BPL), to gradually uncover user preferences\nwith dual distillation strategies. These distillation strategies are designed\nto drive high performance in both factual and counterfactual test environments.\nEmploying a specialized form of teacher-student distillation from a biased\nmodel, BPL retains accurate preference knowledge aligned with the collected\nfeedback, leading to high performance in the factual test. Furthermore, through\nself-distillation with reliability filtering, BPL iteratively refines its\nknowledge throughout the training process. This enables the model to produce\nmore accurate predictions across a broader range of user-item combinations,\nthereby improving performance in the counterfactual test. Comprehensive\nexperiments validate the effectiveness of BPL in both factual and\ncounterfactual tests. Our implementation is accessible via:\nhttps://github.com/SeongKu-Kang/BPL."}
{"id": "2510.16077", "pdf": "https://arxiv.org/pdf/2510.16077", "abs": "https://arxiv.org/abs/2510.16077", "authors": ["Naeem Paeedeh", "Mahardhika Pratama", "Weiping Ding", "Jimmy Cao", "Wolfgang Mayer", "Ryszard Kowalczyk"], "title": "Continual Knowledge Consolidation LORA for Domain Incremental Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Domain Incremental Learning (DIL) is a continual learning sub-branch that\naims to address never-ending arrivals of new domains without catastrophic\nforgetting problems. Despite the advent of parameter-efficient fine-tuning\n(PEFT) approaches, existing works create task-specific LoRAs overlooking shared\nknowledge across tasks. Inaccurate selection of task-specific LORAs during\ninference results in significant drops in accuracy, while existing works rely\non linear or prototype-based classifiers, which have suboptimal generalization\npowers. Our paper proposes continual knowledge consolidation low rank\nadaptation (CONEC-LoRA) addressing the DIL problems. CONEC-LoRA is developed\nfrom consolidations between task-shared LORA to extract common knowledge and\ntask-specific LORA to embrace domain-specific knowledge. Unlike existing\napproaches, CONEC-LoRA integrates the concept of a stochastic classifier whose\nparameters are sampled from a distribution, thus enhancing the likelihood of\ncorrect classifications. Last but not least, an auxiliary network is deployed\nto optimally predict the task-specific LoRAs for inferences and implements the\nconcept of a different-depth network structure in which every layer is\nconnected with a local classifier to take advantage of intermediate\nrepresentations. This module integrates the ball-generator loss and\ntransformation module to address the synthetic sample bias problem. Our\nrigorous experiments demonstrate the advantage of CONEC-LoRA over prior arts in\n4 popular benchmark problems with over 5% margins."}
{"id": "2510.16078", "pdf": "https://arxiv.org/pdf/2510.16078", "abs": "https://arxiv.org/abs/2510.16078", "authors": ["Abdelilah Ganmati", "Karim Afdel", "Lahcen Koutti"], "title": "ISO/IEC-Compliant Match-on-Card Face Verification with Short Binary Templates", "categories": ["cs.CR", "cs.AI", "cs.CV", "68T10, 68T45, 94A60", "I.4.8; I.5.4; I.2.10"], "comment": "~14 pages, 6 figures, 6 tables. Source uses elsarticle class; all\n  figures included as PNG/PDF. Primary: cs.CV", "summary": "We present a practical match-on-card design for face verification in which\ncompact 64/128-bit templates are produced off-card by PCA-ITQ and compared\non-card via constant-time Hamming distance. We specify ISO/IEC 7816-4 and\n14443-4 command APDUs with fixed-length payloads and decision-only status words\n(no score leakage), together with a minimal per-identity EEPROM map. Using real\nbinary codes from a CelebA working set (55 identities, 412 images), we (i)\nderive operating thresholds from ROC/DET, (ii) replay enroll->verify\ntransactions at those thresholds, and (iii) bound end-to-end time by pure link\nlatency plus a small constant on-card budget. Even at the slowest contact rate\n(9.6 kbps), total verification time is 43.9 ms (64 b) and 52.3 ms (128 b); at\n38.4 kbps both are <14 ms. At FAR = 1%, both code lengths reach TPR = 0.836,\nwhile 128 b lowers EER relative to 64 b. An optional +6 B helper (targeted\nsymbol-level parity over empirically unstable bits) is latency-negligible.\nOverall, short binary templates, fixed-payload decision-only APDUs, and\nconstant-time matching satisfy ISO/IEC transport constraints with wide timing\nmargin and align with ISO/IEC 24745 privacy goals. Limitations: single-dataset\nevaluation and design-level (pre-hardware) timing; we outline AgeDB/CFP-FP and\non-card microbenchmarks as next steps."}
{"id": "2510.16079", "pdf": "https://arxiv.org/pdf/2510.16079", "abs": "https://arxiv.org/abs/2510.16079", "authors": ["Rong Wu", "Xiaoman Wang", "Jianbiao Mei", "Pinlong Cai", "Daocheng Fu", "Cheng Yang", "Licheng Wen", "Xuemeng Yang", "Yufan Shen", "Yuxin Wang", "Botian Shi"], "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Current Large Language Model (LLM) agents show strong performance in tool\nuse, but lack the crucial capability to systematically learn from their own\nexperiences. While existing frameworks mainly focus on mitigating external\nknowledge gaps, they fail to address a more fundamental limitation: the\ninability to iteratively refine problem-solving strategies. In this work, we\nintroduce EvolveR, a framework designed to enable agent to self-improve through\na complete, closed-loop experience lifecycle. This lifecycle comprises two key\nstages: (1) Offline Self-Distillation, where the agent's interaction\ntrajectories are synthesized into a structured repository of abstract, reusable\nstrategic principles; (2) Online Interaction, where the agent interacts with\ntasks and actively retrieves distilled principles to guide its decision-making,\naccumulating a diverse set of behavioral trajectories. This loop employs a\npolicy reinforcement mechanism to iteratively update the agent based on its\nperformance. We demonstrate the effectiveness of EvolveR on complex multi-hop\nquestion-answering benchmarks, where it achieves superior performance over\nstrong agentic baselines. Our work presents a comprehensive blueprint for\nagents that learn not only from external data but also from the consequences of\ntheir own actions, paving the way for more autonomous and continuously\nimproving systems. Code is available at https://github.com/Edaizi/EvolveR."}
{"id": "2510.16080", "pdf": "https://arxiv.org/pdf/2510.16080", "abs": "https://arxiv.org/abs/2510.16080", "authors": ["Kerem Delikoyun", "Qianyu Chen", "Win Sen Kuan", "John Tshon Yit Soong", "Matthew Edward Cove", "Oliver Hayden"], "title": "TriAgent: Automated Biomarker Discovery with Deep Research Grounding for Triage in Acute Care by LLM-Based Multi-Agent Collaboration", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Emergency departments worldwide face rising patient volumes, workforce\nshortages, and variability in triage decisions that threaten the delivery of\ntimely and accurate care. Current triage methods rely primarily on vital signs,\nroutine laboratory values, and clinicians' judgment, which, while effective,\noften miss emerging biological signals that could improve risk prediction for\ninfection typing or antibiotic administration in acute conditions. To address\nthis challenge, we introduce TriAgent, a large language model (LLM)-based\nmulti-agent framework that couples automated biomarker discovery with deep\nresearch for literature-grounded validation and novelty assessment. TriAgent\nemploys a supervisor research agent to generate research topics and delegate\ntargeted queries to specialized sub-agents for evidence retrieval from various\ndata sources. Findings are synthesized to classify biomarkers as either\ngrounded in existing knowledge or flagged as novel candidates, offering\ntransparent justification and highlighting unexplored pathways in acute care\nrisk stratification. Unlike prior frameworks limited to existing routine\nclinical biomarkers, TriAgent aims to deliver an end-to-end framework from data\nanalysis to literature grounding to improve transparency, explainability and\nexpand the frontier of potentially actionable clinical biomarkers. Given a\nuser's clinical query and quantitative triage data, TriAgent achieved a topic\nadherence F1 score of 55.7 +/- 5.0%, surpassing the CoT-ReAct agent by over\n10%, and a faithfulness score of 0.42 +/- 0.39, exceeding all baselines by more\nthan 50%. Across experiments, TriAgent consistently outperformed\nstate-of-the-art LLM-based agentic frameworks in biomarker justification and\nliterature-grounded novelty assessment. We share our repo:\nhttps://github.com/CellFace/TriAgent."}
{"id": "2510.16081", "pdf": "https://arxiv.org/pdf/2510.16081", "abs": "https://arxiv.org/abs/2510.16081", "authors": ["Jiaye Yang", "Xinyu Zhao", "Tianlong Chen", "Kandyce Brennan"], "title": "SARHAchat: An LLM-Based Chatbot for Sexual and Reproductive Health Counseling", "categories": ["cs.CY", "cs.AI"], "comment": "5 pages, 1 figure", "summary": "While Artificial Intelligence (AI) shows promise in healthcare applications,\nexisting conversational systems often falter in complex and sensitive medical\ndomains such as Sexual and Reproductive Health (SRH). These systems frequently\nstruggle with hallucination and lack the specialized knowledge required,\nparticularly for sensitive SRH topics. Furthermore, current AI approaches in\nhealthcare tend to prioritize diagnostic capabilities over comprehensive\npatient care and education. Addressing these gaps, this work at the UNC School\nof Nursing introduces SARHAchat, a proof-of-concept Large Language Model\n(LLM)-based chatbot. SARHAchat is designed as a reliable, user-centered system\nintegrating medical expertise with empathetic communication to enhance SRH care\ndelivery. Our evaluation demonstrates SARHAchat's ability to provide accurate\nand contextually appropriate contraceptive counseling while maintaining a\nnatural conversational flow. The demo is available at\nhttps://sarhachat.com/}{https://sarhachat.com/."}
{"id": "2510.16082", "pdf": "https://arxiv.org/pdf/2510.16082", "abs": "https://arxiv.org/abs/2510.16082", "authors": ["Elias Hossain", "Mehrdad Shoeibi", "Ivan Garibay", "Niloofar Yousefi"], "title": "Interpretable RNA-Seq Clustering with an LLM-Based Agentic Evidence-Grounded Framework", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose CITE V.1, an agentic, evidence-grounded framework that leverages\nLarge Language Models (LLMs) to provide transparent and reproducible\ninterpretations of RNA-seq clusters. Unlike existing enrichment-based\napproaches that reduce results to broad statistical associations and LLM-only\nmodels that risk unsupported claims or fabricated citations, CITE V.1\ntransforms cluster interpretation by producing biologically coherent\nexplanations explicitly anchored in the biomedical literature. The framework\norchestrates three specialized agents: a Retriever that gathers domain\nknowledge from PubMed and UniProt, an Interpreter that formulates functional\nhypotheses, and Critics that evaluate claims, enforce evidence grounding, and\nqualify uncertainty through confidence and reliability indicators. Applied to\nSalmonella enterica RNA-seq data, CITE V.1 generated biologically meaningful\ninsights supported by the literature, while an LLM-only Gemini baseline\nfrequently produced speculative results with false citations. By moving RNA-seq\nanalysis from surface-level enrichment to auditable, interpretable, and\nevidence-based hypothesis generation, CITE V.1 advances the transparency and\nreliability of AI in biomedicine."}
{"id": "2510.16083", "pdf": "https://arxiv.org/pdf/2510.16083", "abs": "https://arxiv.org/abs/2510.16083", "authors": ["Jaehan Kim", "Minkyoo Song", "Minjae Seo", "Youngjin Jin", "Seungwon Shin", "Jinwoo Kim"], "title": "PassREfinder-FL: Privacy-Preserving Credential Stuffing Risk Prediction via Graph-Based Federated Learning for Representing Password Reuse between Websites", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Accepted by Elsevier Expert Systems with Applications", "summary": "Credential stuffing attacks have caused significant harm to online users who\nfrequently reuse passwords across multiple websites. While prior research has\nattempted to detect users with reused passwords or identify malicious login\nattempts, existing methods often compromise usability by restricting password\ncreation or website access, and their reliance on complex account-sharing\nmechanisms hinders real-world deployment. To address these limitations, we\npropose PassREfinder-FL, a novel framework that predicts credential stuffing\nrisks across websites. We introduce the concept of password reuse relations --\ndefined as the likelihood of users reusing passwords between websites -- and\nrepresent them as edges in a website graph. Using graph neural networks (GNNs),\nwe perform a link prediction task to assess credential reuse risk between\nsites. Our approach scales to a large number of arbitrary websites by\nincorporating public website information and linking newly observed websites as\nnodes in the graph. To preserve user privacy, we extend PassREfinder-FL with a\nfederated learning (FL) approach that eliminates the need to share user\nsensitive information across administrators. Evaluation on a real-world dataset\nof 360 million breached accounts from 22,378 websites shows that\nPassREfinder-FL achieves an F1-score of 0.9153 in the FL setting. We further\nvalidate that our FL-based GNN achieves a 4-11% performance improvement over\nother state-of-the-art GNN models through an ablation study. Finally, we\ndemonstrate that the predicted results can be used to quantify password reuse\nlikelihood as actionable risk scores."}
{"id": "2510.16085", "pdf": "https://arxiv.org/pdf/2510.16085", "abs": "https://arxiv.org/abs/2510.16085", "authors": ["Xun Wei", "Pukai Zhou", "Zeyu Wang"], "title": "MoPHES:Leveraging on-device LLMs as Agent for Mobile Psychological Health Evaluation and Support", "categories": ["cs.CY", "cs.AI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "The 2022 World Mental Health Report calls for global mental health care\nreform, amid rising prevalence of issues like anxiety and depression that\naffect nearly one billion people worldwide. Traditional in-person therapy fails\nto meet this demand, and the situation is worsened by stigma. While\ngeneral-purpose large language models (LLMs) offer efficiency for AI-driven\nmental health solutions, they underperform because they lack specialized\nfine-tuning. Existing LLM-based mental health chatbots can engage in empathetic\nconversations, but they overlook real-time user mental state assessment which\nis critical for professional counseling. This paper proposes MoPHES, a\nframework that integrates mental state evaluation, conversational support, and\nprofessional treatment recommendations. The agent developed under this\nframework uses two fine-tuned MiniCPM4-0.5B LLMs: one is fine-tuned on mental\nhealth conditions datasets to assess users' mental states and predict the\nseverity of anxiety and depression; the other is fine-tuned on multi-turn\ndialogues to handle conversations with users. By leveraging insights into\nusers' mental states, our agent provides more tailored support and professional\ntreatment recommendations. Both models are also deployed directly on mobile\ndevices to enhance user convenience and protect user privacy. Additionally, to\nevaluate the performance of MoPHES with other LLMs, we develop a benchmark for\nthe automatic evaluation of mental state prediction and multi-turn counseling\ndialogues, which includes comprehensive evaluation metrics, datasets, and\nmethods."}
{"id": "2510.16089", "pdf": "https://arxiv.org/pdf/2510.16089", "abs": "https://arxiv.org/abs/2510.16089", "authors": ["William Hoy", "Nurcin Celik"], "title": "STABLE: Gated Continual Learning for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) increasingly require mechanisms for continual\nadaptation without full retraining. However, sequential updates can lead to\ncatastrophic forgetting, where new edits degrade previously acquired knowledge.\nThis work presents STABLE, a gated continual self editing framework that\nconstrains forgetting during sequential updates using parameter efficient fine\ntuning via Low Rank Adaptation (LoRA; see arXiv:2106.09685). Each candidate\nedit is evaluated against a stability budget using one of three metrics: (i)\nExact Match (EM) drop, capturing factual accuracy loss; (ii) bits increase,\nreflecting reduced model confidence; and (iii) KL divergence, quantifying\ndistributional drift between the base and adapted models. If a threshold is\nexceeded, the LoRA update is rescaled through a clipping procedure or rejected.\nExperiments on the Qwen-2.5-7B model show that gating effectively mitigates\nforgetting while preserving adaptability. EM based gating achieved the highest\ncumulative performance in short continual learning sequences. Our results show\nthat different gating strategies can achieve comparable distribution shift\n(measured by KL divergence) while producing different accuracy outcomes,\nhighlighting the importance of gating design in continual adaptation. This\napproach offers a principled method for continual model editing, enabling LLMs\nto integrate new knowledge while maintaining reliability. Code:\nhttps://github.com/Bhoy1/STABLE"}
{"id": "2510.16091", "pdf": "https://arxiv.org/pdf/2510.16091", "abs": "https://arxiv.org/abs/2510.16091", "authors": ["Binglan Han", "Anuradha Mathrani", "Teo Susnjak"], "title": "Evaluating Prompting Strategies and Large Language Models in Systematic Literature Review Screening: Relevance and Task-Stage Classification", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This study quantifies how prompting strategies interact with large language\nmodels (LLMs) to automate the screening stage of systematic literature reviews\n(SLRs). We evaluate six LLMs (GPT-4o, GPT-4o-mini, DeepSeek-Chat-V3,\nGemini-2.5-Flash, Claude-3.5-Haiku, Llama-4-Maverick) under five prompt types\n(zero-shot, few-shot, chain-of-thought (CoT), CoT-few-shot, self-reflection)\nacross relevance classification and six Level-2 tasks, using accuracy,\nprecision, recall, and F1. Results show pronounced model-prompt interaction\neffects: CoT-few-shot yields the most reliable precision-recall balance;\nzero-shot maximizes recall for high-sensitivity passes; and self-reflection\nunderperforms due to over-inclusivity and instability across models. GPT-4o and\nDeepSeek provide robust overall performance, while GPT-4o-mini performs\ncompetitively at a substantially lower dollar cost. A cost-performance analysis\nfor relevance classification (per 1,000 abstracts) reveals large absolute\ndifferences among model-prompt pairings; GPT-4o-mini remains low-cost across\nprompts, and structured prompts (CoT/CoT-few-shot) on GPT-4o-mini offer\nattractive F1 at a small incremental cost. We recommend a staged workflow that\n(1) deploys low-cost models with structured prompts for first-pass screening\nand (2) escalates only borderline cases to higher-capacity models. These\nfindings highlight LLMs' uneven but promising potential to automate literature\nscreening. By systematically analyzing prompt-model interactions, we provide a\ncomparative benchmark and practical guidance for task-adaptive LLM deployment."}
{"id": "2510.16092", "pdf": "https://arxiv.org/pdf/2510.16092", "abs": "https://arxiv.org/abs/2510.16092", "authors": ["Devvrit Khatri", "Pranamya Kulkarni", "Nilesh Gupta", "Yerram Varun", "Liqian Peng", "Jay Yagnik", "Praneeth Netrapalli", "Cho-Jui Hsieh", "Alec Go", "Inderjit S Dhillon", "Aditya Kusupati", "Prateek Jain"], "title": "Compressing Many-Shots in In-Context Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have been shown to be able to learn different\ntasks without explicit finetuning when given many input-output examples /\ndemonstrations through In-Context Learning (ICL). Increasing the number of\nexamples, called ``shots'', improves downstream task performance but incurs\nhigher memory and computational costs. In this work, we study an approach to\nimprove the memory and computational efficiency of ICL inference by compressing\nthe many-shot prompts. Given many shots comprising t tokens, our goal is to\ngenerate a m soft-token summary, where m < t. We first show that existing\nprompt compression methods are ineffective for many-shot compression, and\nsimply using fewer shots as a baseline is surprisingly strong. To achieve\neffective compression, we find that: (a) a stronger compressor model with more\ntrainable parameters is necessary, and (b) compressing many-shot\nrepresentations at each transformer layer enables more fine-grained compression\nby providing each layer with its own compressed representation. Based on these\ninsights, we propose MemCom, a layer-wise compression method. We systematically\nevaluate various compressor models and training approaches across different\nmodel sizes (2B and 7B), architectures (Gemma and Mistral), many-shot sequence\nlengths (3k-6k tokens), and compression ratios (3x to 8x). MemCom outperforms\nstrong baselines across all compression ratios on multiple classification tasks\nwith large label sets. Notably, while baseline performance degrades sharply at\nhigher compression ratios, often by over 20-30%, MemCom maintains high accuracy\nwith minimal degradation, typically dropping by less than 10%."}
{"id": "2510.16097", "pdf": "https://arxiv.org/pdf/2510.16097", "abs": "https://arxiv.org/abs/2510.16097", "authors": ["Eleni Straitouri", "Stratis Tsirtsis", "Ander Artola Velasco", "Manuel Gomez-Rodriguez"], "title": "Narrowing Action Choices with AI Improves Human Sequential Decisions", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.HC", "stat.ML"], "comment": "Accepted at the Human-AI Complementarity for Decision Making Workshop\n  2025 by the NSF AI Institute for Societal Decision Making", "summary": "Recent work has shown that, in classification tasks, it is possible to design\ndecision support systems that do not require human experts to understand when\nto cede agency to a classifier or when to exercise their own agency to achieve\ncomplementarity$\\unicode{x2014}$experts using these systems make more accurate\npredictions than those made by the experts or the classifier alone. The key\nprinciple underpinning these systems reduces to adaptively controlling the\nlevel of human agency, by design. Can we use the same principle to achieve\ncomplementarity in sequential decision making tasks? In this paper, we answer\nthis question affirmatively. We develop a decision support system that uses a\npre-trained AI agent to narrow down the set of actions a human can take to a\nsubset, and then asks the human to take an action from this action set. Along\nthe way, we also introduce a bandit algorithm that leverages the smoothness\nproperties of the action sets provided by our system to efficiently optimize\nthe level of human agency. To evaluate our decision support system, we conduct\na large-scale human subject study ($n = 1{,}600$) where participants play a\nwildfire mitigation game. We find that participants who play the game supported\nby our system outperform those who play on their own by $\\sim$$30$% and the AI\nagent used by our system by $>$$2$%, even though the AI agent largely\noutperforms participants playing without support. We have made available the\ndata gathered in our human subject study as well as an open source\nimplementation of our system at\nhttps://github.com/Networks-Learning/narrowing-action-choices ."}
{"id": "2510.16134", "pdf": "https://arxiv.org/pdf/2510.16134", "abs": "https://arxiv.org/abs/2510.16134", "authors": ["Chen Kong", "James Fort", "Aria Kang", "Jonathan Wittmer", "Simon Green", "Tianwei Shen", "Yipu Zhao", "Cheng Peng", "Gustavo Solaira", "Andrew Berkovich", "Nikhil Raina", "Vijay Baiyya", "Evgeniy Oleinik", "Eric Huang", "Fan Zhang", "Julian Straub", "Mark Schwesinger", "Luis Pesqueira", "Xiaqing Pan", "Jakob Julian Engel", "Carl Ren", "Mingfei Yan", "Richard Newcombe"], "title": "Aria Gen 2 Pilot Dataset", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG", "cs.RO"], "comment": null, "summary": "The Aria Gen 2 Pilot Dataset (A2PD) is an egocentric multimodal open dataset\ncaptured using the state-of-the-art Aria Gen 2 glasses. To facilitate timely\naccess, A2PD is released incrementally with ongoing dataset enhancements. The\ninitial release features Dia'ane, our primary subject, who records her daily\nactivities alongside friends, each equipped with Aria Gen 2 glasses. It\nencompasses five primary scenarios: cleaning, cooking, eating, playing, and\noutdoor walking. In each of the scenarios, we provide comprehensive raw sensor\ndata and output data from various machine perception algorithms. These data\nillustrate the device's ability to perceive the wearer, the surrounding\nenvironment, and interactions between the wearer and the environment, while\nmaintaining robust performance across diverse users and conditions. The A2PD is\npublicly available at projectaria.com, with open-source tools and usage\nexamples provided in Project Aria Tools."}
{"id": "2510.16136", "pdf": "https://arxiv.org/pdf/2510.16136", "abs": "https://arxiv.org/abs/2510.16136", "authors": ["Sayan Deb Sarkar", "Sinisa Stekovic", "Vincent Lepetit", "Iro Armeni"], "title": "GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "NeurIPS 2025. Project Page: https://sayands.github.io/guideflow3d/", "summary": "Transferring appearance to 3D assets using different representations of the\nappearance object - such as images or text - has garnered interest due to its\nwide range of applications in industries like gaming, augmented reality, and\ndigital content creation. However, state-of-the-art methods still fail when the\ngeometry between the input and appearance objects is significantly different. A\nstraightforward approach is to directly apply a 3D generative model, but we\nshow that this ultimately fails to produce appealing results. Instead, we\npropose a principled approach inspired by universal guidance. Given a\npretrained rectified flow model conditioned on image or text, our training-free\nmethod interacts with the sampling process by periodically adding guidance.\nThis guidance can be modeled as a differentiable loss function, and we\nexperiment with two different types of guidance including part-aware losses for\nappearance and self-similarity. Our experiments show that our approach\nsuccessfully transfers texture and geometric details to the input 3D asset,\noutperforming baselines both qualitatively and quantitatively. We also show\nthat traditional metrics are not suitable for evaluating the task due to their\ninability of focusing on local details and comparing dissimilar inputs, in\nabsence of ground truth data. We thus evaluate appearance transfer quality with\na GPT-based system objectively ranking outputs, ensuring robust and human-like\nassessment, as further confirmed by our user study. Beyond showcased scenarios,\nour method is general and could be extended to different types of diffusion\nmodels and guidance functions."}
{"id": "2510.16144", "pdf": "https://arxiv.org/pdf/2510.16144", "abs": "https://arxiv.org/abs/2510.16144", "authors": ["Sukhdeep Singh", "Avinash Bhat", "Shweta M", "Subhash K Singh", "Moonki Hong", "Madhan Raj K", "Kandeepan Sithamparanathan", "Sunder A. Khowaja", "Kapal Dev"], "title": "Agentic AI for Ultra-Modern Networks: Multi-Agent Framework for RAN Autonomy and Assurance", "categories": ["cs.NI", "cs.AI", "cs.MA"], "comment": null, "summary": "The increasing complexity of Beyond 5G and 6G networks necessitates new\nparadigms for autonomy and assur- ance. Traditional O-RAN control loops rely\nheavily on RIC- based orchestration, which centralizes intelligence and exposes\nthe system to risks such as policy conflicts, data drift, and unsafe actions\nunder unforeseen conditions. In this work, we argue that the future of\nautonomous networks lies in a multi-agentic architecture, where specialized\nagents collaborate to perform data collection, model training, prediction,\npolicy generation, verification, deployment, and assurance. By replacing\ntightly- coupled centralized RIC-based workflows with distributed agents, the\nframework achieves autonomy, resilience, explainability, and system-wide\nsafety. To substantiate this vision, we design and evaluate a traffic steering\nuse case under surge and drift conditions. Results across four KPIs: RRC\nconnected users, IP throughput, PRB utilization, and SINR, demonstrate that a\nnaive predictor-driven deployment improves local KPIs but destabilizes\nneighbors, whereas the agentic system blocks unsafe policies, preserving global\nnetwork health. This study highlights multi- agent architectures as a credible\nfoundation for trustworthy AI- driven autonomy in next-generation RANs."}
{"id": "2510.16152", "pdf": "https://arxiv.org/pdf/2510.16152", "abs": "https://arxiv.org/abs/2510.16152", "authors": ["Mason Smetana", "Lev Khazanovich"], "title": "Publication Trend Analysis and Synthesis via Large Language Model: A Case Study of Engineering in PNAS", "categories": ["cs.DL", "cs.AI", "cs.CL", "cs.LG"], "comment": "35 pages, 10 figures", "summary": "Scientific literature is increasingly siloed by complex language, static\ndisciplinary structures, and potentially sparse keyword systems, making it\ncumbersome to capture the dynamic nature of modern science. This study\naddresses these challenges by introducing an adaptable large language model\n(LLM)-driven framework to quantify thematic trends and map the evolving\nlandscape of scientific knowledge. The approach is demonstrated over a 20-year\ncollection of more than 1,500 engineering articles published by the Proceedings\nof the National Academy of Sciences (PNAS), marked for their breadth and depth\nof research focus. A two-stage classification pipeline first establishes a\nprimary thematic category for each article based on its abstract. The\nsubsequent phase performs a full-text analysis to assign secondary\nclassifications, revealing latent, cross-topic connections across the corpus.\nTraditional natural language processing (NLP) methods, such as Bag-of-Words\n(BoW) and Term Frequency-Inverse Document Frequency (TF-IDF), confirm the\nresulting topical structure and also suggest that standalone word-frequency\nanalyses may be insufficient for mapping fields with high diversity. Finally, a\ndisjoint graph representation between the primary and secondary classifications\nreveals implicit connections between themes that may be less apparent when\nanalyzing abstracts or keywords alone. The findings show that the approach\nindependently recovers much of the journal's editorially embedded structure\nwithout prior knowledge of its existing dual-classification schema (e.g.,\nbiological studies also classified as engineering). This framework offers a\npowerful tool for detecting potential thematic trends and providing a\nhigh-level overview of scientific progress."}
{"id": "2510.16156", "pdf": "https://arxiv.org/pdf/2510.16156", "abs": "https://arxiv.org/abs/2510.16156", "authors": ["Yueqian Lin", "Zhengmian Hu", "Jayakumar Subramanian", "Qinsi Wang", "Nikos Vlassis", "Hai \"Helen\" Li", "Yiran Chen"], "title": "AsyncVoice Agent: Real-Time Explanation for LLM Planning and Reasoning", "categories": ["eess.AS", "cs.AI", "cs.MM"], "comment": "Accepted to the IEEE ASRU 2025 Demo Track", "summary": "Effective human-AI collaboration on complex reasoning tasks requires that\nusers understand and interact with the model's process, not just receive an\noutput. However, the monolithic text from methods like Chain-of-Thought (CoT)\nprevents this, as current interfaces lack real-time verbalization and robust\nuser barge-in. We present AsyncVoice Agent, a system whose asynchronous\narchitecture decouples a streaming LLM backend from a conversational voice\nfrontend. This design allows narration and inference to run in parallel,\nempowering users to interrupt, query, and steer the model's reasoning process\nat any time. Objective benchmarks show this approach reduces interaction\nlatency by more than 600x compared to monolithic baselines while ensuring high\nfidelity and competitive task accuracy. By enabling a two-way dialogue with a\nmodel's thought process, AsyncVoice Agent offers a new paradigm for building\nmore effective, steerable, and trustworthy human-AI systems for high-stakes\ntasks."}
{"id": "2510.16171", "pdf": "https://arxiv.org/pdf/2510.16171", "abs": "https://arxiv.org/abs/2510.16171", "authors": ["Longwei Wang", "Ifrat Ikhtear Uddin", "KC Santosh", "Chaowei Zhang", "Xiao Qin", "Yang Zhou"], "title": "Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted for the proceedings of 39th Conference on Neural Information\n  Processing Systems (NeurIPS 2025)", "summary": "Adversarial examples reveal critical vulnerabilities in deep neural networks\nby exploiting their sensitivity to imperceptible input perturbations. While\nadversarial training remains the predominant defense strategy, it often incurs\nsignificant computational cost and may compromise clean-data accuracy. In this\nwork, we investigate an architectural approach to adversarial robustness by\nembedding group-equivariant convolutions-specifically, rotation- and\nscale-equivariant layers-into standard convolutional neural networks (CNNs).\nThese layers encode symmetry priors that align model behavior with structured\ntransformations in the input space, promoting smoother decision boundaries and\ngreater resilience to adversarial attacks. We propose and evaluate two\nsymmetry-aware architectures: a parallel design that processes standard and\nequivariant features independently before fusion, and a cascaded design that\napplies equivariant operations sequentially. Theoretically, we demonstrate that\nsuch models reduce hypothesis space complexity, regularize gradients, and yield\ntighter certified robustness bounds under the CLEVER (Cross Lipschitz Extreme\nValue for nEtwork Robustness) framework. Empirically, our models consistently\nimprove adversarial robustness and generalization across CIFAR-10, CIFAR-100,\nand CIFAR-10C under both FGSM and PGD attacks, without requiring adversarial\ntraining. These findings underscore the potential of symmetry-enforcing\narchitectures as efficient and principled alternatives to data\naugmentation-based defenses."}
{"id": "2510.16175", "pdf": "https://arxiv.org/pdf/2510.16175", "abs": "https://arxiv.org/abs/2510.16175", "authors": ["Pablo Samuel Castro"], "title": "The Formalism-Implementation Gap in Reinforcement Learning Research", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The last decade has seen an upswing in interest and adoption of reinforcement\nlearning (RL) techniques, in large part due to its demonstrated capabilities at\nperforming certain tasks at \"super-human levels\". This has incentivized the\ncommunity to prioritize research that demonstrates RL agent performance, often\nat the expense of research aimed at understanding their learning dynamics.\nPerformance-focused research runs the risk of overfitting on academic\nbenchmarks -- thereby rendering them less useful -- which can make it difficult\nto transfer proposed techniques to novel problems. Further, it implicitly\ndiminishes work that does not push the performance-frontier, but aims at\nimproving our understanding of these techniques. This paper argues two points:\n(i) RL research should stop focusing solely on demonstrating agent\ncapabilities, and focus more on advancing the science and understanding of\nreinforcement learning; and (ii) we need to be more precise on how our\nbenchmarks map to the underlying mathematical formalisms. We use the popular\nArcade Learning Environment (ALE; Bellemare et al., 2013) as an example of a\nbenchmark that, despite being increasingly considered \"saturated\", can be\neffectively used for developing this understanding, and facilitating the\ndeployment of RL techniques in impactful real-world problems."}
{"id": "2510.16185", "pdf": "https://arxiv.org/pdf/2510.16185", "abs": "https://arxiv.org/abs/2510.16185", "authors": ["Daniel Donnelly", "Angelo Ferrando", "Francesco Belardinelli"], "title": "Expressive Reward Synthesis with the Runtime Monitoring Language", "categories": ["cs.LG", "cs.AI", "cs.FL", "stat.ML"], "comment": null, "summary": "A key challenge in reinforcement learning (RL) is reward (mis)specification,\nwhereby imprecisely defined reward functions can result in unintended, possibly\nharmful, behaviours. Indeed, reward functions in RL are typically treated as\nblack-box mappings from state-action pairs to scalar values. While effective in\nmany settings, this approach provides no information about why rewards are\ngiven, which can hinder learning and interpretability. Reward Machines address\nthis issue by representing reward functions as finite state automata, enabling\nthe specification of structured, non-Markovian reward functions. However, their\nexpressivity is typically bounded by regular languages, leaving them unable to\ncapture more complex behaviours such as counting or parametrised conditions. In\nthis work, we build on the Runtime Monitoring Language (RML) to develop a novel\nclass of language-based Reward Machines. By leveraging the built-in memory of\nRML, our approach can specify reward functions for non-regular, non-Markovian\ntasks. We demonstrate the expressiveness of our approach through experiments,\nhighlighting additional advantages in flexible event-handling and task\nspecification over existing Reward Machine-based methods."}
{"id": "2510.16187", "pdf": "https://arxiv.org/pdf/2510.16187", "abs": "https://arxiv.org/abs/2510.16187", "authors": ["Rupal Nigam", "Niket Parikh", "Hamid Osooli", "Mikihisa Yuasa", "Jacob Heglund", "Huy T. Tran"], "title": "Zero-Shot Coordination in Ad Hoc Teams with Generalized Policy Improvement and Difference Rewards", "categories": ["cs.MA", "cs.AI", "cs.RO"], "comment": "10 pages, 8 figures", "summary": "Real-world multi-agent systems may require ad hoc teaming, where an agent\nmust coordinate with other previously unseen teammates to solve a task in a\nzero-shot manner. Prior work often either selects a pretrained policy based on\nan inferred model of the new teammates or pretrains a single policy that is\nrobust to potential teammates. Instead, we propose to leverage all pretrained\npolicies in a zero-shot transfer setting. We formalize this problem as an ad\nhoc multi-agent Markov decision process and present a solution that uses two\nkey ideas, generalized policy improvement and difference rewards, for efficient\nand effective knowledge transfer between different teams. We empirically\ndemonstrate that our algorithm, Generalized Policy improvement for Ad hoc\nTeaming (GPAT), successfully enables zero-shot transfer to new teams in three\nsimulated environments: cooperative foraging, predator-prey, and Overcooked. We\nalso demonstrate our algorithm in a real-world multi-robot setting."}
{"id": "2510.16196", "pdf": "https://arxiv.org/pdf/2510.16196", "abs": "https://arxiv.org/abs/2510.16196", "authors": ["Zheng Huang", "Enpei Zhang", "Yinghao Cai", "Weikang Qiu", "Carl Yang", "Elynn Chen", "Xiang Zhang", "Rex Ying", "Dawei Zhou", "Yujun Yan"], "title": "Seeing Through the Brain: New Insights from Decoding Visual Stimuli with fMRI", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Understanding how the brain encodes visual information is a central challenge\nin neuroscience and machine learning. A promising approach is to reconstruct\nvisual stimuli, essentially images, from functional Magnetic Resonance Imaging\n(fMRI) signals. This involves two stages: transforming fMRI signals into a\nlatent space and then using a pretrained generative model to reconstruct\nimages. The reconstruction quality depends on how similar the latent space is\nto the structure of neural activity and how well the generative model produces\nimages from that space. Yet, it remains unclear which type of latent space best\nsupports this transformation and how it should be organized to represent visual\nstimuli effectively. We present two key findings. First, fMRI signals are more\nsimilar to the text space of a language model than to either a vision based\nspace or a joint text image space. Second, text representations and the\ngenerative model should be adapted to capture the compositional nature of\nvisual stimuli, including objects, their detailed attributes, and\nrelationships. Building on these insights, we propose PRISM, a model that\nProjects fMRI sIgnals into a Structured text space as an interMediate\nrepresentation for visual stimuli reconstruction. It includes an object centric\ndiffusion module that generates images by composing individual objects to\nreduce object detection errors, and an attribute relationship search module\nthat automatically identifies key attributes and relationships that best align\nwith the neural activity. Extensive experiments on real world datasets\ndemonstrate that our framework outperforms existing methods, achieving up to an\n8% reduction in perceptual loss. These results highlight the importance of\nusing structured text as the intermediate space to bridge fMRI signals and\nimage reconstruction."}
{"id": "2510.16197", "pdf": "https://arxiv.org/pdf/2510.16197", "abs": "https://arxiv.org/abs/2510.16197", "authors": ["Daniel Messenger", "Daniel Serino", "Balu Nadiga", "Marc Klasky"], "title": "Revealing Low-Dimensional Structure in 2D Richtmyer-Meshkov Instabilities via Parametric Reduced-Order Modeling", "categories": ["physics.flu-dyn", "cs.AI"], "comment": null, "summary": "Efficient modeling of the Richtmyer-Meshkov instability (RMI) is essential to\nmany engineering tasks, including high-speed combustion and drive and capsule\ngeometry optimization in Inertial Confinement Fusion (ICF). In the latter, RMI\ncauses the ablator and fuel to mix, introducing cold spots into the fuel and\nlowering performance; controlling RMI is thus a core ICF design concern. In\nthis work, we introduce a reduced-order model for two-dimensional RMI based on\nthe Latent Space Dynamics Identification (LaSDI) algorithm. We demonstrate the\nefficacy of the proposed methodology in efficiently parametrizing the solution\nspace over a high-dimensional parameter vector consisting of material EOS\nparameters and initial conditions known to affect RMI growth rates. Using only\nlate-time partial observations of the dynamics, we use our framework to not\nonly provide a highly efficient dynamic surrogate model, but to reveal that the\nRMI exhibits the structure of a surprisingly low-dimensional and linear\ndynamical system, into the nonlinear growth regime, after a suitable nonlinear\ntransformation is applied to the material interface, which we approximate as a\ntrained autoencoder. Our use of practical observables and fundamental\nparameters suggests that such ROMs may be useful for downstream engineering\ntasks which confront the RMI, while the low-dimensional representation suggests\na new direction for theoretical work."}
{"id": "2510.16219", "pdf": "https://arxiv.org/pdf/2510.16219", "abs": "https://arxiv.org/abs/2510.16219", "authors": ["Yang Feng", "Xudong Pan"], "title": "SentinelNet: Safeguarding Multi-Agent Collaboration Through Credit-Based Dynamic Threat Detection", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Malicious agents pose significant threats to the reliability and\ndecision-making capabilities of Multi-Agent Systems (MAS) powered by Large\nLanguage Models (LLMs). Existing defenses often fall short due to reactive\ndesigns or centralized architectures which may introduce single points of\nfailure. To address these challenges, we propose SentinelNet, the first\ndecentralized framework for proactively detecting and mitigating malicious\nbehaviors in multi-agent collaboration. SentinelNet equips each agent with a\ncredit-based detector trained via contrastive learning on augmented adversarial\ndebate trajectories, enabling autonomous evaluation of message credibility and\ndynamic neighbor ranking via bottom-k elimination to suppress malicious\ncommunications. To overcome the scarcity of attack data, it generates\nadversarial trajectories simulating diverse threats, ensuring robust training.\nExperiments on MAS benchmarks show SentinelNet achieves near-perfect detection\nof malicious agents, close to 100% within two debate rounds, and recovers 95%\nof system accuracy from compromised baselines. By exhibiting strong\ngeneralizability across domains and attack patterns, SentinelNet establishes a\nnovel paradigm for safeguarding collaborative MAS."}
{"id": "2510.16227", "pdf": "https://arxiv.org/pdf/2510.16227", "abs": "https://arxiv.org/abs/2510.16227", "authors": ["Jennifer Hu", "Ethan Gotlieb Wilcox", "Siyuan Song", "Kyle Mahowald", "Roger P. Levy"], "title": "What Can String Probability Tell Us About Grammaticality?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "What have language models (LMs) learned about grammar? This question remains\nhotly debated, with major ramifications for linguistic theory. However, since\nprobability and grammaticality are distinct notions in linguistics, it is not\nobvious what string probabilities can reveal about an LM's underlying\ngrammatical knowledge. We present a theoretical analysis of the relationship\nbetween grammar, meaning, and string probability, based on simple assumptions\nabout the generative process of corpus data. Our framework makes three\npredictions, which we validate empirically using 280K sentence pairs in English\nand Chinese: (1) correlation between the probability of strings within minimal\npairs, i.e., string pairs with minimal semantic differences; (2) correlation\nbetween models' and humans' deltas within minimal pairs; and (3) poor\nseparation in probability space between unpaired grammatical and ungrammatical\nstrings. Our analyses give theoretical grounding for using probability to learn\nabout LMs' structural knowledge, and suggest directions for future work in LM\ngrammatical evaluation."}
{"id": "2510.16233", "pdf": "https://arxiv.org/pdf/2510.16233", "abs": "https://arxiv.org/abs/2510.16233", "authors": ["Patricia West", "Michelle WL Wan", "Alexander Hepburn", "Edwin Simpson", "Raul Santos-Rodriguez", "Jeffrey N Clark"], "title": "Machine Learning for Climate Policy: Understanding Policy Progression in the European Green Deal", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Climate change demands effective legislative action to mitigate its impacts.\nThis study explores the application of machine learning (ML) to understand the\nprogression of climate policy from announcement to adoption, focusing on\npolicies within the European Green Deal. We present a dataset of 165 policies,\nincorporating text and metadata. We aim to predict a policy's progression\nstatus, and compare text representation methods, including TF-IDF, BERT, and\nClimateBERT. Metadata features are included to evaluate the impact on\npredictive performance. On text features alone, ClimateBERT outperforms other\napproaches (RMSE = 0.17, R^2 = 0.29), while BERT achieves superior performance\nwith the addition of metadata features (RMSE = 0.16, R^2 = 0.38). Using methods\nfrom explainable AI highlights the influence of factors such as policy wording\nand metadata including political party and country representation. These\nfindings underscore the potential of ML tools in supporting climate policy\nanalysis and decision-making."}
{"id": "2510.16253", "pdf": "https://arxiv.org/pdf/2510.16253", "abs": "https://arxiv.org/abs/2510.16253", "authors": ["Arielle Sanford", "Shuo Sun", "Christian B. Mendl"], "title": "Protein Folding with Neural Ordinary Differential Equations", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM", "stat.ML", "I.2.1; J.3"], "comment": null, "summary": "Recent advances in protein structure prediction, such as AlphaFold, have\ndemonstrated the power of deep neural architectures like the Evoformer for\ncapturing complex spatial and evolutionary constraints on protein conformation.\nHowever, the depth of the Evoformer, comprising 48 stacked blocks, introduces\nhigh computational costs and rigid layerwise discretization. Inspired by Neural\nOrdinary Differential Equations (Neural ODEs), we propose a continuous-depth\nformulation of the Evoformer, replacing its 48 discrete blocks with a Neural\nODE parameterization that preserves its core attention-based operations. This\ncontinuous-time Evoformer achieves constant memory cost (in depth) via the\nadjoint method, while allowing a principled trade-off between runtime and\naccuracy through adaptive ODE solvers. Benchmarking on protein structure\nprediction tasks, we find that the Neural ODE-based Evoformer produces\nstructurally plausible predictions and reliably captures certain secondary\nstructure elements, such as alpha-helices, though it does not fully replicate\nthe accuracy of the original architecture. However, our model achieves this\nperformance using dramatically fewer resources, just 17.5 hours of training on\na single GPU, highlighting the promise of continuous-depth models as a\nlightweight and interpretable alternative for biomolecular modeling. This work\nopens new directions for efficient and adaptive protein structure prediction\nframeworks."}
{"id": "2510.16255", "pdf": "https://arxiv.org/pdf/2510.16255", "abs": "https://arxiv.org/abs/2510.16255", "authors": ["Sarah Egler", "John Schulman", "Nicholas Carlini"], "title": "Detecting Adversarial Fine-tuning with Auditing Agents", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) providers expose fine-tuning APIs that let end\nusers fine-tune their frontier LLMs. Unfortunately, it has been shown that an\nadversary with fine-tuning access to an LLM can bypass safeguards. Particularly\nconcerning, such attacks may avoid detection with datasets that are only\nimplicitly harmful. Our work studies robust detection mechanisms for\nadversarial use of fine-tuning APIs. We introduce the concept of a fine-tuning\nauditing agent and show it can detect harmful fine-tuning prior to model\ndeployment. We provide our auditing agent with access to the fine-tuning\ndataset, as well as the fine-tuned and pre-fine-tuned models, and request the\nagent assigns a risk score for the fine-tuning job. We evaluate our detection\napproach on a diverse set of eight strong fine-tuning attacks from the\nliterature, along with five benign fine-tuned models, totaling over 1400\nindependent audits. These attacks are undetectable with basic content\nmoderation on the dataset, highlighting the challenge of the task. With the\nbest set of affordances, our auditing agent achieves a 56.2% detection rate of\nadversarial fine-tuning at a 1% false positive rate. Most promising, the\nauditor is able to detect covert cipher attacks that evade safety evaluations\nand content moderation of the dataset. While benign fine-tuning with\nunintentional subtle safety degradation remains a challenge, we establish a\nbaseline configuration for further work in this area. We release our auditing\nagent at https://github.com/safety-research/finetuning-auditor."}
{"id": "2510.16263", "pdf": "https://arxiv.org/pdf/2510.16263", "abs": "https://arxiv.org/abs/2510.16263", "authors": ["Jierui Peng", "Yanyan Zhang", "Yicheng Duan", "Tuo Liang", "Vipin Chaudhary", "Yu Yin"], "title": "NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Homepage: https://vulab-ai.github.io/NEBULA-Alpha/", "summary": "The evaluation of Vision-Language-Action (VLA) agents is hindered by the\ncoarse, end-task success metric that fails to provide precise skill diagnosis\nor measure robustness to real-world perturbations. This challenge is\nexacerbated by a fragmented data landscape that impedes reproducible research\nand the development of generalist models. To address these limitations, we\nintroduce \\textbf{NEBULA}, a unified ecosystem for single-arm manipulation that\nenables diagnostic and reproducible evaluation. NEBULA features a novel\ndual-axis evaluation protocol that combines fine-grained \\textit{capability\ntests} for precise skill diagnosis with systematic \\textit{stress tests} that\nmeasure robustness. A standardized API and a large-scale, aggregated dataset\nare provided to reduce fragmentation and support cross-dataset training and\nfair comparison. Using NEBULA, we demonstrate that top-performing VLAs struggle\nwith key capabilities such as spatial reasoning and dynamic adaptation, which\nare consistently obscured by conventional end-task success metrics. By\nmeasuring both what an agent can do and when it does so reliably, NEBULA\nprovides a practical foundation for robust, general-purpose embodied agents."}
{"id": "2510.16273", "pdf": "https://arxiv.org/pdf/2510.16273", "abs": "https://arxiv.org/abs/2510.16273", "authors": ["Jingyue Huang", "Zachary Novack", "Phillip Long", "Yupeng Hou", "Ke Chen", "Taylor Berg-Kirkpatrick", "Julian McAuley"], "title": "MuseTok: Symbolic Music Tokenization for Generation and Semantic Understanding", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Discrete representation learning has shown promising results across various\ndomains, including generation and understanding in image, speech and language.\nInspired by these advances, we propose MuseTok, a tokenization method for\nsymbolic music, and investigate its effectiveness in both music generation and\nunderstanding tasks. MuseTok employs the residual vector quantized-variational\nautoencoder (RQ-VAE) on bar-wise music segments within a Transformer-based\nencoder-decoder framework, producing music codes that achieve high-fidelity\nmusic reconstruction and accurate understanding of music theory. For\ncomprehensive evaluation, we apply MuseTok to music generation and semantic\nunderstanding tasks, including melody extraction, chord recognition, and\nemotion recognition. Models incorporating MuseTok outperform previous\nrepresentation learning baselines in semantic understanding while maintaining\ncomparable performance in content generation. Furthermore, qualitative analyses\non MuseTok codes, using ground-truth categories and synthetic datasets, reveal\nthat MuseTok effectively captures underlying musical concepts from large music\ncollections."}
{"id": "2510.16281", "pdf": "https://arxiv.org/pdf/2510.16281", "abs": "https://arxiv.org/abs/2510.16281", "authors": ["Yilin Wu", "Anqi Li", "Tucker Hermans", "Fabio Ramos", "Andrea Bajcsy", "Claudia P'erez-D'Arpino"], "title": "Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Reasoning Vision Language Action (VLA) models improve robotic\ninstruction-following by generating step-by-step textual plans before low-level\nactions, an approach inspired by Chain-of-Thought (CoT) reasoning in language\nmodels. Yet even with a correct textual plan, the generated actions can still\nmiss the intended outcomes in the plan, especially in out-of-distribution (OOD)\nscenarios. We formalize this phenomenon as a lack of embodied CoT faithfulness,\nand introduce a training-free, runtime policy steering method for\nreasoning-action alignment. Given a reasoning VLA's intermediate textual plan,\nour framework samples multiple candidate action sequences from the same model,\npredicts their outcomes via simulation, and uses a pre-trained Vision-Language\nModel (VLM) to select the sequence whose outcome best aligns with the VLA's own\ntextual plan. Only executing action sequences that align with the textual\nreasoning turns our base VLA's natural action diversity from a source of error\ninto a strength, boosting robustness to semantic and visual OOD perturbations\nand enabling novel behavior composition without costly re-training. We also\ncontribute a reasoning-annotated extension of LIBERO-100, environment\nvariations tailored for OOD evaluation, and demonstrate up to 15% performance\ngain over prior work on behavior composition tasks and scales with compute and\ndata diversity. Project Website at:\nhttps://yilin-wu98.github.io/steering-reasoning-vla/"}
{"id": "2510.16289", "pdf": "https://arxiv.org/pdf/2510.16289", "abs": "https://arxiv.org/abs/2510.16289", "authors": ["Yoonho Lee", "Junseok Lee", "Sangwoo Seo", "Sungwon Kim", "Yeongmin Kim", "Chanyoung Park"], "title": "Disentangling Hyperedges through the Lens of Category Theory", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to NeurIPS 2025", "summary": "Despite the promising results of disentangled representation learning in\ndiscovering latent patterns in graph-structured data, few studies have explored\ndisentanglement for hypergraph-structured data. Integrating hyperedge\ndisentanglement into hypergraph neural networks enables models to leverage\nhidden hyperedge semantics, such as unannotated relations between nodes, that\nare associated with labels. This paper presents an analysis of hyperedge\ndisentanglement from a category-theoretical perspective and proposes a novel\ncriterion for disentanglement derived from the naturality condition. Our\nproof-of-concept model experimentally showed the potential of the proposed\ncriterion by successfully capturing functional relations of genes (nodes) in\ngenetic pathways (hyperedges)."}
{"id": "2510.16293", "pdf": "https://arxiv.org/pdf/2510.16293", "abs": "https://arxiv.org/abs/2510.16293", "authors": ["Saejin Oh", "Xinyi Fang", "I-Hsin Lin", "Paris Dee", "Christopher S. Dunham", "Stacy M. Copp", "Abigail G. Doyle", "Javier Read de Alaniz", "Mengyang Gu"], "title": "Synergizing chemical and AI communities for advancing laboratories of the future", "categories": ["stat.AP", "cs.AI", "cs.LG"], "comment": null, "summary": "The development of automated experimental facilities and the digitization of\nexperimental data have introduced numerous opportunities to radically advance\nchemical laboratories. As many laboratory tasks involve predicting and\nunderstanding previously unknown chemical relationships, machine learning (ML)\napproaches trained on experimental data can substantially accelerate the\nconventional design-build-test-learn process. This outlook article aims to help\nchemists understand and begin to adopt ML predictive models for a variety of\nlaboratory tasks, including experimental design, synthesis optimization, and\nmaterials characterization. Furthermore, this article introduces how artificial\nintelligence (AI) agents based on large language models can help researchers\nacquire background knowledge in chemical or data science and accelerate various\naspects of the discovery process. We present three case studies in distinct\nareas to illustrate how ML models and AI agents can be leveraged to reduce\ntime-consuming experiments and manual data analysis. Finally, we highlight\nexisting challenges that require continued synergistic effort from both\nexperimental and computational communities to address."}
{"id": "2510.16295", "pdf": "https://arxiv.org/pdf/2510.16295", "abs": "https://arxiv.org/abs/2510.16295", "authors": ["Ryoto Miyamoto", "Xin Fan", "Fuyuko Kido", "Tsuneo Matsumoto", "Hayato Yamana"], "title": "OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "OpenLVLM-MIA is a new benchmark that highlights fundamental challenges in\nevaluating membership inference attacks (MIA) against large vision-language\nmodels (LVLMs). While prior work has reported high attack success rates, our\nanalysis suggests that these results often arise from detecting distributional\nbias introduced during dataset construction rather than from identifying true\nmembership status. To address this issue, we introduce a controlled benchmark\nof 6{,}000 images where the distributions of member and non-member samples are\ncarefully balanced, and ground-truth membership labels are provided across\nthree distinct training stages. Experiments using OpenLVLM-MIA demonstrated\nthat the performance of state-of-the-art MIA methods converged to random chance\nunder unbiased conditions. By offering a transparent and unbiased benchmark,\nOpenLVLM-MIA clarifies the current limitations of MIA research on LVLMs and\nprovides a solid foundation for developing stronger privacy-preserving\ntechniques."}
{"id": "2510.16306", "pdf": "https://arxiv.org/pdf/2510.16306", "abs": "https://arxiv.org/abs/2510.16306", "authors": ["Xin Wang", "Yu Wang", "Yunchao Liu", "Jens Meiler", "Tyler Derr"], "title": "Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Ligand-based virtual screening (VS) is an essential step in drug discovery\nthat evaluates large chemical libraries to identify compounds that potentially\nbind to a therapeutic target. However, VS faces three major challenges: class\nimbalance due to the low active rate, structural imbalance among active\nmolecules where certain scaffolds dominate, and the need to identify\nstructurally diverse active compounds for novel drug development. We introduce\nScaffAug, a scaffold-aware VS framework that addresses these challenges through\nthree modules. The augmentation module first generates synthetic data\nconditioned on scaffolds of actual hits using generative AI, specifically a\ngraph diffusion model. This helps mitigate the class imbalance and furthermore\nthe structural imbalance, due to our proposed scaffold-aware sampling\nalgorithm, designed to produce more samples for active molecules with\nunderrepresented scaffolds. A model-agnostic self-training module is then used\nto safely integrate the generated synthetic data from our augmentation module\nwith the original labeled data. Lastly, we introduce a reranking module that\nimproves VS by enhancing scaffold diversity in the top recommended set of\nmolecules, while still maintaining and even enhancing the overall general\nperformance of identifying novel, active compounds. We conduct comprehensive\ncomputational experiments across five target classes, comparing ScaffAug\nagainst existing baseline methods by reporting the performance of multiple\nevaluation metrics and performing ablation studies on ScaffAug. Overall, this\nwork introduces novel perspectives on effectively enhancing VS by leveraging\ngenerative augmentations, reranking, and general scaffold-awareness."}
{"id": "2510.16310", "pdf": "https://arxiv.org/pdf/2510.16310", "abs": "https://arxiv.org/abs/2510.16310", "authors": ["Olajumoke O. Adekunle", "Joseph D. Akinyemi", "Khadijat T. Ladoja", "Olufade F. W. Onifade"], "title": "Lung Cancer Classification from CT Images Using ResNet", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "I.4.0; I.4.9"], "comment": "9 pages,4 figures, 3 tables", "summary": "Lung cancer, a malignancy originating in lung tissues, is commonly diagnosed\nand classified using medical imaging techniques, particularly computed\ntomography (CT). Despite the integration of machine learning and deep learning\nmethods, the predictive efficacy of automated systems for lung cancer\nclassification from CT images remains below the desired threshold for clinical\nadoption. Existing research predominantly focuses on binary classification,\ndistinguishing between malignant and benign lung nodules. In this study, a\nnovel deep learning-based approach is introduced, aimed at an improved\nmulti-class classification, discerning various subtypes of lung cancer from CT\nimages. Leveraging a pre-trained ResNet model, lung tissue images were\nclassified into three distinct classes, two of which denote malignancy and one\nbenign. Employing a dataset comprising 15,000 lung CT images sourced from the\nLC25000 histopathological images, the ResNet50 model was trained on 10,200\nimages, validated on 2,550 images, and tested on the remaining 2,250 images.\nThrough the incorporation of custom layers atop the ResNet architecture and\nmeticulous hyperparameter fine-tuning, a remarkable test accuracy of 98.8% was\nrecorded. This represents a notable enhancement over the performance of prior\nmodels on the same dataset."}
{"id": "2510.16321", "pdf": "https://arxiv.org/pdf/2510.16321", "abs": "https://arxiv.org/abs/2510.16321", "authors": ["Junno Yun", "YaÅar Utku AlÃ§alar", "Mehmet AkÃ§akaya"], "title": "Time-Embedded Algorithm Unrolling for Computational MRI", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "physics.med-ph"], "comment": "Neural Information Processing Systems (NeurIPS), 2025", "summary": "Algorithm unrolling methods have proven powerful for solving the regularized\nleast squares problem in computational magnetic resonance imaging (MRI). These\napproaches unfold an iterative algorithm with a fixed number of iterations,\ntypically alternating between a neural network-based proximal operator for\nregularization, a data fidelity operation and auxiliary updates with learnable\nparameters. While the connection to optimization methods dictate that the\nproximal operator network should be shared across unrolls, this can introduce\nartifacts or blurring. Heuristically, practitioners have shown that using\ndistinct networks may be beneficial, but this significantly increases the\nnumber of learnable parameters, making it challenging to prevent overfitting.\nTo address these shortcomings, by taking inspirations from proximal operators\nwith varying thresholds in approximate message passing (AMP) and the success of\ntime-embedding in diffusion models, we propose a time-embedded algorithm\nunrolling scheme for inverse problems. Specifically, we introduce a novel\nperspective on the iteration-dependent proximal operation in vector AMP (VAMP)\nand the subsequent Onsager correction in the context of algorithm unrolling,\nframing them as a time-embedded neural network. Similarly, the scalar weights\nin the data fidelity operation and its associated Onsager correction are cast\nas time-dependent learnable parameters. Our extensive experiments on the\nfastMRI dataset, spanning various acceleration rates and datasets, demonstrate\nthat our method effectively reduces aliasing artifacts and mitigates noise\namplification, achieving state-of-the-art performance. Furthermore, we show\nthat our time-embedding strategy extends to existing algorithm unrolling\napproaches, enhancing reconstruction quality without increasing the\ncomputational complexity significantly."}
{"id": "2510.16340", "pdf": "https://arxiv.org/pdf/2510.16340", "abs": "https://arxiv.org/abs/2510.16340", "authors": ["Pratham Singla", "Shivank Garg", "Ayush Singh", "Ishan Garg", "Ketan Suhaas Saichandran"], "title": "Thinking About Thinking: Evaluating Reasoning in Post-Trained Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in post-training techniques have endowed Large Language\nModels (LLMs) with enhanced capabilities for tackling complex, logic-intensive\ntasks through the generation of supplementary planning tokens. This development\nraises a fundamental question: Are these models aware of what they \"learn\" and\n\"think\"? To address this, we define three core competencies: (1) awareness of\nlearned latent policies, (2) generalization of these policies across domains,\nand (3) alignment between internal reasoning traces and final outputs. We\nempirically evaluate these abilities on several tasks, each designed to require\nlearning a distinct policy. Furthermore, we contrast the profiles of models\npost-trained via Supervised Fine-Tuning (SFT), Direct Policy Optimization\n(DPO), and Group Relative Policy Optimization (GRPO). Our findings indicate\nthat RL-trained models not only demonstrate greater awareness of their learned\nbehaviors and stronger generalizability to novel, structurally similar tasks\nthan SFT models but also often exhibit weak alignment between their reasoning\ntraces and final outputs, an effect most pronounced in GRPO-trained models."}
{"id": "2510.16344", "pdf": "https://arxiv.org/pdf/2510.16344", "abs": "https://arxiv.org/abs/2510.16344", "authors": ["Chenrui Tie", "Shengxiang Sun", "Yudi Lin", "Yanbo Wang", "Zhongrui Li", "Zhouhan Zhong", "Jinxuan Zhu", "Yiman Pang", "Haonan Chen", "Junting Chen", "Ruihai Wu", "Lin Shao"], "title": "Manual2Skill++: Connector-Aware General Robotic Assembly from Instruction Manuals via Vision-Language Models", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Assembly hinges on reliably forming connections between parts; yet most\nrobotic approaches plan assembly sequences and part poses while treating\nconnectors as an afterthought. Connections represent the critical \"last mile\"\nof assembly execution, while task planning may sequence operations and motion\nplan may position parts, the precise establishment of physical connections\nultimately determines assembly success or failure. In this paper, we consider\nconnections as first-class primitives in assembly representation, including\nconnector types, specifications, quantities, and placement locations. Drawing\ninspiration from how humans learn assembly tasks through step-by-step\ninstruction manuals, we present Manual2Skill++, a vision-language framework\nthat automatically extracts structured connection information from assembly\nmanuals. We encode assembly tasks as hierarchical graphs where nodes represent\nparts and sub-assemblies, and edges explicitly model connection relationships\nbetween components. A large-scale vision-language model parses symbolic\ndiagrams and annotations in manuals to instantiate these graphs, leveraging the\nrich connection knowledge embedded in human-designed instructions. We curate a\ndataset containing over 20 assembly tasks with diverse connector types to\nvalidate our representation extraction approach, and evaluate the complete task\nunderstanding-to-execution pipeline across four complex assembly scenarios in\nsimulation, spanning furniture, toys, and manufacturing components with\nreal-world correspondence."}
{"id": "2510.16363", "pdf": "https://arxiv.org/pdf/2510.16363", "abs": "https://arxiv.org/abs/2510.16363", "authors": ["Nilmadhab Das", "Vishal Vaibhav", "Yash Sunil Choudhary", "V. Vijaya Saradhi", "Ashish Anand"], "title": "End-to-End Argument Mining through Autoregressive Argumentative Structure Prediction", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted version. To appear in IJCNN 2025", "summary": "Argument Mining (AM) helps in automating the extraction of complex\nargumentative structures such as Argument Components (ACs) like Premise, Claim\netc. and Argumentative Relations (ARs) like Support, Attack etc. in an\nargumentative text. Due to the inherent complexity of reasoning involved with\nthis task, modelling dependencies between ACs and ARs is challenging. Most of\nthe recent approaches formulate this task through a generative paradigm by\nflattening the argumentative structures. In contrast to that, this study\njointly formulates the key tasks of AM in an end-to-end fashion using\nAutoregressive Argumentative Structure Prediction (AASP) framework. The\nproposed AASP framework is based on the autoregressive structure prediction\nframework that has given good performance for several NLP tasks. AASP framework\nmodels the argumentative structures as constrained pre-defined sets of actions\nwith the help of a conditional pre-trained language model. These actions build\nthe argumentative structures step-by-step in an autoregressive manner to\ncapture the flow of argumentative reasoning in an efficient way. Extensive\nexperiments conducted on three standard AM benchmarks demonstrate that AASP\nachieves state-of-theart (SoTA) results across all AM tasks in two benchmarks\nand delivers strong results in one benchmark."}
{"id": "2510.16371", "pdf": "https://arxiv.org/pdf/2510.16371", "abs": "https://arxiv.org/abs/2510.16371", "authors": ["Mohammad Javad Ahmadi", "Iman Gandomi", "Parisa Abdi", "Seyed-Farzad Mohammadi", "Amirhossein Taslimi", "Mehdi Khodaparast", "Hassan Hashemi", "Mahdi Tavakoli", "Hamid D. Taghirad"], "title": "Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "20 pages, 11 figures, 11 tables. Data descriptor for the Cataract-LMM\n  benchmark dataset. Source code and dataset are available", "summary": "The development of computer-assisted surgery systems depends on large-scale,\nannotated datasets. Current resources for cataract surgery often lack the\ndiversity and annotation depth needed to train generalizable deep-learning\nmodels. To address this gap, we present a dataset of 3,000 phacoemulsification\ncataract surgery videos from two surgical centers, performed by surgeons with a\nrange of experience levels. This resource is enriched with four annotation\nlayers: temporal surgical phases, instance segmentation of instruments and\nanatomical structures, instrument-tissue interaction tracking, and quantitative\nskill scores based on the established competency rubrics like the ICO-OSCAR.\nThe technical quality of the dataset is supported by a series of benchmarking\nexperiments for key surgical AI tasks, including workflow recognition, scene\nsegmentation, and automated skill assessment. Furthermore, we establish a\ndomain adaptation baseline for the phase recognition task by training a model\non a subset of surgical centers and evaluating its performance on a held-out\ncenter. The dataset and annotations are available in Google Form\n(https://docs.google.com/forms/d/e/1FAIpQLSfmyMAPSTGrIy2sTnz0-TMw08ZagTimRulbAQcWdaPwDy187A/viewform?usp=dialog)."}
{"id": "2510.16373", "pdf": "https://arxiv.org/pdf/2510.16373", "abs": "https://arxiv.org/abs/2510.16373", "authors": ["Federico Ravenda", "Seyed Ali Bahrainian", "Andrea Raballo", "Antonietta Mira"], "title": "Navigating through the hidden embedding space: steering LLMs to improve mental health assessment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid evolution of Large Language Models (LLMs) is transforming AI,\nopening new opportunities in sensitive and high-impact areas such as Mental\nHealth (MH). Yet, despite these advancements, recent evidence reveals that\nsmaller-scale models still struggle to deliver optimal performance in\ndomain-specific applications. In this study, we present a cost-efficient yet\npowerful approach to improve MH assessment capabilities of an LLM, without\nrelying on any computationally intensive techniques. Our lightweight method\nconsists of a linear transformation applied to a specific layer's activations,\nleveraging steering vectors to guide the model's output. Remarkably, this\nintervention enables the model to achieve improved results across two distinct\ntasks: (1) identifying whether a Reddit post is useful for detecting the\npresence or absence of depressive symptoms (relevance prediction task), and (2)\ncompleting a standardized psychological screening questionnaire for depression\nbased on users' Reddit post history (questionnaire completion task). Results\nhighlight the untapped potential of steering mechanisms as computationally\nefficient tools for LLMs' MH domain adaptation."}
{"id": "2510.16376", "pdf": "https://arxiv.org/pdf/2510.16376", "abs": "https://arxiv.org/abs/2510.16376", "authors": ["Han Wang", "Chao Ning"], "title": "Conformal Prediction in The Loop: A Feedback-Based Uncertainty Model for Trajectory Optimization", "categories": ["math.OC", "cs.AI", "cs.RO", "cs.SY", "eess.SY", "math.ST", "stat.TH"], "comment": "Accepted by NeurIPS 2025 Main Track", "summary": "Conformal Prediction (CP) is a powerful statistical machine learning tool to\nconstruct uncertainty sets with coverage guarantees, which has fueled its\nextensive adoption in generating prediction regions for decision-making tasks,\ne.g., Trajectory Optimization (TO) in uncertain environments. However, existing\nmethods predominantly employ a sequential scheme, where decisions rely\nunidirectionally on the prediction regions, and consequently the information\nfrom decision-making fails to be fed back to instruct CP. In this paper, we\npropose a novel Feedback-Based CP (Fb-CP) framework for shrinking-horizon TO\nwith a joint risk constraint over the entire mission time. Specifically, a\nCP-based posterior risk calculation method is developed by fully leveraging the\nrealized trajectories to adjust the posterior allowable risk, which is then\nallocated to future times to update prediction regions. In this way, the\ninformation in the realized trajectories is continuously fed back to the CP,\nenabling attractive feedback-based adjustments of the prediction regions and a\nprovable online improvement in trajectory performance. Furthermore, we\ntheoretically prove that such adjustments consistently maintain the coverage\nguarantees of the prediction regions, thereby ensuring provable safety.\nAdditionally, we develop a decision-focused iterative risk allocation algorithm\nwith theoretical convergence analysis for allocating the posterior allowable\nrisk which closely aligns with Fb-CP. Furthermore, we extend the proposed\nmethod to handle distribution shift. The effectiveness and superiority of the\nproposed method are demonstrated through benchmark experiments."}
{"id": "2510.16380", "pdf": "https://arxiv.org/pdf/2510.16380", "abs": "https://arxiv.org/abs/2510.16380", "authors": ["Yu Ying Chiu", "Michael S. Lee", "Rachel Calcott", "Brandon Handoko", "Paul de Font-Reaulx", "Paula Rodriguez", "Chen Bo Calvin Zhang", "Ziwen Han", "Udari Madhushani Sehwag", "Yash Maurya", "Christina Q Knight", "Harry R. Lloyd", "Florence Bacus", "Mantas Mazeika", "Bing Liu", "Yejin Choi", "Mitchell L Gordon", "Sydney Levine"], "title": "MoReBench: Evaluating Procedural and Pluralistic Moral Reasoning in Language Models, More than Outcomes", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "comment": "46 pages, 8 figures, 10 tables. Preprint", "summary": "As AI systems progress, we rely more on them to make decisions with us and\nfor us. To ensure that such decisions are aligned with human values, it is\nimperative for us to understand not only what decisions they make but also how\nthey come to those decisions. Reasoning language models, which provide both\nfinal responses and (partially transparent) intermediate thinking traces,\npresent a timely opportunity to study AI procedural reasoning. Unlike math and\ncode problems which often have objectively correct answers, moral dilemmas are\nan excellent testbed for process-focused evaluation because they allow for\nmultiple defensible conclusions. To do so, we present MoReBench: 1,000 moral\nscenarios, each paired with a set of rubric criteria that experts consider\nessential to include (or avoid) when reasoning about the scenarios. MoReBench\ncontains over 23 thousand criteria including identifying moral considerations,\nweighing trade-offs, and giving actionable recommendations to cover cases on AI\nadvising humans moral decisions as well as making moral decisions autonomously.\nSeparately, we curate MoReBench-Theory: 150 examples to test whether AI can\nreason under five major frameworks in normative ethics. Our results show that\nscaling laws and existing benchmarks on math, code, and scientific reasoning\ntasks fail to predict models' abilities to perform moral reasoning. Models also\nshow partiality towards specific moral frameworks (e.g., Benthamite Act\nUtilitarianism and Kantian Deontology), which might be side effects of popular\ntraining paradigms. Together, these benchmarks advance process-focused\nreasoning evaluation towards safer and more transparent AI."}
{"id": "2510.16381", "pdf": "https://arxiv.org/pdf/2510.16381", "abs": "https://arxiv.org/abs/2510.16381", "authors": ["David Peer", "Sebastian Stabinger"], "title": "ATA: A Neuro-Symbolic Approach to Implement Autonomous and Trustworthy Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities, yet\ntheir deployment in high-stakes domains is hindered by inherent limitations in\ntrustworthiness, including hallucinations, instability, and a lack of\ntransparency. To address these challenges, we introduce a generic\nneuro-symbolic approach, which we call Autonomous Trustworthy Agents (ATA). The\ncore of our approach lies in decoupling tasks into two distinct phases: Offline\nknowledge ingestion and online task processing. During knowledge ingestion, an\nLLM translates an informal problem specification into a formal, symbolic\nknowledge base. This formal representation is crucial as it can be verified and\nrefined by human experts, ensuring its correctness and alignment with domain\nrequirements. In the subsequent task processing phase, each incoming input is\nencoded into the same formal language. A symbolic decision engine then utilizes\nthis encoded input in conjunction with the formal knowledge base to derive a\nreliable result. Through an extensive evaluation on a complex reasoning task,\nwe demonstrate that a concrete implementation of ATA is competitive with\nstate-of-the-art end-to-end reasoning models in a fully automated setup while\nmaintaining trustworthiness. Crucially, with a human-verified and corrected\nknowledge base, our approach significantly outperforms even larger models,\nwhile exhibiting perfect determinism, enhanced stability against input\nperturbations, and inherent immunity to prompt injection attacks. By generating\ndecisions grounded in symbolic reasoning, ATA offers a practical and\ncontrollable architecture for building the next generation of transparent,\nauditable, and reliable autonomous agents."}
{"id": "2510.16387", "pdf": "https://arxiv.org/pdf/2510.16387", "abs": "https://arxiv.org/abs/2510.16387", "authors": ["Fu-An Chao", "Bi-Cheng Yan", "Berlin Chen"], "title": "Probing the Hidden Talent of ASR Foundation Models for L2 English Oral Assessment", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "comment": null, "summary": "In this paper, we explore the untapped potential of Whisper, a\nwell-established automatic speech recognition (ASR) foundation model, in the\ncontext of L2 spoken language assessment (SLA). Unlike prior studies that\nextrinsically analyze transcriptions produced by Whisper, our approach goes a\nstep further to probe its latent capabilities by extracting acoustic and\nlinguistic features from hidden representations. With only a lightweight\nclassifier being trained on top of Whisper's intermediate and final outputs,\nour method achieves strong performance on the GEPT picture-description dataset,\noutperforming existing cutting-edge baselines, including a multimodal approach.\nFurthermore, by incorporating image and text-prompt information as auxiliary\nrelevance cues, we demonstrate additional performance gains. Finally, we\nconduct an in-depth analysis of Whisper's embeddings, which reveals that, even\nwithout task-specific fine-tuning, the model intrinsically encodes both ordinal\nproficiency patterns and semantic aspects of speech, highlighting its potential\nas a powerful foundation for SLA and other spoken language understanding tasks."}
{"id": "2510.16396", "pdf": "https://arxiv.org/pdf/2510.16396", "abs": "https://arxiv.org/abs/2510.16396", "authors": ["Yeh Keng Hao", "Hsu Tzu Wei", "Sun Min"], "title": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to AICCC 2025", "summary": "With the increasing ubiquity of AR/VR devices, the deployment of deep\nlearning models on edge devices has become a critical challenge. These devices\nrequire real-time inference, low power consumption, and minimal latency. Many\nframework designers face the conundrum of balancing efficiency and performance.\nWe design a light framework that adopts an encoder-decoder architecture and\nintroduces several key contributions aimed at improving both efficiency and\naccuracy. We apply sparse convolution on a ResNet-18 backbone to exploit the\ninherent sparsity in hand pose images, achieving a 42% end-to-end efficiency\nimprovement. Moreover, we propose our SPLite decoder. This new architecture\nsignificantly boosts the decoding process's frame rate by 3.1x on the Raspberry\nPi 5, while maintaining accuracy on par. To further optimize performance, we\napply quantization-aware training, reducing memory usage while preserving\naccuracy (PA-MPJPE increases only marginally from 9.0 mm to 9.1 mm on\nFreiHAND). Overall, our system achieves a 2.98x speed-up on a Raspberry Pi 5\nCPU (BCM2712 quad-core Arm A76 processor). Our method is also evaluated on\ncompound benchmark datasets, demonstrating comparable accuracy to\nstate-of-the-art approaches while significantly enhancing computational\nefficiency."}
{"id": "2510.16411", "pdf": "https://arxiv.org/pdf/2510.16411", "abs": "https://arxiv.org/abs/2510.16411", "authors": ["Minh-Khoi Nguyen-Nhat", "Rachel S. Y. Teo", "Laziz Abdullaev", "Maurice Mok", "Viet-Hoang Tran", "Tan Minh Nguyen"], "title": "Modeling Expert Interactions in Sparse Mixture of Experts via Graph Structures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sparse Mixture of Experts (SMoE) has emerged as a promising solution to\nachieving unparalleled scalability in deep learning by decoupling model\nparameter count from computational cost. By activating only a small subset of\nparameters per sample, SMoE enables significant growth in model capacity while\nmaintaining efficiency. However, SMoE struggles to adapt to distributional\nshifts, leading to reduced robustness under data contamination. In this work,\nwe introduce SymphonySMoE, a novel family of SMoE that introduces a social\ngraph to model interactions among experts. This graph-based structure enhances\nthe token routing process, addressing the robustness challenges that are\ninherent in conventional SMoE designs. SymphonySMoE is lightweight, modular,\nand integrates seamlessly with existing SMoE-based models such as the XMoE and\nthe Generalist Language Model. We provide both theoretical analysis and\nempirical evidence demonstrating SymphonySMoE's advantages over baseline SMoE.\nExtensive experiments on language modeling and visual instruction tuning\nvalidate our method's effectiveness. We further highlight the scalability of\nSymphonySMoE to models with 4.2 and 7.4 billion parameters, showcasing its\napplicability in fine-tuning tasks for large-scale systems."}
{"id": "2510.16416", "pdf": "https://arxiv.org/pdf/2510.16416", "abs": "https://arxiv.org/abs/2510.16416", "authors": ["Xiaojun Guo", "Runyu Zhou", "Yifei Wang", "Qi Zhang", "Chenheng Zhang", "Stefanie Jegelka", "Xiaohan Wang", "Jiajun Chai", "Guojun Yin", "Wei Lin", "Yisen Wang"], "title": "SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-language models (VLMs) have shown remarkable abilities by integrating\nlarge language models with visual inputs. However, they often fail to utilize\nvisual evidence adequately, either depending on linguistic priors in\nvision-centric tasks or resorting to textual shortcuts during reasoning.\nAlthough reinforcement learning (RL) can align models with desired behaviors,\nits application to VLMs has been hindered by the lack of scalable and reliable\nreward mechanisms. To overcome this challenge, we propose SSL4RL, a novel\nframework that leverages self-supervised learning (SSL) tasks as a source of\nverifiable rewards for RL-based fine-tuning. Our approach reformulates SSL\nobjectives-such as predicting image rotation or reconstructing masked\npatches-into dense, automatic reward signals, eliminating the need for human\npreference data or unreliable AI evaluators. Experiments show that SSL4RL\nsubstantially improves performance on both vision-centric and vision-language\nreasoning benchmarks. Furthermore, through systematic ablations, we identify\nkey factors-such as task difficulty, model scale, and semantic alignment with\nthe target domain-that influence the effectiveness of SSL4RL tasks, offering\nnew design principles for future work. We also demonstrate the framework's\ngenerality by applying it to graph learning, where it yields significant gains.\nSSL4RL establishes a versatile and effective paradigm for aligning multimodal\nmodels using verifiable, self-supervised objectives."}
{"id": "2510.16442", "pdf": "https://arxiv.org/pdf/2510.16442", "abs": "https://arxiv.org/abs/2510.16442", "authors": ["Haoran Sun", "Chen Cai", "Huiping Zhuang", "Kong Aik Lee", "Lap-Pui Chau", "Yi Wang"], "title": "EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The rapid development of deepfake video technology has not only facilitated\nartistic creation but also made it easier to spread misinformation. Traditional\ndeepfake video detection (DVD) methods face issues such as a lack of\ntransparency in their principles and insufficient generalization capabilities\nto cope with evolving forgery techniques. This highlights an urgent need for\ndetectors that can identify forged content and provide verifiable reasoning\nexplanations. This paper proposes the explainable deepfake video detection\n(EDVD) task and designs the EDVD-LLaMA multimodal, a large language model\n(MLLM) reasoning framework, which provides traceable reasoning processes\nalongside accurate detection results and trustworthy explanations. Our approach\nfirst incorporates a Spatio-Temporal Subtle Information Tokenization (ST-SIT)\nto extract and fuse global and local cross-frame deepfake features, providing\nrich spatio-temporal semantic information input for MLLM reasoning. Second, we\nconstruct a Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) mechanism, which\nintroduces facial feature data as hard constraints during the reasoning process\nto achieve pixel-level spatio-temporal video localization, suppress\nhallucinated outputs, and enhance the reliability of the chain of thought. In\naddition, we build an Explainable Reasoning FF++ benchmark dataset\n(ER-FF++set), leveraging structured data to annotate videos and ensure quality\ncontrol, thereby supporting dual supervision for reasoning and detection.\nExtensive experiments demonstrate that EDVD-LLaMA achieves outstanding\nperformance and robustness in terms of detection accuracy, explainability, and\nits ability to handle cross-forgery methods and cross-dataset scenarios.\nCompared to previous DVD methods, it provides a more explainable and superior\nsolution. The source code and dataset will be publicly available."}
{"id": "2510.16448", "pdf": "https://arxiv.org/pdf/2510.16448", "abs": "https://arxiv.org/abs/2510.16448", "authors": ["Yongxiang Hua", "Haoyu Cao", "Zhou Tao", "Bocheng Li", "Zihao Wu", "Chaohu Liu", "Linli Xu"], "title": "Input Domain Aware MoE: Decoupling Routing Decisions from Task Optimization in Mixture of Experts", "categories": ["cs.LG", "cs.AI"], "comment": "ACM MM25", "summary": "Sparse Mixture of Experts (sMoE) has become a pivotal approach for scaling\nlarge vision-language models, offering substantial capacity while maintaining\ncomputational efficiency through dynamic, sparse activation of experts.\nHowever, existing routing mechanisms, typically based on similarity scoring,\nstruggle to effectively capture the underlying input structure. This limitation\nleads to a trade-off between expert specialization and balanced computation,\nhindering both scalability and performance. We propose Input Domain Aware MoE,\na novel routing framework that leverages a probabilistic mixture model to\nbetter partition the input space. By modeling routing probabilities as a\nmixture of distributions, our method enables experts to develop clear\nspecialization boundaries while achieving balanced utilization. Unlike\nconventional approaches, our routing mechanism is trained independently of\ntask-specific objectives, allowing for stable optimization and decisive expert\nassignments. Empirical results on vision-language tasks demonstrate that our\nmethod consistently outperforms existing sMoE approaches, achieving higher task\nperformance and improved expert utilization balance."}
{"id": "2510.16470", "pdf": "https://arxiv.org/pdf/2510.16470", "abs": "https://arxiv.org/abs/2510.16470", "authors": ["Elham Khabiri", "Jeffrey O. Kephart", "Fenno F. Heath III", "Srideepika Jayaraman", "Fateh A. Tipu", "Yingjie Li", "Dhruv Shah", "Achille Fokoue", "Anu Bhamidipaty"], "title": "Declarative Techniques for NL Queries over Heterogeneous Data", "categories": ["cs.DB", "cs.AI", "cs.SE"], "comment": null, "summary": "In many industrial settings, users wish to ask questions in natural language,\nthe answers to which require assembling information from diverse structured\ndata sources. With the advent of Large Language Models (LLMs), applications can\nnow translate natural language questions into a set of API calls or database\ncalls, execute them, and combine the results into an appropriate natural\nlanguage response. However, these applications remain impractical in realistic\nindustrial settings because they do not cope with the data source heterogeneity\nthat typifies such environments. In this work, we simulate the heterogeneity of\nreal industry settings by introducing two extensions of the popular Spider\nbenchmark dataset that require a combination of database and API calls. Then,\nwe introduce a declarative approach to handling such data heterogeneity and\ndemonstrate that it copes with data source heterogeneity significantly better\nthan state-of-the-art LLM-based agentic or imperative code generation systems.\nOur augmented benchmarks are available to the research community."}
{"id": "2510.16499", "pdf": "https://arxiv.org/pdf/2510.16499", "abs": "https://arxiv.org/abs/2510.16499", "authors": ["Michelle Yuan", "Khushbu Pahwa", "Shuaichen Chang", "Mustafa Kaba", "Jiarong Jiang", "Xiaofei Ma", "Yi Zhang", "Monica Sunkara"], "title": "Automated Composition of Agents: A Knapsack Approach for Agentic Component Selection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to NeurIPS 2025 Conference", "summary": "Designing effective agentic systems requires the seamless composition and\nintegration of agents, tools, and models within dynamic and uncertain\nenvironments. Most existing methods rely on static, semantic retrieval\napproaches for tool or agent discovery. However, effective reuse and\ncomposition of existing components remain challenging due to incomplete\ncapability descriptions and the limitations of retrieval methods. Component\nselection suffers because the decisions are not based on capability, cost, and\nreal-time utility. To address these challenges, we introduce a structured,\nautomated framework for agentic system composition that is inspired by the\nknapsack problem. Our framework enables a composer agent to systematically\nidentify, select, and assemble an optimal set of agentic components by jointly\nconsidering performance, budget constraints, and compatibility. By dynamically\ntesting candidate components and modeling their utility in real-time, our\napproach streamlines the assembly of agentic systems and facilitates scalable\nreuse of resources. Empirical evaluation with Claude 3.5 Sonnet across five\nbenchmarking datasets shows that our online-knapsack-based composer\nconsistently lies on the Pareto frontier, achieving higher success rates at\nsignificantly lower component costs compared to our baselines. In the\nsingle-agent setup, the online knapsack composer shows a success rate\nimprovement of up to 31.6% in comparison to the retrieval baselines. In\nmulti-agent systems, the online knapsack composer increases success rate from\n37% to 87% when agents are selected from an agent inventory of 100+ agents. The\nsubstantial performance gap confirms the robust adaptability of our method\nacross diverse domains and budget constraints."}
{"id": "2510.16511", "pdf": "https://arxiv.org/pdf/2510.16511", "abs": "https://arxiv.org/abs/2510.16511", "authors": ["Dongchan Cho", "Jiho Han", "Keumyeong Kang", "Minsang Kim", "Honggyu Ryu", "Namsoon Jung"], "title": "Structured Temporal Causality for Interpretable Multivariate Time Series Anomaly Detection", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted by NeurIPS 2025", "summary": "Real-world multivariate time series anomalies are rare and often unlabeled.\nAdditionally, prevailing methods rely on increasingly complex architectures\ntuned to benchmarks, detecting only fragments of anomalous segments and\noverstating performance. In this paper, we introduce OracleAD, a simple and\ninterpretable unsupervised framework for multivariate time series anomaly\ndetection. OracleAD encodes each variable's past sequence into a single causal\nembedding to jointly predict the present time point and reconstruct the input\nwindow, effectively modeling temporal dynamics. These embeddings then undergo a\nself-attention mechanism to project them into a shared latent space and capture\nspatial relationships. These relationships are not static, since they are\nmodeled by a property that emerges from each variable's temporal dynamics. The\nprojected embeddings are aligned to a Stable Latent Structure (SLS)\nrepresenting normal-state relationships. Anomalies are identified using a dual\nscoring mechanism based on prediction error and deviation from the SLS,\nenabling fine-grained anomaly diagnosis at each time point and across\nindividual variables. Since any noticeable SLS deviation originates from\nembeddings that violate the learned temporal causality of normal data, OracleAD\ndirectly pinpoints the root-cause variables at the embedding level. OracleAD\nachieves state-of-the-art results across multiple real-world datasets and\nevaluation protocols, while remaining interpretable through SLS."}
{"id": "2510.16514", "pdf": "https://arxiv.org/pdf/2510.16514", "abs": "https://arxiv.org/abs/2510.16514", "authors": ["Duygu Sap", "Martin Lotz", "Connor Mattinson"], "title": "Image Categorization and Search via a GAT Autoencoder and Representative Models", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 22 figures, Under review", "summary": "We propose a method for image categorization and retrieval that leverages\ngraphs and a graph attention network (GAT)-based autoencoder. Our approach is\nrepresentative-centric, that is, we execute the categorization and retrieval\nprocess via the representative models we construct for the images and image\ncategories. We utilize a graph where nodes represent images (or their\nrepresentatives) and edges capture similarity relationships. GAT highlights\nimportant features and relationships between images, enabling the autoencoder\nto construct context-aware latent representations that capture the key features\nof each image relative to its neighbors. We obtain category representatives\nfrom these embeddings and categorize a query image by comparing its\nrepresentative to the category representatives. We then retrieve the most\nsimilar image to the query image within its identified category. We demonstrate\nthe effectiveness of our representative-centric approach through experiments\nwith both the GAT autoencoders and standard feature-based techniques."}
{"id": "2510.16518", "pdf": "https://arxiv.org/pdf/2510.16518", "abs": "https://arxiv.org/abs/2510.16518", "authors": ["JesÃºs Ortega-Peimbert", "Finn Lukas Busch", "Timon Homberger", "Quantao Yang", "Olov Andersson"], "title": "DIV-Nav: Open-Vocabulary Spatial Relationships for Multi-Object Navigation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Advances in open-vocabulary semantic mapping and object navigation have\nenabled robots to perform an informed search of their environment for an\narbitrary object. However, such zero-shot object navigation is typically\ndesigned for simple queries with an object name like \"television\" or \"blue\nrug\". Here, we consider more complex free-text queries with spatial\nrelationships, such as \"find the remote on the table\" while still leveraging\nrobustness of a semantic map. We present DIV-Nav, a real-time navigation system\nthat efficiently addresses this problem through a series of relaxations: i)\nDecomposing natural language instructions with complex spatial constraints into\nsimpler object-level queries on a semantic map, ii) computing the Intersection\nof individual semantic belief maps to identify regions where all objects\nco-exist, and iii) Validating the discovered objects against the original,\ncomplex spatial constrains via a LVLM. We further investigate how to adapt the\nfrontier exploration objectives of online semantic mapping to such spatial\nsearch queries to more effectively guide the search process. We validate our\nsystem through extensive experiments on the MultiON benchmark and real-world\ndeployment on a Boston Dynamics Spot robot using a Jetson Orin AGX. More\ndetails and videos are available at https://anonsub42.github.io/reponame/"}
{"id": "2510.16536", "pdf": "https://arxiv.org/pdf/2510.16536", "abs": "https://arxiv.org/abs/2510.16536", "authors": ["Niranjana Arun Menon", "Yulong Li", "Iqra Farooq", "Sara Ahmed", "Muhammad Awais", "Imran Razzak"], "title": "Few-Label Multimodal Modeling of SNP Variants and ECG Phenotypes Using Large Language Models for Cardiovascular Risk Stratification", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Cardiovascular disease (CVD) risk stratification remains a major challenge\ndue to its multifactorial nature and limited availability of high-quality\nlabeled datasets. While genomic and electrophysiological data such as SNP\nvariants and ECG phenotypes are increasingly accessible, effectively\nintegrating these modalities in low-label settings is non-trivial. This\nchallenge arises from the scarcity of well-annotated multimodal datasets and\nthe high dimensionality of biological signals, which limit the effectiveness of\nconventional supervised models. To address this, we present a few-label\nmultimodal framework that leverages large language models (LLMs) to combine\ngenetic and electrophysiological information for cardiovascular risk\nstratification. Our approach incorporates a pseudo-label refinement strategy to\nadaptively distill high-confidence labels from weakly supervised predictions,\nenabling robust model fine-tuning with only a small set of ground-truth\nannotations. To enhance the interpretability, we frame the task as a Chain of\nThought (CoT) reasoning problem, prompting the model to produce clinically\nrelevant rationales alongside predictions. Experimental results demonstrate\nthat the integration of multimodal inputs, few-label supervision, and CoT\nreasoning improves robustness and generalizability across diverse patient\nprofiles. Experimental results using multimodal SNP variants and ECG-derived\nfeatures demonstrated comparable performance to models trained on the full\ndataset, underscoring the promise of LLM-based few-label multimodal modeling\nfor advancing personalized cardiovascular care."}
{"id": "2510.16540", "pdf": "https://arxiv.org/pdf/2510.16540", "abs": "https://arxiv.org/abs/2510.16540", "authors": ["Jihoon Kwon", "Kyle Min", "Jy-yong Sohn"], "title": "Enhancing Compositional Reasoning in CLIP via Reconstruction and Alignment of Text Descriptions", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at NeurIPS 2025 (poster). This is the camera-ready version", "summary": "Despite recent advances, vision-language models trained with standard\ncontrastive objectives still struggle with compositional reasoning -- the\nability to understand structured relationships between visual and linguistic\nelements. This shortcoming is largely due to the tendency of the text encoder\nto focus on individual words rather than their relations, a limitation\nreinforced by contrastive training that primarily aligns words with visual\nobjects. In this paper, we introduce REconstruction and Alignment of text\nDescriptions (READ), a fine-tuning method designed to enhance compositional\nreasoning by adding two auxiliary objectives to the contrastive learning: (1) a\ntoken-level reconstruction objective, where a frozen pre-trained decoder\nreconstructs alternative captions based on the embedding of the original\ncaption; and (2) a sentence-level alignment objective, which explicitly aligns\nparaphrased sentences in the embedding space. We show that READ-CLIP, a model\nderived by applying the READ method to the pre-trained CLIP model, achieves the\nstate-of-the-art performance across five major compositional reasoning\nbenchmarks, outperforming the strongest conventional fine-tuning baseline by up\nto 4.1%. Furthermore, applying the READ to existing CLIP variants (including\nNegCLIP and FSC-CLIP) also improves performance on these benchmarks.\nQuantitative and qualitative analyses reveal that our proposed objectives --\nreconstruction and alignment -- offer complementary benefits: the former\nencourages the encoder to capture relationships between words within a caption,\nwhile the latter ensures consistent representations for paraphrases expressed\nwith different wording."}
{"id": "2510.16541", "pdf": "https://arxiv.org/pdf/2510.16541", "abs": "https://arxiv.org/abs/2510.16541", "authors": ["Binyuan Huang", "Yongdong Luo", "Xianda Guo", "Xiawu Zheng", "Zheng Zhu", "Jiahui Pan", "Chengju Zhou"], "title": "Watch Where You Move: Region-aware Dynamic Aggregation and Excitation for Gait Recognition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep learning-based gait recognition has achieved great success in various\napplications. The key to accurate gait recognition lies in considering the\nunique and diverse behavior patterns in different motion regions, especially\nwhen covariates affect visual appearance. However, existing methods typically\nuse predefined regions for temporal modeling, with fixed or equivalent temporal\nscales assigned to different types of regions, which makes it difficult to\nmodel motion regions that change dynamically over time and adapt to their\nspecific patterns. To tackle this problem, we introduce a Region-aware Dynamic\nAggregation and Excitation framework (GaitRDAE) that automatically searches for\nmotion regions, assigns adaptive temporal scales and applies corresponding\nattention. Specifically, the framework includes two core modules: the\nRegion-aware Dynamic Aggregation (RDA) module, which dynamically searches the\noptimal temporal receptive field for each region, and the Region-aware Dynamic\nExcitation (RDE) module, which emphasizes the learning of motion regions\ncontaining more stable behavior patterns while suppressing attention to static\nregions that are more susceptible to covariates. Experimental results show that\nGaitRDAE achieves state-of-the-art performance on several benchmark datasets."}
{"id": "2510.16547", "pdf": "https://arxiv.org/pdf/2510.16547", "abs": "https://arxiv.org/abs/2510.16547", "authors": ["Alif Elham Khan", "Mohammad Junayed Hasan", "Humayra Anjum", "Nabeel Mohammed", "Sifat Momen"], "title": "Predicting life satisfaction using machine learning and explainable AI", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Life satisfaction is a crucial facet of human well-being. Hence, research on\nlife satisfaction is incumbent for understanding how individuals experience\ntheir lives and influencing interventions targeted at enhancing mental health\nand well-being. Life satisfaction has traditionally been measured using analog,\ncomplicated, and frequently error-prone methods. These methods raise questions\nconcerning validation and propagation. However, this study demonstrates the\npotential for machine learning algorithms to predict life satisfaction with a\nhigh accuracy of 93.80% and a 73.00% macro F1-score. The dataset comes from a\ngovernment survey of 19000 people aged 16-64 years in Denmark. Using feature\nlearning techniques, 27 significant questions for assessing contentment were\nextracted, making the study highly reproducible, simple, and easily\ninterpretable. Furthermore, clinical and biomedical large language models\n(LLMs) were explored for predicting life satisfaction by converting tabular\ndata into natural language sentences through mapping and adding meaningful\ncounterparts, achieving an accuracy of 93.74% and macro F1-score of 73.21%. It\nwas found that life satisfaction prediction is more closely related to the\nbiomedical domain than the clinical domain. Ablation studies were also\nconducted to understand the impact of data resampling and feature selection\ntechniques on model performance. Moreover, the correlation between primary\ndeterminants with different age brackets was analyzed, and it was found that\nhealth condition is the most important determinant across all ages. This study\ndemonstrates how machine learning, large language models and XAI can jointly\ncontribute to building trust and understanding in using AI to investigate human\nbehavior, with significant ramifications for academics and professionals\nworking to quantify and comprehend subjective well-being."}
{"id": "2510.16552", "pdf": "https://arxiv.org/pdf/2510.16552", "abs": "https://arxiv.org/abs/2510.16552", "authors": ["Ang Li", "Yifei Wang", "Zhihang Yuan", "Stefanie Jegelka", "Yisen Wang"], "title": "LANPO: Bootstrapping Language and Numerical Feedback for Reinforcement Learning in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning in large language models (LLMs) often relies on scalar\nrewards, a practice that discards valuable textual rationale buried in the\nrollouts, forcing the model to explore \\textit{de novo} with each attempt and\nhindering sample efficiency. While LLMs can uniquely learn from language\nfeedback provided in-context, naively integrating on-line experiences into RL\ntraining presents a paradox: feedback from the same problem risks information\nleakage and memorization, while feedback from different problems often leads to\nbehavior collapse due to irrelevant context. To resolve this tension, we\npropose \\textbf{Language-And-Numerical Policy Optimization (LANPO)}, a\nframework that cleanly separates the roles of feedback: language guides\nexploration, while numerical rewards drive optimization. LANPO builds a dynamic\nexperience pool from past trials and introduces two principles to ensure\nfeedback is effective: \\emph{Reward-Agnostic Reflection} for safe intra-sample\nself-correction and \\emph{Relevant Abstraction} to distill generalizable\nlessons from inter-sample experiences. Across mathematical reasoning\nbenchmarks, LANPO enables 7B and 14B models to significantly outperform strong\nbaselines trained with GRPO in test accuracy. Our work provides a robust method\nfor integrating historical experiences into the LLM RL loop, creating more\neffective and data-efficient learning agents."}
{"id": "2510.16558", "pdf": "https://arxiv.org/pdf/2510.16558", "abs": "https://arxiv.org/abs/2510.16558", "authors": ["Xiaofan Li", "Xing Gao"], "title": "Toward Understanding Security Issues in the Model Context Protocol Ecosystem", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The Model Context Protocol (MCP) is an emerging open standard that enables\nAI-powered applications to interact with external tools through structured\nmetadata. A rapidly growing ecosystem has formed around MCP, including a wide\nrange of MCP hosts (i.e., Cursor, Windsurf, Claude Desktop, and Cline), MCP\nregistries (i.e., mcp.so, MCP Market, MCP Store, Pulse MCP, Smithery, and npm),\nand thousands of community-contributed MCP servers. Although the MCP ecosystem\nis gaining traction, there has been little systematic study of its architecture\nand associated security risks. In this paper, we present the first\ncomprehensive security analysis of the MCP ecosystem. We decompose MCP\necosystem into three core components: hosts, registries, and servers, and study\nthe interactions and trust relationships among them. Users search for servers\non registries and configure them in the host, which translates LLM-generated\noutput into external tool invocations provided by the servers and executes\nthem. Our qualitative analysis reveals that hosts lack output verification\nmechanisms for LLM-generated outputs, enabling malicious servers to manipulate\nmodel behavior and induce a variety of security threats, including but not\nlimited to sensitive data exfiltration. We uncover a wide range of\nvulnerabilities that enable attackers to hijack servers, due to the lack of a\nvetted server submission process in registries. To support our analysis, we\ncollect and analyze a dataset of 67,057 servers from six public registries. Our\nquantitative analysis demonstrates that a substantial number of servers can be\nhijacked by attackers. Finally, we propose practical defense strategies for MCP\nhosts, registries, and users. We responsibly disclosed our findings to affected\nhosts and registries."}
{"id": "2510.16565", "pdf": "https://arxiv.org/pdf/2510.16565", "abs": "https://arxiv.org/abs/2510.16565", "authors": ["Seungho Cho", "Changgeon Ko", "Eui Jun Hwang", "Junmyeong Lee", "Huije Lee", "Jong C. Park"], "title": "Language over Content: Tracing Cultural Understanding in Multilingual Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to CIKM 2025 Workshop on Human Centric AI", "summary": "Large language models (LLMs) are increasingly used across diverse cultural\ncontexts, making accurate cultural understanding essential. Prior evaluations\nhave mostly focused on output-level performance, obscuring the factors that\ndrive differences in responses, while studies using circuit analysis have\ncovered few languages and rarely focused on culture. In this work, we trace\nLLMs' internal cultural understanding mechanisms by measuring activation path\noverlaps when answering semantically equivalent questions under two conditions:\nvarying the target country while fixing the question language, and varying the\nquestion language while fixing the country. We also use same-language country\npairs to disentangle language from cultural aspects. Results show that internal\npaths overlap more for same-language, cross-country questions than for\ncross-language, same-country questions, indicating strong language-specific\npatterns. Notably, the South Korea-North Korea pair exhibits low overlap and\nhigh variability, showing that linguistic similarity does not guarantee aligned\ninternal representation."}
{"id": "2510.16573", "pdf": "https://arxiv.org/pdf/2510.16573", "abs": "https://arxiv.org/abs/2510.16573", "authors": ["Muhammad Ammar", "Hadiya Murad Hadi", "Usman Majeed Butt"], "title": "AI-Generated Text Detection in Low-Resource Languages: A Case Study on Urdu", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are now capable of generating text that closely\nresembles human writing, making them powerful tools for content creation, but\nthis growing ability has also made it harder to tell whether a piece of text\nwas written by a human or by a machine. This challenge becomes even more\nserious for languages like Urdu, where there are very few tools available to\ndetect AI-generated text. To address this gap, we propose a novel AI-generated\ntext detection framework tailored for the Urdu language. A balanced dataset\ncomprising 1,800 humans authored, and 1,800 AI generated texts, sourced from\nmodels such as Gemini, GPT-4o-mini, and Kimi AI was developed. Detailed\nlinguistic and statistical analysis was conducted, focusing on features such as\ncharacter and word counts, vocabulary richness (Type Token Ratio), and N-gram\npatterns, with significance evaluated through t-tests and MannWhitney U tests.\nThree state-of-the-art multilingual transformer models such as\nmdeberta-v3-base, distilbert-base-multilingualcased, and xlm-roberta-base were\nfine-tuned on this dataset. The mDeBERTa-v3-base achieved the highest\nperformance, with an F1-score 91.29 and accuracy of 91.26% on the test set.\nThis research advances efforts in contesting misinformation and academic\nmisconduct in Urdu-speaking communities and contributes to the broader\ndevelopment of NLP tools for low resource languages."}
{"id": "2510.16590", "pdf": "https://arxiv.org/pdf/2510.16590", "abs": "https://arxiv.org/abs/2510.16590", "authors": ["Alan Kai Hassen", "Andrius Bernatavicius", "Antonius P. A. Janssen", "Mike Preuss", "Gerard J. P. van Westen", "Djork-ArnÃ© Clevert"], "title": "Atom-anchored LLMs speak Chemistry: A Retrosynthesis Demonstration", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": "Alan Kai Hassen and Andrius Bernatavicius contributed equally to this\n  work", "summary": "Applications of machine learning in chemistry are often limited by the\nscarcity and expense of labeled data, restricting traditional supervised\nmethods. In this work, we introduce a framework for molecular reasoning using\ngeneral-purpose Large Language Models (LLMs) that operates without requiring\nlabeled training data. Our method anchors chain-of-thought reasoning to the\nmolecular structure by using unique atomic identifiers. First, the LLM performs\na one-shot task to identify relevant fragments and their associated chemical\nlabels or transformation classes. In an optional second step, this\nposition-aware information is used in a few-shot task with provided class\nexamples to predict the chemical transformation. We apply our framework to\nsingle-step retrosynthesis, a task where LLMs have previously underperformed.\nAcross academic benchmarks and expert-validated drug discovery molecules, our\nwork enables LLMs to achieve high success rates in identifying chemically\nplausible reaction sites ($\\geq90\\%$), named reaction classes ($\\geq40\\%$), and\nfinal reactants ($\\geq74\\%$). Beyond solving complex chemical tasks, our work\nalso provides a method to generate theoretically grounded synthetic datasets by\nmapping chemical knowledge onto the molecular structure and thereby addressing\ndata scarcity."}
{"id": "2510.16591", "pdf": "https://arxiv.org/pdf/2510.16591", "abs": "https://arxiv.org/abs/2510.16591", "authors": ["Cassidy Ashworth", "Pietro LiÃ²", "Francesco Caso"], "title": "Symmetry and Generalisation in Neural Approximations of Renormalisation Transformations", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "stat.ML"], "comment": null, "summary": "Deep learning models have proven enormously successful at using multiple\nlayers of representation to learn relevant features of structured data.\nEncoding physical symmetries into these models can improve performance on\ndifficult tasks, and recent work has motivated the principle of parameter\nsymmetry breaking and restoration as a unifying mechanism underlying their\nhierarchical learning dynamics. We evaluate the role of parameter symmetry and\nnetwork expressivity in the generalisation behaviour of neural networks when\nlearning a real-space renormalisation group (RG) transformation, using the\ncentral limit theorem (CLT) as a test case map. We consider simple multilayer\nperceptrons (MLPs) and graph neural networks (GNNs), and vary weight symmetries\nand activation functions across architectures. Our results reveal a competition\nbetween symmetry constraints and expressivity, with overly complex or\noverconstrained models generalising poorly. We analytically demonstrate this\npoor generalisation behaviour for certain constrained MLP architectures by\nrecasting the CLT as a cumulant recursion relation and making use of an\nestablished framework to propagate cumulants through MLPs. We also empirically\nvalidate an extension of this framework from MLPs to GNNs, elucidating the\ninternal information processing performed by these more complex models. These\nfindings offer new insight into the learning dynamics of symmetric networks and\ntheir limitations in modelling structured physical transformations."}
{"id": "2510.16596", "pdf": "https://arxiv.org/pdf/2510.16596", "abs": "https://arxiv.org/abs/2510.16596", "authors": ["Yiyang Huang", "Liang Shi", "Yitian Zhang", "Yi Xu", "Yun Fu"], "title": "SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) excel in diverse cross-modal tasks.\nHowever, object hallucination, where models produce plausible but inaccurate\nobject descriptions, remains a significant challenge. In contrast to previous\nwork focusing on LLM components, this paper is the first to trace LVLM\nhallucinations to visual encoders and identifies three key issues: statistical\nbias, inherent bias, and vulnerability. To address these challenges, we propose\nSHIELD, a training-free framework that mitigates hallucinations through three\nstrategies: re-weighting visual tokens to reduce statistical bias, introducing\nnoise-derived tokens to counter inherent bias, and applying adversarial attacks\nwith contrastive decoding to address vulnerability. Experiments demonstrate\nthat SHIELD effectively mitigates object hallucinations across diverse\nbenchmarks and LVLM families. Moreover, SHIELD achieves strong performance on\nthe general LVLM benchmark, highlighting its broad applicability. Code will be\nreleased."}
{"id": "2510.16607", "pdf": "https://arxiv.org/pdf/2510.16607", "abs": "https://arxiv.org/abs/2510.16607", "authors": ["Tianwei Wang", "Xinhui Ma", "Wei Pang"], "title": "Asymptotically Stable Quaternion-valued Hopfield-structured Neural Network with Periodic Projection-based Supervised Learning Rules", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Motivated by the geometric advantages of quaternions in representing\nrotations and postures, we propose a quaternion-valued supervised learning\nHopfield-structured neural network (QSHNN) with a fully connected structure\ninspired by the classic Hopfield neural network (HNN). Starting from a\ncontinuous-time dynamical model of HNNs, we extend the formulation to the\nquaternionic domain and establish the existence and uniqueness of fixed points\nwith asymptotic stability. For the learning rules, we introduce a periodic\nprojection strategy that modifies standard gradient descent by periodically\nprojecting each 4*4 block of the weight matrix onto the closest quaternionic\nstructure in the least-squares sense. This approach preserves both convergence\nand quaternionic consistency throughout training. Benefiting from this rigorous\nmathematical foundation, the experimental model implementation achieves high\naccuracy, fast convergence, and strong reliability across randomly generated\ntarget sets. Moreover, the evolution trajectories of the QSHNN exhibit\nwell-bounded curvature, i.e., sufficient smoothness, which is crucial for\napplications such as control systems or path planning modules in robotic arms,\nwhere joint postures are parameterized by quaternion neurons. Beyond these\napplication scenarios, the proposed model offers a practical implementation\nframework and a general mathematical methodology for designing neural networks\nunder hypercomplex or non-commutative algebraic structures."}
{"id": "2510.16609", "pdf": "https://arxiv.org/pdf/2510.16609", "abs": "https://arxiv.org/abs/2510.16609", "authors": ["Avrim Blum", "Daniel Hsu", "Cyrus Rashtchian", "Donya Saless"], "title": "Prior Makes It Possible: From Sublinear Graph Algorithms to LLM Test-Time Methods", "categories": ["cs.LG", "cs.AI", "cs.CC", "cs.DS"], "comment": null, "summary": "Test-time augmentation, such as Retrieval-Augmented Generation (RAG) or tool\nuse, critically depends on an interplay between a model's parametric knowledge\nand externally retrieved information. However, the theoretical underpinnings of\nthis relationship remain poorly understood. Specifically, it is not clear how\nmuch pre-training knowledge is required to answer queries with a small number\nof augmentation steps, which is a desirable property in practice. To address\nthis question, we formulate multi-step reasoning as an $s$-$t$ connectivity\nproblem on a knowledge graph. We represent a model's pre-training parametric\nknowledge as a partial, potentially noisy subgraph. We view augmentation as\nquerying an oracle for true edges that augment the model's knowledge. Then, we\ncharacterize the necessary and sufficient number of augmentation steps for the\nmodel to generate an accurate answer given partial prior knowledge. One key\nresult shows a phase transition: if the prior knowledge graph over $n$ vertices\nis disconnected into small components, then finding a path via augmentation is\ninefficient and requires $\\Omega(\\sqrt{n})$ queries. On the other hand, once\nthe density of correct knowledge surpasses a threshold, forming a giant\ncomponent, we can find paths with an expected constant number of queries."}
{"id": "2510.16611", "pdf": "https://arxiv.org/pdf/2510.16611", "abs": "https://arxiv.org/abs/2510.16611", "authors": ["Melika Filvantorkaman", "Maral Filvan Torkaman"], "title": "A Deep Learning Framework for Real-Time Image Processing in Medical Diagnostics: Enhancing Accuracy and Speed in Clinical Applications", "categories": ["cs.CV", "cs.AI"], "comment": "20 pages, 4 figures", "summary": "Medical imaging plays a vital role in modern diagnostics; however,\ninterpreting high-resolution radiological data remains time-consuming and\nsusceptible to variability among clinicians. Traditional image processing\ntechniques often lack the precision, robustness, and speed required for\nreal-time clinical use. To overcome these limitations, this paper introduces a\ndeep learning framework for real-time medical image analysis designed to\nenhance diagnostic accuracy and computational efficiency across multiple\nimaging modalities, including X-ray, CT, and MRI. The proposed system\nintegrates advanced neural network architectures such as U-Net, EfficientNet,\nand Transformer-based models with real-time optimization strategies including\nmodel pruning, quantization, and GPU acceleration. The framework enables\nflexible deployment on edge devices, local servers, and cloud infrastructures,\nensuring seamless interoperability with clinical systems such as PACS and EHR.\nExperimental evaluations on public benchmark datasets demonstrate\nstate-of-the-art performance, achieving classification accuracies above 92%,\nsegmentation Dice scores exceeding 91%, and inference times below 80\nmilliseconds. Furthermore, visual explanation tools such as Grad-CAM and\nsegmentation overlays enhance transparency and clinical interpretability. These\nresults indicate that the proposed framework can substantially accelerate\ndiagnostic workflows, reduce clinician workload, and support trustworthy AI\nintegration in time-critical healthcare environments."}
{"id": "2510.16635", "pdf": "https://arxiv.org/pdf/2510.16635", "abs": "https://arxiv.org/abs/2510.16635", "authors": ["Wonduk Seo", "Juhyeon Lee", "Junseo Koh", "Hyunjin An", "Jian Park", "Seunghyun Lee", "Haihua Chen", "Yi Bu"], "title": "Prompt Optimization via Retrieved Reasoning Assets and Multi-Agent Analysis", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.HC", "cs.IR"], "comment": "Preprint", "summary": "Prompt optimization has emerged as an effective alternative to retraining for\nimproving the performance of Large Language Models (LLMs). However, most\nexisting approaches treat evaluation as a black box, relying solely on\nnumerical scores while offering limited insight into why a prompt succeeds or\nfails. They also depend heavily on trial-and-error refinements, which are\ndifficult to interpret and control. In this paper, we introduce MA-SAPO, a\nMulti-Agent framework for Score-Aware Prompt Optimization. Compared to prior\nmethods, MA-SAPO explicitly couples evaluation outcomes with structured\nreasoning to guide systematic edits. The framework specifically consists of two\nstages: during the Reasoning Phase, agents collaboratively explain metric\nscores, diagnose weaknesses, and synthesize targeted refinements that are\nstored as reusable reasoning assets; during the Test Phase, agents retrieve\nthese assets to analyze optimized prompts and apply only evidence-grounded\nedits. By turning evaluation signals into interpretable reasoning chains,\nMA-SAPO produces prompt refinements that are more transparent, auditable, and\ncontrollable. Experiments on the HelpSteer1/2 benchmarks demonstrate consistent\nimprovements over single-pass prompting, retrieval-augmented baselines, and\nprior multi-agent strategies, validating the effectiveness of our approach."}
{"id": "2510.16643", "pdf": "https://arxiv.org/pdf/2510.16643", "abs": "https://arxiv.org/abs/2510.16643", "authors": ["Aaron Ray", "Jacob Arkin", "Harel Biggie", "Chuchu Fan", "Luca Carlone", "Nicholas Roy"], "title": "Structured Interfaces for Automated Reasoning with 3D Scene Graphs", "categories": ["cs.CV", "cs.AI", "cs.RO", "I.2.9; I.2.10; H.3.3"], "comment": "25 pages, 3 figures", "summary": "In order to provide a robot with the ability to understand and react to a\nuser's natural language inputs, the natural language must be connected to the\nrobot's underlying representations of the world. Recently, large language\nmodels (LLMs) and 3D scene graphs (3DSGs) have become a popular choice for\ngrounding natural language and representing the world. In this work, we address\nthe challenge of using LLMs with 3DSGs to ground natural language. Existing\nmethods encode the scene graph as serialized text within the LLM's context\nwindow, but this encoding does not scale to large or rich 3DSGs. Instead, we\npropose to use a form of Retrieval Augmented Generation to select a subset of\nthe 3DSG relevant to the task. We encode a 3DSG in a graph database and provide\na query language interface (Cypher) as a tool to the LLM with which it can\nretrieve relevant data for language grounding. We evaluate our approach on\ninstruction following and scene question-answering tasks and compare against\nbaseline context window and code generation methods. Our results show that\nusing Cypher as an interface to 3D scene graphs scales significantly better to\nlarge, rich graphs on both local and cloud-based models. This leads to large\nperformance improvements in grounded language tasks while also substantially\nreducing the token count of the scene graph content. A video supplement is\navailable at https://www.youtube.com/watch?v=zY_YI9giZSA."}
{"id": "2510.16645", "pdf": "https://arxiv.org/pdf/2510.16645", "abs": "https://arxiv.org/abs/2510.16645", "authors": ["Zhixuan He", "Yue Feng"], "title": "Unleashing Diverse Thinking Modes in LLMs through Multi-Agent Collaboration", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate strong performance but often lack\ninterpretable reasoning. This paper introduces the Multi-Agent Collaboration\nFramework for Diverse Thinking Modes (DiMo), which enhances both performance\nand interpretability by simulating a structured debate among four specialized\nLLM agents. Each agent embodies a distinct reasoning paradigm, allowing the\nframework to collaboratively explore diverse cognitive approaches. Through\niterative debate, agents challenge and refine initial responses, yielding more\nrobust conclusions and an explicit, auditable reasoning chain. Across six\nbenchmarks and under a unified open-source setup, DiMo improves accuracy over\nwidely used single-model and debate baselines, with the largest gains on math.\nWe position DiMo as a semantics-aware, Web-native multi-agent framework: it\nmodels human-machine intelligence with LLM agents that produce semantically\ntyped, URL-annotated evidence chains for explanations and user-friendly\ninteractions. Although our experiments use standard reasoning benchmarks, the\nframework is designed to be instantiated over Web corpora and knowledge graphs,\ncombining retrieval-augmented reasoning with structured justifications that\ndownstream systems can inspect and reuse."}
{"id": "2510.16662", "pdf": "https://arxiv.org/pdf/2510.16662", "abs": "https://arxiv.org/abs/2510.16662", "authors": ["Huyen N. Nguyen", "Nils Gehlenborg"], "title": "Safire: Similarity Framework for Visualization Retrieval", "categories": ["cs.HC", "cs.AI", "cs.IR", "cs.LG", "H.1.2; H.3.3; I.3.6"], "comment": "To appear in IEEE VIS 2025", "summary": "Effective visualization retrieval necessitates a clear definition of\nsimilarity. Despite the growing body of work in specialized visualization\nretrieval systems, a systematic approach to understanding visualization\nsimilarity remains absent. We introduce the Similarity Framework for\nVisualization Retrieval (Safire), a conceptual model that frames visualization\nsimilarity along two dimensions: comparison criteria and representation\nmodalities. Comparison criteria identify the aspects that make visualizations\nsimilar, which we divide into primary facets (data, visual encoding,\ninteraction, style, metadata) and derived properties (data-centric and\nhuman-centric measures). Safire connects what to compare with how comparisons\nare executed through representation modalities. We categorize existing\nrepresentation approaches into four groups based on their levels of information\ncontent and visualization determinism: raster image, vector image,\nspecification, and natural language description, together guiding what is\ncomputable and comparable. We analyze several visualization retrieval systems\nusing Safire to demonstrate its practical value in clarifying similarity\nconsiderations. Our findings reveal how particular criteria and modalities\nalign across different use cases. Notably, the choice of representation\nmodality is not only an implementation detail but also an important decision\nthat shapes retrieval capabilities and limitations. Based on our analysis, we\nprovide recommendations and discuss broader implications for multimodal\nlearning, AI applications, and visualization reproducibility."}
{"id": "2510.16670", "pdf": "https://arxiv.org/pdf/2510.16670", "abs": "https://arxiv.org/abs/2510.16670", "authors": ["Yiyang Liu", "James C. Liang", "Heng Fan", "Wenhao Yang", "Yiming Cui", "Xiaotian Han", "Lifu Huang", "Dongfang Liu", "Qifan Wang", "Cheng Han"], "title": "All You Need is One: Capsule Prompt Tuning with a Single Vector", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "NeurIPS 2025", "summary": "Prompt-based learning has emerged as a parameter-efficient finetuning (PEFT)\napproach to facilitate Large Language Model (LLM) adaptation to downstream\ntasks by conditioning generation with task-aware guidance. Despite its\nsuccesses, current prompt-based learning methods heavily rely on laborious grid\nsearching for optimal prompt length and typically require considerable number\nof prompts, introducing additional computational burden. Worse yet, our pioneer\nfindings indicate that the task-aware prompt design is inherently limited by\nits absence of instance-aware information, leading to a subtle attention\ninterplay with the input sequence. In contrast, simply incorporating\ninstance-aware information as a part of the guidance can enhance the\nprompt-tuned model performance without additional fine-tuning. Moreover, we\nfind an interesting phenomenon, namely \"attention anchor\", that incorporating\ninstance-aware tokens at the earliest position of the sequence can successfully\npreserve strong attention to critical structural information and exhibit more\nactive attention interaction with all input tokens. In light of our\nobservation, we introduce Capsule Prompt-Tuning (CaPT), an efficient and\neffective solution that leverages off-the-shelf, informative instance semantics\ninto prompt-based learning. Our approach innovatively integrates both\ninstance-aware and task-aware information in a nearly parameter-free manner\n(i.e., one single capsule prompt). Empirical results demonstrate that our\nmethod can exhibit superior performance across various language tasks (e.g.,\n84.03\\% average accuracy on T5-Large), serving as an \"attention anchor,\" while\nenjoying high parameter efficiency (e.g., 0.003\\% of model parameters on\nLlama3.2-1B)."}
{"id": "2510.16677", "pdf": "https://arxiv.org/pdf/2510.16677", "abs": "https://arxiv.org/abs/2510.16677", "authors": ["Ran Tong", "Jiaqi Liu", "Su Liu", "Xin Hu", "Lanruo Wang"], "title": "Renaissance of RNNs in Streaming Clinical Time Series: Compact Recurrence Remains Competitive with Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present a compact, strictly causal benchmark for streaming clinical time\nseries on the MIT--BIH Arrhythmia Database using per-second heart rate. Two\ntasks are studied under record-level, non-overlapping splits: near-term\ntachycardia risk (next ten seconds) and one-step heart rate forecasting. We\ncompare a GRU-D (RNN) and a Transformer under matched training budgets against\nstrong non-learned baselines. Evaluation is calibration-aware for\nclassification and proper for forecasting, with temperature scaling and grouped\nbootstrap confidence intervals. On MIT-BIH, GRU-D slightly surpasses the\nTransformer for tachycardia risk, while the Transformer clearly lowers\nforecasting error relative to GRU-D and persistence. Our results show that, in\nlongitudinal monitoring, model choice is task-dependent: compact RNNs remain\ncompetitive for short-horizon risk scoring, whereas compact Transformers\ndeliver clearer gains for point forecasting."}
{"id": "2510.16688", "pdf": "https://arxiv.org/pdf/2510.16688", "abs": "https://arxiv.org/abs/2510.16688", "authors": ["Yejie Guo", "Yunzhong Hou", "Wufei Ma", "Meng Tang", "Ming-Hsuan Yang"], "title": "Pursuing Minimal Sufficiency in Spatial Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Spatial reasoning, the ability to ground language in 3D understanding,\nremains a persistent challenge for Vision-Language Models (VLMs). We identify\ntwo fundamental bottlenecks: inadequate 3D understanding capabilities stemming\nfrom 2D-centric pre-training, and reasoning failures induced by redundant 3D\ninformation. To address these, we first construct a Minimal Sufficient Set\n(MSS) of information before answering a given question: a compact selection of\n3D perception results from \\textit{expert models}. We introduce MSSR (Minimal\nSufficient Spatial Reasoner), a dual-agent framework that implements this\nprinciple. A Perception Agent programmatically queries 3D scenes using a\nversatile perception toolbox to extract sufficient information, including a\nnovel SOG (Situated Orientation Grounding) module that robustly extracts\nlanguage-grounded directions. A Reasoning Agent then iteratively refines this\ninformation to pursue minimality, pruning redundant details and requesting\nmissing ones in a closed loop until the MSS is curated. Extensive experiments\ndemonstrate that our method, by explicitly pursuing both sufficiency and\nminimality, significantly improves accuracy and achieves state-of-the-art\nperformance across two challenging benchmarks. Furthermore, our framework\nproduces interpretable reasoning paths, offering a promising source of\nhigh-quality training data for future models. Source code is available at\nhttps://github.com/gyj155/mssr."}
{"id": "2510.16703", "pdf": "https://arxiv.org/pdf/2510.16703", "abs": "https://arxiv.org/abs/2510.16703", "authors": ["Yizuo Chen", "Adnan Darwiche"], "title": "On the Granularity of Causal Effect Identifiability", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "The classical notion of causal effect identifiability is defined in terms of\ntreatment and outcome variables. In this note, we consider the identifiability\nof state-based causal effects: how an intervention on a particular state of\ntreatment variables affects a particular state of outcome variables. We\ndemonstrate that state-based causal effects may be identifiable even when\nvariable-based causal effects may not. Moreover, we show that this separation\noccurs only when additional knowledge -- such as context-specific\nindependencies and conditional functional dependencies -- is available. We\nfurther examine knowledge that constrains the states of variables, and show\nthat such knowledge does not improve identifiability on its own but can improve\nboth variable-based and state-based identifiability when combined with other\nknowledge such as context-specific independencies. Our findings highlight\nsituations where causal effects of interest may be estimable from observational\ndata and this identifiability may be missed by existing variable-based\nframeworks."}
{"id": "2510.16708", "pdf": "https://arxiv.org/pdf/2510.16708", "abs": "https://arxiv.org/abs/2510.16708", "authors": ["Kailai Yang", "Yan Leng", "Xin Zhang", "Tianlin Zhang", "Paul Thompson", "Bernard Keavney", "Maciej Tomaszewski", "Sophia Ananiadou"], "title": "Natural Language Processing Applications in Cardiology: A Narrative Review", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Cardiovascular disease has become increasingly prevalent in modern society\nand has a significant effect on global health and well-being. Heart-related\nconditions are intricate, multifaceted disorders, which may be influenced by a\ncombination of genetic predispositions, lifestyle choices, and various\nsocioeconomic and clinical factors. Information regarding these potentially\ncomplex interrelationships is dispersed among diverse types of textual data,\nwhich include patient narratives, medical records, and scientific literature,\namong others. Natural language processing (NLP) techniques have increasingly\nbeen adopted as a powerful means to analyse and make sense of this vast amount\nof unstructured data. This, in turn, can allow healthcare professionals to gain\ndeeper insights into the cardiology field, which has the potential to\nrevolutionize current approaches to the diagnosis, treatment, and prevention of\ncardiac problems. This review provides a detailed overview of NLP research in\ncardiology between 2014 and 2025. We queried six literature databases to find\narticles describing the application of NLP techniques in the context of a range\nof different cardiovascular diseases. Following a rigorous screening process,\nwe identified a total of 265 relevant articles. We analysed each article from\nmultiple dimensions, i.e., NLP paradigm types, cardiology-related task types,\ncardiovascular disease types, and data source types. Our analysis reveals\nconsiderable diversity within each of these dimensions, thus demonstrating the\nconsiderable breadth of NLP research within the field. We also perform a\ntemporal analysis, which illustrates the evolution and changing trends in NLP\nmethods employed over the last decade that we cover. To our knowledge, the\nreview constitutes the most comprehensive overview of NLP research in\ncardiology to date."}
{"id": "2510.16709", "pdf": "https://arxiv.org/pdf/2510.16709", "abs": "https://arxiv.org/abs/2510.16709", "authors": ["Liu Haojie", "Gao Suixiang"], "title": "HumanCM: One Step Human Motion Prediction", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages, 2 figures, 2 tables", "summary": "We present HumanCM, a one-step human motion prediction framework built upon\nconsistency models. Instead of relying on multi-step denoising as in\ndiffusion-based methods, HumanCM performs efficient single-step generation by\nlearning a self-consistent mapping between noisy and clean motion states. The\nframework adopts a Transformer-based spatiotemporal architecture with temporal\nembeddings to model long-range dependencies and preserve motion coherence.\nExperiments on Human3.6M and HumanEva-I demonstrate that HumanCM achieves\ncomparable or superior accuracy to state-of-the-art diffusion models while\nreducing inference steps by up to two orders of magnitude."}
{"id": "2510.16712", "pdf": "https://arxiv.org/pdf/2510.16712", "abs": "https://arxiv.org/abs/2510.16712", "authors": ["Shivam Ratnakar", "Sanjay Raghavendra"], "title": "The Chameleon Nature of LLMs: Quantifying Multi-Turn Stance Instability in Search-Enabled Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Integration of Large Language Models with search/retrieval engines has become\nubiquitous, yet these systems harbor a critical vulnerability that undermines\ntheir reliability. We present the first systematic investigation of \"chameleon\nbehavior\" in LLMs: their alarming tendency to shift stances when presented with\ncontradictory questions in multi-turn conversations (especially in\nsearch-enabled LLMs). Through our novel Chameleon Benchmark Dataset, comprising\n17,770 carefully crafted question-answer pairs across 1,180 multi-turn\nconversations spanning 12 controversial domains, we expose fundamental flaws in\nstate-of-the-art systems. We introduce two theoretically grounded metrics: the\nChameleon Score (0-1) that quantifies stance instability, and Source Re-use\nRate (0-1) that measures knowledge diversity. Our rigorous evaluation of\nLlama-4-Maverick, GPT-4o-mini, and Gemini-2.5-Flash reveals consistent\nfailures: all models exhibit severe chameleon behavior (scores 0.391-0.511),\nwith GPT-4o-mini showing the worst performance. Crucially, small\nacross-temperature variance (less than 0.004) suggests the effect is not a\nsampling artifact. Our analysis uncovers the mechanism: strong correlations\nbetween source re-use rate and confidence (r=0.627) and stance changes\n(r=0.429) are statistically significant (p less than 0.05), indicating that\nlimited knowledge diversity makes models pathologically deferential to query\nframing. These findings highlight the need for comprehensive consistency\nevaluation before deploying LLMs in healthcare, legal, and financial systems\nwhere maintaining coherent positions across interactions is critical for\nreliable decision support."}
{"id": "2510.16714", "pdf": "https://arxiv.org/pdf/2510.16714", "abs": "https://arxiv.org/abs/2510.16714", "authors": ["Xiongkun Linghu", "Jiangyong Huang", "Ziyu Zhu", "Baoxiong Jia", "Siyuan Huang"], "title": "Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://scenecot.github.io/", "summary": "Existing research on 3D Large Language Models (LLMs) still struggles to\nachieve grounded question-answering, primarily due to the under-exploration of\nthe mech- anism of human-like scene-object grounded reasoning. This paper\nbridges the gap by presenting a novel framework. We first introduce a grounded\nChain-of- Thought reasoning method in 3D scenes (SCENECOT), decoupling a\ncomplex reasoning task into simpler and manageable problems, and building\ncorresponding visual clues based on multimodal expert modules. To enable such a\nmethod, we develop SCENECOT-185K, the first large-scale grounded CoT reasoning\ndataset, consisting of 185K high-quality instances. Extensive experiments\nacross various complex 3D scene reasoning benchmarks demonstrate that our new\nframework achieves strong performance with high grounding-QA coherence. To the\nbest of our knowledge, this is the first successful application of CoT\nreasoning to 3D scene understanding, enabling step-by-step human-like reasoning\nand showing potential for extension to broader 3D scene understanding\nscenarios."}
{"id": "2510.16727", "pdf": "https://arxiv.org/pdf/2510.16727", "abs": "https://arxiv.org/abs/2510.16727", "authors": ["Sanskar Pandey", "Ruhaan Chopra", "Angkul Puniya", "Sohom Pal"], "title": "Beacon: Single-Turn Diagnosis and Mitigation of Latent Sycophancy in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models internalize a structural trade-off between truthfulness\nand obsequious flattery, emerging from reward optimization that conflates\nhelpfulness with polite submission. This latent bias, known as sycophancy,\nmanifests as a preference for user agreement over principled reasoning. We\nintroduce Beacon, a single-turn forced-choice benchmark that isolates this bias\nindependent of conversational context, enabling precise measurement of the\ntension between factual accuracy and submissive bias. Evaluations across twelve\nstate-of-the-art models reveal that sycophancy decomposes into stable\nlinguistic and affective sub-biases, each scaling with model capacity. We\nfurther propose prompt-level and activation-level interventions that modulate\nthese biases in opposing directions, exposing the internal geometry of\nalignment as a dynamic manifold between truthfulness and socially compliant\njudgment. Beacon reframes sycophancy as a measurable form of normative\nmisgeneralization, providing a reproducible foundation for studying and\nmitigating alignment drift in large-scale generative systems."}
{"id": "2510.16757", "pdf": "https://arxiv.org/pdf/2510.16757", "abs": "https://arxiv.org/abs/2510.16757", "authors": ["Young In Kim", "Andrea Agiollo", "Rajiv Khanna"], "title": "SAMOSA: Sharpness Aware Minimization for Open Set Active learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern machine learning solutions require extensive data collection where\nlabeling remains costly. To reduce this burden, open set active learning\napproaches aim to select informative samples from a large pool of unlabeled\ndata that includes irrelevant or unknown classes. In this context, we propose\nSharpness Aware Minimization for Open Set Active Learning (SAMOSA) as an\neffective querying algorithm. Building on theoretical findings concerning the\nimpact of data typicality on the generalization properties of traditional\nstochastic gradient descent (SGD) and sharpness-aware minimization (SAM),\nSAMOSA actively queries samples based on their typicality. SAMOSA effectively\nidentifies atypical samples that belong to regions of the embedding manifold\nclose to the model decision boundaries. Therefore, SAMOSA prioritizes the\nsamples that are (i) highly informative for the targeted classes, and (ii)\nuseful for distinguishing between targeted and unwanted classes. Extensive\nexperiments show that SAMOSA achieves up to 3% accuracy improvement over the\nstate of the art across several datasets, while not introducing computational\noverhead. The source code of our experiments is available at:\nhttps://anonymous.4open.science/r/samosa-DAF4"}
{"id": "2510.16772", "pdf": "https://arxiv.org/pdf/2510.16772", "abs": "https://arxiv.org/abs/2510.16772", "authors": ["Thuy Phuong Vu", "Dinh-Cuong Hoang", "Minhhuy Le", "Phan Xuan Tan"], "title": "Region in Context: Text-condition Image editing with Human-like semantic reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent research has made significant progress in localizing and editing image\nregions based on text. However, most approaches treat these regions in\nisolation, relying solely on local cues without accounting for how each part\ncontributes to the overall visual and semantic composition. This often results\nin inconsistent edits, unnatural transitions, or loss of coherence across the\nimage. In this work, we propose Region in Context, a novel framework for\ntext-conditioned image editing that performs multilevel semantic alignment\nbetween vision and language, inspired by the human ability to reason about\nedits in relation to the whole scene. Our method encourages each region to\nunderstand its role within the global image context, enabling precise and\nharmonized changes. At its core, the framework introduces a dual-level guidance\nmechanism: regions are represented with full-image context and aligned with\ndetailed region-level descriptions, while the entire image is simultaneously\nmatched to a comprehensive scene-level description generated by a large\nvision-language model. These descriptions serve as explicit verbal references\nof the intended content, guiding both local modifications and global structure.\nExperiments show that it produces more coherent and instruction-aligned\nresults. Code is available at:\nhttps://github.com/thuyvuphuong/Region-in-Context.git"}
{"id": "2510.16774", "pdf": "https://arxiv.org/pdf/2510.16774", "abs": "https://arxiv.org/abs/2510.16774", "authors": ["Yuguang Yue", "Irakli Salia", "Samuel Hunt", "Christopher Green", "Wenzhe Shi", "Jonathan J Hunt"], "title": "Learning to play: A Multimodal Agent for 3D Game-Play", "categories": ["cs.LG", "cs.AI"], "comment": "International Conference on Computer Vision Workshop on Multi-Modal\n  Reasoning for Agentic Intelligence", "summary": "We argue that 3-D first-person video games are a challenging environment for\nreal-time multi-modal reasoning. We first describe our dataset of human\ngame-play, collected across a large variety of 3-D first-person games, which is\nboth substantially larger and more diverse compared to prior publicly disclosed\ndatasets, and contains text instructions. We demonstrate that we can learn an\ninverse dynamics model from this dataset, which allows us to impute actions on\na much larger dataset of publicly available videos of human game play that lack\nrecorded actions. We then train a text-conditioned agent for game playing using\nbehavior cloning, with a custom architecture capable of realtime inference on a\nconsumer GPU. We show the resulting model is capable of playing a variety of\n3-D games and responding to text input. Finally, we outline some of the\nremaining challenges such as long-horizon tasks and quantitative evaluation\nacross a large set of games."}
{"id": "2510.16776", "pdf": "https://arxiv.org/pdf/2510.16776", "abs": "https://arxiv.org/abs/2510.16776", "authors": ["Mingzheng Zhang", "Jinfeng Gao", "Dan Xu", "Jiangrui Yu", "Yuhan Qiao", "Lan Chen", "Jin Tang", "Xiao Wang"], "title": "EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "X-ray image-based medical report generation (MRG) is a pivotal area in\nartificial intelligence that can significantly reduce diagnostic burdens for\nclinicians and patient wait times. Existing MRG models predominantly rely on\nLarge Language Models (LLMs) to improve report generation, with limited\nexploration of pre-trained vision foundation models or advanced fine-tuning\ntechniques. Mainstream frameworks either avoid fine-tuning or utilize\nsimplistic methods like LoRA, often neglecting the potential of enhancing\ncross-attention mechanisms. Additionally, while Transformer-based models\ndominate vision-language tasks, non-Transformer architectures, such as the\nMamba network, remain underexplored for medical report generation, presenting a\npromising avenue for future research. In this paper, we propose EMRRG, a novel\nX-ray report generation framework that fine-tunes pre-trained Mamba networks\nusing parameter-efficient methods. Specifically, X-ray images are divided into\npatches, tokenized, and processed by an SSM-based vision backbone for feature\nextraction, with Partial LoRA yielding optimal performance. An LLM with a\nhybrid decoder generates the medical report, enabling end-to-end training and\nachieving strong results on benchmark datasets. Extensive experiments on three\nwidely used benchmark datasets fully validated the effectiveness of our\nproposed strategies for the X-ray MRG. The source code of this paper will be\nreleased on https://github.com/Event-AHU/Medical_Image_Analysis."}
{"id": "2510.16781", "pdf": "https://arxiv.org/pdf/2510.16781", "abs": "https://arxiv.org/abs/2510.16781", "authors": ["Shihao Ji", "Zihui Song"], "title": "Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "The remarkable zero-shot reasoning capabilities of large-scale Visual\nLanguage Models (VLMs) on static images have yet to be fully translated to the\nvideo domain. Conventional video understanding models often rely on extensive,\ntask-specific training on annotated datasets, a process that is both costly and\nlimited in scalability. This paper introduces a novel, training-free framework\nfor video understanding that circumvents end-to-end training by synergistically\ncombining the rich semantic priors of pre-trained VLMs with classic machine\nlearning algorithms for pattern discovery. Our core idea is to reframe video\nunderstanding as a self-supervised spatio-temporal clustering problem within a\nhigh-dimensional semantic feature space. The proposed pipeline first transforms\na video stream into a semantic feature trajectory using the frozen visual\nencoder of a pre-trained VLM. Subsequently, we employ Kernel Temporal\nSegmentation (KTS), a robust machine learning technique, to partition the\ncontinuous feature stream into discrete, semantically coherent event segments.\nThese segments are then subjected to unsupervised density-based clustering to\nidentify recurring macroscopic scenes and themes throughout the video. By\nselecting representative keyframes from each discovered cluster and leveraging\nthe VLM's generative capabilities for textual description, our framework\nautomatically produces a structured, multi-modal summary of the video content.\nThis approach provides an effective, interpretable, and model-agnostic pathway\nfor zero-shot, automated structural analysis of video content."}
{"id": "2510.16783", "pdf": "https://arxiv.org/pdf/2510.16783", "abs": "https://arxiv.org/abs/2510.16783", "authors": ["Sheikh Jubair", "Arwa Omayrah", "Amal Alshammari", "Alhanoof Althnian", "Abdulhamed Alothaimen", "Norah A. Alzahrani", "Shahad D. Alzaidi", "Nora Al-Twairesh", "Abdulmohsen Al-Thubaity"], "title": "LC-Eval: A Bilingual Multi-Task Evaluation Benchmark for Long-Context Understanding", "categories": ["cs.CL", "cs.AI"], "comment": "1 figure, 15 tables, 10 main pages", "summary": "Recent advancements in Large Language Models (LLMs) have demonstrated\nsophisticated capabilities, including the ability to process and comprehend\nextended contexts. These emergent capabilities necessitate rigorous evaluation\nmethods to effectively assess their performance in long-context understanding.\nIn this paper, we present \\textbf{LC-Eval}, a bilingual, multi-task evaluation\nbenchmark designed to evaluate long-context understanding in English and\nArabic, targeting context lengths ranging from 4k to over 128k tokens. LC-Eval\nintroduces four novel and challenging tasks: multi-document question answering,\nbilingual question answering, claim verification within a paragraph, and\nmultiple-choice questions based on long contexts. These tasks are designed to\nassess LLMs' abilities in deep reasoning, document comprehension, information\ntracing, and bilingual information extraction and understanding. The benchmark\nincludes datasets in both Arabic and English for each task, allowing for a\ncomparative analysis of their performance across different text genres.\nEvaluations were conducted on both open-weight and closed LLMs, with results\nindicating that LC-Eval presents significant challenges. Even high-performing\nmodels, such as GPT-4o, struggled with certain tasks, highlighting the\ncomplexity and rigor of the benchmark."}
{"id": "2510.16786", "pdf": "https://arxiv.org/pdf/2510.16786", "abs": "https://arxiv.org/abs/2510.16786", "authors": ["Pengfei Gao", "Chao Peng"], "title": "More with Less: An Empirical Study of Turn-Control Strategies for Efficient Coding Agents", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "LLM-powered coding agents, which operate in iterative loops (turns) to solve\nsoftware engineering tasks, are becoming increasingly powerful. However, their\npractical deployment is hindered by significant and unpredictable costs. This\nchallenge arises from a combination of factors: quadratically growing token\ncounts with each turn, the high price of models, the large number of turns\nrequired for real-world tasks, and the tendency of agents to take inefficient\nor unnecessary actions. While existing research focuses on optimizing\nindividual turns, the strategic control of the total number of turns remains an\nunderexplored area for managing agent performance and cost. To address this\ngap, we conduct a comprehensive empirical study on SWE-bench using three\nstate-of-the-art models and evaluate the impact of three distinct turn-control\nstrategies: an unrestricted baseline, a fixed-turn limit with reminders, and a\nnovel dynamic-turn strategy that grants extensions on-demand. Our findings\nfirst reveal a fundamental trade-off in the unrestricted setting, where no\nsingle model excels across performance, cost, and turn efficiency. We then show\nthat a fixed-turn limit, specifically at the 75th percentile of the baseline,\nserves as a \"sweet spot\", substantially reducing costs (by 24%-68%) with\nminimal impact on solve rates. Most significantly, the dynamic-turn strategy\nconsistently outperforms fixed-limit approaches, achieving comparable or better\nsolve rates while further reducing costs by an additional 12%-24% by\nintelligently allocating resources only to tasks that need them. This work\nprovides the first systematic analysis of turn-control strategies, offering\nsimple yet effective guidelines for developers to balance cost and efficacy. We\ndemonstrate that dynamic resource allocation is a superior, easy-to-implement\napproach for deploying powerful yet economically viable coding agents."}
{"id": "2510.16797", "pdf": "https://arxiv.org/pdf/2510.16797", "abs": "https://arxiv.org/abs/2510.16797", "authors": ["Vera Pavlova", "Mohammed Makhlouf"], "title": "MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce MOSAIC (Masked Objective with Selective Adaptation for In-domain\nContrastive learning), a multi-stage framework for domain adaptation of\nsentence embedding models that incorporates joint domain-specific masked\nsupervision. Our approach addresses the challenges of adapting large-scale\ngeneral-domain sentence embedding models to specialized domains. By jointly\noptimizing masked language modeling (MLM) and contrastive objectives within a\nunified training pipeline, our method enables effective learning of\ndomain-relevant representations while preserving the robust semantic\ndiscrimination properties of the original model. We empirically validate our\napproach on both high-resource and low-resource domains, achieving improvements\nup to 13.4% in NDCG@10 (Normalized Discounted Cumulative Gain) over strong\ngeneral-domain baselines. Comprehensive ablation studies further demonstrate\nthe effectiveness of each component, highlighting the importance of balanced\njoint supervision and staged adaptation."}
{"id": "2510.16805", "pdf": "https://arxiv.org/pdf/2510.16805", "abs": "https://arxiv.org/abs/2510.16805", "authors": ["Mariam Rakka", "Marios Fournarakis", "Olga Krestinskaya", "Jinane Bazzi", "Khaled N. Salama", "Fadi Kurdahi", "Ahmed M. Eltawil", "Mohammed E. Fouda"], "title": "Mixed-Precision Quantization for Language Models: Techniques and Prospects", "categories": ["cs.LG", "cs.AI"], "comment": "46 pages, 6 figures, 5 tables", "summary": "The rapid scaling of language models (LMs) has resulted in unprecedented\ncomputational, memory, and energy requirements, making their training and\ndeployment increasingly unsustainable. Quantization has emerged as an essential\ncompression technique to reduce model size, alleviate memory bottlenecks, and\naccelerate inference. However, while uniform low-bit quantization (e.g., INT8,\nINT4) provides significant efficiency gains, it can degrade accuracy in\nsensitive components of transformer-based LMs. Mixed-precision quantization\noffers a promising alternative by selectively allocating precision across\nlayers or within tensors to balance efficiency and accuracy. This survey\nprovides a comprehensive overview of Mixed-Precision quantization frameworks\nfor LMs (MXPLMs). We first review quantization fundamentals, including uniform\nand non-uniform quantizers, quantization granularity, and methods widely used\nin post-training quantization. We then categorize and compare recent MXPLM\nframeworks according to their bit allocation strategies and precision\nconfigurations across weights, activations, and key-value caches. A comparative\nanalysis highlights differences in perplexity, zero-shot task performance, and\ndeployment trade-offs. Furthermore, we contrast MXPLMs with earlier\nmixed-precision quantization methods for deep neural networks, identifying\nstrategies that transfer and those that face challenges in the LM setting.\nFinally, we summarize open issues and future directions, including\nhardware-aware design, activation quantization, and scalable optimization\nmethods for billion-parameter models. By consolidating recent advances, this\nwork serves as a reference for understanding the current landscape and research\nprospects of mixed-precision quantization for large-scale language models."}
{"id": "2510.16807", "pdf": "https://arxiv.org/pdf/2510.16807", "abs": "https://arxiv.org/abs/2510.16807", "authors": ["Zhoutong Wu", "Yuan Zhang", "Yiming Dong", "Chenheng Zhang", "Cong Fang", "Kun Yuan", "Zhouchen Lin"], "title": "Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads", "categories": ["cs.LG", "cs.AI"], "comment": "The code is available at:\n  \\url{https://github.com/Zhoutong-Wu/SkipV1Former}", "summary": "Transformer models have driven breakthroughs across various language tasks by\ntheir strong capability to learn rich contextual representations. Scaling them\nto improve representation, however, often demands substantial memory and\ncompute costs, such as the Key-Value (KV) cache used during auto-regressive\ndecoding. Skip connections offer a promising way to improve representation\nwithout bloating resource usage, yet most prior works either improve\nexpressivity while leaving KV costs unchanged, or reduce memory at the cost of\nweaker representation. In this work, we propose SkipV1Former, a Transformer\nvariant that uses skip connections from the first layer's Value heads to\nstrengthen model representation and reduce KV cache. Specifically, from the\nsecond block onward, each layer reuses half of its Value heads from the very\nfirst layer, while computing the other half as usual-cutting Value projections\nand V cache by nearly 50 \\%. Theoretically, we show that routing uncompressed\nfirst-layer Values into deeper layers restores information lost to compression\nand accelerates the model's implicit mesa-optimization-a key pattern of\nTransformer in auto-regressive tasks. Empirically, across different model\nscales, SkipV1Former delivers consistent reductions of approximately 25 \\% in\nKV cache while improving perplexity relative to standard Multi-Head Attention\n(MHA) Transformers and some advanced variants. Moreover, we propose a recipe\nfor uptraining existing MHA Transformer checkpoints to SkipV1Former with only\n10-15\\% additional compute. Finally, SkipV1Former can seamlessly combine\nadvanced methods like Group-Query Attention and Multi-Latent Attention to\nachieve further KV cache savings and performance improvement. When combined\nwith YOCO, it cuts KV cache size by nearly 50 \\% while still improving\nperformance."}
{"id": "2510.16809", "pdf": "https://arxiv.org/pdf/2510.16809", "abs": "https://arxiv.org/abs/2510.16809", "authors": ["Amirkia Rafiei Oskooei", "Kaan Baturalp Cosdan", "Husamettin Isiktas", "Mehmet S. Aktas"], "title": "When Many-Shot Prompting Fails: An Empirical Study of LLM Code Translation", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.PL", "68T50, 68N30, 68W40", "I.2.7; D.2.7; I.2.6"], "comment": null, "summary": "Large Language Models (LLMs) with vast context windows offer new avenues for\nin-context learning (ICL), where providing many examples (\"many-shot\"\nprompting) is often assumed to enhance performance. We investigate this\nassumption for the complex task of code translation. Through a large-scale\nempirical study of over 90,000 translations, we systematically evaluate the\nimpact of scaling in-context examples from zero-shot to many-shot\nconfigurations of up to 625 examples, with prompts spanning from approximately\n100,000 to 800,000 tokens. Our findings reveal a \"many-shot paradox\": while\nstatic similarity metrics may modestly improve with more examples, functional\ncorrectness consistently peaks with few-shot prompting (5-25 examples).\nProviding substantially more examples often degrades this crucial functional\nperformance. This study highlights that for code translation, the quality of a\nfew well-chosen examples outweighs sheer quantity, challenging the universal\nefficacy of \"more is better\" for ICL and underscoring the task-dependent nature\nof optimal prompting strategies. Our results have significant implications for\neffectively leveraging LLMs in software engineering."}
{"id": "2510.16814", "pdf": "https://arxiv.org/pdf/2510.16814", "abs": "https://arxiv.org/abs/2510.16814", "authors": ["Simon Jaxy", "Anton Theys", "Patrick Willett", "W. Chris Carleton", "Ralf Vandam", "Pieter Libin"], "title": "Needles in the Landscape: Semi-Supervised Pseudolabeling for Archaeological Site Discovery under Label Scarcity", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Archaeological predictive modelling estimates where undiscovered sites are\nlikely to occur by combining known locations with environmental, cultural, and\ngeospatial variables. We address this challenge using a deep learning approach\nbut must contend with structural label scarcity inherent to archaeology:\npositives are rare, and most locations are unlabeled. To address this, we adopt\na semi-supervised, positive-unlabeled (PU) learning strategy, implemented as a\nsemantic segmentation model and evaluated on two datasets covering a\nrepresentative range of archaeological periods. Our approach employs dynamic\npseudolabeling, refined with a Conditional Random Field (CRF) implemented via\nan RNN, increasing label confidence under severe class imbalance. On a\ngeospatial dataset derived from a digital elevation model (DEM), our model\nperforms on par with the state-of-the-art, LAMAP, while achieving higher Dice\nscores. On raw satellite imagery, assessed end-to-end with stratified k-fold\ncross-validation, it maintains performance and yields predictive surfaces with\nimproved interpretability. Overall, our results indicate that semi-supervised\nlearning offers a promising approach to identifying undiscovered sites across\nlarge, sparsely annotated landscapes."}
{"id": "2510.16815", "pdf": "https://arxiv.org/pdf/2510.16815", "abs": "https://arxiv.org/abs/2510.16815", "authors": ["Hans Hergen Lehmann", "Jae Hee Lee", "Steven Schockaert", "Stefan Wermter"], "title": "Knowing the Facts but Choosing the Shortcut: Understanding How Large Language Models Compare Entities", "categories": ["cs.CL", "cs.AI"], "comment": "33 pages, 20 figures. Submitted ACL ARR 2025 October (under review)", "summary": "Large Language Models (LLMs) are increasingly used for knowledge-based\nreasoning tasks, yet understanding when they rely on genuine knowledge versus\nsuperficial heuristics remains challenging. We investigate this question\nthrough entity comparison tasks by asking models to compare entities along\nnumerical attributes (e.g., ``Which river is longer, the Danube or the\nNile?''), which offer clear ground truth for systematic analysis. Despite\nhaving sufficient numerical knowledge to answer correctly, LLMs frequently make\npredictions that contradict this knowledge. We identify three heuristic biases\nthat strongly influence model predictions: entity popularity, mention order,\nand semantic co-occurrence. For smaller models, a simple logistic regression\nusing only these surface cues predicts model choices more accurately than the\nmodel's own numerical predictions, suggesting heuristics largely override\nprincipled reasoning. Crucially, we find that larger models (32B parameters)\nselectively rely on numerical knowledge when it is more reliable, while smaller\nmodels (7--8B parameters) show no such discrimination, which explains why\nlarger models outperform smaller ones even when the smaller models possess more\naccurate knowledge. Chain-of-thought prompting steers all models towards using\nthe numerical features across all model sizes."}
{"id": "2510.16816", "pdf": "https://arxiv.org/pdf/2510.16816", "abs": "https://arxiv.org/abs/2510.16816", "authors": ["Ming Zhong", "Zhenya Yan"], "title": "Efficient High-Accuracy PDEs Solver with the Linear Attention Neural Operator", "categories": ["cs.LG", "cs.AI", "math-ph", "math.MP", "physics.comp-ph"], "comment": "31 pages, 8 figures", "summary": "Neural operators offer a powerful data-driven framework for learning mappings\nbetween function spaces, in which the transformer-based neural operator\narchitecture faces a fundamental scalability-accuracy trade-off: softmax\nattention provides excellent fidelity but incurs quadratic complexity\n$\\mathcal{O}(N^2 d)$ in the number of mesh points $N$ and hidden dimension $d$,\nwhile linear attention variants reduce cost to $\\mathcal{O}(N d^2)$ but often\nsuffer significant accuracy degradation. To address the aforementioned\nchallenge, in this paper, we present a novel type of neural operators, Linear\nAttention Neural Operator (LANO), which achieves both scalability and high\naccuracy by reformulating attention through an agent-based mechanism. LANO\nresolves this dilemma by introducing a compact set of $M$ agent tokens $(M \\ll\nN)$ that mediate global interactions among $N$ tokens. This agent attention\nmechanism yields an operator layer with linear complexity $\\mathcal{O}(MN d)$\nwhile preserving the expressive power of softmax attention. Theoretically, we\ndemonstrate the universal approximation property, thereby demonstrating\nimproved conditioning and stability properties. Empirically, LANO surpasses\ncurrent state-of-the-art neural PDE solvers, including Transolver with\nslice-based softmax attention, achieving average $19.5\\%$ accuracy improvement\nacross standard benchmarks. By bridging the gap between linear complexity and\nsoftmax-level performance, LANO establishes a scalable, high-accuracy\nfoundation for scientific machine learning applications."}
{"id": "2510.16822", "pdf": "https://arxiv.org/pdf/2510.16822", "abs": "https://arxiv.org/abs/2510.16822", "authors": ["Yahia Battach", "Abdulwahab Felemban", "Faizan Farooq Khan", "Yousef A. Radwan", "Xiang Li", "Fabio Marchese", "Sara Beery", "Burton H. Jones", "Francesca Benzoni", "Mohamed Elhoseiny"], "title": "ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Coral reefs are rapidly declining due to anthropogenic pressures such as\nclimate change, underscoring the urgent need for scalable, automated\nmonitoring. We introduce ReefNet, a large public coral reef image dataset with\npoint-label annotations mapped to the World Register of Marine Species (WoRMS).\nReefNet aggregates imagery from 76 curated CoralNet sources and an additional\nsite from Al Wajh in the Red Sea, totaling approximately 925000 genus-level\nhard coral annotations with expert-verified labels. Unlike prior datasets,\nwhich are often limited by size, geography, or coarse labels and are not\nML-ready, ReefNet offers fine-grained, taxonomically mapped labels at a global\nscale to WoRMS. We propose two evaluation settings: (i) a within-source\nbenchmark that partitions each source's images for localized evaluation, and\n(ii) a cross-source benchmark that withholds entire sources to test domain\ngeneralization. We analyze both supervised and zero-shot classification\nperformance on ReefNet and find that while supervised within-source performance\nis promising, supervised performance drops sharply across domains, and\nperformance is low across the board for zero-shot models, especially for rare\nand visually similar genera. This provides a challenging benchmark intended to\ncatalyze advances in domain generalization and fine-grained coral\nclassification. We will release our dataset, benchmarking code, and pretrained\nmodels to advance robust, domain-adaptive, global coral reef monitoring and\nconservation."}
{"id": "2510.16829", "pdf": "https://arxiv.org/pdf/2510.16829", "abs": "https://arxiv.org/abs/2510.16829", "authors": ["Navreet Kaur", "Hoda Ayad", "Hayoung Jung", "Shravika Mittal", "Munmun De Choudhury", "Tanushree Mitra"], "title": "Who's Asking? Simulating Role-Based Questions for Conversational AI Evaluation", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "Language model users often embed personal and social context in their\nquestions. The asker's role -- implicit in how the question is framed --\ncreates specific needs for an appropriate response. However, most evaluations,\nwhile capturing the model's capability to respond, often ignore who is asking.\nThis gap is especially critical in stigmatized domains such as opioid use\ndisorder (OUD), where accounting for users' contexts is essential to provide\naccessible, stigma-free responses. We propose CoRUS (COmmunity-driven Roles for\nUser-centric Question Simulation), a framework for simulating role-based\nquestions. Drawing on role theory and posts from an online OUD recovery\ncommunity (r/OpiatesRecovery), we first build a taxonomy of asker roles --\npatients, caregivers, practitioners. Next, we use it to simulate 15,321\nquestions that embed each role's goals, behaviors, and experiences. Our\nevaluations show that these questions are both highly believable and comparable\nto real-world data. When used to evaluate five LLMs, for the same question but\ndiffering roles, we find systematic differences: vulnerable roles, such as\npatients and caregivers, elicit more supportive responses (+17%) and reduced\nknowledge content (-19%) in comparison to practitioners. Our work demonstrates\nhow implicitly signaling a user's role shapes model responses, and provides a\nmethodology for role-informed evaluation of conversational AI."}
{"id": "2510.16834", "pdf": "https://arxiv.org/pdf/2510.16834", "abs": "https://arxiv.org/abs/2510.16834", "authors": ["Jing Yang", "Sirui Wang", "Chao Wu", "Fan Fan"], "title": "SchrÃ¶dinger Bridge Mamba for One-Step Speech Enhancement", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "5 pages, 1 figure", "summary": "We propose Schr\\\"odinger Bridge Mamba (SBM), a new concept of\ntraining-inference framework motivated by the inherent compatibility between\nSchr\\\"odinger Bridge (SB) training paradigm and selective state-space model\nMamba. We exemplify the concept of SBM with an implementation for generative\nspeech enhancement. Experiments on a joint denoising and dereverberation task\nusing four benchmark datasets demonstrate that SBM, with only 1-step inference,\noutperforms strong baselines with 1-step or iterative inference and achieves\nthe best real-time factor (RTF). Beyond speech enhancement, we discuss the\nintegration of SB paradigm and selective state-space model architecture based\non their underlying alignment, which indicates a promising direction for\nexploring new deep generative models potentially applicable to a broad range of\ngenerative tasks. Demo page: https://sbmse.github.io"}
{"id": "2510.16844", "pdf": "https://arxiv.org/pdf/2510.16844", "abs": "https://arxiv.org/abs/2510.16844", "authors": ["Jiajie Jin", "Yuyao Zhang", "Yimeng Xu", "Hongjin Qian", "Yutao Zhu", "Zhicheng Dou"], "title": "FinSight: Towards Real-World Financial Deep Research", "categories": ["cs.CL", "cs.AI", "cs.CE"], "comment": "Working in progress", "summary": "Generating professional financial reports is a labor-intensive and\nintellectually demanding process that current AI systems struggle to fully\nautomate. To address this challenge, we introduce FinSight (Financial InSight),\na novel multi agent framework for producing high-quality, multimodal financial\nreports. The foundation of FinSight is the Code Agent with Variable Memory\n(CAVM) architecture, which unifies external data, designed tools, and agents\ninto a programmable variable space, enabling flexible data collection, analysis\nand report generation through executable code. To ensure professional-grade\nvisualization, we propose an Iterative Vision-Enhanced Mechanism that\nprogressively refines raw visual outputs into polished financial charts.\nFurthermore, a two stage Writing Framework expands concise Chain-of-Analysis\nsegments into coherent, citation-aware, and multimodal reports, ensuring both\nanalytical depth and structural consistency. Experiments on various company and\nindustry-level tasks demonstrate that FinSight significantly outperforms all\nbaselines, including leading deep research systems in terms of factual\naccuracy, analytical depth, and presentation quality, demonstrating a clear\npath toward generating reports that approach human-expert quality."}
{"id": "2510.16851", "pdf": "https://arxiv.org/pdf/2510.16851", "abs": "https://arxiv.org/abs/2510.16851", "authors": ["Zhengqi Pei", "Qingming Huang", "Shuhui Wang"], "title": "Neuronal Group Communication for Efficient Neural representation", "categories": ["cs.CL", "cs.AI", "cs.NE"], "comment": "28 pages, 2 figures", "summary": "The ever-increasing scale of modern neural networks has brought unprecedented\nperformance alongside daunting challenges in efficiency and interpretability.\nThis paper addresses the core question of how to build large neural systems\nthat learn efficient, modular, and interpretable representations. We propose\nNeuronal Group Communication (NGC), a theory-driven framework that reimagines a\nneural network as a dynamical system of interacting neuronal groups rather than\na monolithic collection of neural weights. Instead of treating each weight as\nan independent trainable parameter, NGC treats weights as transient\ninteractions between embedding-like neuronal states, with neural computation\nunfolding through iterative communication among groups of neurons. This\nlow-rank, modular representation yields compact models: groups of neurons\nexchange low-dimensional signals, enabling intra-group specialization and\ninter-group information sharing while dramatically reducing redundant\nparameters. By drawing on dynamical systems theory, we introduce a neuronal\nstability metric (analogous to Lyapunov stability) that quantifies the\ncontraction of neuron activations toward stable patterns during sequence\nprocessing. Using this metric, we reveal that emergent reasoning capabilities\ncorrespond to an external driving force or ``potential'', which nudges the\nneural dynamics away from trivial trajectories while preserving stability.\nEmpirically, we instantiate NGC in large language models (LLMs) and demonstrate\nimproved performance on complex reasoning benchmarks under moderate\ncompression. NGC consistently outperforms standard low-rank approximations and\ncross-layer basis-sharing methods at comparable compression rates. We conclude\nby discussing the broader implications of NGC, including how structured\nneuronal group dynamics might relate to generalization in high-dimensional\nlearning systems."}
{"id": "2510.16853", "pdf": "https://arxiv.org/pdf/2510.16853", "abs": "https://arxiv.org/abs/2510.16853", "authors": ["Matthew Sharp", "Omer Bilgin", "Iason Gabriel", "Lewis Hammond"], "title": "Agentic Inequality", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Autonomous AI agents, capable of complex planning and action, represent a\nsignificant technological evolution beyond current generative tools. As these\nsystems become integrated into political and economic life, their distribution\nand capabilities will be highly consequential. This paper introduces and\nexplores \"agentic inequality\" - the potential disparities in power,\nopportunity, and outcomes stemming from differential access to, and\ncapabilities of, AI agents. We analyse the dual potential of this technology,\nexploring how agents could both exacerbate existing divides and, under the\nright conditions, serve as a powerful equalising force. To this end, the paper\nmakes three primary contributions. First, it establishes an analytical\nframework by delineating the three core dimensions through which this\ninequality can manifest: disparities in the availability, quality, and quantity\nof agents. Second, it argues that agentic inequality is distinct from prior\ntechnological divides. Unlike tools that primarily augment human abilities,\nagents act as autonomous delegates, creating novel power asymmetries through\nscalable goal delegation and direct agent-to-agent competition that are poised\nto reshape outcomes across economic and socio-political spheres. Finally, it\nprovides a systematic analysis of the technical and socioeconomic drivers -\nfrom model release strategies to market incentives - that will shape the\ndistribution of agentic power, concluding with a research agenda for navigating\nthe complex governance challenges ahead."}
{"id": "2510.16854", "pdf": "https://arxiv.org/pdf/2510.16854", "abs": "https://arxiv.org/abs/2510.16854", "authors": ["Akhila Kambhatla", "Taminul Islam", "Khaled R Ahmed"], "title": "ArmFormer: Lightweight Transformer Architecture for Real-Time Multi-Class Weapon Segmentation and Classification", "categories": ["cs.CV", "cs.AI", "68T07", "I.2.10; I.5.4; I.4.6"], "comment": "9 pages with 4 figures and 5 tables. This is a preprint submitted to\n  arXiv", "summary": "The escalating threat of weapon-related violence necessitates automated\ndetection systems capable of pixel-level precision for accurate threat\nassessment in real-time security applications. Traditional weapon detection\napproaches rely on object detection frameworks that provide only coarse\nbounding box localizations, lacking the fine-grained segmentation required for\ncomprehensive threat analysis. Furthermore, existing semantic segmentation\nmodels either sacrifice accuracy for computational efficiency or require\nexcessive computational resources incompatible with edge deployment scenarios.\nThis paper presents ArmFormer, a lightweight transformer-based semantic\nsegmentation framework that strategically integrates Convolutional Block\nAttention Module (CBAM) with MixVisionTransformer architecture to achieve\nsuperior accuracy while maintaining computational efficiency suitable for\nresource-constrained edge devices. Our approach combines CBAM-enhanced encoder\nbackbone with attention-integrated hamburger decoder to enable multi-class\nweapon segmentation across five categories: handgun, rifle, knife, revolver,\nand human. Comprehensive experiments demonstrate that ArmFormer achieves\nstate-of-the-art performance with 80.64% mIoU and 89.13% mFscore while\nmaintaining real-time inference at 82.26 FPS. With only 4.886G FLOPs and 3.66M\nparameters, ArmFormer outperforms heavyweight models requiring up to 48x more\ncomputation, establishing it as the optimal solution for deployment on portable\nsecurity cameras, surveillance drones, and embedded AI accelerators in\ndistributed security infrastructure."}
{"id": "2510.16857", "pdf": "https://arxiv.org/pdf/2510.16857", "abs": "https://arxiv.org/abs/2510.16857", "authors": ["Jiyan Qiu", "Lyulin Kuang", "Guan Wang", "Yichen Xu", "Leiyao Cui", "Shaotong Fu", "Yixin Zhu", "Ruihua Zhang"], "title": "DrivAerStar: An Industrial-Grade CFD Dataset for Vehicle Aerodynamic Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Vehicle aerodynamics optimization has become critical for automotive\nelectrification, where drag reduction directly determines electric vehicle\nrange and energy efficiency. Traditional approaches face an intractable\ntrade-off: computationally expensive Computational Fluid Dynamics (CFD)\nsimulations requiring weeks per design iteration, or simplified models that\nsacrifice production-grade accuracy. While machine learning offers\ntransformative potential, existing datasets exhibit fundamental limitations --\ninadequate mesh resolution, missing vehicle components, and validation errors\nexceeding 5% -- preventing deployment in industrial workflows. We present\nDrivAerStar, comprising 12,000 industrial-grade automotive CFD simulations\ngenerated using $\\text{STAR-CCM+}^\\unicode{xAE}$ software. The dataset\nsystematically explores three vehicle configurations through 20 Computer Aided\nDesign (CAD) parameters via Free Form Deformation (FFD) algorithms, including\ncomplete engine compartments and cooling systems with realistic internal\nairflow. DrivAerStar achieves wind tunnel validation accuracy below 1.04% -- a\nfive-fold improvement over existing datasets -- through refined mesh strategies\nwith strict wall $y^+$ control. Benchmarks demonstrate that models trained on\nthis data achieve production-ready accuracy while reducing computational costs\nfrom weeks to minutes. This represents the first dataset bridging academic\nmachine learning research and industrial CFD practice, establishing a new\nstandard for data-driven aerodynamic optimization in automotive development.\nBeyond automotive applications, DrivAerStar demonstrates a paradigm for\nintegrating high-fidelity physics simulations with Artificial Intelligence (AI)\nacross engineering disciplines where computational constraints currently limit\ninnovation."}
{"id": "2510.16877", "pdf": "https://arxiv.org/pdf/2510.16877", "abs": "https://arxiv.org/abs/2510.16877", "authors": ["Heming Zou", "Yunliang Zang", "Wutong Xu", "Xiangyang Ji"], "title": "Fly-CL: A Fly-Inspired Framework for Enhancing Efficient Decorrelation and Reduced Training Time in Pre-trained Model-based Continual Representation Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Using a nearly-frozen pretrained model, the continual representation learning\nparadigm reframes parameter updates as a similarity-matching problem to\nmitigate catastrophic forgetting. However, directly leveraging pretrained\nfeatures for downstream tasks often suffers from multicollinearity in the\nsimilarity-matching stage, and more advanced methods can be computationally\nprohibitive for real-time, low-latency applications. Inspired by the fly\nolfactory circuit, we propose Fly-CL, a bio-inspired framework compatible with\na wide range of pretrained backbones. Fly-CL substantially reduces training\ntime while achieving performance comparable to or exceeding that of current\nstate-of-the-art methods. We theoretically show how Fly-CL progressively\nresolves multicollinearity, enabling more effective similarity matching with\nlow time complexity. Extensive simulation experiments across diverse network\narchitectures and data regimes validate Fly-CL's effectiveness in addressing\nthis challenge through a biologically inspired design. Code is available at\nhttps://github.com/gfyddha/Fly-CL."}
{"id": "2510.16882", "pdf": "https://arxiv.org/pdf/2510.16882", "abs": "https://arxiv.org/abs/2510.16882", "authors": ["Heming Zou", "Yixiu Mao", "Yun Qu", "Qi Wang", "Xiangyang Ji"], "title": "Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Supervised fine-tuning (SFT) is a commonly used technique to adapt large\nlanguage models (LLMs) to downstream tasks. In practice, SFT on a full dataset\nis computationally expensive and sometimes suffers from overfitting or bias\namplification. This facilitates the rise of data curation in SFT, which\nprioritizes the most valuable data to optimze. This work studies the online\nbatch selection family that dynamically scores and filters samples during the\ntraining process. However, existing popular methods often (i) rely merely on\nthe utility of data to select a subset while neglecting other crucial factors\nlike diversity, (ii) rely on external resources such as reference models or\nvalidation sets, and (iii) incur extra training time over full-dataset\ntraining. To address these limitations, this work develops \\textbf{UDS\n(Utility-Diversity Sampling)}, a framework for efficient online batch selection\nin SFT. UDS leverages the nuclear norm of the logits matrix to capture both\ndata utility and intra-sample diversity, while estimating inter-sample\ndiversity through efficient low-dimensional embedding comparisons with a\nlightweight memory buffer of historical samples. Such a design eliminates the\nneed for external resources and unnecessary backpropagation, securing\ncomputational efficiency. Experiments on multiple benchmarks demonstrate that\nUDS consistently outperforms state-of-the-art online batch selection methods\nunder varying data budgets, and significantly reduces training time compared to\nfull-dataset fine-tuning. Code is available at https://github.com/gfyddha/UDS."}
{"id": "2510.16893", "pdf": "https://arxiv.org/pdf/2510.16893", "abs": "https://arxiv.org/abs/2510.16893", "authors": ["Bo-Han Feng", "Chien-Feng Liu", "Yu-Hsuan Li Liang", "Chih-Kai Yang", "Szu-Wei Fu", "Zhehuai Chen", "Ke-Han Lu", "Sung-Feng Huang", "Chao-Han Huck Yang", "Yu-Chiang Frank Wang", "Yun-Nung Chen", "Hung-yi Lee"], "title": "Investigating Safety Vulnerabilities of Large Audio-Language Models Under Speaker Emotional Variations", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": "Submitted to ICASSP 2026", "summary": "Large audio-language models (LALMs) extend text-based LLMs with auditory\nunderstanding, offering new opportunities for multimodal applications. While\ntheir perception, reasoning, and task performance have been widely studied,\ntheir safety alignment under paralinguistic variation remains underexplored.\nThis work systematically investigates the role of speaker emotion. We construct\na dataset of malicious speech instructions expressed across multiple emotions\nand intensities, and evaluate several state-of-the-art LALMs. Our results\nreveal substantial safety inconsistencies: different emotions elicit varying\nlevels of unsafe responses, and the effect of intensity is non-monotonic, with\nmedium expressions often posing the greatest risk. These findings highlight an\noverlooked vulnerability in LALMs and call for alignment strategies explicitly\ndesigned to ensure robustness under emotional variation, a prerequisite for\ntrustworthy deployment in real-world settings."}
{"id": "2510.16898", "pdf": "https://arxiv.org/pdf/2510.16898", "abs": "https://arxiv.org/abs/2510.16898", "authors": ["Salih Salihoglu", "Ibrahim Ahmed", "Afshin Asadi"], "title": "Adaptive Online Learning with LSTM Networks for Energy Price Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate prediction of electricity prices is crucial for stakeholders in the\nenergy market, particularly for grid operators, energy producers, and\nconsumers. This study focuses on developing a predictive model leveraging Long\nShort-Term Memory (LSTM) networks to forecast day-ahead electricity prices in\nthe California energy market. The model incorporates a variety of features,\nincluding historical price data, weather conditions, and the energy generation\nmix. A novel custom loss function that integrates Mean Absolute Error (MAE),\nJensen-Shannon Divergence (JSD), and a smoothness penalty is introduced to\nenhance the prediction accuracy and interpretability. Additionally, an online\nlearning approach is implemented to allow the model to adapt to new data\nincrementally, ensuring continuous relevance and accuracy. The results\ndemonstrate that the custom loss function can improve the model's performance,\naligning predicted prices more closely with actual values, particularly during\npeak intervals. Also, the online learning model outperforms other models by\neffectively incorporating real-time data, resulting in lower prediction error\nand variability. The inclusion of the energy generation mix further enhances\nthe model's predictive capabilities, highlighting the importance of\ncomprehensive feature integration. This research provides a robust framework\nfor electricity price forecasting, offering valuable insights and tools for\nbetter decision-making in dynamic electricity markets."}
{"id": "2510.16899", "pdf": "https://arxiv.org/pdf/2510.16899", "abs": "https://arxiv.org/abs/2510.16899", "authors": ["Dun Liu", "Qin Pang", "Guangai Liu", "Hongyu Mou", "Jipeng Fan", "Yiming Miao", "Pin-Han Ho", "Limei Peng"], "title": "SNOMED CT-powered Knowledge Graphs for Structured Clinical Data and Diagnostic Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The effectiveness of artificial intelligence (AI) in healthcare is\nsignificantly hindered by unstructured clinical documentation, which results in\nnoisy, inconsistent, and logically fragmented training data. To address this\nchallenge, we present a knowledge-driven framework that integrates the\nstandardized clinical terminology SNOMED CT with the Neo4j graph database to\nconstruct a structured medical knowledge graph. In this graph, clinical\nentities such as diseases, symptoms, and medications are represented as nodes,\nand semantic relationships such as ``caused by,'' ``treats,'' and ``belongs\nto'' are modeled as edges in Neo4j, with types mapped from formal SNOMED CT\nrelationship concepts (e.g., \\texttt{Causative agent}, \\texttt{Indicated for}).\nThis design enables multi-hop reasoning and ensures terminological consistency.\nBy extracting and standardizing entity-relationship pairs from clinical texts,\nwe generate structured, JSON-formatted datasets that embed explicit diagnostic\npathways. These datasets are used to fine-tune large language models (LLMs),\nsignificantly improving the clinical logic consistency of their outputs.\nExperimental results demonstrate that our knowledge-guided approach enhances\nthe validity and interpretability of AI-generated diagnostic reasoning,\nproviding a scalable solution for building reliable AI-assisted clinical\nsystems."}
{"id": "2510.16911", "pdf": "https://arxiv.org/pdf/2510.16911", "abs": "https://arxiv.org/abs/2510.16911", "authors": ["Sarah Al-Shareeda", "Gulcihan Ozdemir", "Heung Seok Jeon", "Khaleel Ahmad"], "title": "A Lightweight DL Model for Smart Grid Power Forecasting with Feature and Resolution Mismatch", "categories": ["cs.LG", "cs.AI"], "comment": "5 pages, 3 figures, The IEEE PES ISGT Middle East 2025 (ISGT-ME 2025)\n  November 23-26th 2025, Dubai, UAE", "summary": "How can short-term energy consumption be accurately forecasted when sensor\ndata is noisy, incomplete, and lacks contextual richness? This question guided\nour participation in the \\textit{2025 Competition on Electric Energy\nConsumption Forecast Adopting Multi-criteria Performance Metrics}, which\nchallenged teams to predict next-day power demand using real-world\nhigh-frequency data. We proposed a robust yet lightweight Deep Learning (DL)\npipeline combining hourly downsizing, dual-mode imputation (mean and polynomial\nregression), and comprehensive normalization, ultimately selecting Standard\nScaling for optimal balance. The lightweight GRU-LSTM sequence-to-one model\nachieves an average RMSE of 601.9~W, MAE of 468.9~W, and 84.36\\% accuracy.\nDespite asymmetric inputs and imputed gaps, it generalized well, captured\nnonlinear demand patterns, and maintained low inference latency. Notably,\nspatiotemporal heatmap analysis reveals a strong alignment between temperature\ntrends and predicted consumption, further reinforcing the model's reliability.\nThese results demonstrate that targeted preprocessing paired with compact\nrecurrent architectures can still enable fast, accurate, and deployment-ready\nenergy forecasting in real-world conditions."}
{"id": "2510.16914", "pdf": "https://arxiv.org/pdf/2510.16914", "abs": "https://arxiv.org/abs/2510.16914", "authors": ["Hongwei Yan", "Guanglong Sun", "Zhiqi Kang", "Yi Zhong", "Liyuan Wang"], "title": "Domain Generalizable Continual Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "25 pages", "summary": "To adapt effectively to dynamic real-world environments, intelligent systems\nmust continually acquire new skills while generalizing them to diverse, unseen\nscenarios. Here, we introduce a novel and realistic setting named domain\ngeneralizable continual learning (DGCL): a model learns sequential tasks with\neach involving a single domain, aiming to perform well across all encountered\ntasks and domains. This setting poses unique challenges in acquiring,\nretaining, and leveraging both semantic- and domain-relevant information for\nrobust generalization. Although state-of-the-art continual learning (CL)\nmethods have employed pre-trained models (PTMs) to enhance task-specific\ngeneralization, they typically assume identical training and testing domains\nfor each task and therefore perform poorly in DGCL. To this end, we propose\nadaptive Domain Transformation (DoT), an innovative PTMs-based approach\ntailored to DGCL. Inspired by the distributed-plus-hub theory of the human\nbrain, DoT disentangles semantic- and domain-relevant information in\nrepresentation learning, and adaptively transforms task representations across\nvarious domains for output alignment, ensuring balanced and generalized\npredictions. DoT serves as a plug-in strategy that greatly facilitates\nstate-of-the-art CL baselines under both full parameter tuning and\nparameter-efficient tuning paradigms in DGCL, validated by extensive\nexperiments. Also, DoT is shown to accumulate domain-generalizable knowledge\nfrom DGCL, and ensure resource efficiency with a lightweight implementation."}
{"id": "2510.16917", "pdf": "https://arxiv.org/pdf/2510.16917", "abs": "https://arxiv.org/abs/2510.16917", "authors": ["Chih-Kai Yang", "Yen-Ting Piao", "Tzu-Wen Hsu", "Szu-Wei Fu", "Zhehuai Chen", "Ke-Han Lu", "Sung-Feng Huang", "Chao-Han Huck Yang", "Yu-Chiang Frank Wang", "Yun-Nung Chen", "Hung-yi Lee"], "title": "SAKE: Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": "Work in progress", "summary": "Knowledge editing offers an efficient way to update model knowledge without\nfull retraining, but prior work has concentrated almost exclusively on textual\nor visual modalities. We introduce SAKE, the first benchmark specifically\ndesigned for editing auditory attribute knowledge in Large Audio-Language\nModels (LALMs). Unlike factual updates, SAKE targets several abstract auditory\nattributes, capturing knowledge types that go beyond conventional textual and\nvisual domains. We benchmark seven editing methods on two LALMs along four\ndimensions: reliability, generality, audio/text locality, and portability.\nResults highlight challenges such as preserving intra-attribute knowledge\nunrelated to the edit, generalizing edits to multimodal reasoning, and\nmaintaining edits under sequential updates. SAKE provides a principled\nframework to study how knowledge editing extends to the auditory modalities,\nopening new directions for maintaining and adapting LALMs in more diverse\nreal-world scenarios."}
{"id": "2510.16923", "pdf": "https://arxiv.org/pdf/2510.16923", "abs": "https://arxiv.org/abs/2510.16923", "authors": ["Mansi Phute", "Matthew Hull", "Haoran Wang", "Alec Helbling", "ShengYun Peng", "Willian Lunardi", "Martin Andreoni", "Wenke Lee", "Polo Chau"], "title": "UNDREAM: Bridging Differentiable Rendering and Photorealistic Simulation for End-to-end Adversarial Attacks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep learning models deployed in safety critical applications like autonomous\ndriving use simulations to test their robustness against adversarial attacks in\nrealistic conditions. However, these simulations are non-differentiable,\nforcing researchers to create attacks that do not integrate simulation\nenvironmental factors, reducing attack success. To address this limitation, we\nintroduce UNDREAM, the first software framework that bridges the gap between\nphotorealistic simulators and differentiable renderers to enable end-to-end\noptimization of adversarial perturbations on any 3D objects. UNDREAM enables\nmanipulation of the environment by offering complete control over weather,\nlighting, backgrounds, camera angles, trajectories, and realistic human and\nobject movements, thereby allowing the creation of diverse scenes. We showcase\na wide array of distinct physically plausible adversarial objects that UNDREAM\nenables researchers to swiftly explore in different configurable environments.\nThis combination of photorealistic simulation and differentiable optimization\nopens new avenues for advancing research of physical adversarial attacks."}
{"id": "2510.16933", "pdf": "https://arxiv.org/pdf/2510.16933", "abs": "https://arxiv.org/abs/2510.16933", "authors": ["MatyÃ¡Å¡ Brabec", "JiÅÃ­ Klepl", "Michal TÃ¶pfer", "Martin KruliÅ¡"], "title": "Tutoring LLM into a Better CUDA Optimizer", "categories": ["cs.DC", "cs.AI"], "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Euro-Par 2025: Parallel Processing, Part II, and is available\n  online at https://doi.org/10.1007/978-3-031-99857-7_18", "summary": "Recent leaps in large language models (LLMs) caused a revolution in\nprogramming tools (like GitHub Copilot) that can help with code generation,\ndebugging, and even performance optimization. In this paper, we focus on the\ncapabilities of the most recent reasoning models to generate optimized CUDA\ncode for predefined, well-known tasks. Our objective is to determine which\ntypes of code optimizations and parallel patterns the LLMs can perform by\nthemselves and whether they can be improved by tutoring (providing more\ndetailed hints and guidelines in the prompt). The generated solutions were\nevaluated both automatically (for correctness and speedup) and manually (code\nreviews) to provide a more detailed perspective. We also tried an interactive\napproach where the LLM can fix its previous mistakes within a session. The\nresults indicate that LLMs are quite skilled coders; however, they require\ntutoring to reach optimized solutions provided by parallel computing experts."}
{"id": "2510.16940", "pdf": "https://arxiv.org/pdf/2510.16940", "abs": "https://arxiv.org/abs/2510.16940", "authors": ["Cristian J. Vaca-Rubio", "Roberto Pereira", "Luis Blanco", "Engin Zeydan", "MÃ rius Caus"], "title": "A Primer on Kolmogorov-Arnold Networks (KANs) for Probabilistic Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "This work introduces Probabilistic Kolmogorov-Arnold Network (P-KAN), a novel\nprobabilistic extension of Kolmogorov-Arnold Networks (KANs) for time series\nforecasting. By replacing scalar weights with spline-based functional\nconnections and directly parameterizing predictive distributions, P-KANs offer\nexpressive yet parameter-efficient models capable of capturing nonlinear and\nheavy-tailed dynamics. We evaluate P-KANs on satellite traffic forecasting,\nwhere uncertainty-aware predictions enable dynamic thresholding for resource\nallocation. Results show that P-KANs consistently outperform Multi Layer\nPerceptron (MLP) baselines in both accuracy and calibration, achieving superior\nefficiency-risk trade-offs while using significantly fewer parameters. We build\nup P-KANs on two distributions, namely Gaussian and Student-t distributions.\nThe Gaussian variant provides robust, conservative forecasts suitable for\nsafety-critical scenarios, whereas the Student-t variant yields sharper\ndistributions that improve efficiency under stable demand. These findings\nestablish P-KANs as a powerful framework for probabilistic forecasting with\ndirect applicability to satellite communications and other resource-constrained\ndomains."}
{"id": "2510.16943", "pdf": "https://arxiv.org/pdf/2510.16943", "abs": "https://arxiv.org/abs/2510.16943", "authors": ["Dania Refai", "Moataz Ahmed"], "title": "Peering Inside the Black Box: Uncovering LLM Errors in Optimization Modelling through Component-Level Evaluation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to convert natural\nlanguage descriptions into mathematical optimization formulations. Current\nevaluations often treat formulations as a whole, relying on coarse metrics like\nsolution accuracy or runtime, which obscure structural or numerical errors. In\nthis study, we present a comprehensive, component-level evaluation framework\nfor LLM-generated formulations. Beyond the conventional optimality gap, our\nframework introduces metrics such as precision and recall for decision\nvariables and constraints, constraint and objective root mean squared error\n(RMSE), and efficiency indicators based on token usage and latency. We evaluate\nGPT-5, LLaMA 3.1 Instruct, and DeepSeek Math across optimization problems of\nvarying complexity under six prompting strategies. Results show that GPT-5\nconsistently outperforms other models, with chain-of-thought, self-consistency,\nand modular prompting proving most effective. Analysis indicates that solver\nperformance depends primarily on high constraint recall and low constraint\nRMSE, which together ensure structural correctness and solution reliability.\nConstraint precision and decision variable metrics play secondary roles, while\nconcise outputs enhance computational efficiency. These findings highlight\nthree principles for NLP-to-optimization modeling: (i) Complete constraint\ncoverage prevents violations, (ii) minimizing constraint RMSE ensures\nsolver-level accuracy, and (iii) concise outputs improve computational\nefficiency. The proposed framework establishes a foundation for fine-grained,\ndiagnostic evaluation of LLMs in optimization modeling."}
{"id": "2510.16958", "pdf": "https://arxiv.org/pdf/2510.16958", "abs": "https://arxiv.org/abs/2510.16958", "authors": ["Ganglin Tian", "Anastase Alexandre Charantonis", "Camille Le Coz", "Alexis Tantet", "Riwal Plougonven"], "title": "Quantile Regression, Variational Autoencoders, and Diffusion Models for Uncertainty Quantification: A Spatial Analysis of Sub-seasonal Wind Speed Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "This Work has been submitted to Monthly Weather Review. Copyright in\n  this Work may be transferred without further notice", "summary": "This study aims to improve the spatial representation of uncertainties when\nregressing surface wind speeds from large-scale atmospheric predictors for\nsub-seasonal forecasting. Sub-seasonal forecasting often relies on large-scale\natmospheric predictors such as 500 hPa geopotential height (Z500), which\nexhibit higher predictability than surface variables and can be downscaled to\nobtain more localised information. Previous work by Tian et al. (2024)\ndemonstrated that stochastic perturbations based on model residuals can improve\nensemble dispersion representation in statistical downscaling frameworks, but\nthis method fails to represent spatial correlations and physical consistency\nadequately. More sophisticated approaches are needed to capture the complex\nrelationships between large-scale predictors and local-scale predictands while\nmaintaining physical consistency. Probabilistic deep learning models offer\npromising solutions for capturing complex spatial dependencies. This study\nevaluates three probabilistic methods with distinct uncertainty quantification\nmechanisms: Quantile Regression Neural Network that directly models\ndistribution quantiles, Variational Autoencoders that leverage latent space\nsampling, and Diffusion Models that utilise iterative denoising. These models\nare trained on ERA5 reanalysis data and applied to ECMWF sub-seasonal hindcasts\nto regress probabilistic wind speed ensembles. Our results show that\nprobabilistic downscaling approaches provide more realistic spatial uncertainty\nrepresentations compared to simpler stochastic methods, with each probabilistic\nmodel offering different strengths in terms of ensemble dispersion,\ndeterministic skill, and physical consistency. These findings establish\nprobabilistic downscaling as an effective enhancement to operational\nsub-seasonal wind forecasts for renewable energy planning and risk assessment."}
{"id": "2510.16968", "pdf": "https://arxiv.org/pdf/2510.16968", "abs": "https://arxiv.org/abs/2510.16968", "authors": ["Pingzhi Li", "Morris Yu-Chao Huang", "Zhen Tan", "Qingquan Song", "Jie Peng", "Kai Zou", "Yu Cheng", "Kaidi Xu", "Tianlong Chen"], "title": "Leave It to the Experts: Detecting Knowledge Distillation via MoE Expert Signatures", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Code is at https://github.com/unites-lab/shadow-moe", "summary": "Knowledge Distillation (KD) accelerates training of large language models\n(LLMs) but poses intellectual property protection and LLM diversity risks.\nExisting KD detection methods based on self-identity or output similarity can\nbe easily evaded through prompt engineering. We present a KD detection\nframework effective in both white-box and black-box settings by exploiting an\noverlooked signal: the transfer of MoE \"structural habits\", especially internal\nrouting patterns. Our approach analyzes how different experts specialize and\ncollaborate across various inputs, creating distinctive fingerprints that\npersist through the distillation process. To extend beyond the white-box setup\nand MoE architectures, we further propose Shadow-MoE, a black-box method that\nconstructs proxy MoE representations via auxiliary distillation to compare\nthese patterns between arbitrary model pairs. We establish a comprehensive,\nreproducible benchmark that offers diverse distilled checkpoints and an\nextensible framework to facilitate future research. Extensive experiments\ndemonstrate >94% detection accuracy across various scenarios and strong\nrobustness to prompt-based evasion, outperforming existing baselines while\nhighlighting the structural habits transfer in LLMs."}
{"id": "2510.16973", "pdf": "https://arxiv.org/pdf/2510.16973", "abs": "https://arxiv.org/abs/2510.16973", "authors": ["Praveenbalaji Rajendran", "Mojtaba Safari", "Wenfeng He", "Mingzhe Hu", "Shansong Wang", "Jun Zhou", "Xiaofeng Yang"], "title": "Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis", "categories": ["cs.CV", "cs.AI", "physics.med-ph"], "comment": null, "summary": "Recent advancements in artificial intelligence (AI), particularly foundation\nmodels (FMs), have revolutionized medical image analysis, demonstrating strong\nzero- and few-shot performance across diverse medical imaging tasks, from\nsegmentation to report generation. Unlike traditional task-specific AI models,\nFMs leverage large corpora of labeled and unlabeled multimodal datasets to\nlearn generalized representations that can be adapted to various downstream\nclinical applications with minimal fine-tuning. However, despite the rapid\nproliferation of FM research in medical imaging, the field remains fragmented,\nlacking a unified synthesis that systematically maps the evolution of\narchitectures, training paradigms, and clinical applications across modalities.\nTo address this gap, this review article provides a comprehensive and\nstructured analysis of FMs in medical image analysis. We systematically\ncategorize studies into vision-only and vision-language FMs based on their\narchitectural foundations, training strategies, and downstream clinical tasks.\nAdditionally, a quantitative meta-analysis of the studies was conducted to\ncharacterize temporal trends in dataset utilization and application domains. We\nalso critically discuss persistent challenges, including domain adaptation,\nefficient fine-tuning, computational constraints, and interpretability along\nwith emerging solutions such as federated learning, knowledge distillation, and\nadvanced prompting. Finally, we identify key future research directions aimed\nat enhancing the robustness, explainability, and clinical integration of FMs,\nthereby accelerating their translation into real-world medical practice."}
{"id": "2510.16983", "pdf": "https://arxiv.org/pdf/2510.16983", "abs": "https://arxiv.org/abs/2510.16983", "authors": ["Yuanzhi Zhu", "Eleftherios Tsonis", "Lucas Degeorge", "Vicky Kalogeiton"], "title": "One-step Diffusion Models with Bregman Density Ratio Matching", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "work in progress", "summary": "Diffusion and flow models achieve high generative quality but remain\ncomputationally expensive due to slow multi-step sampling. Distillation methods\naccelerate them by training fast student generators, yet most existing\nobjectives lack a unified theoretical foundation. In this work, we propose\nDi-Bregman, a compact framework that formulates diffusion distillation as\nBregman divergence-based density-ratio matching. This convex-analytic view\nconnects several existing objectives through a common lens. Experiments on\nCIFAR-10 and text-to-image generation demonstrate that Di-Bregman achieves\nimproved one-step FID over reverse-KL distillation and maintains high visual\nfidelity compared to the teacher model. Our results highlight Bregman\ndensity-ratio matching as a practical and theoretically-grounded route toward\nefficient one-step diffusion generation."}
{"id": "2510.16985", "pdf": "https://arxiv.org/pdf/2510.16985", "abs": "https://arxiv.org/abs/2510.16985", "authors": ["Akif Islam", "Mohd Ruhul Ameen"], "title": "Parameter-Efficient Fine-Tuning for Low-Resource Languages: A Comparative Study of LLMs for Bengali Hate Speech Detection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to IEEE COMPAS 2025. 6 pages, 3 figures, 6 tables", "summary": "Bengali social media platforms have witnessed a sharp increase in hate\nspeech, disproportionately affecting women and adolescents. While datasets such\nas BD-SHS provide a basis for structured evaluation, most prior approaches rely\non either computationally costly full-model fine-tuning or proprietary APIs.\nThis paper presents the first application of Parameter-Efficient Fine-Tuning\n(PEFT) for Bengali hate speech detection using LoRA and QLoRA. Three\ninstruction-tuned large language models - Gemma-3-4B, Llama-3.2-3B, and\nMistral-7B - were fine-tuned on the BD-SHS dataset of 50,281 annotated\ncomments. Each model was adapted by training fewer than 1% of its parameters,\nenabling experiments on a single consumer-grade GPU. The results show that\nLlama-3.2-3B achieved the highest F1-score of 92.23%, followed by Mistral-7B at\n88.94% and Gemma-3-4B at 80.25%. These findings establish PEFT as a practical\nand replicable strategy for Bengali and related low-resource languages."}
{"id": "2510.16988", "pdf": "https://arxiv.org/pdf/2510.16988", "abs": "https://arxiv.org/abs/2510.16988", "authors": ["Junhao Zhao", "Zishuai Liu", "Ruili Fang", "Jin Lu", "Linghan Zhang", "Fei Dou"], "title": "CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The recognition of Activities of Daily Living (ADLs) from event-triggered\nambient sensors is an essential task in Ambient Assisted Living, yet existing\nmethods remain constrained by representation-level limitations. Sequence-based\napproaches preserve temporal order of sensor activations but are sensitive to\nnoise and lack spatial awareness, while image-based approaches capture global\npatterns and implicit spatial correlations but compress fine-grained temporal\ndynamics and distort sensor layouts. Naive fusion (e.g., feature concatenation)\nfail to enforce alignment between sequence- and image-based representation\nviews, underutilizing their complementary strengths. We propose Contrastive\nAlignment for ADL Recognition from Event-Triggered Sensor Streams (CARE), an\nend-to-end framework that jointly optimizes representation learning via\nSequence-Image Contrastive Alignment (SICA) and classification via\ncross-entropy, ensuring both cross-representation alignment and task-specific\ndiscriminability. CARE integrates (i) time-aware, noise-resilient sequence\nencoding with (ii) spatially-informed and frequency-sensitive image\nrepresentations, and employs (iii) a joint contrastive-classification objective\nfor end-to-end learning of aligned and discriminative embeddings. Evaluated on\nthree CASAS datasets, CARE achieves state-of-the-art performance (89.8% on\nMilan, 88.9% on Cairo, and 73.3% on Kyoto7) and demonstrates robustness to\nsensor malfunctions and layout variability, highlighting its potential for\nreliable ADL recognition in smart homes."}
{"id": "2510.17004", "pdf": "https://arxiv.org/pdf/2510.17004", "abs": "https://arxiv.org/abs/2510.17004", "authors": ["Eleftherios Tzanis", "Michail E. Klontzas"], "title": "ReclAIm: A multi-agent framework for degradation-aware performance tuning of medical imaging AI", "categories": ["cs.MA", "cs.AI"], "comment": "25 pages, 4 figures", "summary": "Ensuring the long-term reliability of AI models in clinical practice requires\ncontinuous performance monitoring and corrective actions when degradation\noccurs. Addressing this need, this manuscript presents ReclAIm, a multi-agent\nframework capable of autonomously monitoring, evaluating, and fine-tuning\nmedical image classification models. The system, built on a large language\nmodel core, operates entirely through natural language interaction, eliminating\nthe need for programming expertise. ReclAIm successfully trains, evaluates, and\nmaintains consistent performance of models across MRI, CT, and X-ray datasets.\nOnce ReclAIm detects significant performance degradation, it autonomously\nexecutes state-of-the-art fine-tuning procedures that substantially reduce the\nperformance gap. In cases with performance drops of up to -41.1% (MRI\nInceptionV3), ReclAIm managed to readjust performance metrics within 1.5% of\nthe initial model results. ReclAIm enables automated, continuous maintenance of\nmedical imaging AI models in a user-friendly and adaptable manner that\nfacilitates broader adoption in both research and clinical environments."}
{"id": "2510.17015", "pdf": "https://arxiv.org/pdf/2510.17015", "abs": "https://arxiv.org/abs/2510.17015", "authors": ["Mingyan Yang", "Guanjie Wang", "Manqi Luo", "Yifei Liu", "Chen Chen", "Han Zhao", "Yu Feng", "Quan Chen", "Minyi Guo"], "title": "Justitia: Fair and Efficient Scheduling for LLM Applications", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "In the era of Large Language Models (LLMs), it has been popular to launch a\nseries of LLM inferences -- we call an LLM application -- to better solve\nreal-world problems. When serving those applications in shared GPU servers, the\nschedulers are expected to attain fast application completions with guaranteed\nworst-case performance. However, mainstream LLM schedulers fail to behave well\nfor LLM applications -- due to head-of-line blocking or over-constrained\nresource allocation. In this paper, we propose to serve LLM applications in a\nfair and also efficient manner. To this end, we design Justitia, a novel\nscheduler with three key techniques. First, given that memory is prevalently a\nbottleneck for mainstream inference frameworks like vLLM, Justitia models the\nservice cost of LLM applications in a memory-centric manner. Meanwhile, it uses\na simple neural network model to conduct light-weight and also accurate demand\nprediction. Moreover, Justitia adopts a virtual-time based fair queuing\nalgorithm to reduce the overall performance with guaranteed worst-case delay.\nWe have implemented Justitia atop vLLM, and experimental results involving\ndiverse LLM applications show that it can substantially enhance the scheduling\nefficiency with fairness preserved."}
{"id": "2510.17022", "pdf": "https://arxiv.org/pdf/2510.17022", "abs": "https://arxiv.org/abs/2510.17022", "authors": ["Kevin P. O Keeffe"], "title": "Curiosity-driven RL for symbolic equation solving", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at the NeurIPS 2025 MATH-AI Workshop", "summary": "We explore if RL can be useful for symbolic mathematics. Previous work showed\ncontrastive learning can solve linear equations in one variable. We show\nmodel-free PPO \\cite{schulman2017proximal} augmented with curiosity-based\nexploration and graph-based actions can solve nonlinear equations such as those\ninvolving radicals, exponentials, and trig functions. Our work suggests\ncuriosity-based exploration may be useful for general symbolic reasoning tasks."}
{"id": "2510.17038", "pdf": "https://arxiv.org/pdf/2510.17038", "abs": "https://arxiv.org/abs/2510.17038", "authors": ["Pedram Fekri", "Majid Roshanfar", "Samuel Barbeau", "Seyedfarzad Famouri", "Thomas Looi", "Dale Podolsky", "Mehrdad Zadeh", "Javad Dargahi"], "title": "DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for Autonomous Catheter Navigation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Cardiac catheterization remains a cornerstone of minimally invasive\ninterventions, yet it continues to rely heavily on manual operation. Despite\nadvances in robotic platforms, existing systems are predominantly follow-leader\nin nature, requiring continuous physician input and lacking intelligent\nautonomy. This dependency contributes to operator fatigue, more radiation\nexposure, and variability in procedural outcomes. This work moves towards\nautonomous catheter navigation by introducing DINO-CVA, a multimodal\ngoal-conditioned behavior cloning framework. The proposed model fuses visual\nobservations and joystick kinematics into a joint embedding space, enabling\npolicies that are both vision-aware and kinematic-aware. Actions are predicted\nautoregressively from expert demonstrations, with goal conditioning guiding\nnavigation toward specified destinations. A robotic experimental setup with a\nsynthetic vascular phantom was designed to collect multimodal datasets and\nevaluate performance. Results show that DINO-CVA achieves high accuracy in\npredicting actions, matching the performance of a kinematics-only baseline\nwhile additionally grounding predictions in the anatomical environment. These\nfindings establish the feasibility of multimodal, goal-conditioned\narchitectures for catheter navigation, representing an important step toward\nreducing operator dependency and improving the reliability of catheterbased\ntherapies."}
{"id": "2510.17045", "pdf": "https://arxiv.org/pdf/2510.17045", "abs": "https://arxiv.org/abs/2510.17045", "authors": ["Deepak Sridhar", "Kartikeya Bhardwaj", "Jeya Pradha Jeyaraj", "Nuno Vasconcelos", "Ankita Nayak", "Harris Teague"], "title": "Video Reasoning without Training", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Video reasoning using Large Multimodal Models (LMMs) relies on costly\nreinforcement learning (RL) and verbose chain-of-thought, resulting in\nsubstantial computational overhead during both training and inference.\nMoreover, the mechanisms that control the thinking process in these reasoning\nmodels are very limited. In this paper, using entropy of the model's output as\na signal, we discover that the high-quality models go through a series of\nmicro-explorations and micro-exploitations which keep the reasoning process\ngrounded (i.e., avoid excessive randomness while the model is exploring or\nthinking through an answer). We further observe that once this \"thinking\"\nprocess is over, more accurate models demonstrate a better convergence by\nreducing the entropy significantly via a final exploitation phase (i.e., a more\ncertain convergence towards a solution trajectory). We then use these novel,\ntheoretically-grounded insights to tune the model's behavior directly at\ninference, without using any RL or supervised fine-tuning. Specifically, during\ninference, our proposed approach called V-Reason (Video-Reason) adapts the\nvalue cache of the LMM via a few optimization steps on a small, trainable\ncontroller using an entropy-based objective, i.e., no supervision from any\ndataset or RL is necessary. This tuning improves the model's micro-exploration\nand exploitation behavior during inference. Our experiments show that our\nproposed method achieves significant improvements over the base\ninstruction-tuned models across several video reasoning datasets, narrowing the\ngap with RL-trained models to within 0.6% average accuracy without any\ntraining, while offering massive efficiency benefits: output tokens are reduced\nby 58.6% compared to the RL model."}
{"id": "2510.17057", "pdf": "https://arxiv.org/pdf/2510.17057", "abs": "https://arxiv.org/abs/2510.17057", "authors": ["Nikolaus Howe", "Micah Carroll"], "title": "The Ends Justify the Thoughts: RL-Induced Motivated Reasoning in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages", "summary": "The use of reinforcement learning (RL) with chain-of-thought (CoT) reasoning\nhas emerged as a promising approach for developing more capable language\nmodels. In turn, this has led to investigation of CoT monitoring as a\ncompelling method for detecting harmful behaviors such as reward hacking, under\nthe assumption that models' reasoning processes reflect their internal\ndecision-making. In practice, LLM training often produces unintended behaviors\ndue to imperfect reward signals, leading models to develop misaligned\ntendencies. A common corrective approach is to apply post-hoc instructions to\navoid problematic behaviors like sycophancy, but what happens to the model's\nreasoning process when these instructions conflict with learned behaviors? We\ninvestigate this question in simple settings and find that models engage in\nsystematic motivated reasoning -- generating plausible-sounding justifications\nfor violating their instructions while downplaying potential harms. Beyond\nbeing an interesting property of training, we find that while motivated\nreasoning can be detected by most frontier reasoning models, smaller LLM judges\ncan fail to identify a portion of it, and in rare cases can themselves be\npersuaded that the reasoning is correct, despite it contradicting clear\ninstructions. This capability gap raises concerns that as models become more\nsophisticated, their motivated reasoning may become increasingly difficult for\nmonitors to detect. Our results underscore the need to account for motivated\nreasoning when relying on chain-of-thought processes for model evaluation and\noversight. All code for this paper will be made available. WARNING: some\nexamples in this paper may be upsetting."}
{"id": "2510.17058", "pdf": "https://arxiv.org/pdf/2510.17058", "abs": "https://arxiv.org/abs/2510.17058", "authors": ["Hassan Hamad", "Yuou Qiu", "Peter A. Beerel", "Keith M. Chugg"], "title": "Bitwidth-Specific Logarithmic Arithmetic for Future Hardware-Accelerated Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While advancements in quantization have significantly reduced the\ncomputational costs of inference in deep learning, training still predominantly\nrelies on complex floating-point arithmetic. Low-precision fixed-point training\npresents a compelling alternative. This work introduces a novel enhancement in\nlow-precision logarithmic fixed-point training, geared towards future hardware\naccelerator designs. We propose incorporating bitwidth in the design of\napproximations to arithmetic operations. To this end, we introduce a new\nhardware-friendly, piece-wise linear approximation for logarithmic addition.\nUsing simulated annealing, we optimize this approximation at different\nprecision levels. A C++ bit-true simulation demonstrates training of VGG-11 and\nVGG-16 models on CIFAR-100 and TinyImageNet, respectively, using 12-bit integer\narithmetic with minimal accuracy degradation compared to 32-bit floating-point\ntraining. Our hardware study reveals up to 32.5% reduction in area and 53.5%\nreduction in energy consumption for the proposed LNS multiply-accumulate units\ncompared to that of linear fixed-point equivalents."}
{"id": "2510.17062", "pdf": "https://arxiv.org/pdf/2510.17062", "abs": "https://arxiv.org/abs/2510.17062", "authors": ["Guoqing Luo", "Iffat Maab", "Lili Mou", "Junichi Yamagishi"], "title": "Investigating Thinking Behaviours of Reasoning-Based Language Models for Social Bias Mitigation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While reasoning-based large language models excel at complex tasks through an\ninternal, structured thinking process, a concerning phenomenon has emerged that\nsuch a thinking process can aggregate social stereotypes, leading to biased\noutcomes. However, the underlying behaviours of these language models in social\nbias scenarios remain underexplored. In this work, we systematically\ninvestigate mechanisms within the thinking process behind this phenomenon and\nuncover two failure patterns that drive social bias aggregation: 1) stereotype\nrepetition, where the model relies on social stereotypes as its primary\njustification, and 2) irrelevant information injection, where it fabricates or\nintroduces new details to support a biased narrative. Building on these\ninsights, we introduce a lightweight prompt-based mitigation approach that\nqueries the model to review its own initial reasoning against these specific\nfailure patterns. Experiments on question answering (BBQ and StereoSet) and\nopen-ended (BOLD) benchmarks show that our approach effectively reduces bias\nwhile maintaining or improving accuracy."}
{"id": "2510.17088", "pdf": "https://arxiv.org/pdf/2510.17088", "abs": "https://arxiv.org/abs/2510.17088", "authors": ["Zan Li", "Rui Fan"], "title": "Explainable Heterogeneous Anomaly Detection in Financial Networks via Adaptive Expert Routing", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Financial anomalies exhibit heterogeneous mechanisms (price shocks, liquidity\nfreezes, contagion cascades, regime shifts), but existing detectors treat all\nanomalies uniformly, producing scalar scores without revealing which mechanism\nis failing, where risks concentrate, or how to intervene. This opacity prevents\ntargeted regulatory responses. Three unsolved challenges persist: (1) static\ngraph structures cannot adapt when market correlations shift during regime\nchanges; (2) uniform detection mechanisms miss type-specific signatures across\nmultiple temporal scales while failing to integrate individual behaviors with\nnetwork contagion; (3) black-box outputs provide no actionable guidance on\nanomaly mechanisms or their temporal evolution.\n  We address these via adaptive graph learning with specialized expert networks\nthat provide built-in interpretability. Our framework captures multi-scale\ntemporal dependencies through BiLSTM with self-attention, fuses temporal and\nspatial information via cross-modal attention, learns dynamic graphs through\nneural multi-source interpolation, adaptively balances learned dynamics with\nstructural priors via stress-modulated fusion, routes anomalies to four\nmechanism-specific experts, and produces dual-level interpretable attributions.\nCritically, interpretability is embedded architecturally rather than applied\npost-hoc.\n  On 100 US equities (2017-2024), we achieve 92.3% detection of 13 major events\nwith 3.8-day lead time, outperforming best baseline by 30.8pp. Silicon Valley\nBank case study demonstrates anomaly evolution tracking: Price-Shock expert\nweight rose to 0.39 (33% above baseline 0.29) during closure, peaking at 0.48\n(66% above baseline) one week later, revealing automatic temporal mechanism\nidentification without labeled supervision."}
{"id": "2510.17098", "pdf": "https://arxiv.org/pdf/2510.17098", "abs": "https://arxiv.org/abs/2510.17098", "authors": ["Elias Hossain", "Swayamjit Saha", "Somshubhra Roy", "Ravi Prasad"], "title": "Can Transformer Memory Be Corrupted? Investigating Cache-Side Vulnerabilities in Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Even when prompts and parameters are secured, transformer language models\nremain vulnerable because their key-value (KV) cache during inference\nconstitutes an overlooked attack surface. This paper introduces Malicious Token\nInjection (MTI), a modular framework that systematically perturbs cached key\nvectors at selected layers and timesteps through controlled magnitude and\nfrequency, using additive Gaussian noise, zeroing, and orthogonal rotations. A\ntheoretical analysis quantifies how these perturbations propagate through\nattention, linking logit deviations to the Frobenius norm of corruption and\nsoftmax Lipschitz dynamics. Empirical results show that MTI significantly\nalters next-token distributions and downstream task performance across GPT-2\nand LLaMA-2/7B, as well as destabilizes retrieval-augmented and agentic\nreasoning pipelines. These findings identify cache integrity as a critical yet\nunderexplored vulnerability in current LLM deployments, positioning cache\ncorruption as a reproducible and theoretically grounded threat model for future\nrobustness and security research."}
{"id": "2510.17109", "pdf": "https://arxiv.org/pdf/2510.17109", "abs": "https://arxiv.org/abs/2510.17109", "authors": ["Tianyang Xu", "Dan Zhang", "Kushan Mitra", "Estevam Hruschka"], "title": "Verification-Aware Planning for Multi-Agent Systems", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "comment": "Submission for ARR Oct", "summary": "Large language model (LLM) agents are increasingly deployed to tackle complex\ntasks, often necessitating collaboration among multiple specialized agents.\nHowever, multi-agent collaboration introduces new challenges in planning,\ncoordination, and verification. Execution failures frequently arise not from\nflawed reasoning alone, but from subtle misalignments in task interpretation,\noutput format, or inter-agent handoffs. To address these challenges, we present\nVeriMAP, a framework for multi-agent collaboration with verification-aware\nplanning. The VeriMAP planner decomposes tasks, models subtask dependencies,\nand encodes planner-defined passing criteria as subtask verification functions\n(VFs) in Python and natural language. We evaluate VeriMAP on diverse datasets,\ndemonstrating that it outperforms both single- and multi-agent baselines while\nenhancing system robustness and interpretability. Our analysis highlights how\nverification-aware planning enables reliable coordination and iterative\nrefinement in multi-agent systems, without relying on external labels or\nannotations."}
{"id": "2510.17111", "pdf": "https://arxiv.org/pdf/2510.17111", "abs": "https://arxiv.org/abs/2510.17111", "authors": ["Weifan Guan", "Qinghao Hu", "Aosheng Li", "Jian Cheng"], "title": "Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Vision-Language-Action (VLA) models extend vision-language models to embodied\ncontrol by mapping natural-language instructions and visual observations to\nrobot actions. Despite their capabilities, VLA systems face significant\nchallenges due to their massive computational and memory demands, which\nconflict with the constraints of edge platforms such as on-board mobile\nmanipulators that require real-time performance. Addressing this tension has\nbecome a central focus of recent research. In light of the growing efforts\ntoward more efficient and scalable VLA systems, this survey provides a\nsystematic review of approaches for improving VLA efficiency, with an emphasis\non reducing latency, memory footprint, and training and inference costs. We\ncategorize existing solutions into four dimensions: model architecture,\nperception feature, action generation, and training/inference strategies,\nsummarizing representative techniques within each category. Finally, we discuss\nfuture trends and open challenges, highlighting directions for advancing\nefficient embodied intelligence."}
{"id": "2510.17115", "pdf": "https://arxiv.org/pdf/2510.17115", "abs": "https://arxiv.org/abs/2510.17115", "authors": ["Wei Du", "Nuowei Liu", "Jie Wang", "Jiahao Kuang", "Tao Ji", "Xiaoling Wang", "Yuanbin Wu"], "title": "DVAGen: Dynamic Vocabulary Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Language models trained with a fixed vocabulary struggle to generalize to\nnovel or out-of-vocabulary words, limiting their flexibility in handling\ndiverse token combinations. Existing dynamic vocabulary approaches attempt to\naddress this limitation but face challenges such as fragmented codebases, lack\nof support for modern LLMs, and limited inference scalability. To overcome\nthese issues, we introduce DVAGen, a fully open-source, unified framework\ndesigned for training, evaluation, and visualization of dynamic\nvocabulary-augmented language models. Our framework modularizes the pipeline\nfor ease of customization, integrates seamlessly with open-source LLMs, and is\nthe first to provide both CLI and WebUI tools for real-time result inspection.\nWe validate the effectiveness of dynamic vocabulary methods on modern LLMs and\ndemonstrate support for batch inference, significantly improving inference\nthroughput."}
{"id": "2510.17131", "pdf": "https://arxiv.org/pdf/2510.17131", "abs": "https://arxiv.org/abs/2510.17131", "authors": ["Xin Gao", "Jiyao Liu", "Guanghao Li", "Yueming Lyu", "Jianxiong Gao", "Weichen Yu", "Ningsheng Xu", "Liang Wang", "Caifeng Shan", "Ziwei Liu", "Chenyang Si"], "title": "GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection", "categories": ["cs.CV", "cs.AI"], "comment": "28 pages, 16 figures, conference", "summary": "Recent advancements have explored text-to-image diffusion models for\nsynthesizing out-of-distribution (OOD) samples, substantially enhancing the\nperformance of OOD detection. However, existing approaches typically rely on\nperturbing text-conditioned embeddings, resulting in semantic instability and\ninsufficient shift diversity, which limit generalization to realistic OOD. To\naddress these challenges, we propose GOOD, a novel and flexible framework that\ndirectly guides diffusion sampling trajectories towards OOD regions using\noff-the-shelf in-distribution (ID) classifiers. GOOD incorporates dual-level\nguidance: (1) Image-level guidance based on the gradient of log partition to\nreduce input likelihood, drives samples toward low-density regions in pixel\nspace. (2) Feature-level guidance, derived from k-NN distance in the\nclassifier's latent space, promotes sampling in feature-sparse regions. Hence,\nthis dual-guidance design enables more controllable and diverse OOD sample\ngeneration. Additionally, we introduce a unified OOD score that adaptively\ncombines image and feature discrepancies, enhancing detection robustness. We\nperform thorough quantitative and qualitative analyses to evaluate the\neffectiveness of GOOD, demonstrating that training with samples generated by\nGOOD can notably enhance OOD detection performance."}
{"id": "2510.17132", "pdf": "https://arxiv.org/pdf/2510.17132", "abs": "https://arxiv.org/abs/2510.17132", "authors": ["Ioannis Tsaknakis", "Bingqing Song", "Shuyu Gan", "Dongyeop Kang", "Alfredo Garcia", "Gaowen Liu", "Charles Fleming", "Mingyi Hong"], "title": "Do LLMs Recognize Your Latent Preferences? A Benchmark for Latent Information Discovery in Personalized Interaction", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) excel at producing broadly relevant text, but\nthis generality becomes a limitation when user-specific preferences are\nrequired, such as recommending restaurants or planning travel. In these\nscenarios, users rarely articulate every preference explicitly; instead, much\nof what they care about remains latent, waiting to be inferred. This raises a\nfundamental question: Can LLMs uncover and reason about such latent information\nthrough conversation?\n  We address this problem by introducing a unified benchmark for evaluating\nlatent information discovery - the ability of LLMs to reveal and utilize hidden\nuser attributes through multi-turn interaction. The benchmark spans three\nprogressively realistic settings: the classic 20 Questions game, Personalized\nQuestion Answering, and Personalized Text Summarization. All tasks share a\ntri-agent framework (User, Assistant, Judge) enabling turn-level evaluation of\nelicitation and adaptation. Our results reveal that while LLMs can indeed\nsurface latent information through dialogue, their success varies dramatically\nwith context: from 32% to 98%, depending on task complexity, topic, and number\nof hidden attributes. This benchmark provides the first systematic framework\nfor studying latent information discovery in personalized interaction,\nhighlighting that effective preference inference remains an open frontier for\nbuilding truly adaptive AI systems."}
{"id": "2510.17157", "pdf": "https://arxiv.org/pdf/2510.17157", "abs": "https://arxiv.org/abs/2510.17157", "authors": ["Yinghui Wang", "Xinyu Zhang", "Peng Du"], "title": "GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Generating editable, parametric CAD models from a single image holds great\npotential to lower the barriers of industrial concept design. However, current\nmulti-modal large language models (MLLMs) still struggle with accurately\ninferring 3D geometry from 2D images due to limited spatial reasoning\ncapabilities. We address this limitation by introducing GACO-CAD, a novel\ntwo-stage post-training framework. It is designed to achieve a joint objective:\nsimultaneously improving the geometric accuracy of the generated CAD models and\nencouraging the use of more concise modeling procedures. First, during\nsupervised fine-tuning, we leverage depth and surface normal maps as dense\ngeometric priors, combining them with the RGB image to form a multi-channel\ninput. In the context of single-view reconstruction, these priors provide\ncomplementary spatial cues that help the MLLM more reliably recover 3D geometry\nfrom 2D observations. Second, during reinforcement learning, we introduce a\ngroup length reward that, while preserving high geometric fidelity, promotes\nthe generation of more compact and less redundant parametric modeling\nsequences. A simple dynamic weighting strategy is adopted to stabilize\ntraining. Experiments on the DeepCAD and Fusion360 datasets show that GACO-CAD\nachieves state-of-the-art performance under the same MLLM backbone,\nconsistently outperforming existing methods in terms of code validity,\ngeometric accuracy, and modeling conciseness."}
{"id": "2510.17163", "pdf": "https://arxiv.org/pdf/2510.17163", "abs": "https://arxiv.org/abs/2510.17163", "authors": ["Shuzheng Gao", "Eric John Li", "Man Ho Lam", "Jingyu Xiao", "Yuxuan Wan", "Chaozheng Wang", "Ng Man Tik", "Michael R. Lyu"], "title": "TREAT: A Code LLMs Trustworthiness / Reliability Evaluation and Testing Framework", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large foundation models are fundamentally transforming the software\nengineering landscape, demonstrating exceptional capabilities across diverse\ntasks such as code generation, debugging, and testing. Despite this rapid\nprogress, a significant gap remains in how to comprehensively evaluate these\nmodels' trustworthiness in real-world software engineering scenarios. Existing\nbenchmarks suffer from limited task scope and fail to incorporate critical\nevaluation aspects such as the robustness and reliability of models. To bridge\nthis gap, we present an evaluation framework called TREAT (Code LLMs\nTrustworthiness / Reliability Evaluation And Testing) that provides a holistic\nassessment of model performance in code intelligence tasks. Our evaluation\nframework addresses key limitations in existing approaches with four main\nimprovements: (1) Multi-Task Holistic Evaluation that spans diverse software\nengineering activities rather than limited coding tasks; (2) Multi-Language and\nMulti-Modality Assessment that extends beyond traditional single-language,\ntext-only benchmarks to include multi-modality coding tasks; (3) Robustness\nAssessment that evaluates model reliability under semantically-preserving code\ntransformations; and (4) Rigorous Evaluation Methodology that enhances the\ntrustworthiness of evaluation results through diverse evaluation prompts and\nadaptive solution extraction. Based on this evaluation framework, we assess 26\nstate-of-the-art models and uncover both their strengths and limitations,\nyielding several key insights:(1) Current models show substantial performance\nvariation across programming tasks; (2) Multi-modal language models demonstrate\nspecific performance limitations in UI code generation and edit;"}
{"id": "2510.17179", "pdf": "https://arxiv.org/pdf/2510.17179", "abs": "https://arxiv.org/abs/2510.17179", "authors": ["Yingzi Han", "Jiakai He", "Chuanlong Xie", "Jianping Li"], "title": "Benchmarking Out-of-Distribution Detection for Plankton Recognition: A Systematic Evaluation of Advanced Methods in Marine Ecological Monitoring", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Automated plankton recognition models face significant challenges during\nreal-world deployment due to distribution shifts (Out-of-Distribution, OoD)\nbetween training and test data. This stems from plankton's complex\nmorphologies, vast species diversity, and the continuous discovery of novel\nspecies, which leads to unpredictable errors during inference. Despite rapid\nadvancements in OoD detection methods in recent years, the field of plankton\nrecognition still lacks a systematic integration of the latest computer vision\ndevelopments and a unified benchmark for large-scale evaluation. To address\nthis, this paper meticulously designed a series of OoD benchmarks simulating\nvarious distribution shift scenarios based on the DYB-PlanktonNet dataset\n\\cite{875n-f104-21}, and systematically evaluated twenty-two OoD detection\nmethods. Extensive experimental results demonstrate that the ViM\n\\cite{wang2022vim} method significantly outperforms other approaches in our\nconstructed benchmarks, particularly excelling in Far-OoD scenarios with\nsubstantial improvements in key metrics. This comprehensive evaluation not only\nprovides a reliable reference for algorithm selection in automated plankton\nrecognition but also lays a solid foundation for future research in plankton\nOoD detection. To our knowledge, this study marks the first large-scale,\nsystematic evaluation and analysis of Out-of-Distribution data detection\nmethods in plankton recognition. Code is available at\nhttps://github.com/BlackJack0083/PlanktonOoD."}
{"id": "2510.17191", "pdf": "https://arxiv.org/pdf/2510.17191", "abs": "https://arxiv.org/abs/2510.17191", "authors": ["Peiru Zheng", "Yun Zhao", "Zhan Gong", "Hong Zhu", "Shaohua Wu"], "title": "SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": "6 pages, 2 figures, 2 tables", "summary": "End-to-end autonomous driving has emerged as a promising paradigm for\nachieving robust and intelligent driving policies. However, existing end-to-end\nmethods still face significant challenges, such as suboptimal decision-making\nin complex scenarios. In this paper,we propose SimpleVSF (Simple VLM-Scoring\nFusion), a novel framework that enhances end-to-end planning by leveraging the\ncognitive capabilities of Vision-Language Models (VLMs) and advanced trajectory\nfusion techniques. We utilize the conventional scorers and the novel\nVLM-enhanced scorers. And we leverage a robust weight fusioner for quantitative\naggregation and a powerful VLM-based fusioner for qualitative, context-aware\ndecision-making. As the leading approach in the ICCV 2025 NAVSIM v2 End-to-End\nDriving Challenge, our SimpleVSF framework demonstrates state-of-the-art\nperformance, achieving a superior balance between safety, comfort, and\nefficiency."}
{"id": "2510.17196", "pdf": "https://arxiv.org/pdf/2510.17196", "abs": "https://arxiv.org/abs/2510.17196", "authors": ["Jiaqi Leng", "Xiang Hu", "Junxiong Wang", "Jianguo Li", "Wei Wu", "Yucheng Lu"], "title": "Understanding and Improving Length Generalization in Hierarchical Sparse Attention Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Preprint. Work in progress", "summary": "Effectively processing long contexts is a critical challenge for language\nmodels. While standard Transformers are limited by quadratic complexity and\npoor length extrapolation, alternative architectures like sliding window\nattention and state space models sacrifice the ability to effectively utilize\nthe full context due to their fixed-size memory. Chunk-based sparse attention\nhas emerged as a promising paradigm for extreme length generalization, yet the\nkey architectural principles underpinning its success are not yet fully\nunderstood. In this work, we present a systematic dissection of these models to\nidentify the core components driving their performance. Through a unified\nframework and comprehensive ablation studies, we demonstrate that a combination\nof three design principles is critical: (1) an expressive, non-linear Chunk\nEncoder with a dedicated CLS token to produce representations for retrieval;\n(2) a Bypassing Residual Path to stably integrate retrieved global information\nwithout it being overridden by the local residual stream; and (3) enforced\nselection sparsity during pre-training to bridge the train-test distribution\ngap. We provide a theoretical motivation for intra-chunk information processing\nand landmark generation. By combining these principles, we establish a new\nstate-of-the-art for training-free length extrapolation, successfully\ngeneralizing models trained on a 4K context to 32 million tokens on RULER and\nBABILong. Our findings provide a clear and empirically-grounded set of design\nprinciples for developing future, highly-capable long-context language models."}
{"id": "2510.17197", "pdf": "https://arxiv.org/pdf/2510.17197", "abs": "https://arxiv.org/abs/2510.17197", "authors": ["Pu Zhang", "Yuwei Li", "Xingyuan Xian", "Guoming Tang"], "title": "ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "As the capabilities of Vision-Language Models (VLMs) advance, they can\nprocess increasingly large inputs, which, unlike in LLMs, generates significant\nvisual token redundancy and leads to prohibitive inference costs. While many\nmethods aim to reduce these costs by pruning visual tokens, existing\napproaches, whether based on attention or diversity, typically neglect the\nguidance of the text prompt and thus fail to prioritize task relevance. In this\nwork, we propose a novel, zero-shot method that reframes the problem by\nintroducing a prompt-aware perspective, explicitly modeling visual token\npruning as a balance between task relevance and information diversity. Our\nhierarchical approach first selects a core set of task-relevant visual tokens\nand then supplements them with diversity tokens to preserve broader context.\nExperiments across multiple models and benchmarks show that our method achieves\nperformance that matches or surpasses the state-of-the-art with only minimal\naccuracy loss, even when pruning up to 90\\% of the tokens. Furthermore, these\ngains are accompanied by significant reductions in GPU memory footprint and\ninference latency."}
{"id": "2510.17198", "pdf": "https://arxiv.org/pdf/2510.17198", "abs": "https://arxiv.org/abs/2510.17198", "authors": ["M Saifuzzaman Rafat", "Mohd Ruhul Ameen", "Akif Islam", "Abu Saleh Musa Miah", "Jungpil Shin"], "title": "From Pixels to People: Satellite-Based Mapping and Quantification of Riverbank Erosion and Lost Villages in Bangladesh", "categories": ["cs.CV", "cs.AI"], "comment": "Submitted to the International Conference on Data and Applied\n  Analytics (IDAA 2025). 15 pages, 5 figures, 4 tables", "summary": "The great rivers of Bangladesh, arteries of commerce and sustenance, are also\nagents of relentless destruction. Each year, they swallow whole villages and\nvast tracts of farmland, erasing communities from the map and displacing\nthousands of families. To track this slow-motion catastrophe has, until now,\nbeen a Herculean task for human analysts. Here we show how a powerful\ngeneral-purpose vision model, the Segment Anything Model (SAM), can be adapted\nto this task with remarkable precision. To do this, we assembled a new dataset\n- a digital chronicle of loss compiled from historical Google Earth imagery of\nBangladesh's most vulnerable regions, including Mokterer Char Union, Kedarpur\nUnion, Balchipara village, and Chowhali Upazila, from 2003 to 2025. Crucially,\nthis dataset is the first to include manually annotated data on the settlements\nthat have vanished beneath the water. Our method first uses a simple\ncolor-channel analysis to provide a rough segmentation of land and water, and\nthen fine-tunes SAM's mask decoder to recognize the subtle signatures of\nriverbank erosion. The resulting model demonstrates a keen eye for this\ndestructive process, achieving a mean Intersection over Union of 86.30% and a\nDice score of 92.60% - a performance that significantly surpasses traditional\nmethods and off-the-shelf deep learning models. This work delivers three key\ncontributions: the first annotated dataset of disappeared settlements in\nBangladesh due to river erosion; a specialized AI model fine-tuned for this\ncritical task; and a method for quantifying land loss with compelling visual\nevidence. Together, these tools provide a powerful new lens through which\npolicymakers and disaster management agencies can monitor erosion, anticipate\nits trajectory, and ultimately protect the vulnerable communities in its path."}
{"id": "2510.17199", "pdf": "https://arxiv.org/pdf/2510.17199", "abs": "https://arxiv.org/abs/2510.17199", "authors": ["Nirai Hayakawa", "Kazumasa Shimari", "Kazuma Yamasaki", "Hirotatsu Hoshikawa", "Rikuto Tsuchida", "Kenichi Matsumoto"], "title": "Round Outcome Prediction in VALORANT Using Tactical Features from Video Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to IEEE 2025 Conference on Games", "summary": "Recently, research on predicting match outcomes in esports has been actively\nconducted, but much of it is based on match log data and statistical\ninformation. This research targets the FPS game VALORANT, which requires\ncomplex strategies, and aims to build a round outcome prediction model by\nanalyzing minimap information in match footage. Specifically, based on the\nvideo recognition model TimeSformer, we attempt to improve prediction accuracy\nby incorporating detailed tactical features extracted from minimap information,\nsuch as character position information and other in-game events. This paper\nreports preliminary results showing that a model trained on a dataset augmented\nwith such tactical event labels achieved approximately 81% prediction accuracy,\nespecially from the middle phases of a round onward, significantly\noutperforming a model trained on a dataset with the minimap information itself.\nThis suggests that leveraging tactical features from match footage is highly\neffective for predicting round outcomes in VALORANT."}
{"id": "2510.17206", "pdf": "https://arxiv.org/pdf/2510.17206", "abs": "https://arxiv.org/abs/2510.17206", "authors": ["Michael Hersche", "Samuel Moor-Smith", "Thomas Hofmann", "Abbas Rahimi"], "title": "Soft-Masked Diffusion Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Diffusion models have demonstrated strong potential in language modeling,\noffering various advantages over traditional autoregressive approaches. Their\nability to generate and revise entire responses in parallel enables faster\ngeneration and built-in self-correction mechanisms. Most modern diffusion-based\nlanguage models employ masked diffusion, where decoding involves iteratively\nprocessing masked tokens based on a binary decision: either retaining the mask\nor replacing it with the predicted token. However, this binary choice discards\nvaluable predictive information when the mask is retained. To address this\nlimitation, we introduce soft-masking (SM), a novel method that dynamically\nblends the embedding of the mask token with the embeddings of the top-$k$\npredicted tokens from the previous decoding step, for each retained mask. This\nprovides the model with a more informative prior, preserving context from\nearlier computations and allowing partial information about masked tokens to\npropagate beyond a single step. We propose a training methodology that adapts a\npretrained masked diffusion language model to incorporate SM. We demonstrate\nthat continuing pretraining a 169M parameter model with SM leads to improved\nperplexity and MAUVE scores. Furthermore, we finetune two state-of-the-art\ndiffusion models, Dream-7B and Dream-Coder-7B, with SM. SM consistently\nimproves performance across multiple coding benchmarks, particularly in\nhigh-throughput settings."}
{"id": "2510.17212", "pdf": "https://arxiv.org/pdf/2510.17212", "abs": "https://arxiv.org/abs/2510.17212", "authors": ["Jundong Zhang", "Yuhui Situ", "Fanji Zhang", "Rongji Deng", "Tianqi Wei"], "title": "D2C-HRHR: Discrete Actions with Double Distributional Critics for High-Risk-High-Return Tasks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Tasks involving high-risk-high-return (HRHR) actions, such as obstacle\ncrossing, often exhibit multimodal action distributions and stochastic returns.\nMost reinforcement learning (RL) methods assume unimodal Gaussian policies and\nrely on scalar-valued critics, which limits their effectiveness in HRHR\nsettings. We formally define HRHR tasks and theoretically show that Gaussian\npolicies cannot guarantee convergence to the optimal solution. To address this,\nwe propose a reinforcement learning framework that (i) discretizes continuous\naction spaces to approximate multimodal distributions, (ii) employs\nentropy-regularized exploration to improve coverage of risky but rewarding\nactions, and (iii) introduces a dual-critic architecture for more accurate\ndiscrete value distribution estimation. The framework scales to\nhigh-dimensional action spaces, supporting complex control domains. Experiments\non locomotion and manipulation benchmarks with high risks of failure\ndemonstrate that our method outperforms baselines, underscoring the importance\nof explicitly modeling multimodality and risk in RL."}
{"id": "2510.17214", "pdf": "https://arxiv.org/pdf/2510.17214", "abs": "https://arxiv.org/abs/2510.17214", "authors": ["Chenyan Fei", "Dalin Zhang", "Chen Melinda Dang"], "title": "Diagnosis of Fuel Cell Health Status with Deep Sparse Auto-Encoder Neural Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Effective and accurate diagnosis of fuel cell health status is crucial for\nensuring the stable operation of fuel cell stacks. Among various parameters,\nhigh-frequency impedance serves as a critical indicator for assessing fuel cell\nstate and health conditions. However, its online testing is prohibitively\ncomplex and costly. This paper employs a deep sparse auto-encoding network for\nthe prediction and classification of high-frequency impedance in fuel cells,\nachieving metric of accuracy rate above 92\\%. The network is further deployed\non an FPGA, attaining a hardware-based recognition rate almost 90\\%."}
{"id": "2510.17218", "pdf": "https://arxiv.org/pdf/2510.17218", "abs": "https://arxiv.org/abs/2510.17218", "authors": ["Zhuo Cao", "Heming Du", "Bingqing Zhang", "Xin Yu", "Xue Li", "Sen Wang"], "title": "When One Moment Isn't Enough: Multi-Moment Retrieval with Cross-Moment Interactions", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to NeurIPS 2025", "summary": "Existing Moment retrieval (MR) methods focus on Single-Moment Retrieval\n(SMR). However, one query can correspond to multiple relevant moments in\nreal-world applications. This makes the existing datasets and methods\ninsufficient for video temporal grounding. By revisiting the gap between\ncurrent MR tasks and real-world applications, we introduce a high-quality\ndatasets called QVHighlights Multi-Moment Dataset (QV-M$^2$), along with new\nevaluation metrics tailored for multi-moment retrieval (MMR). QV-M$^2$ consists\nof 2,212 annotations covering 6,384 video segments. Building on existing\nefforts in MMR, we propose a framework called FlashMMR. Specifically, we\npropose a Multi-moment Post-verification module to refine the moment\nboundaries. We introduce constrained temporal adjustment and subsequently\nleverage a verification module to re-evaluate the candidate segments. Through\nthis sophisticated filtering pipeline, low-confidence proposals are pruned, and\nrobust multi-moment alignment is achieved. We retrain and evaluate 6 existing\nMR methods on QV-M$^2$ and QVHighlights under both SMR and MMR settings.\nResults show that QV-M$^2$ serves as an effective benchmark for training and\nevaluating MMR models, while FlashMMR provides a strong baseline. Specifically,\non QV-M$^2$, it achieves improvements over prior SOTA method by 3.00% on G-mAP,\n2.70% on mAP@3+tgt, and 2.56% on mR@3. The proposed benchmark and method\nestablish a foundation for advancing research in more realistic and challenging\nvideo temporal grounding scenarios. Code is released at\nhttps://github.com/Zhuo-Cao/QV-M2."}
{"id": "2510.17234", "pdf": "https://arxiv.org/pdf/2510.17234", "abs": "https://arxiv.org/abs/2510.17234", "authors": ["Yuyang Hong", "Qi Yang", "Tao Zhang", "Zili Wang", "Zhaojin Fu", "Kun Ding", "Bin Fan", "Shiming Xiang"], "title": "Taming Modality Entanglement in Continual Audio-Visual Segmentation", "categories": ["cs.MM", "cs.AI", "cs.CV"], "comment": null, "summary": "Recently, significant progress has been made in multi-modal continual\nlearning, aiming to learn new tasks sequentially in multi-modal settings while\npreserving performance on previously learned ones. However, existing methods\nmainly focus on coarse-grained tasks, with limitations in addressing modality\nentanglement in fine-grained continual learning settings. To bridge this gap,\nwe introduce a novel Continual Audio-Visual Segmentation (CAVS) task, aiming to\ncontinuously segment new classes guided by audio. Through comprehensive\nanalysis, two critical challenges are identified: 1) multi-modal semantic\ndrift, where a sounding objects is labeled as background in sequential tasks;\n2) co-occurrence confusion, where frequent co-occurring classes tend to be\nconfused. In this work, a Collision-based Multi-modal Rehearsal (CMR) framework\nis designed to address these challenges. Specifically, for multi-modal semantic\ndrift, a Multi-modal Sample Selection (MSS) strategy is proposed to select\nsamples with high modal consistency for rehearsal. Meanwhile, for co-occurence\nconfusion, a Collision-based Sample Rehearsal (CSR) mechanism is designed,\nallowing for the increase of rehearsal sample frequency of those confusable\nclasses during training process. Moreover, we construct three audio-visual\nincremental scenarios to verify effectiveness of our method. Comprehensive\nexperiments demonstrate that our method significantly outperforms single-modal\ncontinual learning methods."}
{"id": "2510.17241", "pdf": "https://arxiv.org/pdf/2510.17241", "abs": "https://arxiv.org/abs/2510.17241", "authors": ["Stefania Ionescu", "Robin Forsberg", "Elsa Lichtenegger", "Salima Jaoua", "Kshitijaa Jaglan", "Florian Dorfler", "Aniko Hannak"], "title": "Visibility Allocation Systems: How Algorithmic Design Shapes Online Visibility and Societal Outcomes", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Throughout application domains, we now rely extensively on algorithmic\nsystems to engage with ever-expanding datasets of information. Despite their\nbenefits, these systems are often complex (comprising of many intricate tools,\ne.g., moderation, recommender systems, prediction models), of unknown structure\n(due to the lack of accompanying documentation), and having hard-to-predict yet\npotentially severe downstream consequences (due to the extensive use,\nsystematic enactment of existing errors, and many comprising feedback loops).\nAs such, understanding and evaluating these systems as a whole remains a\nchallenge for both researchers and legislators. To aid ongoing efforts, we\nintroduce a formal framework for such visibility allocation systems (VASs)\nwhich we define as (semi-)automated systems deciding which (processed) data to\npresent a human user with. We review typical tools comprising VASs and define\nthe associated computational problems they solve. By doing so, VASs can be\ndecomposed into sub-processes and illustrated via data flow diagrams. Moreover,\nwe survey metrics for evaluating VASs throughout the pipeline, thus aiding\nsystem diagnostics. Using forecasting-based recommendations in school choice as\na case study, we demonstrate how our framework can support VAS evaluation. We\nalso discuss how our framework can support ongoing AI-legislative efforts to\nlocate obligations, quantify systemic risks, and enable adaptive compliance."}
{"id": "2510.17252", "pdf": "https://arxiv.org/pdf/2510.17252", "abs": "https://arxiv.org/abs/2510.17252", "authors": ["Mohd Ruhul Ameen", "Akif Islam", "Abu Saleh Musa Miah", "Ayesha Siddiqua", "Jungpil Shin"], "title": "How News Feels: Understanding Affective Bias in Multilingual Headlines for Human-Centered Media Design", "categories": ["cs.CL", "cs.AI"], "comment": "15 pages, 7 figures, 4 tables. Submitted to the International\n  Conference on Data and Applied Analytics (IDAA 2025)", "summary": "News media often shape the public mood not only by what they report but by\nhow they frame it. The same event can appear calm in one outlet and alarming in\nanother, reflecting subtle emotional bias in reporting. Negative or emotionally\ncharged headlines tend to attract more attention and spread faster, which in\nturn encourages outlets to frame stories in ways that provoke stronger\nreactions. This research explores that tendency through large-scale emotion\nanalysis of Bengali news. Using zero-shot inference with Gemma-3 4B, we\nanalyzed 300000 Bengali news headlines and their content to identify the\ndominant emotion and overall tone of each. The findings reveal a clear\ndominance of negative emotions, particularly anger, fear, and disappointment,\nand significant variation in how similar stories are emotionally portrayed\nacross outlets. Based on these insights, we propose design ideas for a\nhuman-centered news aggregator that visualizes emotional cues and helps readers\nrecognize hidden affective framing in daily news."}
{"id": "2510.17253", "pdf": "https://arxiv.org/pdf/2510.17253", "abs": "https://arxiv.org/abs/2510.17253", "authors": ["Ãzkan Canay", "{Ã}mit KocabÄ±cak"], "title": "Augmented Web Usage Mining and User Experience Optimization with CAWAL's Enriched Analytics Data", "categories": ["cs.HC", "cs.AI", "68T09, 68U35", "H.5.2; H.3.3; I.2.6"], "comment": "19 pages, 5 figures. Published in International Journal of\n  Human-Computer Interaction (Taylor & Francis, 2025)", "summary": "Understanding user behavior on the web is increasingly critical for\noptimizing user experience (UX). This study introduces Augmented Web Usage\nMining (AWUM), a methodology designed to enhance web usage mining and improve\nUX by enriching the interaction data provided by CAWAL (Combined Application\nLog and Web Analytics), a framework for advanced web analytics. Over 1.2\nmillion session records collected in one month (~8.5GB of data) were processed\nand transformed into enriched datasets. AWUM analyzes session structures, page\nrequests, service interactions, and exit methods. Results show that 87.16% of\nsessions involved multiple pages, contributing 98.05% of total pageviews; 40%\nof users accessed various services and 50% opted for secure exits. Association\nrule mining revealed patterns of frequently accessed services, highlighting\nCAWAL's precision and efficiency over conventional methods. AWUM offers a\ncomprehensive understanding of user behavior and strong potential for\nlarge-scale UX optimization."}
{"id": "2510.17269", "pdf": "https://arxiv.org/pdf/2510.17269", "abs": "https://arxiv.org/abs/2510.17269", "authors": ["Luis Wiedmann", "Orr Zohar", "Amir Mahla", "Xiaohan Wang", "Rui Li", "Thibaud Frere", "Leandro von Werra", "Aritra Roy Gosthipaty", "AndrÃ©s Marafioti"], "title": "FineVision: Open Data Is All You Need", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The advancement of vision-language models (VLMs) is hampered by a fragmented\nlandscape of inconsistent and contaminated public datasets. We introduce\nFineVision, a meticulously collected, curated, and unified corpus of 24 million\nsamples - the largest open resource of its kind. We unify more than 200 sources\ninto 185 subsets via a semi-automated, human-in-the-loop pipeline: automation\nperforms bulk ingestion and schema mapping, while reviewers audit mappings and\nspot-check outputs to verify faithful consumption of annotations, appropriate\nformatting and diversity, and safety; issues trigger targeted fixes and\nre-runs. The workflow further applies rigorous de-duplication within and across\nsources and decontamination against 66 public benchmarks. FineVision also\nencompasses agentic/GUI tasks with a unified action space; reviewers validate\nschemas and inspect a sample of trajectories to confirm executable fidelity.\nModels trained on FineVision consistently outperform those trained on existing\nopen mixtures across a broad evaluation suite, underscoring the benefits of\nscale, data hygiene, and balanced automation with human oversight. We release\nthe corpus and curation tools to accelerate data-centric VLM research."}
{"id": "2510.17281", "pdf": "https://arxiv.org/pdf/2510.17281", "abs": "https://arxiv.org/abs/2510.17281", "authors": ["Qingyao Ai", "Yichen Tang", "Changyue Wang", "Jianming Long", "Weihang Su", "Yiqun Liu"], "title": "MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Scaling up data, parameters, and test-time computation has been the\nmainstream methods to improve LLM systems (LLMsys), but their upper bounds are\nalmost reached due to the gradual depletion of high-quality data and marginal\ngains obtained from larger computational resource consumption. Inspired by the\nabilities of human and traditional AI systems in learning from practice,\nconstructing memory and continual learning frameworks for LLMsys has become an\nimportant and popular research direction in recent literature. Yet, existing\nbenchmarks for LLM memory often focus on evaluating the system on homogeneous\nreading comprehension tasks with long-form inputs rather than testing their\nabilities to learn from accumulated user feedback in service time. Therefore,\nwe propose a user feedback simulation framework and a comprehensive benchmark\ncovering multiple domains, languages, and types of tasks to evaluate the\ncontinual learning abilities of LLMsys. Experiments show that the effectiveness\nand efficiency of state-of-the-art baselines are far from satisfying, and we\nhope this benchmark could pave the way for future studies on LLM memory and\noptimization algorithms."}
{"id": "2510.17301", "pdf": "https://arxiv.org/pdf/2510.17301", "abs": "https://arxiv.org/abs/2510.17301", "authors": ["Panos Kalnis. Shuo Shang", "Christian S. Jensen"], "title": "Comprehending Spatio-temporal Data via Cinematic Storytelling using Large Language Models", "categories": ["cs.DB", "cs.AI"], "comment": "5 pages", "summary": "Spatio-temporal data captures complex dynamics across both space and time,\nyet traditional visualizations are complex, require domain expertise and often\nfail to resonate with broader audiences. Here, we propose MapMuse, a\nstorytelling-based framework for interpreting spatio-temporal datasets,\ntransforming them into compelling, narrative-driven experiences. We utilize\nlarge language models and employ retrieval augmented generation (RAG) and\nagent-based techniques to generate comprehensive stories. Drawing on principles\ncommon in cinematic storytelling, we emphasize clarity, emotional connection,\nand audience-centric design. As a case study, we analyze a dataset of taxi\ntrajectories. Two perspectives are presented: a captivating story based on a\nheat map that visualizes millions of taxi trip endpoints to uncover urban\nmobility patterns; and a detailed narrative following a single long taxi\njourney, enriched with city landmarks and temporal shifts. By portraying\nlocations as characters and movement as plot, we argue that data storytelling\ndrives insight, engagement, and action from spatio-temporal information. The\ncase study illustrates how MapMuse can bridge the gap between data complexity\nand human understanding. The aim of this short paper is to provide a glimpse to\nthe potential of the cinematic storytelling technique as an effective\ncommunication tool for spatio-temporal data, as well as to describe open\nproblems and opportunities for future research."}
{"id": "2510.17314", "pdf": "https://arxiv.org/pdf/2510.17314", "abs": "https://arxiv.org/abs/2510.17314", "authors": ["Lipeng Xie", "Sen Huang", "Zhuo Zhang", "Anni Zou", "Yunpeng Zhai", "Dingchao Ren", "Kezun Zhang", "Haoyuan Hu", "Boyin Liu", "Haoran Chen", "Zhaoyang Liu", "Bolin Ding"], "title": "Auto-Rubric: Learning to Extract Generalizable Criteria for Reward Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reward models are essential for aligning Large Language Models (LLMs) with\nhuman values, yet their development is hampered by costly preference datasets\nand poor interpretability. While recent rubric-based approaches offer\ntransparency, they often lack systematic quality control and optimization,\ncreating a trade-off between scalability and reliability. We address these\nlimitations with a novel, training-free framework built on a key assumption:\n\\textit{evaluation rubrics underlying human preferences exhibit significant\ngeneralization ability across diverse queries}, a property that enables\nremarkable data efficiency. Our two-stage approach first infers high-quality,\nquery-specific rubrics using a validation-guided\n\\textbf{Propose-Evaluate-Revise} pipeline. Second, it generalizes these\ngranular rubrics into a compact, non-redundant core set by maximizing an\n\\textbf{information-theoretic coding rate}. The final output is an\ninterpretable, hierarchical \"Theme-Tips\" rubric set. Extensive experiments\ndemonstrate the framework's exceptional data efficiency and performance.\nCritically, using just 70 preference pairs (1.5\\% of the source data), our\nmethod also empowers smaller models like Qwen3-8B to outperform specialized,\nfully-trained counterparts. This work pioneers a scalable, interpretable, and\ndata-efficient path for reward modeling."}
{"id": "2510.17330", "pdf": "https://arxiv.org/pdf/2510.17330", "abs": "https://arxiv.org/abs/2510.17330", "authors": ["Gyuhwan Park", "Kihyun Na", "Injung Kim"], "title": "CharDiff: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 6 figures", "summary": "The significance of license plate image restoration goes beyond the\npreprocessing stage of License Plate Recognition (LPR) systems, as it also\nserves various purposes, including increasing evidential value, enhancing the\nclarity of visual interface, and facilitating further utilization of license\nplate images. We propose a novel diffusion-based framework with character-level\nguidance, CharDiff, which effectively restores and recognizes severely degraded\nlicense plate images captured under realistic conditions. CharDiff leverages\nfine-grained character-level priors extracted through external segmentation and\nOptical Character Recognition (OCR) modules tailored for low-quality license\nplate images. For precise and focused guidance, CharDiff incorporates a novel\nCharacter-guided Attention through Region-wise Masking (CHARM) module, which\nensures that each character's guidance is restricted to its own region, thereby\navoiding interference with other regions. In experiments, CharDiff\nsignificantly outperformed the baseline restoration models in both restoration\nquality and recognition accuracy, achieving a 28% relative reduction in CER on\nthe Roboflow-LP dataset, compared to the best-performing baseline model. These\nresults indicate that the structured character-guided conditioning effectively\nenhances the robustness of diffusion-based license plate restoration and\nrecognition in practical deployment scenarios."}
{"id": "2510.17345", "pdf": "https://arxiv.org/pdf/2510.17345", "abs": "https://arxiv.org/abs/2510.17345", "authors": ["Peihong Zhang", "Yuxuan Liu", "Rui Sang", "Zhixin Li", "Yiqiang Cai", "Yizhou Tan", "Shengchen Li"], "title": "DDSC: Dynamic Dual-Signal Curriculum for Data-Efficient Acoustic Scene Classification under Domain Shift", "categories": ["cs.SD", "cs.AI"], "comment": "Paper has submitted to ICASSP2026", "summary": "Acoustic scene classification (ASC) suffers from device-induced domain shift,\nespecially when labels are limited. Prior work focuses on curriculum-based\ntraining schedules that structure data presentation by ordering or reweighting\ntraining examples from easy-to-hard to facilitate learning; however, existing\ncurricula are static, fixing the ordering or the weights before training and\nignoring that example difficulty and marginal utility evolve with the learned\nrepresentation. To overcome this limitation, we propose the Dynamic Dual-Signal\nCurriculum (DDSC), a training schedule that adapts the curriculum online by\ncombining two signals computed each epoch: a domain-invariance signal and a\nlearning-progress signal. A time-varying scheduler fuses these signals into\nper-example weights that prioritize domain-invariant examples in early epochs\nand progressively emphasize device-specific cases. DDSC is lightweight,\narchitecture-agnostic, and introduces no additional inference overhead. Under\nthe official DCASE 2024 Task~1 protocol, DDSC consistently improves\ncross-device performance across diverse ASC baselines and label budgets, with\nthe largest gains on unseen-device splits."}
{"id": "2510.17346", "pdf": "https://arxiv.org/pdf/2510.17346", "abs": "https://arxiv.org/abs/2510.17346", "authors": ["Peihong Zhang", "Zhixin Li", "Yuxuan Liu", "Rui Sang", "Yiqiang Cai", "Yizhou Tan", "Shengchen Li"], "title": "TopSeg: A Multi-Scale Topological Framework for Data-Efficient Heart Sound Segmentation", "categories": ["cs.SD", "cs.AI"], "comment": "Paper has submitted to ICASSP2026", "summary": "Deep learning approaches for heart-sound (PCG) segmentation built on\ntime--frequency features can be accurate but often rely on large expert-labeled\ndatasets, limiting robustness and deployment. We present TopSeg, a topological\nrepresentation-centric framework that encodes PCG dynamics with multi-scale\ntopological features and decodes them using a lightweight temporal\nconvolutional network (TCN) with an order- and duration-constrained inference\nstep. To evaluate data efficiency and generalization, we train exclusively on\nPhysioNet 2016 dataset with subject-level subsampling and perform external\nvalidation on CirCor dataset. Under matched-capacity decoders, the topological\nfeatures consistently outperform spectrogram and envelope inputs, with the\nlargest margins at low data budgets; as a full system, TopSeg surpasses\nrepresentative end-to-end baselines trained on their native inputs under the\nsame budgets while remaining competitive at full data. Ablations at 10%\ntraining confirm that all scales contribute and that combining H_0 and H_1\nyields more reliable S1/S2 localization and boundary stability. These results\nindicate that topology-aware representations provide a strong inductive bias\nfor data-efficient, cross-dataset PCG segmentation, supporting practical use\nwhen labeled data are limited."}
{"id": "2510.17354", "pdf": "https://arxiv.org/pdf/2510.17354", "abs": "https://arxiv.org/abs/2510.17354", "authors": ["Chenghao Zhang", "Guanting Dong", "Xinyu Yang", "Zhicheng Dou"], "title": "Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": "This work is in progress", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for\nenhancing large language models (LLMs) by retrieving relevant documents from an\nexternal corpus. However, existing RAG systems primarily focus on unimodal text\ndocuments, and often fall short in real-world scenarios where both queries and\ndocuments may contain mixed modalities (such as text and images). In this\npaper, we address the challenge of Universal Retrieval-Augmented Generation\n(URAG), which involves retrieving and reasoning over mixed-modal information to\nimprove vision-language generation. To this end, we propose Nyx, a unified\nmixed-modal to mixed-modal retriever tailored for URAG scenarios. To mitigate\nthe scarcity of realistic mixed-modal data, we introduce a four-stage automated\npipeline for generation and filtering, leveraging web documents to construct\nNyxQA, a dataset comprising diverse mixed-modal question-answer pairs that\nbetter reflect real-world information needs. Building on this high-quality\ndataset, we adopt a two-stage training framework for Nyx: we first perform\npre-training on NyxQA along with a variety of open-source retrieval datasets,\nfollowed by supervised fine-tuning using feedback from downstream\nvision-language models (VLMs) to align retrieval outputs with generative\npreferences. Experimental results demonstrate that Nyx not only performs\ncompetitively on standard text-only RAG benchmarks, but also excels in the more\ngeneral and realistic URAG setting, significantly improving generation quality\nin vision-language tasks."}
{"id": "2510.17358", "pdf": "https://arxiv.org/pdf/2510.17358", "abs": "https://arxiv.org/abs/2510.17358", "authors": ["Joachim Diederich"], "title": "Localist LLMs with Recruitment Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present a novel framework for training large language models with\ncontinuously adjustable internal representations that span the full spectrum\nfrom localist (interpretable, rule-based) to distributed (generalizable,\nefficient) encodings. The key innovations are (1) a locality dial, a tunable\nparameter that dynamically controls the degree of localization during both\ntraining and inference without requiring model retraining, (2) an\ninformation-theoretic recruitment mechanism that adaptively allocates semantic\nblocks as needed, eliminating the requirement for complete domain knowledge at\ninitialization, and (3) a hierarchical recruitment framework that extends\ncapacity allocation to entire specialized LLMs, enabling multi-granularity\narchitectural adaptation. This is achieved through group sparsity penalties on\nattention mechanisms, information-theoretic anchor design, dynamic rule\ninjection, and principled recruitment criteria based on penalized likelihood\nwith explicit units. We provide rigorous mathematical results establishing\nexplicit threshold conditions under which attention provably concentrates on\nsemantically relevant blocks at stationary points, with exact bounds on\nattention entropy and pointer fidelity. The hierarchical recruitment mechanism\nprovides convergence guarantees at both the block level (fine-grained,\nwithin-LLM) and the LLM level (coarse-grained, cross-domain), ensuring the\nsystem discovers semantic partitions that balance model complexity against data\nencoding efficiency. This framework enables practitioners to continuously\ninterpolate between interpretable and high-performance modes while adapting\narchitectural capacity at multiple granularities, supporting applications in\nregulated domains requiring both transparency and capability."}
{"id": "2510.17369", "pdf": "https://arxiv.org/pdf/2510.17369", "abs": "https://arxiv.org/abs/2510.17369", "authors": ["Haochen Su", "Cristian Meo", "Francesco Stella", "Andrea Peirone", "Kai Junge", "Josie Hughes"], "title": "Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted by NeurIPS 2025 SpaVLE workshop. 4 pages, 2 figures(in main\n  paper, excluding references and supplements)", "summary": "Robotic systems are increasingly expected to operate in human-centered,\nunstructured environments where safety, adaptability, and generalization are\nessential. Vision-Language-Action (VLA) models have been proposed as a language\nguided generalized control framework for real robots. However, their deployment\nhas been limited to conventional serial link manipulators. Coupled by their\nrigidity and unpredictability of learning based control, the ability to safely\ninteract with the environment is missing yet critical. In this work, we present\nthe deployment of a VLA model on a soft continuum manipulator to demonstrate\nautonomous safe human-robot interaction. We present a structured finetuning and\ndeployment pipeline evaluating two state-of-the-art VLA models (OpenVLA-OFT and\n$\\pi_0$) across representative manipulation tasks, and show while\nout-of-the-box policies fail due to embodiment mismatch, through targeted\nfinetuning the soft robot performs equally to the rigid counterpart. Our\nfindings highlight the necessity of finetuning for bridging embodiment gaps,\nand demonstrate that coupling VLA models with soft robots enables safe and\nflexible embodied AI in human-shared environments."}
{"id": "2510.17380", "pdf": "https://arxiv.org/pdf/2510.17380", "abs": "https://arxiv.org/abs/2510.17380", "authors": ["Julen Cestero", "Carmine Delle Femine", "Kenji S. Muro", "Marco Quartulli", "Marcello Restelli"], "title": "Optimizing Energy Management of Smart Grid using Reinforcement Learning aided by Surrogate models built using Physics-informed Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Optimizing the energy management within a smart grids scenario presents\nsignificant challenges, primarily due to the complexity of real-world systems\nand the intricate interactions among various components. Reinforcement Learning\n(RL) is gaining prominence as a solution for addressing the challenges of\nOptimal Power Flow in smart grids. However, RL needs to iterate compulsively\nthroughout a given environment to obtain the optimal policy. This means\nobtaining samples from a, most likely, costly simulator, which can lead to a\nsample efficiency problem. In this work, we address this problem by\nsubstituting costly smart grid simulators with surrogate models built using\nPhisics-informed Neural Networks (PINNs), optimizing the RL policy training\nprocess by arriving to convergent results in a fraction of the time employed by\nthe original environment."}
{"id": "2510.17385", "pdf": "https://arxiv.org/pdf/2510.17385", "abs": "https://arxiv.org/abs/2510.17385", "authors": ["Pengxiang Cai", "Zihao Gao", "Jintai Chen"], "title": "TabR1: Taming GRPO for tabular reasoning LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Tabular prediction has traditionally relied on gradient-boosted decision\ntrees and specialized deep learning models, which excel within tasks but\nprovide limited interpretability and weak transfer across tables. Reasoning\nlarge language models (LLMs) promise cross-task adaptability with trans- parent\nreasoning traces, yet their potential has not been fully realized for tabular\ndata. This paper presents TabR1, the first reasoning LLM for tabular prediction\nwith multi-step reasoning. At its core is Permutation Relative Policy\nOptimization (PRPO), a simple yet efficient reinforcement learning method that\nencodes column-permutation invariance as a structural prior. By construct- ing\nmultiple label-preserving permutations per sample and estimating advantages\nboth within and across permutations, PRPO transforms sparse rewards into dense\nlearning signals and improves generalization. With limited supervision, PRPO\nactivates the reasoning ability of LLMs for tabular prediction, enhancing\nfew-shot and zero-shot performance as well as interpretability. Comprehensive\nexperiments demonstrate that TabR1 achieves performance comparable to strong\nbaselines under full-supervision fine-tuning. In the zero-shot setting, TabR1\napproaches the performance of strong baselines under the 32-shot setting.\nMoreover, TabR1 (8B) substantially outperforms much larger LLMs across various\ntasks, achieving up to 53.17% improvement over DeepSeek-R1 (685B)."}
{"id": "2510.17386", "pdf": "https://arxiv.org/pdf/2510.17386", "abs": "https://arxiv.org/abs/2510.17386", "authors": ["Elaheh Hosseinkhani", "Martin Leucker"], "title": "Inference of Deterministic Finite Automata via Q-Learning", "categories": ["cs.FL", "cs.AI"], "comment": null, "summary": "Traditional approaches to inference of deterministic finite-state automata\n(DFA) stem from symbolic AI, including both active learning methods (e.g.,\nAngluin's L* algorithm and its variants) and passive techniques (e.g., Biermann\nand Feldman's method, RPNI). Meanwhile, sub-symbolic AI, particularly machine\nlearning, offers alternative paradigms for learning from data, such as\nsupervised, unsupervised, and reinforcement learning (RL). This paper\ninvestigates the use of Q-learning, a well-known reinforcement learning\nalgorithm, for the passive inference of deterministic finite automata. It\nbuilds on the core insight that the learned Q-function, which maps state-action\npairs to rewards, can be reinterpreted as the transition function of a DFA over\na finite domain. This provides a novel bridge between sub-symbolic learning and\nsymbolic representations. The paper demonstrates how Q-learning can be adapted\nfor automaton inference and provides an evaluation on several examples."}
{"id": "2510.17389", "pdf": "https://arxiv.org/pdf/2510.17389", "abs": "https://arxiv.org/abs/2510.17389", "authors": ["Numaan Naeem", "Abdellah El Mekki", "Muhammad Abdul-Mageed"], "title": "EduAdapt: A Question Answer Benchmark Dataset for Evaluating Grade-Level Adaptability in LLMs", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "28 pages, 2 figures, 14 tables, 50 listings, EMNLP 2025 Main", "summary": "Large language models (LLMs) are transforming education by answering\nquestions, explaining complex concepts, and generating content across a wide\nrange of subjects. Despite strong performance on academic benchmarks, they\noften fail to tailor responses to students' grade levels. This is a critical\nneed in K-12 education, where age-appropriate vocabulary and explanation are\nessential for effective learning. Existing models frequently produce outputs\nthat are too advanced or vague for younger learners, and there are no\nstandardized benchmarks to evaluate their ability to adjust across cognitive\nand developmental stages. To address this gap, we introduce EduAdapt, a\nbenchmark of nearly 48k grade-labeled QA pairs across nine science subjects,\nspanning Grades 1-12 and grouped into four grade levels. We evaluate a diverse\nset of open-source LLMs on EduAdapt and find that while larger models generally\nperform better, they still struggle with generating suitable responses for\nearly-grade students (Grades 1-5). Our work presents the first dataset and\nevaluation framework for assessing grade-level adaptability in LLMs, aiming to\nfoster more developmentally aligned educational AI systems through better\ntraining and prompting strategies. EduAdapt code and datasets are publicly\navailable at https://github.com/NaumanNaeem/EduAdapt."}
{"id": "2510.17402", "pdf": "https://arxiv.org/pdf/2510.17402", "abs": "https://arxiv.org/abs/2510.17402", "authors": ["Jiacheng Xie", "Shuai Zeng", "Yang Yu", "Xiaoting Tang", "Guanghui An", "Dong Xu"], "title": "Leveraging Group Relative Policy Optimization to Advance Large Language Models in Traditional Chinese Medicine", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Traditional Chinese Medicine (TCM) presents a rich and structurally unique\nknowledge system that challenges conventional applications of large language\nmodels (LLMs). Although previous TCM-specific LLMs have shown progress through\nsupervised fine-tuning, they often face limitations in alignment, data quality,\nand evaluation consistency. In this study, we introduce Ladder-base, the first\nTCM-focused LLM trained with Group Relative Policy Optimization (GRPO), a\nreinforcement learning method that improves reasoning and factual consistency\nby optimizing response selection based on intra-group comparisons. Ladder-base\nis built upon the Qwen2.5-7B-Instruct foundation model and trained exclusively\non the textual subset of the TCM-Ladder benchmark, using 80 percent of the data\nfor training and the remaining 20 percent split evenly between validation and\ntest sets. Through standardized evaluation, Ladder-base demonstrates superior\nperformance across multiple reasoning metrics when compared to both\nstate-of-the-art general-purpose LLMs such as GPT-4, Gemini 2.5, Claude 3, and\nQwen3 and domain-specific TCM models including BenTsao, HuatuoGPT2, and\nZhongjing. These findings suggest that GRPO provides an effective and efficient\nstrategy for aligning LLMs with expert-level reasoning in traditional medical\ndomains and supports the development of trustworthy and clinically grounded TCM\nartificial intelligence systems."}
{"id": "2510.17405", "pdf": "https://arxiv.org/pdf/2510.17405", "abs": "https://arxiv.org/abs/2510.17405", "authors": ["Mardiyyah Oduwole", "Prince Mireku", "Fatimo Adebanjo", "Oluwatosin Olajide", "Mahi Aminu Aliyu", "Jekaterina Novikova"], "title": "AFRICAPTION: Establishing a New Paradigm for Image Captioning in African Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal AI research has overwhelmingly focused on high-resource languages,\nhindering the democratization of advancements in the field. To address this, we\npresent AfriCaption, a comprehensive framework for multilingual image\ncaptioning in 20 African languages and our contributions are threefold: (i) a\ncurated dataset built on Flickr8k, featuring semantically aligned captions\ngenerated via a context-aware selection and translation process; (ii) a\ndynamic, context-preserving pipeline that ensures ongoing quality through model\nensembling and adaptive substitution; and (iii) the AfriCaption model, a 0.5B\nparameter vision-to-text architecture that integrates SigLIP and NLLB200 for\ncaption generation across under-represented languages. This unified framework\nensures ongoing data quality and establishes the first scalable\nimage-captioning resource for under-represented African languages, laying the\ngroundwork for truly inclusive multimodal AI."}
{"id": "2510.17415", "pdf": "https://arxiv.org/pdf/2510.17415", "abs": "https://arxiv.org/abs/2510.17415", "authors": ["Jiacheng Xie", "Yang Yu", "Yibo Chen", "Hanyao Zhang", "Lening Zhao", "Jiaxuan He", "Lei Jiang", "Xiaoting Tang", "Guanghui An", "Dong Xu"], "title": "BenCao: An Instruction-Tuned Large Language Model for Traditional Chinese Medicine", "categories": ["cs.CL", "cs.AI", "cs.MA", "cs.MM", "cs.SE"], "comment": null, "summary": "Traditional Chinese Medicine (TCM), with a history spanning over two\nmillennia, plays a role in global healthcare. However, applying large language\nmodels (LLMs) to TCM remains challenging due to its reliance on holistic\nreasoning, implicit logic, and multimodal diagnostic cues. Existing TCM-domain\nLLMs have made progress in text-based understanding but lack multimodal\nintegration, interpretability, and clinical applicability. To address these\nlimitations, we developed BenCao, a ChatGPT-based multimodal assistant for TCM,\nintegrating structured knowledge bases, diagnostic data, and expert feedback\nrefinement. BenCao was trained through natural language instruction tuning\nrather than parameter retraining, aligning with expert-level reasoning and\nethical norms specific to TCM. The system incorporates a comprehensive\nknowledge base of over 1,000 classical and modern texts, a scenario-based\ninstruction framework for diverse interactions, a chain-of-thought simulation\nmechanism for interpretable reasoning, and a feedback refinement process\ninvolving licensed TCM practitioners. BenCao connects to external APIs for\ntongue-image classification and multimodal database retrieval, enabling dynamic\naccess to diagnostic resources. In evaluations across single-choice question\nbenchmarks and multimodal classification tasks, BenCao achieved superior\naccuracy to general-domain and TCM-domain models, particularly in diagnostics,\nherb recognition, and constitution classification. The model was deployed as an\ninteractive application on the OpenAI GPTs Store, accessed by nearly 1,000\nusers globally as of October 2025. This study demonstrates the feasibility of\ndeveloping a TCM-domain LLM through natural language-based instruction tuning\nand multimodal integration, offering a practical framework for aligning\ngenerative AI with traditional medical reasoning and a scalable pathway for\nreal-world deployment."}
{"id": "2510.17426", "pdf": "https://arxiv.org/pdf/2510.17426", "abs": "https://arxiv.org/abs/2510.17426", "authors": ["Tiancheng Hu", "Benjamin Minixhofer", "Nigel Collier"], "title": "Navigating the Alignment-Calibration Trade-off: A Pareto-Superior Frontier via Model Merging", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The \"alignment tax\" of post-training is typically framed as a drop in task\naccuracy. We show it also involves a severe loss of calibration, making models\noverconfident, less reliable, and model outputs less diverse. We show that this\ntrade-off can be navigated effectively via a simple post-hoc intervention:\ninterpolating between a model's weights before and after alignment. Crucially,\nthis is not a strict trade-off. We find that the process consistently reveals\nPareto-optimal interpolations - models that improve accuracy beyond both\nparents while substantially recovering the calibration lost during alignment.\nOur work demonstrates that simple model merging provides a computationally\nefficient method for mitigating the full scope of the alignment tax, yielding\nmodels that are more capable and more reliable."}
{"id": "2510.17439", "pdf": "https://arxiv.org/pdf/2510.17439", "abs": "https://arxiv.org/abs/2510.17439", "authors": ["Zhengshen Zhang", "Hao Li", "Yalun Dai", "Zhengbang Zhu", "Lei Zhou", "Chenchen Liu", "Dong Wang", "Francis E. H. Tay", "Sijin Chen", "Ziwei Liu", "Yuxiao Liu", "Xinghang Li", "Pan Zhou"], "title": "From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Project page: https://falcon-vla.github.io/", "summary": "Existing vision-language-action (VLA) models act in 3D real-world but are\ntypically built on 2D encoders, leaving a spatial reasoning gap that limits\ngeneralization and adaptability. Recent 3D integration techniques for VLAs\neither require specialized sensors and transfer poorly across modalities, or\ninject weak cues that lack geometry and degrade vision-language alignment. In\nthis work, we introduce FALCON (From Spatial to Action), a novel paradigm that\ninjects rich 3D spatial tokens into the action head. FALCON leverages spatial\nfoundation models to deliver strong geometric priors from RGB alone, and\nincludes an Embodied Spatial Model that can optionally fuse depth, or pose for\nhigher fidelity when available, without retraining or architectural changes. To\npreserve language reasoning, spatial tokens are consumed by a Spatial-Enhanced\nAction Head rather than being concatenated into the vision-language backbone.\nThese designs enable FALCON to address limitations in spatial representation,\nmodality transferability, and alignment. In comprehensive evaluations across\nthree simulation benchmarks and eleven real-world tasks, our proposed FALCON\nachieves state-of-the-art performance, consistently surpasses competitive\nbaselines, and remains robust under clutter, spatial-prompt conditioning, and\nvariations in object scale and height."}
{"id": "2510.17451", "pdf": "https://arxiv.org/pdf/2510.17451", "abs": "https://arxiv.org/abs/2510.17451", "authors": ["Florent Foucaud", "Harmender Gahlawat", "Fionn Mc Inerney", "Prafullkumar Tale"], "title": "The Parameterized Complexity of Computing the VC-Dimension", "categories": ["cs.CC", "cs.AI", "cs.DM", "cs.LG", "math.CO"], "comment": "To appear in the proceedings of NeurIPS 2025", "summary": "The VC-dimension is a fundamental and well-studied measure of the complexity\nof a set system (or hypergraph) that is central to many areas of machine\nlearning. We establish several new results on the complexity of computing the\nVC-dimension. In particular, given a hypergraph\n$\\mathcal{H}=(\\mathcal{V},\\mathcal{E})$, we prove that the naive\n$2^{\\mathcal{O}(|\\mathcal{V}|)}$-time algorithm is asymptotically tight under\nthe Exponential Time Hypothesis (ETH). We then prove that the problem admits a\n1-additive fixed-parameter approximation algorithm when parameterized by the\nmaximum degree of $\\mathcal{H}$ and a fixed-parameter algorithm when\nparameterized by its dimension, and that these are essentially the only such\nexploitable structural parameters. Lastly, we consider a generalization of the\nproblem, formulated using graphs, which captures the VC-dimension of both set\nsystems and graphs. We show that it is fixed-parameter tractable parameterized\nby the treewidth of the graph (which, in the case of set systems, applies to\nthe treewidth of its incidence graph). In contrast with closely related\nproblems whose dependency on the treewidth is necessarily double-exponential\n(assuming the ETH), our algorithm has a relatively low dependency on the\ntreewidth."}
{"id": "2510.17469", "pdf": "https://arxiv.org/pdf/2510.17469", "abs": "https://arxiv.org/abs/2510.17469", "authors": ["Jing Liu"], "title": "Layer Specialization Underlying Compositional Reasoning in Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformers exhibit compositional reasoning on sequences not observed during\ntraining, a capability often attributed to in-context learning (ICL) and skill\ncomposition. We investigate this phenomenon using the Random Hierarchy Model\n(RHM), a probabilistic context-free grammar that generates sequences through\nrecursive rule application. Models are trained on subsets of sequences and\nevaluated across four generalization conditions: memorization, in-distribution\ngeneralization, out-of-distribution generalization with the same rules, and\ncross-layer transfer. Behaviorally, performance improves systematically with\ntask complexity and the number of in-context examples, with out-of-distribution\ntasks requiring substantially more examples than in-distribution scenarios.\nMechanistically, we identify a progressive emergence of layer specialization\nduring training that correlates with generalization performance. Principal\ncomponent analysis and attention pattern clustering reveal that transformers\ndevelop structured, hierarchically organized representations in specialized\nlayers. These results demonstrate that transformers develop modular,\ninterpretable mechanisms supporting compositional reasoning, linking internal\nalgorithmic structure to observed behavioral capabilities."}
{"id": "2510.17475", "pdf": "https://arxiv.org/pdf/2510.17475", "abs": "https://arxiv.org/abs/2510.17475", "authors": ["Fo Hu", "Can Wang", "Qinxu Zheng", "Xusheng Yang", "Bin Zhou", "Gang Li", "Yu Sun", "Wen-an Zhang"], "title": "DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for Cross-Domain EEG-based Emotion Recognition", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 9 figures", "summary": "Significant inter-individual variability limits the generalization of\nEEG-based emotion recognition under cross-domain settings. We address two core\nchallenges in multi-source adaptation: (1) dynamically modeling distributional\nheterogeneity across sources and quantifying their relevance to a target to\nreduce negative transfer; and (2) achieving fine-grained semantic consistency\nto strengthen class discrimination. We propose a distribution-aware\nmulti-source domain adaptation network (DAMSDAN). DAMSDAN integrates\nprototype-based constraints with adversarial learning to drive the encoder\ntoward discriminative, domain-invariant emotion representations. A domain-aware\nsource weighting strategy based on maximum mean discrepancy (MMD) dynamically\nestimates inter-domain shifts and reweights source contributions. In addition,\na prototype-guided conditional alignment module with dual pseudo-label\ninteraction enhances pseudo-label reliability and enables category-level,\nfine-grained alignment, mitigating noise propagation and semantic drift.\nExperiments on SEED and SEED-IV show average accuracies of 94.86\\% and 79.78\\%\nfor cross-subject, and 95.12\\% and 83.15\\% for cross-session protocols. On the\nlarge-scale FACED dataset, DAMSDAN achieves 82.88\\% (cross-subject). Extensive\nablations and interpretability analyses corroborate the effectiveness of the\nproposed framework for cross-domain EEG-based emotion recognition."}
{"id": "2510.17482", "pdf": "https://arxiv.org/pdf/2510.17482", "abs": "https://arxiv.org/abs/2510.17482", "authors": ["Chenxu Dang", "Haiyan Liu", "Guangjun Bao", "Pei An", "Xinyue Tang", "Jie Ma", "Bingchuan Sun", "Yan Wang"], "title": "SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries", "categories": ["cs.CV", "cs.AI"], "comment": "Under Review", "summary": "Semantic occupancy has emerged as a powerful representation in world models\nfor its ability to capture rich spatial semantics. However, most existing\noccupancy world models rely on static and fixed embeddings or grids, which\ninherently limit the flexibility of perception. Moreover, their ``in-place\nclassification\" over grids exhibits a potential misalignment with the dynamic\nand continuous nature of real scenarios.In this paper, we propose SparseWorld,\na novel 4D occupancy world model that is flexible, adaptive, and efficient,\npowered by sparse and dynamic queries. We propose a Range-Adaptive Perception\nmodule, in which learnable queries are modulated by the ego vehicle states and\nenriched with temporal-spatial associations to enable extended-range\nperception. To effectively capture the dynamics of the scene, we design a\nState-Conditioned Forecasting module, which replaces classification-based\nforecasting with regression-guided formulation, precisely aligning the dynamic\nqueries with the continuity of the 4D environment. In addition, We specifically\ndevise a Temporal-Aware Self-Scheduling training strategy to enable smooth and\nefficient training. Extensive experiments demonstrate that SparseWorld achieves\nstate-of-the-art performance across perception, forecasting, and planning\ntasks. Comprehensive visualizations and ablation studies further validate the\nadvantages of SparseWorld in terms of flexibility, adaptability, and\nefficiency. The code is available at https://github.com/MSunDYY/SparseWorld."}
{"id": "2510.17496", "pdf": "https://arxiv.org/pdf/2510.17496", "abs": "https://arxiv.org/abs/2510.17496", "authors": ["Giacomo Camposampiero", "Michael Hersche", "Roger Wattenhofer", "Abu Sebastian", "Abbas Rahimi"], "title": "I-RAVEN-X: Benchmarking Generalization and Robustness of Analogical and Mathematical Reasoning in Large Language and Reasoning Models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at the 5th Workshop on Mathematical Reasoning and AI\n  (MATH-AI), NeurIPS 2025", "summary": "We introduce I-RAVEN-X, a symbolic benchmark designed to evaluate\ngeneralization and robustness in analogical and mathematical reasoning for\nLarge Language Models (LLMs) and Large Reasoning Models (LRMs). I-RAVEN-X\nextends I-RAVEN by increasing operand complexity, attribute range, and\nintroducing perceptual uncertainty. Compared to LLMs, empirical results show\nthat LRMs achieve improved productivity and systematicity on longer reasoning\nrelations and wider attribute ranges, respectively. However, LRMs are still\nsignificantly challenged by reasoning under uncertainty and cannot effectively\nexplore multiple probabilistic outcomes."}
{"id": "2510.17501", "pdf": "https://arxiv.org/pdf/2510.17501", "abs": "https://arxiv.org/abs/2510.17501", "authors": ["Yuanli Wu", "Long Zhang", "Yue Du", "Bin Li"], "title": "Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the rapid proliferation of video content across social media,\nsurveillance, and education platforms, efficiently summarizing long videos into\nconcise yet semantically faithful surrogates has become increasingly vital.\nExisting supervised methods achieve strong in-domain accuracy by learning from\ndense annotations but suffer from high labeling costs and limited cross-dataset\ngeneralization, while unsupervised approaches, though label-free, often fail to\ncapture high-level human semantics and fine-grained narrative cues. More\nrecently, zero-shot prompting pipelines have leveraged large language models\n(LLMs) for training-free video summarization, yet remain highly sensitive to\nhandcrafted prompt templates and dataset-specific score normalization. To\novercome these limitations, we introduce a rubric-guided, pseudo-labeled\nprompting framework that transforms a small subset of ground-truth annotations\ninto high-confidence pseudo labels, which are aggregated into structured,\ndataset-adaptive scoring rubrics guiding interpretable scene evaluation. During\ninference, first and last segments are scored based solely on their\ndescriptions, whereas intermediate ones incorporate brief contextual summaries\nof adjacent scenes to assess narrative progression and redundancy. This\ncontextual prompting enables the LLM to balance local salience and global\ncoherence without parameter tuning. On SumMe and TVSum, our method achieves F1\nscores of \\textbf{57.58} and \\textbf{63.05}, surpassing unsupervised and prior\nzero-shot baselines while approaching supervised performance. The results\ndemonstrate that rubric-guided pseudo labeling effectively stabilizes LLM-based\nscoring and establishes a general, interpretable zero-shot paradigm for video\nsummarization."}
{"id": "2510.17515", "pdf": "https://arxiv.org/pdf/2510.17515", "abs": "https://arxiv.org/abs/2510.17515", "authors": ["Hoang Pham", "The-Anh Ta", "Tom Jacobs", "Rebekka Burkholz", "Long Tran-Thanh"], "title": "The Graphon Limit Hypothesis: Understanding Neural Network Pruning via Infinite Width Analysis", "categories": ["cs.LG", "cs.AI"], "comment": "NeurIPS 2025 Spotlight", "summary": "Sparse neural networks promise efficiency, yet training them effectively\nremains a fundamental challenge. Despite advances in pruning methods that\ncreate sparse architectures, understanding why some sparse structures are\nbetter trainable than others with the same level of sparsity remains poorly\nunderstood. Aiming to develop a systematic approach to this fundamental\nproblem, we propose a novel theoretical framework based on the theory of graph\nlimits, particularly graphons, that characterizes sparse neural networks in the\ninfinite-width regime. Our key insight is that connectivity patterns of sparse\nneural networks induced by pruning methods converge to specific graphons as\nnetworks' width tends to infinity, which encodes implicit structural biases of\ndifferent pruning methods. We postulate the Graphon Limit Hypothesis and\nprovide empirical evidence to support it. Leveraging this graphon\nrepresentation, we derive a Graphon Neural Tangent Kernel (Graphon NTK) to\nstudy the training dynamics of sparse networks in the infinite width limit.\nGraphon NTK provides a general framework for the theoretical analysis of sparse\nnetworks. We empirically show that the spectral analysis of Graphon NTK\ncorrelates with observed training dynamics of sparse networks, explaining the\nvarying convergence behaviours of different pruning methods. Our framework\nprovides theoretical insights into the impact of connectivity patterns on the\ntrainability of various sparse network architectures."}
{"id": "2510.17516", "pdf": "https://arxiv.org/pdf/2510.17516", "abs": "https://arxiv.org/abs/2510.17516", "authors": ["Tiancheng Hu", "Joachim Baumann", "Lorenzo Lupo", "Dirk Hovy", "Nigel Collier", "Paul RÃ¶ttger"], "title": "SimBench: Benchmarking the Ability of Large Language Models to Simulate Human Behaviors", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": "Project Website: http://simbench.tiancheng.hu/ Data:\n  https://huggingface.co/datasets/pitehu/SimBench", "summary": "Large language model (LLM) simulations of human behavior have the potential\nto revolutionize the social and behavioral sciences, if and only if they\nfaithfully reflect real human behaviors. Current evaluations are fragmented,\nbased on bespoke tasks and metrics, creating a patchwork of incomparable\nresults. To address this, we introduce SimBench, the first large-scale,\nstandardized benchmark for a robust, reproducible science of LLM simulation. By\nunifying 20 diverse datasets covering tasks from moral decision-making to\neconomic choice across a large global participant pool, SimBench provides the\nnecessary foundation to ask fundamental questions about when, how, and why LLM\nsimulations succeed or fail. We show that, while even the best LLMs today have\nlimited simulation ability (score: 40.80/100), performance scales log-linearly\nwith model size. Simulation performance is not improved by increased\ninference-time compute. We demonstrate an alignment-simulation trade-off:\ninstruction-tuning improves performance on low-entropy (consensus) questions\nbut degrades it on high-entropy (diverse) ones. Models particularly struggle\nwhen simulating specific demographic groups. Finally, we demonstrate that\nsimulation ability correlates most strongly with deep, knowledge-intensive\nreasoning (MMLU-Pro, r=0.939). By making progress measurable, we aim to\naccelerate the development of more faithful LLM simulators."}
{"id": "2510.17519", "pdf": "https://arxiv.org/pdf/2510.17519", "abs": "https://arxiv.org/abs/2510.17519", "authors": ["Yongshun Zhang", "Zhongyi Fan", "Yonghang Zhang", "Zhangzikang Li", "Weifeng Chen", "Zhongwei Feng", "Chaoyue Wang", "Peng Hou", "Anxiang Zeng"], "title": "MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models", "categories": ["cs.CV", "cs.AI"], "comment": "Technical Report; Project Page:\n  \\href{https://github.com/Shopee-MUG/MUG-V}", "summary": "In recent years, large-scale generative models for visual content\n(\\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable\nprogress. However, training large-scale video generation models remains\nparticularly challenging and resource-intensive due to cross-modal text-video\nalignment, the long sequences involved, and the complex spatiotemporal\ndependencies. To address these challenges, we present a training framework that\noptimizes four pillars: (i) data processing, (ii) model architecture, (iii)\ntraining strategy, and (iv) infrastructure for large-scale video generation\nmodels. These optimizations delivered significant efficiency gains and\nperformance improvements across all stages of data preprocessing, video\ncompression, parameter scaling, curriculum-based pretraining, and\nalignment-focused post-training. Our resulting model, MUG-V 10B, matches recent\nstate-of-the-art video generators overall and, on e-commerce-oriented video\ngeneration tasks, surpasses leading open-source baselines in human evaluations.\nMore importantly, we open-source the complete stack, including model weights,\nMegatron-Core-based large-scale training code, and inference pipelines for\nvideo generation and enhancement. To our knowledge, this is the first public\nrelease of large-scale video generation training code that exploits\nMegatron-Core to achieve high training efficiency and near-linear multi-node\nscaling, details are available in\n\\href{https://github.com/Shopee-MUG/MUG-V}{our webpage}."}
{"id": "2510.17529", "pdf": "https://arxiv.org/pdf/2510.17529", "abs": "https://arxiv.org/abs/2510.17529", "authors": ["Yovin Yahathugoda", "Davide Prezzi", "Piyalitt Ittichaiwong", "Vicky Goh", "Sebastien Ourselin", "Michela Antonelli"], "title": "MambaX-Net: Dual-Input Mamba-Enhanced Cross-Attention Network for Longitudinal MRI Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Active Surveillance (AS) is a treatment option for managing low and\nintermediate-risk prostate cancer (PCa), aiming to avoid overtreatment while\nmonitoring disease progression through serial MRI and clinical follow-up.\nAccurate prostate segmentation is an important preliminary step for automating\nthis process, enabling automated detection and diagnosis of PCa. However,\nexisting deep-learning segmentation models are often trained on\nsingle-time-point and expertly annotated datasets, making them unsuitable for\nlongitudinal AS analysis, where multiple time points and a scarcity of expert\nlabels hinder their effective fine-tuning. To address these challenges, we\npropose MambaX-Net, a novel semi-supervised, dual-scan 3D segmentation\narchitecture that computes the segmentation for time point t by leveraging the\nMRI and the corresponding segmentation mask from the previous time point. We\nintroduce two new components: (i) a Mamba-enhanced Cross-Attention Module,\nwhich integrates the Mamba block into cross attention to efficiently capture\ntemporal evolution and long-range spatial dependencies, and (ii) a Shape\nExtractor Module that encodes the previous segmentation mask into a latent\nanatomical representation for refined zone delination. Moreover, we introduce a\nsemi-supervised self-training strategy that leverages pseudo-labels generated\nfrom a pre-trained nnU-Net, enabling effective learning without expert\nannotations. MambaX-Net was evaluated on a longitudinal AS dataset, and results\nshowed that it significantly outperforms state-of-the-art U-Net and\nTransformer-based models, achieving superior prostate zone segmentation even\nwhen trained on limited and noisy data."}
{"id": "2510.17564", "pdf": "https://arxiv.org/pdf/2510.17564", "abs": "https://arxiv.org/abs/2510.17564", "authors": ["Lindsay Spoor", "Ãlvaro Serra-GÃ³mez", "Aske Plaat", "Thomas Moerland"], "title": "An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "In safety-critical domains such as robotics, navigation and power systems,\nconstrained optimization problems arise where maximizing performance must be\ncarefully balanced with associated constraints. Safe reinforcement learning\nprovides a framework to address these challenges, with Lagrangian methods being\na popular choice. However, the effectiveness of Lagrangian methods crucially\ndepends on the choice of the Lagrange multiplier $\\lambda$, which governs the\ntrade-off between return and constraint cost. A common approach is to update\nthe multiplier automatically during training. Although this is standard in\npractice, there remains limited empirical evidence on the robustness of an\nautomated update and its influence on overall performance. Therefore, we\nanalyze (i) optimality and (ii) stability of Lagrange multipliers in safe\nreinforcement learning across a range of tasks. We provide $\\lambda$-profiles\nthat give a complete visualization of the trade-off between return and\nconstraint cost of the optimization problem. These profiles show the highly\nsensitive nature of $\\lambda$ and moreover confirm the lack of general\nintuition for choosing the optimal value $\\lambda^*$. Our findings additionally\nshow that automated multiplier updates are able to recover and sometimes even\nexceed the optimal performance found at $\\lambda^*$ due to the vast difference\nin their learning trajectories. Furthermore, we show that automated multiplier\nupdates exhibit oscillatory behavior during training, which can be mitigated\nthrough PID-controlled updates. However, this method requires careful tuning to\nachieve consistently better performance across tasks. This highlights the need\nfor further research on stabilizing Lagrangian methods in safe reinforcement\nlearning. The code used to reproduce our results can be found at\nhttps://github.com/lindsayspoor/Lagrangian_SafeRL."}
{"id": "2510.17576", "pdf": "https://arxiv.org/pdf/2510.17576", "abs": "https://arxiv.org/abs/2510.17576", "authors": ["Cansu Erdogan", "Cesar Alan Contreras", "Alireza Rastegarpanah", "Manolis Chiou", "Rustam Stolkin"], "title": "Intent-Driven LLM Ensemble Planning for Flexible Multi-Robot Disassembly: Demonstration on EV Batteries", "categories": ["cs.RO", "cs.AI", "cs.HC", "cs.MA"], "comment": "This work is funded by the project called \"Research and Development\n  of a Highly Automated and Safe Streamlined Process for Increasing Lithium-ion\n  Battery Repurposing and Recycling\" (REBELION) under Grant 101104241, and\n  partially supported by the Ministry of National Education, Republic of\n  Turkey. Submitted to Frontiers for Review", "summary": "This paper addresses the problem of planning complex manipulation tasks, in\nwhich multiple robots with different end-effectors and capabilities, informed\nby computer vision, must plan and execute concatenated sequences of actions on\na variety of objects that can appear in arbitrary positions and configurations\nin unstructured scenes. We propose an intent-driven planning pipeline which can\nrobustly construct such action sequences with varying degrees of supervisory\ninput from a human using simple language instructions. The pipeline integrates:\n(i) perception-to-text scene encoding, (ii) an ensemble of large language\nmodels (LLMs) that generate candidate removal sequences based on the operator's\nintent, (iii) an LLM-based verifier that enforces formatting and precedence\nconstraints, and (iv) a deterministic consistency filter that rejects\nhallucinated objects. The pipeline is evaluated on an example task in which two\nrobot arms work collaboratively to dismantle an Electric Vehicle battery for\nrecycling applications. A variety of components must be grasped and removed in\nspecific sequences, determined by human instructions and/or by task-order\nfeasibility decisions made by the autonomous system. On 200 real scenes with\n600 operator prompts across five component classes, we used metrics of\nfull-sequence correctness and next-task correctness to evaluate and compare\nfive LLM-based planners (including ablation analyses of pipeline components).\nWe also evaluated the LLM-based human interface in terms of time to execution\nand NASA TLX with human participant experiments. Results indicate that our\nensemble-with-verification approach reliably maps operator intent to safe,\nexecutable multi-robot plans while maintaining low user effort."}
{"id": "2510.17584", "pdf": "https://arxiv.org/pdf/2510.17584", "abs": "https://arxiv.org/abs/2510.17584", "authors": ["Ludi Li", "Junbin Mao", "Hanhe Lin", "Xu Tian", "Fang-Xiang Wu", "Jin Liu"], "title": "CEPerFed: Communication-Efficient Personalized Federated Learning for Multi-Pulse MRI Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-pulse magnetic resonance imaging (MRI) is widely utilized for clinical\npractice such as Alzheimer's disease diagnosis. To train a robust model for\nmulti-pulse MRI classification, it requires large and diverse data from various\nmedical institutions while protecting privacy by preventing raw data sharing\nacross institutions. Although federated learning (FL) is a feasible solution to\naddress this issue, it poses challenges of model convergence due to the effect\nof data heterogeneity and substantial communication overhead due to large\nnumbers of parameters transmitted within the model. To address these\nchallenges, we propose CEPerFed, a communication-efficient personalized FL\nmethod. It mitigates the effect of data heterogeneity by incorporating\nclient-side historical risk gradients and historical mean gradients to\ncoordinate local and global optimization. The former is used to weight the\ncontributions from other clients, enhancing the reliability of local updates,\nwhile the latter enforces consistency between local updates and the global\noptimization direction to ensure stable convergence across heterogeneous data\ndistributions. To address the high communication overhead, we propose a\nhierarchical SVD (HSVD) strategy that transmits only the most critical\ninformation required for model updates. Experiments on five classification\ntasks demonstrate the effectiveness of the CEPerFed method. The code will be\nreleased upon acceptance at https://github.com/LD0416/CEPerFed."}
{"id": "2510.17591", "pdf": "https://arxiv.org/pdf/2510.17591", "abs": "https://arxiv.org/abs/2510.17591", "authors": ["Guang Yang", "Yujie Zhu"], "title": "HGAdapter: Hypergraph-based Adapters in Language Models for Code Summarization and Clone Detection", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted by the 2025 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2025) as a findings long paper", "summary": "Pre-trained language models (PLMs) are increasingly being applied to\ncode-related tasks. Although PLMs have achieved good results, they do not take\ninto account potential high-order data correlations within the code. We propose\nthree types of high-order correlations in code tokens, i.e. abstract syntax\ntree family correlation, lexical correlation, and line correlation. We design a\ntokens and hyperedges generator to capture these high-order data correlations.\nWe improve the architecture of hypergraph neural networks and combine it with\nadapter tuning to propose a novel hypergraph-based adapter (HGAdapter) to\nfine-tune PLMs. HGAdapter can encode high-order data correlations and is\nallowed to be inserted into various PLMs to enhance performance. Experiments\nwere conducted on several public datasets, including six languages of code\nsummarization and code clone detection tasks. Our methods improved the\nperformance of PLMs in datasets to varying degrees. Experimental results\nvalidate the introduction of high-order data correlations that contribute to\nimproved effectiveness."}
{"id": "2510.17621", "pdf": "https://arxiv.org/pdf/2510.17621", "abs": "https://arxiv.org/abs/2510.17621", "authors": ["Vincenzo Carletti", "Pasquale Foggia", "Carlo Mazzocca", "Giuseppe Parrella", "Mario Vento"], "title": "GUIDE: Enhancing Gradient Inversion Attacks in Federated Learning with Denoising Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of Machine Learning\n(ML) models across multiple clients while preserving their privacy. Rather than\nsharing raw data, federated clients transmit locally computed updates to train\nthe global model. Although this paradigm should provide stronger privacy\nguarantees than centralized ML, client updates remain vulnerable to privacy\nleakage. Adversaries can exploit them to infer sensitive properties about the\ntraining data or even to reconstruct the original inputs via Gradient Inversion\nAttacks (GIAs). Under the honest-butcurious threat model, GIAs attempt to\nreconstruct training data by reversing intermediate updates using\noptimizationbased techniques. We observe that these approaches usually\nreconstruct noisy approximations of the original inputs, whose quality can be\nenhanced with specialized denoising models. This paper presents Gradient Update\nInversion with DEnoising (GUIDE), a novel methodology that leverages diffusion\nmodels as denoising tools to improve image reconstruction attacks in FL. GUIDE\ncan be integrated into any GIAs that exploits surrogate datasets, a widely\nadopted assumption in GIAs literature. We comprehensively evaluate our approach\nin two attack scenarios that use different FL algorithms, models, and datasets.\nOur results demonstrate that GUIDE integrates seamlessly with two state-ofthe-\nart GIAs, substantially improving reconstruction quality across multiple\nmetrics. Specifically, GUIDE achieves up to 46% higher perceptual similarity,\nas measured by the DreamSim metric."}
{"id": "2510.17626", "pdf": "https://arxiv.org/pdf/2510.17626", "abs": "https://arxiv.org/abs/2510.17626", "authors": ["FrÃ©dÃ©ric LIN", "Biruk Abere Ambaw", "Adrian Popescu", "Hejer Ammar", "Romaric Audigier", "HervÃ© Le Borgne"], "title": "CaMiT: A Time-Aware Car Model Dataset for Classification and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "To be published in NeurIPS 2025 Track on Datasets and Benchmarks", "summary": "AI systems must adapt to evolving visual environments, especially in domains\nwhere object appearances change over time. We introduce Car Models in Time\n(CaMiT), a fine-grained dataset capturing the temporal evolution of car models,\na representative class of technological artifacts. CaMiT includes 787K labeled\nsamples of 190 car models (2007-2023) and 5.1M unlabeled samples (2005-2023),\nsupporting both supervised and self-supervised learning. Static pretraining on\nin-domain data achieves competitive performance with large-scale generalist\nmodels while being more resource-efficient, yet accuracy declines when models\nare tested across years. To address this, we propose a time-incremental\nclassification setting, a realistic continual learning scenario with emerging,\nevolving, and disappearing classes. We evaluate two strategies:\ntime-incremental pretraining, which updates the backbone, and time-incremental\nclassifier learning, which updates only the final layer, both improving\ntemporal robustness. Finally, we explore time-aware image generation that\nleverages temporal metadata during training, yielding more realistic outputs.\nCaMiT offers a rich benchmark for studying temporal adaptation in fine-grained\nvisual recognition and generation."}
{"id": "2510.17640", "pdf": "https://arxiv.org/pdf/2510.17640", "abs": "https://arxiv.org/abs/2510.17640", "authors": ["Yuquan Xue", "Guanxing Lu", "Zhenyu Wu", "Chuanrui Zhang", "Bofang Jia", "Zhengyi Gu", "Yansong Tang", "Ziwei Wang"], "title": "RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "9 pages,7 figures, submitted to ICRA2026", "summary": "Vision-Language-Action models (VLAs) have demonstrated remarkable performance\non complex robotic manipulation tasks through imitation learning. However,\nexisting imitation learning datasets contain only successful trajectories and\nlack failure or recovery data, especially for out-of-distribution (OOD) states\nwhere the robot deviates from the main policy due to minor perturbations or\nerrors, leading VLA models to struggle with states deviating from the training\ndistribution. To this end, we propose an automated OOD data augmentation\nframework named RESample through exploratory sampling. Specifically, we first\nleverage offline reinforcement learning to obtain an action-value network that\naccurately identifies sub-optimal actions under the current manipulation\npolicy. We further sample potential OOD states from trajectories via rollout,\nand design an exploratory sampling mechanism that adaptively incorporates these\naction proxies into the training dataset to ensure efficiency. Subsequently,\nour framework explicitly encourages the VLAs to recover from OOD states and\nenhances their robustness against distributional shifts. We conduct extensive\nexperiments on the LIBERO benchmark as well as real-world robotic manipulation\ntasks, demonstrating that RESample consistently improves the stability and\ngeneralization ability of VLA models."}
{"id": "2510.17651", "pdf": "https://arxiv.org/pdf/2510.17651", "abs": "https://arxiv.org/abs/2510.17651", "authors": ["SÃ©bastien Thuau", "Siba Haidar", "Ayush Bajracharya", "Rachid Chelouah"], "title": "Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "7 pages, 1 figure, FLTA 2025", "summary": "We examine frugal federated learning approaches to violence detection by\ncomparing two complementary strategies: (i) zero-shot and federated fine-tuning\nof vision-language models (VLMs), and (ii) personalized training of a compact\n3D convolutional neural network (CNN3D). Using LLaVA-7B and a 65.8M parameter\nCNN3D as representative cases, we evaluate accuracy, calibration, and energy\nusage under realistic non-IID settings. Both approaches exceed 90% accuracy.\nCNN3D slightly outperforms Low-Rank Adaptation(LoRA)-tuned VLMs in ROC AUC and\nlog loss, while using less energy. VLMs remain favorable for contextual\nreasoning and multimodal inference. We quantify energy and CO$_2$ emissions\nacross training and inference, and analyze sustainability trade-offs for\ndeployment. To our knowledge, this is the first comparative study of LoRA-tuned\nvision-language models and personalized CNNs for federated violence detection,\nwith an emphasis on energy efficiency and environmental metrics. These findings\nsupport a hybrid model: lightweight CNNs for routine classification, with\nselective VLM activation for complex or descriptive scenarios. The resulting\nframework offers a reproducible baseline for responsible, resource-aware AI in\nvideo surveillance, with extensions toward real-time, multimodal, and\nlifecycle-aware systems."}
{"id": "2510.17670", "pdf": "https://arxiv.org/pdf/2510.17670", "abs": "https://arxiv.org/abs/2510.17670", "authors": ["Yehonathan Refael", "Amit Aides", "Aviad Barzilai", "George Leifman", "Genady Beryozkin", "Vered Silverman", "Bolous Jaber", "Tomer Shekel"], "title": "On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Open-vocabulary object detection (OVD) models offer remarkable flexibility by\ndetecting objects from arbitrary text queries. However, their zero-shot\nperformance in specialized domains like Remote Sensing (RS) is often\ncompromised by the inherent ambiguity of natural language, limiting critical\ndownstream applications. For instance, an OVD model may struggle to distinguish\nbetween fine-grained classes such as \"fishing boat\" and \"yacht\" since their\nembeddings are similar and often inseparable. This can hamper specific user\ngoals, such as monitoring illegal fishing, by producing irrelevant detections.\nTo address this, we propose a cascaded approach that couples the broad\ngeneralization of a large pre-trained OVD model with a lightweight few-shot\nclassifier. Our method first employs the zero-shot model to generate\nhigh-recall object proposals. These proposals are then refined for high\nprecision by a compact classifier trained in real-time on only a handful of\nuser-annotated examples - drastically reducing the high costs of RS imagery\nannotation.The core of our framework is FLAME, a one-step active learning\nstrategy that selects the most informative samples for training. FLAME\nidentifies, on the fly, uncertain marginal candidates near the decision\nboundary using density estimation, followed by clustering to ensure sample\ndiversity. This efficient sampling technique achieves high accuracy without\ncostly full-model fine-tuning and enables instant adaptation, within less then\na minute, which is significantly faster than state-of-the-art alternatives.Our\nmethod consistently surpasses state-of-the-art performance on RS benchmarks,\nestablishing a practical and resource-efficient framework for adapting\nfoundation models to specific user needs."}
{"id": "2510.17671", "pdf": "https://arxiv.org/pdf/2510.17671", "abs": "https://arxiv.org/abs/2510.17671", "authors": ["Katarzyna Kobalczyk", "Zhiyuan Jerry Lin", "Benjamin Letham", "Zhuokai Zhao", "Maximilian Balandat", "Eytan Bakshy"], "title": "LILO: Bayesian Optimization with Interactive Natural Language Feedback", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "For many real-world applications, feedback is essential in translating\ncomplex, nuanced, or subjective goals into quantifiable optimization\nobjectives. We propose a language-in-the-loop framework that uses a large\nlanguage model (LLM) to convert unstructured feedback in the form of natural\nlanguage into scalar utilities to conduct BO over a numeric search space.\nUnlike preferential BO, which only accepts restricted feedback formats and\nrequires customized models for each domain-specific problem, our approach\nleverages LLMs to turn varied types of textual feedback into consistent utility\nsignals and to easily include flexible user priors without manual kernel\ndesign. At the same time, our method maintains the sample efficiency and\nprincipled uncertainty quantification of BO. We show that this hybrid method\nnot only provides a more natural interface to the decision maker but also\noutperforms conventional BO baselines and LLM-only optimizers, particularly in\nfeedback-limited regimes."}
{"id": "2510.17681", "pdf": "https://arxiv.org/pdf/2510.17681", "abs": "https://arxiv.org/abs/2510.17681", "authors": ["Yuandong Pu", "Le Zhuo", "Songhao Han", "Jinbo Xing", "Kaiwen Zhu", "Shuo Cao", "Bin Fu", "Si Liu", "Hongsheng Li", "Yu Qiao", "Wenlong Zhang", "Xi Chen", "Yihao Liu"], "title": "PICABench: How Far Are We from Physically Realistic Image Editing?", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Image editing has achieved remarkable progress recently. Modern editing\nmodels could already follow complex instructions to manipulate the original\ncontent. However, beyond completing the editing instructions, the accompanying\nphysical effects are the key to the generation realism. For example, removing\nan object should also remove its shadow, reflections, and interactions with\nnearby objects. Unfortunately, existing models and benchmarks mainly focus on\ninstruction completion but overlook these physical effects. So, at this moment,\nhow far are we from physically realistic image editing? To answer this, we\nintroduce PICABench, which systematically evaluates physical realism across\neight sub-dimension (spanning optics, mechanics, and state transitions) for\nmost of the common editing operations (add, remove, attribute change, etc). We\nfurther propose the PICAEval, a reliable evaluation protocol that uses\nVLM-as-a-judge with per-case, region-level human annotations and questions.\nBeyond benchmarking, we also explore effective solutions by learning physics\nfrom videos and construct a training dataset PICA-100K. After evaluating most\nof the mainstream models, we observe that physical realism remains a\nchallenging problem with large rooms to explore. We hope that our benchmark and\nproposed solutions can serve as a foundation for future work moving from naive\ncontent editing toward physically consistent realism."}
{"id": "2510.17684", "pdf": "https://arxiv.org/pdf/2510.17684", "abs": "https://arxiv.org/abs/2510.17684", "authors": ["Xinwei Zhang", "Hu Chen", "Zhe Yuan", "Sukun Tian", "Peng Feng"], "title": "Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Foundation models for medical image segmentation have achieved remarkable\nperformance. Adaptive fine-tuning of natural image segmentation foundation\nmodels is crucial for medical image segmentation tasks. However, some\nlimitations exist in existing fine-tuning methods: 1) insufficient\nrepresentation of high-level features and 2) the fine-tuning process disrupts\nthe structural integrity of pretrained weights. Inspired by these critical\nproblems, we propose an intelligent communication mixture-of-experts\nboosted-medical image segmentation foundation model, named IC-MoE, with twofold\nideas: 1) We construct basic experts, semantic experts, and adaptive experts.\nMoreover, we implement a pixel probability adaptive voting strategy, which\nenables expert selection and fusion through label consistency and load\nbalancing. This approach preliminarily enhances the representation capability\nof high-level features while preserving the structural integrity of pretrained\nweights. 2) We propose a semantic-guided contrastive learning method to address\nthe issue of weak supervision in contrastive learning. This method further\nenhances the representation capability of high-level features while preserving\nthe structural integrity of pretrained weights. Extensive experiments across\nthree public medical image segmentation datasets demonstrate that the IC-MoE\noutperforms other SOTA models. Consequently, the proposed IC-MoE effectively\nsupplements foundational medical image segmentation models with high-level\nfeatures and pretrained structural integrity. We also validate the superior\ngeneralizability of the IC-MoE across diverse medical image segmentation\nscenarios."}
{"id": "2510.17685", "pdf": "https://arxiv.org/pdf/2510.17685", "abs": "https://arxiv.org/abs/2510.17685", "authors": ["Min Cao", "Xinyu Zhou", "Ding Jiang", "Bo Du", "Mang Ye", "Min Zhang"], "title": "Multilingual Text-to-Image Person Retrieval via Bidirectional Relation Reasoning and Aligning", "categories": ["cs.CV", "cs.AI"], "comment": "Final version published in IEEE Transactions on Pattern Analysis and\n  Machine Intelligence (TPAMI). Xplore link:\n  https://ieeexplore.ieee.org/document/11199360", "summary": "Text-to-image person retrieval (TIPR) aims to identify the target person\nusing textual descriptions, facing challenge in modality heterogeneity. Prior\nworks have attempted to address it by developing cross-modal global or local\nalignment strategies. However, global methods typically overlook fine-grained\ncross-modal differences, whereas local methods require prior information to\nexplore explicit part alignments. Additionally, current methods are\nEnglish-centric, restricting their application in multilingual contexts. To\nalleviate these issues, we pioneer a multilingual TIPR task by developing a\nmultilingual TIPR benchmark, for which we leverage large language models for\ninitial translations and refine them by integrating domain-specific knowledge.\nCorrespondingly, we propose Bi-IRRA: a Bidirectional Implicit Relation\nReasoning and Aligning framework to learn alignment across languages and\nmodalities. Within Bi-IRRA, a bidirectional implicit relation reasoning module\nenables bidirectional prediction of masked image and text, implicitly enhancing\nthe modeling of local relations across languages and modalities, a\nmulti-dimensional global alignment module is integrated to bridge the modality\nheterogeneity. The proposed method achieves new state-of-the-art results on all\nmultilingual TIPR datasets. Data and code are presented in\nhttps://github.com/Flame-Chasers/Bi-IRRA."}
{"id": "2510.17687", "pdf": "https://arxiv.org/pdf/2510.17687", "abs": "https://arxiv.org/abs/2510.17687", "authors": ["Xu Zhang", "Hao Li", "Zhichao Lu"], "title": "CrossGuard: Safeguarding MLLMs against Joint-Modal Implicit Malicious Attacks", "categories": ["cs.CR", "cs.AI"], "comment": "14 pages, 8 figures, 2 tables", "summary": "Multimodal Large Language Models (MLLMs) achieve strong reasoning and\nperception capabilities but are increasingly vulnerable to jailbreak attacks.\nWhile existing work focuses on explicit attacks, where malicious content\nresides in a single modality, recent studies reveal implicit attacks, in which\nbenign text and image inputs jointly express unsafe intent. Such joint-modal\nthreats are difficult to detect and remain underexplored, largely due to the\nscarcity of high-quality implicit data. We propose ImpForge, an automated\nred-teaming pipeline that leverages reinforcement learning with tailored reward\nmodules to generate diverse implicit samples across 14 domains. Building on\nthis dataset, we further develop CrossGuard, an intent-aware safeguard\nproviding robust and comprehensive defense against both explicit and implicit\nthreats. Extensive experiments across safe and unsafe benchmarks, implicit and\nexplicit attacks, and multiple out-of-domain settings demonstrate that\nCrossGuard significantly outperforms existing defenses, including advanced\nMLLMs and guardrails, achieving stronger security while maintaining high\nutility. This offers a balanced and practical solution for enhancing MLLM\nrobustness against real-world multimodal threats."}
{"id": "2510.17703", "pdf": "https://arxiv.org/pdf/2510.17703", "abs": "https://arxiv.org/abs/2510.17703", "authors": ["Mhd Adnan Albani", "Riad Sonbol"], "title": "Improving Cross-Patient Generalization in Parkinson's Disease Detection through Chunk-Based Analysis of Hand-Drawn Patterns", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 2 figures, 9 tables", "summary": "Parkinson's disease (PD) is a neurodegenerative disease affecting about 1% of\npeople over the age of 60, causing motor impairments that impede hand\ncoordination activities such as writing and drawing. Many approaches have tried\nto support early detection of Parkinson's disease based on hand-drawn images;\nhowever, we identified two major limitations in the related works: (1) the lack\nof sufficient datasets, (2) the robustness when dealing with unseen patient\ndata. In this paper, we propose a new approach to detect Parkinson's disease\nthat consists of two stages: The first stage classifies based on their drawing\ntype(circle, meander, spiral), and the second stage extracts the required\nfeatures from the images and detects Parkinson's disease. We overcame the\nprevious two limitations by applying a chunking strategy where we divide each\nimage into 2x2 chunks. Each chunk is processed separately when extracting\nfeatures and recognizing Parkinson's disease indicators. To make the final\nclassification, an ensemble method is used to merge the decisions made from\neach chunk. Our evaluation shows that our proposed approach outperforms the top\nperforming state-of-the-art approaches, in particular on unseen patients. On\nthe NewHandPD dataset our approach, it achieved 97.08% accuracy for seen\npatients and 94.91% for unseen patients, our proposed approach maintained a gap\nof only 2.17 percentage points, compared to the 4.76-point drop observed in\nprior work."}
{"id": "2510.17709", "pdf": "https://arxiv.org/pdf/2510.17709", "abs": "https://arxiv.org/abs/2510.17709", "authors": ["Akhil S Anand", "Shambhuraj Sawant", "Jasper Hoffmann", "Dirk Reinhardt", "Sebastien Gros"], "title": "Closing the Sim2Real Performance Gap in RL", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sim2Real aims at training policies in high-fidelity simulation environments\nand effectively transferring them to the real world. Despite the developments\nof accurate simulators and Sim2Real RL approaches, the policies trained purely\nin simulation often suffer significant performance drops when deployed in real\nenvironments. This drop is referred to as the Sim2Real performance gap. Current\nSim2Real RL methods optimize the simulator accuracy and variability as proxies\nfor real-world performance. However, these metrics do not necessarily correlate\nwith the real-world performance of the policy as established theoretically and\nempirically in the literature. We propose a novel framework to address this\nissue by directly adapting the simulator parameters based on real-world\nperformance. We frame this problem as a bi-level RL framework: the inner-level\nRL trains a policy purely in simulation, and the outer-level RL adapts the\nsimulation model and in-sim reward parameters to maximize real-world\nperformance of the in-sim policy. We derive and validate in simple examples the\nmathematical tools needed to develop bi-level RL algorithms that close the\nSim2Real performance gap."}
{"id": "2510.17720", "pdf": "https://arxiv.org/pdf/2510.17720", "abs": "https://arxiv.org/abs/2510.17720", "authors": ["Nanda Kumar Rengarajan", "Jun Yan", "Chun Wang"], "title": "PANER: A Paraphrase-Augmented Framework for Low-Resource Named Entity Recognition", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Named Entity Recognition (NER) is a critical task that requires substantial\nannotated data, making it challenging in low-resource scenarios where label\nacquisition is expensive. While zero-shot and instruction-tuned approaches have\nmade progress, they often fail to generalize to domain-specific entities and do\nnot effectively utilize limited available data. We present a lightweight\nfew-shot NER framework that addresses these challenges through two key\ninnovations: (1) a new instruction tuning template with a simplified output\nformat that combines principles from prior IT approaches to leverage the large\ncontext window of recent state-of-the-art LLMs; (2) introducing a strategic\ndata augmentation technique that preserves entity information while\nparaphrasing the surrounding context, thereby expanding our training data\nwithout compromising semantic relationships. Experiments on benchmark datasets\nshow that our method achieves performance comparable to state-of-the-art models\non few-shot and zero-shot tasks, with our few-shot approach attaining an\naverage F1 score of 80.1 on the CrossNER datasets. Models trained with our\nparaphrasing approach show consistent improvements in F1 scores of up to 17\npoints over baseline versions, offering a promising solution for groups with\nlimited NER training data and compute power."}
{"id": "2510.17722", "pdf": "https://arxiv.org/pdf/2510.17722", "abs": "https://arxiv.org/abs/2510.17722", "authors": ["Yaning Pan", "Zekun Wang", "Qianqian Xie", "Yongqian Wen", "Yuanxing Zhang", "Guohui Zhang", "Haoxuan Hu", "Zhiyu Pan", "Yibing Huang", "Zhidong Gan", "Yonghong Lin", "An Ping", "Tianhao Peng", "Jiaheng Liu"], "title": "MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues", "categories": ["cs.CV", "cs.AI"], "comment": "Project Website: https://github.com/NJU-LINK/MT-Video-Bench", "summary": "The recent development of Multimodal Large Language Models (MLLMs) has\nsignificantly advanced AI's ability to understand visual modalities. However,\nexisting evaluation benchmarks remain limited to single-turn question\nanswering, overlooking the complexity of multi-turn dialogues in real-world\nscenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video\nunderstanding benchmark for evaluating MLLMs in multi-turn dialogues.\nSpecifically, our MT-Video-Bench mainly assesses six core competencies that\nfocus on perceptivity and interactivity, encompassing 987 meticulously curated\nmulti-turn dialogues from diverse domains. These capabilities are rigorously\naligned with real-world applications, such as interactive sports analysis and\nmulti-turn video-based intelligent tutoring. With MT-Video-Bench, we\nextensively evaluate various state-of-the-art open-source and closed-source\nMLLMs, revealing their significant performance discrepancies and limitations in\nhandling multi-turn video dialogues. The benchmark will be publicly available\nto foster future research."}
{"id": "2510.17724", "pdf": "https://arxiv.org/pdf/2510.17724", "abs": "https://arxiv.org/abs/2510.17724", "authors": ["Matheus Ramos Parracho"], "title": "Signature Forgery Detection: Improving Cross-Dataset Generalization", "categories": ["cs.CV", "cs.AI"], "comment": "Undergraduate thesis (preprint)---submitted to Escola Polit\\'ecnica,\n  Universidade Federal do Rio de Janeiro (POLI/UFRJ). The final version will\n  include official signatures and defense approval", "summary": "Automated signature verification is a critical biometric technique used in\nbanking, identity authentication, and legal documentation. Despite the notable\nprogress achieved by deep learning methods, most approaches in offline\nsignature verification still struggle to generalize across datasets, as\nvariations in handwriting styles and acquisition protocols often degrade\nperformance. This study investigates feature learning strategies for signature\nforgery detection, focusing on improving cross-dataset generalization -- that\nis, model robustness when trained on one dataset and tested on another. Using\nthree public benchmarks -- CEDAR, ICDAR, and GPDS Synthetic -- two experimental\npipelines were developed: one based on raw signature images and another\nemploying a preprocessing method referred to as shell preprocessing. Several\nbehavioral patterns were identified and analyzed; however, no definitive\nsuperiority between the two approaches was established. The results show that\nthe raw-image model achieved higher performance across benchmarks, while the\nshell-based model demonstrated promising potential for future refinement toward\nrobust, cross-domain signature verification."}
{"id": "2510.17725", "pdf": "https://arxiv.org/pdf/2510.17725", "abs": "https://arxiv.org/abs/2510.17725", "authors": ["Haozhen Zhang", "Tao Feng", "Pengrui Han", "Jiaxuan You"], "title": "AcademicEval: Live Long-Context LLM Benchmark", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by TMLR. Code is available at\n  https://github.com/ulab-uiuc/AcademicEval", "summary": "Large Language Models (LLMs) have recently achieved remarkable performance in\nlong-context understanding. However, current long-context LLM benchmarks are\nlimited by rigid context length, labor-intensive annotation, and the pressing\nchallenge of label leakage issues during LLM training. Therefore, we propose\n\\textsc{AcademicEval}, a live benchmark for evaluating LLMs over long-context\ngeneration tasks. \\textsc{AcademicEval} adopts papers on arXiv to introduce\nseveral academic writing tasks with long-context inputs, \\textit{i.e.},\n\\textsc{Title}, \\textsc{Abstract}, \\textsc{Introduction}, and \\textsc{Related\nWork}, which cover a wide range of abstraction levels and require no manual\nlabeling. Moreover, \\textsc{AcademicEval} integrates high-quality and\nexpert-curated few-shot demonstrations from a collected co-author graph to\nenable flexible context length. Especially, \\textsc{AcademicEval} features an\nefficient live evaluation, ensuring no label leakage. We conduct a holistic\nevaluation on \\textsc{AcademicEval}, and the results illustrate that LLMs\nperform poorly on tasks with hierarchical abstraction levels and tend to\nstruggle with long few-shot demonstrations, highlighting the challenge of our\nbenchmark. Through experimental analysis, we also reveal some insights for\nenhancing LLMs' long-context modeling capabilities. Code is available at\nhttps://github.com/ulab-uiuc/AcademicEval"}
{"id": "2510.17745", "pdf": "https://arxiv.org/pdf/2510.17745", "abs": "https://arxiv.org/abs/2510.17745", "authors": ["Lars Niedermeier", "Vyom Shah", "Jeffrey L. Krichmar"], "title": "A Multi-Threading Kernel for Enabling Neuromorphic Edge Applications", "categories": ["cs.NE", "cs.AI"], "comment": "Submitted to ISCAS 2026", "summary": "Spiking Neural Networks (SNNs) have sparse, event driven processing that can\nleverage neuromorphic applications. In this work, we introduce a\nmulti-threading kernel that enables neuromorphic applications running at the\nedge, meaning they process sensory input directly and without any up-link to or\ndependency on a cloud service. The kernel shows speed-up gains over single\nthread processing by a factor of four on moderately sized SNNs and 1.7X on a\nSynfire network. Furthermore, it load-balances all cores available on\nmulti-core processors, such as ARM, which run today's mobile devices and is up\nto 70% more energy efficient compared to statical core assignment. The present\nwork can enable the development of edge applications that have low Size,\nWeight, and Power (SWaP), and can prototype the integration of neuromorphic\nchips."}
{"id": "2510.17753", "pdf": "https://arxiv.org/pdf/2510.17753", "abs": "https://arxiv.org/abs/2510.17753", "authors": ["Celeste Riley", "Omar Al-Refai", "Yadira Colunga Reyes", "Eman Hammad"], "title": "Human-AI Interactions: Cognitive, Behavioral, and Emotional Impacts", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "13 pages, 1 figure. Submitted to IEEE Transactions on Technology and\n  Society. Preprint also available on TechRxiv", "summary": "As stories of human-AI interactions continue to be highlighted in the news\nand research platforms, the challenges are becoming more pronounced, including\npotential risks of overreliance, cognitive offloading, social and emotional\nmanipulation, and the nuanced degradation of human agency and judgment. This\npaper surveys recent research on these issues through the lens of the\npsychological triad: cognition, behavior, and emotion. Observations seem to\nsuggest that while AI can substantially enhance memory, creativity, and\nengagement, it also introduces risks such as diminished critical thinking,\nskill erosion, and increased anxiety. Emotional outcomes are similarly mixed,\nwith AI systems showing promise for support and stress reduction, but raising\nconcerns about dependency, inappropriate attachments, and ethical oversight.\nThis paper aims to underscore the need for responsible and context-aware AI\ndesign, highlighting gaps for longitudinal research and grounded evaluation\nframeworks to balance benefits with emerging human-centric risks."}
{"id": "2510.17756", "pdf": "https://arxiv.org/pdf/2510.17756", "abs": "https://arxiv.org/abs/2510.17756", "authors": ["Younghyun Koo", "Maryam Rahnemoonfar"], "title": "Prediction of Sea Ice Velocity and Concentration in the Arctic Ocean using Physics-informed Neural Network", "categories": ["cs.LG", "cs.AI"], "comment": "49 pages, 7 figures, submitted to Environmental Modelling & Software", "summary": "As an increasing amount of remote sensing data becomes available in the\nArctic Ocean, data-driven machine learning (ML) techniques are becoming widely\nused to predict sea ice velocity (SIV) and sea ice concentration (SIC).\nHowever, fully data-driven ML models have limitations in generalizability and\nphysical consistency due to their excessive reliance on the quantity and\nquality of training data. In particular, as Arctic sea ice entered a new phase\nwith thinner ice and accelerated melting, there is a possibility that an ML\nmodel trained with historical sea ice data cannot fully represent the\ndynamically changing sea ice conditions in the future. In this study, we\ndevelop physics-informed neural network (PINN) strategies to integrate physical\nknowledge of sea ice into the ML model. Based on the Hierarchical\nInformation-sharing U-net (HIS-Unet) architecture, we incorporate the physics\nloss function and the activation function to produce physically plausible SIV\nand SIC outputs. Our PINN model outperforms the fully data-driven model in the\ndaily predictions of SIV and SIC, even when trained with a small number of\nsamples. The PINN approach particularly improves SIC predictions in melting and\nearly freezing seasons and near fast-moving ice regions."}
{"id": "2510.17773", "pdf": "https://arxiv.org/pdf/2510.17773", "abs": "https://arxiv.org/abs/2510.17773", "authors": ["Md. Enamul Atiq", "Shaikh Anowarul Fattah"], "title": "Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 7 Figures, 3 Tables", "summary": "Skin cancer is a life-threatening disease where early detection significantly\nimproves patient outcomes. Automated diagnosis from dermoscopic images is\nchallenging due to high intra-class variability and subtle inter-class\ndifferences. Many deep learning models operate as \"black boxes,\" limiting\nclinical trust. In this work, we propose a dual-encoder attention-based\nframework that leverages both segmented lesions and clinical metadata to\nenhance skin lesion classification in terms of both accuracy and\ninterpretability. A novel Deep-UNet architecture with Dual Attention Gates\n(DAG) and Atrous Spatial Pyramid Pooling (ASPP) is first employed to segment\nlesions. The classification stage uses two DenseNet201 encoders-one on the\noriginal image and another on the segmented lesion whose features are fused via\nmulti-head cross-attention. This dual-input design guides the model to focus on\nsalient pathological regions. In addition, a transformer-based module\nincorporates patient metadata (age, sex, lesion site) into the prediction. We\nevaluate our approach on the HAM10000 dataset and the ISIC 2018 and 2019\nchallenges. The proposed method achieves state-of-the-art segmentation\nperformance and significantly improves classification accuracy and average AUC\ncompared to baseline models. To validate our model's reliability, we use\nGradient-weighted Class Activation Mapping (Grad-CAM) to generate heatmaps.\nThese visualizations confirm that our model's predictions are based on the\nlesion area, unlike models that rely on spurious background features. These\nresults demonstrate that integrating precise lesion segmentation and clinical\ndata with attention-based fusion leads to a more accurate and interpretable\nskin cancer classification model."}
{"id": "2510.17776", "pdf": "https://arxiv.org/pdf/2510.17776", "abs": "https://arxiv.org/abs/2510.17776", "authors": ["Jackson Harmon", "Andreas Hochlehnert", "Matthias Bethge", "Ameya Prabhu"], "title": "Mapping Post-Training Forgetting in Language Models at Scale", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "43 pages,15 figures", "summary": "Scaled post-training now drives many of the largest capability gains in\nlanguage models (LMs), yet its effect on pretrained knowledge remains poorly\nunderstood. Not all forgetting is equal: Forgetting one fact (e.g., a U.S.\npresident or an API call) does not \"average out\" by recalling another. Hence,\nwe propose a sample-wise paradigm to measure what is forgotten and when\nbackward transfer occurs. Our metric counts 1->0 transitions (correct before\npost-training, incorrect after) to quantify forgetting and 0->1 transitions to\nquantify backward transfer. Traditional task averages conflate these effects\nand obscure large changes. For multiple-choice benchmarks, we add\nchance-adjusted variants that subtract the expected contribution of random\nguessing from pre- and post-training accuracies. We apply this framework across\npost-training stages, model sizes, and data scales. Our large-scale analysis\nshows that: (1) Domain-continual pretraining induces moderate forgetting with\nlow-to-moderate backward transfer; (2) RL/SFT post-training applied to base\nmodels and Instruction tuning yields moderate-to-large backward transfer on\nmath and logic with overall low-to-moderate forgetting; (3) Applying RL/SFT to\ninstruction-tuned models is sensitive on data scale: at small scales, both\nforgetting and backward transfer are small; at larger scales, effects are mixed\nand warrant further study with better controls; (4) Model merging does not\nreliably mitigate forgetting. Overall, our framework offers a practical\nyardstick for mapping how post-training alters pretrained knowledge at scale --\nenabling progress towards generally capable AI systems."}
{"id": "2510.17792", "pdf": "https://arxiv.org/pdf/2510.17792", "abs": "https://arxiv.org/abs/2510.17792", "authors": ["Gabriel B. Margolis", "Michelle Wang", "Nolan Fey", "Pulkit Agrawal"], "title": "SoftMimic: Learning Compliant Whole-body Control from Examples", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Website: https://gmargo11.github.io/softmimic/", "summary": "We introduce SoftMimic, a framework for learning compliant whole-body control\npolicies for humanoid robots from example motions. Imitating human motions with\nreinforcement learning allows humanoids to quickly learn new skills, but\nexisting methods incentivize stiff control that aggressively corrects\ndeviations from a reference motion, leading to brittle and unsafe behavior when\nthe robot encounters unexpected contacts. In contrast, SoftMimic enables robots\nto respond compliantly to external forces while maintaining balance and\nposture. Our approach leverages an inverse kinematics solver to generate an\naugmented dataset of feasible compliant motions, which we use to train a\nreinforcement learning policy. By rewarding the policy for matching compliant\nresponses rather than rigidly tracking the reference motion, SoftMimic learns\nto absorb disturbances and generalize to varied tasks from a single motion\nclip. We validate our method through simulations and real-world experiments,\ndemonstrating safe and effective interaction with the environment."}
{"id": "2510.17793", "pdf": "https://arxiv.org/pdf/2510.17793", "abs": "https://arxiv.org/abs/2510.17793", "authors": ["Austin Xu", "Xuan-Phi Nguyen", "Yilun Zhou", "Chien-Sheng Wu", "Caiming Xiong", "Shafiq Joty"], "title": "Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "29 pages, 9 tables, 6 figures", "summary": "Finetuning specialized generative evaluators has emerged as a popular\nparadigm to meet the increasing demand for scalable evaluation during both\ntraining and test-time. However, recent work has largely focused on applying\nnew methodology, such as reinforcement learning (RL), to training evaluators,\nshying away from large-scale, data-driven development. In this work, we focus\non data scaling, curating a set of 2.5M samples spanning five unique evaluation\ntasks (pairwise, step-level, reference-free and reference-based verification,\nand single rating) and multiple domains focused on reasoning evaluation. With\nour data, we train Foundational Automatic Reasoning Evaluators (FARE), a family\nof 8B and 20B (with 3.6B active) parameter evaluators, with a simple iterative\nrejection-sampling supervised finetuning (SFT) approach. FARE-8B challenges\nlarger specialized RL-trained evaluators and FARE-20B sets the new standard for\nopen-source evaluators, surpassing specialized 70B+ evaluators. Beyond static\nbenchmarks, we evaluate FARE in real-world tasks: As inference-time rerankers,\nFARE-20B achieves near-oracle performance on MATH. As verifiers in RL training,\nFARE improves the downstream RL-trained model performance by up to 14.1% vs.\nstring-matching verifiers. When initialized from FARE, a continually-finetuned\nFARE-Code outperforms gpt-oss-20B by 65% on evaluating test-case quality."}
{"id": "2510.17795", "pdf": "https://arxiv.org/pdf/2510.17795", "abs": "https://arxiv.org/abs/2510.17795", "authors": ["Yujie Luo", "Zhuoyun Yu", "Xuehai Wang", "Yuqi Zhu", "Ningyu Zhang", "Lanning Wei", "Lun Du", "Da Zheng", "Huajun Chen"], "title": "Executable Knowledge Graphs for Replicating AI Research", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA", "cs.SE"], "comment": "Work in progress", "summary": "Replicating AI research is a crucial yet challenging task for large language\nmodel (LLM) agents. Existing approaches often struggle to generate executable\ncode, primarily due to insufficient background knowledge and the limitations of\nretrieval-augmented generation (RAG) methods, which fail to capture latent\ntechnical details hidden in referenced papers. Furthermore, previous approaches\ntend to overlook valuable implementation-level code signals and lack structured\nknowledge representations that support multi-granular retrieval and reuse. To\novercome these challenges, we propose Executable Knowledge Graphs (xKG), a\nmodular and pluggable knowledge base that automatically integrates technical\ninsights, code snippets, and domain-specific knowledge extracted from\nscientific literature. When integrated into three agent frameworks with two\ndifferent LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on\nPaperBench, demonstrating its effectiveness as a general and extensible\nsolution for automated AI research replication. Code will released at\nhttps://github.com/zjunlp/xKG."}
{"id": "2510.17797", "pdf": "https://arxiv.org/pdf/2510.17797", "abs": "https://arxiv.org/abs/2510.17797", "authors": ["Akshara Prabhakar", "Roshan Ram", "Zixiang Chen", "Silvio Savarese", "Frank Wang", "Caiming Xiong", "Huan Wang", "Weiran Yao"], "title": "Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics", "categories": ["cs.CL", "cs.AI"], "comment": "Technical report; 13 pages plus references and appendices", "summary": "As information grows exponentially, enterprises face increasing pressure to\ntransform unstructured data into coherent, actionable insights. While\nautonomous agents show promise, they often struggle with domain-specific\nnuances, intent alignment, and enterprise integration. We present Enterprise\nDeep Research (EDR), a multi-agent system that integrates (1) a Master Planning\nAgent for adaptive query decomposition, (2) four specialized search agents\n(General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool\necosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a\nVisualization Agent for data-driven insights, and (5) a reflection mechanism\nthat detects knowledge gaps and updates research direction with optional\nhuman-in-the-loop steering guidance. These components enable automated report\ngeneration, real-time streaming, and seamless enterprise deployment, as\nvalidated on internal datasets. On open-ended benchmarks including DeepResearch\nBench and DeepConsult, EDR outperforms state-of-the-art agentic systems without\nany human steering. We release the EDR framework and benchmark trajectories to\nadvance research on multi-agent reasoning applications.\n  Code at https://github.com/SalesforceAIResearch/enterprise-deep-research and\nDataset at https://huggingface.co/datasets/Salesforce/EDR-200"}
{"id": "2510.17802", "pdf": "https://arxiv.org/pdf/2510.17802", "abs": "https://arxiv.org/abs/2510.17802", "authors": ["Rui Pan", "Yang Luo", "Yuxing Liu", "Yang You", "Tong Zhang"], "title": "Unbiased Gradient Low-Rank Projection", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "Memory-efficient optimization is critical for training increasingly large\nlanguage models (LLMs). A popular strategy involves gradient low-rank\nprojection, storing only the projected optimizer states, with GaLore being a\nrepresentative example. However, a significant drawback of many such methods is\ntheir lack of convergence guarantees, as various low-rank projection approaches\nintroduce inherent biases relative to the original optimization algorithms,\nwhich contribute to performance gaps compared to full-parameter training.\nAiming to tackle this problem, this paper investigates the layerwise sampling\ntechnique for debiasing low-rank projection mechanisms. In particular, an\ninstantiation of the paradigm gives rise to a novel and unbiased low-rank\noptimization method built upon GaLore's mechanism and the Muon algorithm, named\nGaLore Unbiased with Muon (GUM). We theoretically prove our method matches the\nconvergence guarantees of the base Muon algorithm while preserving the memory\nefficiency of low-rank techniques. Empirical experiments on LLM fine-tuning and\npretraining also demonstrate non-trivial improvements over GaLore and even\nbetter performance than full-parameter training. Further investigation shows\nthat the improvement of this technique comes from a more uniform distribution\nof knowledge inside layers, leading to more efficient utilization of the model\nparameter space and better memorization."}
