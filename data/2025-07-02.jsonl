{"id": "2507.00008", "pdf": "https://arxiv.org/pdf/2507.00008", "abs": "https://arxiv.org/abs/2507.00008", "authors": ["Hang Wu", "Hongkai Chen", "Yujun Cai", "Chang Liu", "Qingwen Ye", "Ming-Hsuan Yang", "Yiwei Wang"], "title": "DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning", "categories": ["cs.AI", "cs.CV", "cs.HC"], "comment": "8 pages, 6 figures", "summary": "Grounding natural language queries in graphical user interfaces (GUIs) poses\nunique challenges due to the diversity of visual elements, spatial clutter, and\nthe ambiguity of language. In this paper, we introduce DiMo-GUI, a\ntraining-free framework for GUI grounding that leverages two core strategies:\ndynamic visual grounding and modality-aware optimization. Instead of treating\nthe GUI as a monolithic image, our method splits the input into textual\nelements and iconic elements, allowing the model to reason over each modality\nindependently using general-purpose vision-language models. When predictions\nare ambiguous or incorrect, DiMo-GUI dynamically focuses attention by\ngenerating candidate focal regions centered on the model's initial predictions\nand incrementally zooms into subregions to refine the grounding result. This\nhierarchical refinement process helps disambiguate visually crowded layouts\nwithout the need for additional training or annotations. We evaluate our\napproach on standard GUI grounding benchmarks and demonstrate consistent\nimprovements over baseline inference pipelines, highlighting the effectiveness\nof combining modality separation with region-focused reasoning."}
{"id": "2507.00041", "pdf": "https://arxiv.org/pdf/2507.00041", "abs": "https://arxiv.org/abs/2507.00041", "authors": ["Varun Mannam", "Fang Wang", "Chaochun Liu", "Xin Chen"], "title": "TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables", "categories": ["cs.AI", "cs.CV", "cs.IR"], "comment": "Submitted to KDD conference, workshop: Talent and Management\n  Computing (TMC 2025), https://tmcworkshop.github.io/2025/", "summary": "In talent management systems, critical information often resides in complex\ntabular formats, presenting significant retrieval challenges for conventional\nlanguage models. These challenges are pronounced when processing Talent\ndocumentation that requires precise interpretation of tabular relationships for\naccurate information retrieval and downstream decision-making. Current table\nextraction methods struggle with semantic understanding, resulting in poor\nperformance when integrated into retrieval-augmented chat applications. This\npaper identifies a key bottleneck - while structural table information can be\nextracted, the semantic relationships between tabular elements are lost,\ncausing downstream query failures. To address this, we introduce TalentMine, a\nnovel LLM-enhanced framework that transforms extracted tables into semantically\nenriched representations. Unlike conventional approaches relying on CSV or text\nlinearization, our method employs specialized multimodal reasoning to preserve\nboth structural and semantic dimensions of tabular data. Experimental\nevaluation across employee benefits document collections demonstrates\nTalentMine's superior performance, achieving 100% accuracy in query answering\ntasks compared to 0% for standard AWS Textract extraction and 40% for AWS\nTextract Visual Q&A capabilities. Our comparative analysis also reveals that\nthe Claude v3 Haiku model achieves optimal performance for talent management\napplications. The key contributions of this work include (1) a systematic\nanalysis of semantic information loss in current table extraction pipelines,\n(2) a novel LLM-based method for semantically enriched table representation,\n(3) an efficient integration framework for retrieval-augmented systems as\nend-to-end systems, and (4) comprehensive benchmarks on talent analytics tasks\nshowing substantial improvements across multiple categories."}
{"id": "2507.00048", "pdf": "https://arxiv.org/pdf/2507.00048", "abs": "https://arxiv.org/abs/2507.00048", "authors": ["Thomas M. Deucher", "Juan C. Verduzco", "Michael Titus", "Alejandro Strachan"], "title": "A collaborative digital twin built on FAIR data and compute infrastructure", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.CE", "cs.LG"], "comment": "10 pages, 5 figures", "summary": "The integration of machine learning with automated experimentation in\nself-driving laboratories (SDL) offers a powerful approach to accelerate\ndiscovery and optimization tasks in science and engineering applications. When\nsupported by findable, accessible, interoperable, and reusable (FAIR) data\ninfrastructure, SDLs with overlapping interests can collaborate more\neffectively. This work presents a distributed SDL implementation built on\nnanoHUB services for online simulation and FAIR data management. In this\nframework, geographically dispersed collaborators conducting independent\noptimization tasks contribute raw experimental data to a shared central\ndatabase. These researchers can then benefit from analysis tools and machine\nlearning models that automatically update as additional data become available.\nNew data points are submitted through a simple web interface and automatically\nprocessed using a nanoHUB Sim2L, which extracts derived quantities and indexes\nall inputs and outputs in a FAIR data repository called ResultsDB. A separate\nnanoHUB workflow enables sequential optimization using active learning, where\nresearchers define the optimization objective, and machine learning models are\ntrained on-the-fly with all existing data, guiding the selection of future\nexperiments. Inspired by the concept of ``frugal twin\", the optimization task\nseeks to find the optimal recipe to combine food dyes to achieve the desired\ntarget color. With easily accessible and inexpensive materials, researchers and\nstudents can set up their own experiments, share data with collaborators, and\nexplore the combination of FAIR data, predictive ML models, and sequential\noptimization. The tools introduced are generally applicable and can easily be\nextended to other optimization problems."}
{"id": "2507.00050", "pdf": "https://arxiv.org/pdf/2507.00050", "abs": "https://arxiv.org/abs/2507.00050", "authors": ["Devin Y. De Silva", "Sandareka Wickramanayake", "Dulani Meedeniya", "Sanka Rasnayaka"], "title": "SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network", "categories": ["cs.AI", "cs.HC", "cs.LG", "I.2.0"], "comment": null, "summary": "Human Activity Recognition (HAR), which uses data from Inertial Measurement\nUnit (IMU) sensors, has many practical applications in healthcare and assisted\nliving environments. However, its use in real-world scenarios has been limited\nby the lack of comprehensive IMU-based HAR datasets that cover a wide range of\nactivities and the lack of transparency in existing HAR models. Zero-shot HAR\n(ZS-HAR) overcomes the data limitations, but current models struggle to explain\ntheir decisions, making them less transparent. This paper introduces a novel\nIMU-based ZS-HAR model called the Self-Explainable Zero-shot Human Activity\nRecognition Network (SEZ-HARN). It can recognize activities not encountered\nduring training and provide skeleton videos to explain its decision-making\nprocess. We evaluate the effectiveness of the proposed SEZ-HARN on four\nbenchmark datasets PAMAP2, DaLiAc, HTD-MHAD and MHealth and compare its\nperformance against three state-of-the-art black-box ZS-HAR models. The\nexperiment results demonstrate that SEZ-HARN produces realistic and\nunderstandable explanations while achieving competitive Zero-shot recognition\naccuracy. SEZ-HARN achieves a Zero-shot prediction accuracy within 3\\% of the\nbest-performing black-box model on PAMAP2 while maintaining comparable\nperformance on the other three datasets."}
{"id": "2507.00054", "pdf": "https://arxiv.org/pdf/2507.00054", "abs": "https://arxiv.org/abs/2507.00054", "authors": ["Shreyansh Padarha"], "title": "Enhancing Reasoning Capabilities in SLMs with Reward Guided Dataset Distillation", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "17 Pages, 7 figures", "summary": "The push to compress and impart the proficiency of Large Language Models\n(LLMs) into more deployable and efficient Small Language Models (SLMs) has\nbenefited from improvements in knowledge distillation (KD) techniques. These\ntechniques allow a smaller student model to learn from a more capable and\nlarger teacher model's responses. However, distillation often revolves around\nthe student model merely copying the teacher's in-distribution responses,\nlimiting its generalisability. This limitation is amplified on reasoning tasks\nand can be computationally expensive. In this study, we propose AdvDistill, a\nreward-guided dataset distillation framework. We utilise multiple generations\n(responses) from a teacher for each prompt and assign rewards based on\nrule-based verifiers. These varying and normally distributed rewards serve as\nweights when training student models. Our methods and their subsequent\nbehavioural analysis demonstrate a significant improvement in student model\nperformance for mathematical and complex reasoning tasks, showcasing the\nefficacy and benefits of incorporating a rewarding mechanism in dataset\ndistillation processes."}
{"id": "2507.00079", "pdf": "https://arxiv.org/pdf/2507.00079", "abs": "https://arxiv.org/abs/2507.00079", "authors": ["Ethan Smyth", "Alessandro Suglia"], "title": "VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems", "categories": ["cs.AI", "cs.LG"], "comment": "website: https://esmyth-dev.github.io/VoyagerVision.github.io/", "summary": "Open-endedness is an active field of research in the pursuit of capable\nArtificial General Intelligence (AGI), allowing models to pursue tasks of their\nown choosing. Simultaneously, recent advancements in Large Language Models\n(LLMs) such as GPT-4o [9] have allowed such models to be capable of\ninterpreting image inputs. Implementations such as OMNI-EPIC [4] have made use\nof such features, providing an LLM with pixel data of an agent's POV to parse\nthe environment and allow it to solve tasks. This paper proposes that providing\nthese visual inputs to a model gives it greater ability to interpret spatial\nenvironments, and as such, can increase the number of tasks it can successfully\nperform, extending its open-ended potential. To this aim, this paper proposes\nVoyagerVision -- a multi-modal model capable of creating structures within\nMinecraft using screenshots as a form of visual feedback, building on the\nfoundation of Voyager. VoyagerVision was capable of creating an average of 2.75\nunique structures within fifty iterations of the system, as Voyager was\nincapable of this, it is an extension in an entirely new direction.\nAdditionally, in a set of building unit tests VoyagerVision was successful in\nhalf of all attempts in flat worlds, with most failures arising in more complex\nstructures. Project website is available at\nhttps://esmyth-dev.github.io/VoyagerVision.github.io/"}
{"id": "2507.00092", "pdf": "https://arxiv.org/pdf/2507.00092", "abs": "https://arxiv.org/abs/2507.00092", "authors": ["Basab Jha", "Firoj Paudel", "Ujjwal Puri", "Zhang Yuting", "Choi Donghyuk", "Wang Junhao"], "title": "Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "19 pages, 2 figures, 9 tables", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities at\nsolving complex reasoning tasks with Chain-of-Thought (CoT) prompting, but\ntheir decision-making processes remain somewhat blackbox. We introduce\ntextbfinverse reasoning, a novel paradigm enabling LLMs to decompose and\nexplain their own reasoning chains post-hoc. Our approach, used in SAGE-nano, a\n4-billion-parameter reasoning model, employs a metacognitive structure that\nreflects back via attention processes to identify major decision points and\ngenerate explanations of reasoning choices. While typical CoT approaches are\ndirected towards forward reasoning generation, inverse reasoning provides\ninsight into why specific reasoning chains were selected over others. Through\nthorough testing of logical reasoning puzzles, math problems and ethical\ndilemmas from AQUA-RAT, CommonsenseQA, and customized benchmarks, we\ndemonstrate that SAGE-nano is at the cutting edge both on reasoning accuracy\n(74.6% on AQUA-RAT) and explanation quality (92.1% human preference score) for\nits task, and offers performance almost on par with models like Claude-3.5\nSonnet or GPT-4o. Our contributions are: (i) the first rigorous framework for\nLLM self-reflection via inverse reasoning, (ii) a novel metalearning framework\nto reverse the attention flow, (iii) comprehensive evaluation frameworks for\nreasoning transparency, and (iv) evidence that increasing reasoning using\ninverse reasoning improves interpretability along with reasoning performance.\nOur work creates new avenues for transparent AI systems and closes significant\ngaps in AI safety, education, and scientific discovery."}
{"id": "2507.00180", "pdf": "https://arxiv.org/pdf/2507.00180", "abs": "https://arxiv.org/abs/2507.00180", "authors": ["Vidhi Rathore"], "title": "BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Modernizing legacy software systems is a critical but challenging task, often\nhampered by a lack of documentation and understanding of the original system's\nintricate decision logic. Traditional approaches like behavioral cloning merely\nreplicate input-output behavior without capturing the underlying intent. This\npaper proposes a novel pipeline to automatically extract interpretable decision\nlogic from legacy systems treated as black boxes. The approach uses a\nReinforcement Learning (RL) agent to explore the input space and identify\ncritical decision boundaries by rewarding actions that cause meaningful changes\nin the system's output. These counterfactual state transitions, where the\noutput changes, are collected and clustered using K-Means. Decision trees are\nthen trained on these clusters to extract human-readable rules that approximate\nthe system's decision logic near the identified boundaries. I demonstrated the\npipeline's effectiveness on three dummy legacy systems with varying complexity,\nincluding threshold-based, combined-conditional, and non-linear range logic.\nResults show that the RL agent successfully focuses exploration on relevant\nboundary regions, and the extracted rules accurately reflect the core logic of\nthe underlying dummy systems, providing a promising foundation for generating\nspecifications and test cases during legacy migration."}
{"id": "2507.00181", "pdf": "https://arxiv.org/pdf/2507.00181", "abs": "https://arxiv.org/abs/2507.00181", "authors": ["Georgios P. Georgiou"], "title": "ChatGPT produces more \"lazy\" thinkers: Evidence of cognitive engagement decline", "categories": ["cs.AI"], "comment": null, "summary": "Despite the increasing use of large language models (LLMs) in education,\nconcerns have emerged about their potential to reduce deep thinking and active\nlearning. This study investigates the impact of generative artificial\nintelligence (AI) tools, specifically ChatGPT, on the cognitive engagement of\nstudents during academic writing tasks. The study employed an experimental\ndesign with participants randomly assigned to either an AI-assisted (ChatGPT)\nor a non-assisted (control) condition. Participants completed a structured\nargumentative writing task followed by a cognitive engagement scale (CES), the\nCES-AI, developed to assess mental effort, attention, deep processing, and\nstrategic thinking. The results revealed significantly lower cognitive\nengagement scores in the ChatGPT group compared to the control group. These\nfindings suggest that AI assistance may lead to cognitive offloading. The study\ncontributes to the growing body of literature on the psychological implications\nof AI in education and raises important questions about the integration of such\ntools into academic practice. It calls for pedagogical strategies that promote\nactive, reflective engagement with AI-generated content to avoid compromising\nself-regulated learning and deep cognitive involvement of students."}
{"id": "2507.00205", "pdf": "https://arxiv.org/pdf/2507.00205", "abs": "https://arxiv.org/abs/2507.00205", "authors": ["Periklis Petridis", "Georgios Margaritis", "Vasiliki Stoumpou", "Dimitris Bertsimas"], "title": "Holistic Artificial Intelligence in Medicine; improved performance and explainability", "categories": ["cs.AI", "cs.LG"], "comment": "Submitted to npj Digital Medicine", "summary": "With the increasing interest in deploying Artificial Intelligence in\nmedicine, we previously introduced HAIM (Holistic AI in Medicine), a framework\nthat fuses multimodal data to solve downstream clinical tasks. However, HAIM\nuses data in a task-agnostic manner and lacks explainability. To address these\nlimitations, we introduce xHAIM (Explainable HAIM), a novel framework\nleveraging Generative AI to enhance both prediction and explainability through\nfour structured steps: (1) automatically identifying task-relevant patient data\nacross modalities, (2) generating comprehensive patient summaries, (3) using\nthese summaries for improved predictive modeling, and (4) providing clinical\nexplanations by linking predictions to patient-specific medical knowledge.\nEvaluated on the HAIM-MIMIC-MM dataset, xHAIM improves average AUC from 79.9%\nto 90.3% across chest pathology and operative tasks. Importantly, xHAIM\ntransforms AI from a black-box predictor into an explainable decision support\nsystem, enabling clinicians to interactively trace predictions back to relevant\npatient data, bridging AI advancements with clinical utility."}
{"id": "2507.00218", "pdf": "https://arxiv.org/pdf/2507.00218", "abs": "https://arxiv.org/abs/2507.00218", "authors": ["Fangting Zhou", "Attila Lischka", "Balazs Kulcsar", "Jiaming Wu", "Morteza Haghir Chehreghani", "Gilbert Laporte"], "title": "Learning for routing: A guided review of recent developments and future directions", "categories": ["cs.AI", "math.OC"], "comment": "Accepted for publication in Transportation Research Part E: Logistics\n  and Transportation Review", "summary": "This paper reviews the current progress in applying machine learning (ML)\ntools to solve NP-hard combinatorial optimization problems, with a focus on\nrouting problems such as the traveling salesman problem (TSP) and the vehicle\nrouting problem (VRP). Due to the inherent complexity of these problems, exact\nalgorithms often require excessive computational time to find optimal\nsolutions, while heuristics can only provide approximate solutions without\nguaranteeing optimality. With the recent success of machine learning models,\nthere is a growing trend in proposing and implementing diverse ML techniques to\nenhance the resolution of these challenging routing problems. We propose a\ntaxonomy categorizing ML-based routing methods into construction-based and\nimprovement-based approaches, highlighting their applicability to various\nproblem characteristics. This review aims to integrate traditional OR methods\nwith state-of-the-art ML techniques, providing a structured framework to guide\nfuture research and address emerging VRP variants."}
{"id": "2507.00417", "pdf": "https://arxiv.org/pdf/2507.00417", "abs": "https://arxiv.org/abs/2507.00417", "authors": ["Joongwon Kim", "Anirudh Goyal", "Liang Tan", "Hannaneh Hajishirzi", "Srinivasan Iyer", "Tianlu Wang"], "title": "ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context", "categories": ["cs.AI", "cs.CL"], "comment": "36 pages, 23 figures", "summary": "We introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework\nfor training language models to reason like search algorithms, explicitly\nleveraging self-reflection, backtracking, and exploration in their outputs.\nRecently, training large language models (LLMs) via reinforcement learning (RL)\nhas led to the advent of reasoning models with greatly enhanced reasoning\ncapabilities. Open-source replications of reasoning models, while successful,\nbuild upon models that already exhibit strong reasoning capabilities along with\nsearch behavior observed even before RL. As a result, it is yet unclear how to\nboost the reasoning capabilities of other non-reasoner models including Llama\n3. ASTRO teaches such models to internalize structured search behavior through\na synthetic dataset derived from Monte Carlo Tree Search (MCTS) over\nmathematical problem-solving trajectories. By converting search traces into\nnatural language chain-of-thoughts that capture both successes and recoveries\nfrom failure, ASTRO bootstraps models with a rich prior for exploration during\nRL. We finetune our models on these search-derived traces and further improve\nperformance via RL with verifiable rewards. We apply ASTRO to the Llama 3\nfamily of models and achieve absolute performance gains of 16.0% on MATH-500,\n26.9% on AMC 2023, and 20.0% on AIME 2024, especially improving upon\nchallenging problems that require iterative correction. Our results demonstrate\nthat search-inspired training offers a principled way to instill robust\nreasoning capabilities into open LLMs."}
{"id": "2507.00432", "pdf": "https://arxiv.org/pdf/2507.00432", "abs": "https://arxiv.org/abs/2507.00432", "authors": ["Maggie Huan", "Yuetai Li", "Tuney Zheng", "Xiaoyu Xu", "Seungone Kim", "Minxin Du", "Radha Poovendran", "Graham Neubig", "Xiang Yue"], "title": "Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Math reasoning has become the poster child of progress in large language\nmodels (LLMs), with new models rapidly surpassing human-level performance on\nbenchmarks like MATH and AIME. But as math leaderboards improve week by week,\nit is worth asking: do these gains reflect broader problem-solving ability or\njust narrow overfitting? To answer this question, we evaluate over 20\nopen-weight reasoning-tuned models across a broad suite of tasks, including\nmath, scientific QA, agent planning, coding, and standard\ninstruction-following. We surprisingly find that most models that succeed in\nmath fail to transfer their gains to other domains. To rigorously study this\nphenomenon, we conduct controlled experiments on Qwen3-14B models using\nmath-only data but different tuning methods. We find that reinforcement\nlearning (RL)-tuned models generalize well across domains, while supervised\nfine-tuning (SFT)-tuned models often forget general capabilities. Latent-space\nrepresentation and token-space distribution shift analyses reveal that SFT\ninduces substantial representation and output drift, while RL preserves\ngeneral-domain structure. Our results suggest a need to rethink standard\npost-training recipes, particularly the reliance on SFT-distilled data for\nadvancing reasoning models."}
{"id": "2507.00557", "pdf": "https://arxiv.org/pdf/2507.00557", "abs": "https://arxiv.org/abs/2507.00557", "authors": ["Tianyi Ding", "Haokun Li", "Xinpeng Ni", "Bican Xia", "Tianqi Zhao"], "title": "Advancing Local Search in SMT-NRA with MCSAT Integration", "categories": ["cs.AI", "cs.LO", "cs.SC"], "comment": null, "summary": "In this paper, we advance local search for Satisfiability Modulo the Theory\nof Nonlinear Real Arithmetic (SMT-NRA for short). First, we introduce a\ntwo-dimensional cell-jump move, called \\emph{$2d$-cell-jump}, generalizing the\nkey operation, cell-jump, of the local search method for SMT-NRA. Then, we\npropose an extended local search framework, named \\emph{$2d$-LS} (following the\nlocal search framework, LS, for SMT-NRA), integrating the model constructing\nsatisfiability calculus (MCSAT) framework to improve search efficiency. To\nfurther improve the efficiency of MCSAT, we implement a recently proposed\ntechnique called \\emph{sample-cell projection operator} for MCSAT, which is\nwell suited for CDCL-style search in the real domain and helps guide the search\naway from conflicting states. Finally, we design a hybrid framework for SMT-NRA\ncombining MCSAT, $2d$-LS and OpenCAD, to improve search efficiency through\ninformation exchange. The experimental results demonstrate improvements in\nlocal search performance, highlighting the effectiveness of the proposed\nmethods."}
{"id": "2507.00726", "pdf": "https://arxiv.org/pdf/2507.00726", "abs": "https://arxiv.org/abs/2507.00726", "authors": ["Dongyoon Hwang", "Hojoon Lee", "Jaegul Choo", "Dongmin Park", "Jongho Park"], "title": "Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess", "categories": ["cs.AI", "cs.LG"], "comment": "27 pages", "summary": "While reinforcement learning (RL) for large language models (LLMs) has shown\npromise in mathematical reasoning, strategic reasoning for LLMs using RL\nremains largely unexplored. We investigate whether LLMs can develop strategic\nreasoning capabilities through RL in chess. To this end, we leverage a\nchess-pretrained action-value network to provide dense reward on the LLM's\noutput move quality, which can be seen as a form of knowledge distillation. Our\nexperiments show that our distillation-based dense rewards often outperform\nsparse binary rewards. However, surprisingly, all models plateau far below\nexpert levels. We provide SFT and RL ablations on chess reasoning training and\nfind evidence that this limitation stems from a deficit in the pretrained\nmodels' internal understanding of chess--a deficit which RL alone may not be\nable to fully overcome."}
{"id": "2507.00810", "pdf": "https://arxiv.org/pdf/2507.00810", "abs": "https://arxiv.org/abs/2507.00810", "authors": ["Qing Xu", "Xiaohua Xuan"], "title": "A Robust Algorithm for Non-IID Machine Learning Problems with Convergence Analysis", "categories": ["cs.AI", "math.OC"], "comment": null, "summary": "In this paper, we propose an improved numerical algorithm for solving minimax\nproblems based on nonsmooth optimization, quadratic programming and iterative\nprocess. We also provide a rigorous proof of convergence for our algorithm\nunder some mild assumptions, such as gradient continuity and boundedness. Such\nan algorithm can be widely applied in various fields such as robust\noptimization, imbalanced learning, etc."}
{"id": "2507.00841", "pdf": "https://arxiv.org/pdf/2507.00841", "abs": "https://arxiv.org/abs/2507.00841", "authors": ["Siyuan Liang", "Tianmeng Fang", "Zhe Liu", "Aishan Liu", "Yan Xiao", "Jinyuan He", "Ee-Chien Chang", "Xiaochun Cao"], "title": "SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents", "categories": ["cs.AI", "cs.CR"], "comment": "12 pages", "summary": "With the wide application of multimodal foundation models in intelligent\nagent systems, scenarios such as mobile device control, intelligent assistant\ninteraction, and multimodal task execution are gradually relying on such large\nmodel-driven agents. However, the related systems are also increasingly exposed\nto potential jailbreak risks. Attackers may induce the agents to bypass the\noriginal behavioral constraints through specific inputs, and then trigger\ncertain risky and sensitive operations, such as modifying settings, executing\nunauthorized commands, or impersonating user identities, which brings new\nchallenges to system security. Existing security measures for intelligent\nagents still have limitations when facing complex interactions, especially in\ndetecting potentially risky behaviors across multiple rounds of conversations\nor sequences of tasks. In addition, an efficient and consistent automated\nmethodology to assist in assessing and determining the impact of such risks is\ncurrently lacking. This work explores the security issues surrounding mobile\nmultimodal agents, attempts to construct a risk discrimination mechanism by\nincorporating behavioral sequence information, and designs an automated\nassisted assessment scheme based on a large language model. Through preliminary\nvalidation in several representative high-risk tasks, the results show that the\nmethod can improve the recognition of risky behaviors to some extent and assist\nin reducing the probability of agents being jailbroken. We hope that this study\ncan provide some valuable references for the security risk modeling and\nprotection of multimodal intelligent agent systems."}
{"id": "2507.00951", "pdf": "https://arxiv.org/pdf/2507.00951", "abs": "https://arxiv.org/abs/2507.00951", "authors": ["Rizwan Qureshi", "Ranjan Sapkota", "Abbas Shah", "Amgad Muneer", "Anas Zafar", "Ashmal Vayani", "Maged Shoman", "Abdelrahman B. M. Eldaly", "Kai Zhang", "Ferhat Sadak", "Shaina Raza", "Xinqi Fan", "Ravid Shwartz-Ziv", "Hong Yan", "Vinjia Jain", "Aman Chadha", "Manoj Karkee", "Jia Wu", "Philip Torr", "Seyedali Mirjalili"], "title": "Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact", "categories": ["cs.AI"], "comment": null, "summary": "Can machines truly think, reason and act in domains like humans? This\nenduring question continues to shape the pursuit of Artificial General\nIntelligence (AGI). Despite the growing capabilities of models such as GPT-4.5,\nDeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal\nfluency and partial reasoning, these systems remain fundamentally limited by\ntheir reliance on token-level prediction and lack of grounded agency. This\npaper offers a cross-disciplinary synthesis of AGI development, spanning\nartificial intelligence, cognitive neuroscience, psychology, generative models,\nand agent-based systems. We analyze the architectural and cognitive foundations\nof general intelligence, highlighting the role of modular reasoning, persistent\nmemory, and multi-agent coordination. In particular, we emphasize the rise of\nAgentic RAG frameworks that combine retrieval, planning, and dynamic tool use\nto enable more adaptive behavior. We discuss generalization strategies,\nincluding information compression, test-time adaptation, and training-free\nmethods, as critical pathways toward flexible, domain-agnostic intelligence.\nVision-Language Models (VLMs) are reexamined not just as perception modules but\nas evolving interfaces for embodied understanding and collaborative task\ncompletion. We also argue that true intelligence arises not from scale alone\nbut from the integration of memory and reasoning: an orchestration of modular,\ninteractive, and self-improving components where compression enables adaptive\nbehavior. Drawing on advances in neurosymbolic systems, reinforcement learning,\nand cognitive scaffolding, we explore how recent architectures begin to bridge\nthe gap between statistical learning and goal-directed cognition. Finally, we\nidentify key scientific, technical, and ethical challenges on the path to AGI."}
{"id": "2507.00979", "pdf": "https://arxiv.org/pdf/2507.00979", "abs": "https://arxiv.org/abs/2507.00979", "authors": ["Dongyoon Hahm", "Woogyeol Jin", "June Suk Choi", "Sungsoo Ahn", "Kimin Lee"], "title": "Enhancing LLM Agent Safety via Causal Influence Prompting", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted at ACL 2025 Findings, Source code:\n  https://github.com/HahmDY/causal_influence_prompting.git", "summary": "As autonomous agents powered by large language models (LLMs) continue to\ndemonstrate potential across various assistive tasks, ensuring their safe and\nreliable behavior is crucial for preventing unintended consequences. In this\nwork, we introduce CIP, a novel technique that leverages causal influence\ndiagrams (CIDs) to identify and mitigate risks arising from agent\ndecision-making. CIDs provide a structured representation of cause-and-effect\nrelationships, enabling agents to anticipate harmful outcomes and make safer\ndecisions. Our approach consists of three key steps: (1) initializing a CID\nbased on task specifications to outline the decision-making process, (2)\nguiding agent interactions with the environment using the CID, and (3)\niteratively refining the CID based on observed behaviors and outcomes.\nExperimental results demonstrate that our method effectively enhances safety in\nboth code execution and mobile device control tasks."}
{"id": "2507.00002", "pdf": "https://arxiv.org/pdf/2507.00002", "abs": "https://arxiv.org/abs/2507.00002", "authors": ["Christopher James Augeri"], "title": "Hypertokens: Holographic Associative Memory in Tokenized LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "preprint as accepted to https://qnlp.ai/ - Quantum AI and NLP\n  Conference 2025", "summary": "Large Language Models (LLMs) exhibit remarkable capabilities but suffer from\napparent precision loss, reframed here as information spreading. This reframing\nshifts the problem from computational precision to an information-theoretic\ncommunication issue. We address the K:V and V:K memory problem in LLMs by\nintroducing HDRAM (Holographically Defined Random Access Memory), a symbolic\nmemory framework treating transformer latent space as a spread-spectrum\nchannel. Built upon hypertokens, structured symbolic codes integrating\nclassical error-correcting codes (ECC), holographic computing, and\nquantum-inspired search, HDRAM recovers distributed information through\nprincipled despreading. These phase-coherent memory addresses enable efficient\nkey-value operations and Grover-style search in latent space. By combining ECC\ngrammar with compressed sensing and Krylov subspace alignment, HDRAM\nsignificantly improves associative retrieval without architectural changes,\ndemonstrating how Classical-Holographic-Quantum-inspired (CHQ) principles can\nfortify transformer architectures."}
{"id": "2507.00003", "pdf": "https://arxiv.org/pdf/2507.00003", "abs": "https://arxiv.org/abs/2507.00003", "authors": ["Eyhab Al-Masri"], "title": "Deciding When Not to Decide: Indeterminacy-Aware Intrusion Detection with NeutroSENSE", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.NI"], "comment": null, "summary": "This paper presents NeutroSENSE, a neutrosophic-enhanced ensemble framework\nfor interpretable intrusion detection in IoT environments. By integrating\nRandom Forest, XGBoost, and Logistic Regression with neutrosophic logic, the\nsystem decomposes prediction confidence into truth (T), falsity (F), and\nindeterminacy (I) components, enabling uncertainty quantification and\nabstention. Predictions with high indeterminacy are flagged for review using\nboth global and adaptive, class-specific thresholds. Evaluated on the IoT-CAD\ndataset, NeutroSENSE achieved 97% accuracy, while demonstrating that\nmisclassified samples exhibit significantly higher indeterminacy (I = 0.62)\nthan correct ones (I = 0.24). The use of indeterminacy as a proxy for\nuncertainty enables informed abstention and targeted review-particularly\nvaluable in edge deployments. Figures and tables validate the correlation\nbetween I-scores and error likelihood, supporting more trustworthy,\nhuman-in-the-loop AI decisions. This work shows that neutrosophic logic\nenhances both accuracy and explainability, providing a practical foundation for\ntrust-aware AI in edge and fog-based IoT security systems."}
{"id": "2507.00004", "pdf": "https://arxiv.org/pdf/2507.00004", "abs": "https://arxiv.org/abs/2507.00004", "authors": ["Austin R. Ellis-Mohr", "Anuj K. Nayak", "Lav R. Varshney"], "title": "A Theory of Inference Compute Scaling: Reasoning through Directed Stochastic Skill Search", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.PF"], "comment": null, "summary": "Large language models (LLMs) demand considerable computational, energy, and\nfinancial resources during both training and deployment. While scaling laws for\ntraining have guided much of the field's recent progress, inference costs now\nrepresent a significant and growing component of the overall resource burden,\nparticularly for reasoning-focused models. Existing characterizations of\ncompute-optimality that consider model size, dataset size, and inference tokens\nin isolation or in fixed combinations risk overlooking more efficient operating\npoints. We introduce directed stochastic skill search (DS3), a general\nframework that represents inference as stochastic traversal over a learned\nskill graph. From a simplified yet expressive instantiation, we derive\nclosed-form expressions for task success and compute cost across a wide range\nof inference strategies -- including chain-of-thought (CoT) and tree-of-thought\n(ToT) -- enabling comparative analysis as a function of task difficulty and\nmodel capability. To that end, we extend a prior first-principles tripartite\ngraph framework of LLM training to incorporate inference, and separately bridge\nDS3 with empirical methods that characterize LLM scaling behavior. We\ntheoretically recover empirically observed patterns, including: linear accuracy\nscaling with logarithmic compute; variation in preferred inference strategies\nas a function of task difficulty and model capability; emergent behavior\nelicited by reasoning even when performance plateaus under parameter scaling;\nand both best-of-N (BoN) and majority voting behavior captured within a unified\nanalytical framework. By explicitly characterizing training-inference\ninterdependencies, our framework deepens theoretical understanding and supports\nprincipled algorithmic design and resource allocation."}
{"id": "2507.00007", "pdf": "https://arxiv.org/pdf/2507.00007", "abs": "https://arxiv.org/abs/2507.00007", "authors": ["Vasiliy Znamenskiy", "Rafael Niyazov", "Joel Hernandez"], "title": "Integrating Universal Generative AI Platforms in Educational Labs to Foster Critical Thinking and Digital Literacy", "categories": ["cs.CY", "cs.AI", "cs.LG", "68T50, 68U20, 97U50, 97D40", "I.2.7; K.3.1; K.3.2; H.5.3"], "comment": "http://doi.org/10.5121/ijci.2025.140302", "summary": "This paper presents a new educational framework for integrating generative\nartificial intelligence (GenAI) platforms such as ChatGPT, Claude, and Gemini\ninto laboratory activities aimed at developing critical thinking and digital\nliteracy among undergraduate students. Recognizing the limitations and risks of\nuncritical reliance on large language models (LLMs), the proposed pedagogical\nmodel reframes GenAI as a research subject and cognitive tool. Students\nformulate discipline-specific prompts and evaluate GenAI-generated responses in\ntext, image, and video modalities. A pilot implementation in a general\nastronomy course for non-science majors demonstrated high levels of engagement\nand critical reflection, with many students continuing the activity after class\nand presenting results at a research symposium. The results highlight the\nimportance of structured AI interactions in education and suggest that GenAI\ncan improve learning outcomes when combined with reflective assessment methods.\nThe study proposes a replicable model for interdisciplinary AI-integrated lab\nwork, adaptable to scientific disciplines. See the guide to learning activities\nbased on Generative-Ai platforms: https://doi.org/10.5281/zenodo.15555802"}
{"id": "2507.00011", "pdf": "https://arxiv.org/pdf/2507.00011", "abs": "https://arxiv.org/abs/2507.00011", "authors": ["Nathan Vaartjes", "Vincent Francois-Lavet"], "title": "Novel RL approach for efficient Elevator Group Control Systems", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 12 figures", "summary": "Efficient elevator traffic management in large buildings is critical for\nminimizing passenger travel times and energy consumption. Because heuristic- or\npattern-detection-based controllers struggle with the stochastic and\ncombinatorial nature of dispatching, we model the six-elevator, fifteen-floor\nsystem at Vrije Universiteit Amsterdam as a Markov Decision Process and train\nan end-to-end Reinforcement Learning (RL) Elevator Group Control System (EGCS).\nKey innovations include a novel action space encoding to handle the\ncombinatorial complexity of elevator dispatching, the introduction of\ninfra-steps to model continuous passenger arrivals, and a tailored reward\nsignal to improve learning efficiency. In addition, we explore various ways to\nadapt the discounting factor to the infra-step formulation. We investigate RL\narchitectures based on Dueling Double Deep Q-learning, showing that the\nproposed RL-based EGCS adapts to fluctuating traffic patterns, learns from a\nhighly stochastic environment, and thereby outperforms a traditional rule-based\nalgorithm."}
{"id": "2507.00012", "pdf": "https://arxiv.org/pdf/2507.00012", "abs": "https://arxiv.org/abs/2507.00012", "authors": ["Linfeng Ye", "Shayan Mohajer Hamidi", "En-hui Yang"], "title": "Towards Undistillable Models by Minimizing Conditional Mutual Information", "categories": ["cs.LG", "cs.AI", "E.4"], "comment": "27 pages, 6 figures, Transactions on Machine Learning Research", "summary": "A deep neural network (DNN) is said to be undistillable if, when used as a\nblack-box input-output teacher, it cannot be distilled through knowledge\ndistillation (KD). In this case, the distilled student (referred to as the\nknockoff student) does not outperform a student trained independently with\nlabel smoothing (LS student) in terms of prediction accuracy. To protect\nintellectual property of DNNs, it is desirable to build undistillable DNNs. To\nthis end, it is first observed that an undistillable DNN may have the trait\nthat each cluster of its output probability distributions in response to all\nsample instances with the same label should be highly concentrated to the\nextent that each cluster corresponding to each label should ideally collapse\ninto one probability distribution. Based on this observation and by measuring\nthe concentration of each cluster in terms of conditional mutual information\n(CMI), a new training method called CMI minimized (CMIM) method is proposed,\nwhich trains a DNN by jointly minimizing the conventional cross entropy (CE)\nloss and the CMI values of all temperature scaled clusters across the entire\ntemperature spectrum. The resulting CMIM model is shown, by extensive\nexperiments, to be undistillable by all tested KD methods existing in the\nliterature. That is, the knockoff students distilled by these KD methods from\nthe CMIM model underperform the respective LS students. In addition, the CMIM\nmodel is also shown to performs better than the model trained with the CE loss\nalone in terms of their own prediction accuracy."}
{"id": "2507.00013", "pdf": "https://arxiv.org/pdf/2507.00013", "abs": "https://arxiv.org/abs/2507.00013", "authors": ["Hyunwoo Seo", "Chiehyeon Lim"], "title": "ST-MTM: Masked Time Series Modeling with Seasonal-Trend Decomposition for Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted by KDD 2025 research track", "summary": "Forecasting complex time series is an important yet challenging problem that\ninvolves various industrial applications. Recently, masked time-series modeling\nhas been proposed to effectively model temporal dependencies for forecasting by\nreconstructing masked segments from unmasked ones. However, since the semantic\ninformation in time series is involved in intricate temporal variations\ngenerated by multiple time series components, simply masking a raw time series\nignores the inherent semantic structure, which may cause MTM to learn spurious\ntemporal patterns present in the raw data. To capture distinct temporal\nsemantics, we show that masked modeling techniques should address entangled\npatterns through a decomposition approach. Specifically, we propose ST-MTM, a\nmasked time-series modeling framework with seasonal-trend decomposition, which\nincludes a novel masking method for the seasonal-trend components that\nincorporates different temporal variations from each component. ST-MTM uses a\nperiod masking strategy for seasonal components to produce multiple masked\nseasonal series based on inherent multi-periodicity and a sub-series masking\nstrategy for trend components to mask temporal regions that share similar\nvariations. The proposed masking method presents an effective pre-training task\nfor learning intricate temporal variations and dependencies. Additionally,\nST-MTM introduces a contrastive learning task to support masked modeling by\nenhancing contextual consistency among multiple masked seasonal\nrepresentations. Experimental results show that our proposed ST-MTM achieves\nconsistently superior forecasting performance compared to existing masked\nmodeling, contrastive learning, and supervised forecasting methods."}
{"id": "2507.00014", "pdf": "https://arxiv.org/pdf/2507.00014", "abs": "https://arxiv.org/abs/2507.00014", "authors": ["Thomas Joshi", "Shayan Chowdhury", "Fatih Uysal"], "title": "SWE-Bench-CL: Continual Learning for Coding Agents", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) have achieved impressive results on static\ncode-generation benchmarks, but real-world software development unfolds as a\ncontinuous stream of evolving issues, fixes, and feature requests. We introduce\nSWE-Bench-CL, a novel continual learning benchmark built on the human-verified\nSWE-Bench Verified dataset introduced by OpenAI and Princeton-NLP in 2024. By\norganizing GitHub issues into chronologically ordered sequences that reflect\nnatural repository evolution, SWE-Bench-CL enables direct evaluation of an\nagent's ability to accumulate experience, transfer knowledge across tasks, and\nresist catastrophic forgetting. We complement the dataset with (i) a\npreliminary analysis of inter-task structural similarity and contextual\nsensitivity, (ii) an interactive LangGraph-based evaluation framework augmented\nwith a FAISS-backed semantic memory module, and (iii) a suite of specialized\ncontinual learning metrics -- including average accuracy, forgetting,\nforward/backward transfer, tool-use efficiency, and a generalized Composite\nContinual Learning Score and CL-F-beta score -- to capture the\nstability-plasticity trade-off. We outline a rigorous experimental protocol\ncomparing memory-enabled and memory-disabled agents across diverse Python\nrepositories. All code and data are publicly available at\nhttps://github.com/thomasjoshi/agents-never-forget, providing the community\nwith a reproducible platform for developing more adaptive and robust AI agents\nin software engineering."}
{"id": "2507.00015", "pdf": "https://arxiv.org/pdf/2507.00015", "abs": "https://arxiv.org/abs/2507.00015", "authors": ["Lu Zhang", "Sangarapillai Lambotharan", "Gan Zheng", "Guisheng Liao", "Xuekang Liu", "Fabio Roli", "Carsten Maple"], "title": "Vision Transformer with Adversarial Indicator Token against Adversarial Attacks in Radio Signal Classifications", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The remarkable success of transformers across various fields such as natural\nlanguage processing and computer vision has paved the way for their\napplications in automatic modulation classification, a critical component in\nthe communication systems of Internet of Things (IoT) devices. However, it has\nbeen observed that transformer-based classification of radio signals is\nsusceptible to subtle yet sophisticated adversarial attacks. To address this\nissue, we have developed a defensive strategy for transformer-based modulation\nclassification systems to counter such adversarial attacks. In this paper, we\npropose a novel vision transformer (ViT) architecture by introducing a new\nconcept known as adversarial indicator (AdvI) token to detect adversarial\nattacks. To the best of our knowledge, this is the first work to propose an\nAdvI token in ViT to defend against adversarial attacks. Integrating an\nadversarial training method with a detection mechanism using AdvI token, we\ncombine a training time defense and running time defense in a unified neural\nnetwork model, which reduces architectural complexity of the system compared to\ndetecting adversarial perturbations using separate models. We investigate into\nthe operational principles of our method by examining the attention mechanism.\nWe show the proposed AdvI token acts as a crucial element within the ViT,\ninfluencing attention weights and thereby highlighting regions or features in\nthe input data that are potentially suspicious or anomalous. Through\nexperimental results, we demonstrate that our approach surpasses several\ncompetitive methods in handling white-box attack scenarios, including those\nutilizing the fast gradient method, projected gradient descent attacks and\nbasic iterative method."}
{"id": "2507.00016", "pdf": "https://arxiv.org/pdf/2507.00016", "abs": "https://arxiv.org/abs/2507.00016", "authors": ["Xuanbo Liu", "Liu Liu", "Fuxiang Wu", "Fusheng Hao", "Xianglong Liu"], "title": "Gradient-based Fine-Tuning through Pre-trained Model Regularization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Large pre-trained models have demonstrated extensive applications across\nvarious fields. However, fine-tuning these models for specific downstream tasks\ndemands significant computational resources and storage. One fine-tuning\nmethod, gradient-based parameter selection (GPS), focuses on fine-tuning only\nthe parameters with high gradients in each neuron, thereby reducing the number\nof training parameters. Nevertheless, this approach increases computational\nresource requirements and storage demands. In this paper, we propose an\nefficient gradient-based and regularized fine-tuning method (GRFT) that updates\nthe rows or columns of the weight matrix. We theoretically demonstrate that the\nrows or columns with the highest sum of squared gradients are optimal for\nupdating. This strategy effectively reduces storage overhead and improves the\nefficiency of parameter selection. Additionally, we incorporate regularization\nto enhance knowledge transfer from the pre-trained model. GRFT achieves\nstate-of-the-art performance, surpassing existing methods such as GPS, Adapter\nTuning, and LoRA. Notably, GRFT requires updating only 1.22% and 0.30% of the\ntotal parameters on FGVC and VTAB datasets, respectively, demonstrating its\nhigh efficiency and effectiveness. The source code will be released soon."}
{"id": "2507.00018", "pdf": "https://arxiv.org/pdf/2507.00018", "abs": "https://arxiv.org/abs/2507.00018", "authors": ["Bo Wang", "Qinyuan Cheng", "Runyu Peng", "Rong Bao", "Peiji Li", "Qipeng Guo", "Linyang Li", "Zhiyuan Zeng", "Yunhua Zhou", "Xipeng Qiu"], "title": "Implicit Reward as the Bridge: A Unified View of SFT and DPO Connections", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Post-training processes are essential phases in grounding pre-trained\nlanguage models to real-world tasks, with learning from demonstrations or\npreference signals playing a crucial role in this adaptation. We present a\nunified theoretical framework bridging Supervised Fine-Tuning (SFT) and\npreference learning in Large Language Model (LLM) post-training. Through\nrigorous mathematical derivation, we demonstrate that both SFT and preference\nlearning methods like Direct Preference Optimization (DPO) operate within the\nsame optimal policy-reward subspace, with SFT representing a special case of\nimplicit reward learning. Our analysis reveals a critical limitation in\nconventional SFT: the KL divergence term in distribution matching becomes\nconstant with respect to the policy during optimization, failing to constrain\nmodel updates. To address this, we propose a simple yet effective learning rate\nreduction approach that yields significant performance improvements (up to\n\\textbf{25\\%} relative gain and \\textbf{6\\%} absolute win rate increase in\ninstruction following tasks. Additionally, we derive alternative SFT objectives\nfrom various f-divergence functions that preserve the KL term during\noptimization, further enhancing post-DPO model performance. Finally, we extend\nthe theoretical relationship between LLM logits and Q-functions from preference\nlearning to the SFT context, providing mathematical derivations and\nexperimental validation."}
{"id": "2507.00019", "pdf": "https://arxiv.org/pdf/2507.00019", "abs": "https://arxiv.org/abs/2507.00019", "authors": ["Minati Rath", "Hema Date"], "title": "Quantum Inspired Encoding Strategies for Machine Learning Models: Proposing and Evaluating Instance Level, Global Discrete, and Class Conditional Representations", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": null, "summary": "In this study, we propose, evaluate and compare three quantum inspired data\nencoding strategies, Instance Level Strategy (ILS), Global Discrete Strategy\n(GDS) and Class Conditional Value Strategy (CCVS), for transforming classical\ndata into quantum data for use in pure classical machine learning models. The\nprimary objective is to reduce high encoding time while ensuring correct\nencoding values and analyzing their impact on classification performance. The\nInstance Level Strategy treats each row of dataset independently; mimics local\nquantum states. Global Discrete Value Based encoding strategy maps all unique\nfeature values across the full dataset to quantum states uniformly. In\ncontrast, the Class conditional Value based encoding strategy encodes unique\nvalues separately for each class, preserving class dependent information.\n  We apply these encoding strategies to a classification task and assess their\nimpact on en-coding efficiency, correctness, model accuracy, and computational\ncost. By analyzing the trade offs between encoding time, precision, and\npredictive performance, this study provides insights into optimizing quantum\ninspired data transformations for classical machine learning workflows."}
{"id": "2507.00022", "pdf": "https://arxiv.org/pdf/2507.00022", "abs": "https://arxiv.org/abs/2507.00022", "authors": ["Zehao Wang"], "title": "GLU Attention Improve Transformer", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "comment": "4 pages 4 figures", "summary": "Gated Linear Units (GLU) have shown great potential in enhancing neural\nnetwork performance. In this paper, I introduce a novel attention mechanism\ncalled GLU Attention, which introduces nonlinearity into the values of\nAttention. My experiments demonstrate that GLU Attention improves both model\nperformance and convergence speed across text and vision modalities with zero\nadditional parameters and negligible computational costs. GLU Attention is\nlightweight and can seamlessly integrate with other technologies, such as Flash\nAttention, Rotary Position Embedding (RoPE), and various Multi-Head Attention\n(MHA) variants such as Grouped-Query Attention (GQA). This project is\nopen-sourced at github."}
{"id": "2507.00024", "pdf": "https://arxiv.org/pdf/2507.00024", "abs": "https://arxiv.org/abs/2507.00024", "authors": ["Yeyong Yu", "Xilei Bian", "Jie Xiong", "Xing Wu", "Quan Qian"], "title": "AIMatDesign: Knowledge-Augmented Reinforcement Learning for Inverse Materials Design under Data Scarcity", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI"], "comment": null, "summary": "With the growing demand for novel materials, machine learning-driven inverse\ndesign methods face significant challenges in reconciling the high-dimensional\nmaterials composition space with limited experimental data. Existing approaches\nsuffer from two major limitations: (I) machine learning models often lack\nreliability in high-dimensional spaces, leading to prediction biases during the\ndesign process; (II) these models fail to effectively incorporate domain expert\nknowledge, limiting their capacity to support knowledge-guided inverse design.\nTo address these challenges, we introduce AIMatDesign, a reinforcement learning\nframework that addresses these limitations by augmenting experimental data\nusing difference-based algorithms to build a trusted experience pool,\naccelerating model convergence. To enhance model reliability, an automated\nrefinement strategy guided by large language models (LLMs) dynamically corrects\nprediction inconsistencies, reinforcing alignment between reward signals and\nstate value functions. Additionally, a knowledge-based reward function\nleverages expert domain rules to improve stability and efficiency during\ntraining. Our experiments demonstrate that AIMatDesign significantly surpasses\ntraditional machine learning and reinforcement learning methods in discovery\nefficiency, convergence speed, and success rates. Among the numerous candidates\nproposed by AIMatDesign, experimental synthesis of representative Zr-based\nalloys yielded a top-performing BMG with 1.7GPa yield strength and 10.2\\%\nelongation, closely matching predictions. Moreover, the framework accurately\ncaptured the trend of yield strength variation with composition, demonstrating\nits reliability and potential for closed-loop materials discovery."}
{"id": "2507.00025", "pdf": "https://arxiv.org/pdf/2507.00025", "abs": "https://arxiv.org/abs/2507.00025", "authors": ["Tiexin Qin", "Hong Yan", "Haoliang Li"], "title": "Generalizing to New Dynamical Systems via Frequency Domain Adaptation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted by TPAMI 2025", "summary": "Learning the underlying dynamics from data with deep neural networks has\nshown remarkable potential in modeling various complex physical dynamics.\nHowever, current approaches are constrained in their ability to make reliable\npredictions in a specific domain and struggle with generalizing to unseen\nsystems that are governed by the same general dynamics but differ in\nenvironmental characteristics. In this work, we formulate a parameter-efficient\nmethod, Fourier Neural Simulator for Dynamical Adaptation (FNSDA), that can\nreadily generalize to new dynamics via adaptation in the Fourier space.\nSpecifically, FNSDA identifies the shareable dynamics based on the known\nenvironments using an automatic partition in Fourier modes and learns to adjust\nthe modes specific for each new environment by conditioning on low-dimensional\nlatent systematic parameters for efficient generalization. We evaluate our\napproach on four representative families of dynamic systems, and the results\nshow that FNSDA can achieve superior or competitive generalization performance\ncompared to existing methods with a significantly reduced parameter cost. Our\ncode is available at https://github.com/WonderSeven/FNSDA."}
{"id": "2507.00026", "pdf": "https://arxiv.org/pdf/2507.00026", "abs": "https://arxiv.org/abs/2507.00026", "authors": ["Jiale Ding", "Xiang Zheng", "Cong Wang", "Wei-Bin Lee", "Xingjun Ma", "Yu-Gang Jiang"], "title": "ROSE: Toward Reality-Oriented Safety Evaluation of Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed as black-box\ncomponents in real-world applications, evaluating their safety-especially under\nadversarial prompting-has become critical. Arguably, effective safety\nevaluations should be adaptive, evolving with LLM capabilities, and also cover\na broad spectrum of harmful topics and real-world scenarios to fully expose\npotential vulnerabilities. Existing manual safety benchmarks, built on\nhandcrafted adversarial prompts, are limited by their static nature and the\nintensive labor required to update them, making it difficult to keep pace with\nrapidly advancing LLMs. In contrast, automated adversarial prompt generation\noffers a promising path toward adaptive evaluation. However, current methods\noften suffer from insufficient adversarial topic coverage (topic-level\ndiversity) and weak alignment with real-world contexts. These shortcomings stem\nfrom the exploration-exploitation dilemma in black-box optimization and a lack\nof real-world contextualization, resulting in adversarial prompts that are both\ntopically narrow and scenario-repetitive. To address these issues, we propose\nReality-Oriented Safety Evaluation (ROSE), a novel framework that uses\nmulti-objective reinforcement learning to fine-tune an adversarial LLM for\ngenerating topically diverse and contextually rich adversarial prompts.\nExperiments show that ROSE outperforms existing methods in uncovering safety\nvulnerabilities in state-of-the-art LLMs, with notable improvements in\nintegrated evaluation metrics. We hope ROSE represents a step toward more\npractical and reality-oriented safety evaluation of LLMs. WARNING: This paper\ncontains examples of potentially harmful text."}
{"id": "2507.00028", "pdf": "https://arxiv.org/pdf/2507.00028", "abs": "https://arxiv.org/abs/2507.00028", "authors": ["Lihuan Li", "Hao Xue", "Shuang Ao", "Yang Song", "Flora Salim"], "title": "HiT-JEPA: A Hierarchical Self-supervised Trajectory Embedding Framework for Similarity Computation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "The representation of urban trajectory data plays a critical role in\neffectively analyzing spatial movement patterns. Despite considerable progress,\nthe challenge of designing trajectory representations that can capture diverse\nand complementary information remains an open research problem. Existing\nmethods struggle in incorporating trajectory fine-grained details and\nhigh-level summary in a single model, limiting their ability to attend to both\nlong-term dependencies while preserving local nuances. To address this, we\npropose HiT-JEPA (Hierarchical Interactions of Trajectory Semantics via a Joint\nEmbedding Predictive Architecture), a unified framework for learning\nmulti-scale urban trajectory representations across semantic abstraction\nlevels. HiT-JEPA adopts a three-layer hierarchy that progressively captures\npoint-level fine-grained details, intermediate patterns, and high-level\ntrajectory abstractions, enabling the model to integrate both local dynamics\nand global semantics in one coherent structure. Extensive experiments on\nmultiple real-world datasets for trajectory similarity computation show that\nHiT-JEPA's hierarchical design yields richer, multi-scale representations. Code\nis available at: https://anonymous.4open.science/r/HiT-JEPA."}
{"id": "2507.00029", "pdf": "https://arxiv.org/pdf/2507.00029", "abs": "https://arxiv.org/abs/2507.00029", "authors": ["Wenbing Li", "Zikai Song", "Hang Zhou", "Yunyao Zhang", "Junqing Yu", "Wei Yang"], "title": "LoRA-Mixer: Coordinate Modular LoRA Experts Through Serial Attention Routing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent efforts to combine low-rank adaptation (LoRA) with mixture-of-experts\n(MoE) for adapting large language models (LLMs) to multiple tasks still exhibit\nprevailing limitations: they either swap entire attention/feed-forward layers\nfor switch experts or bolt on parallel expert branches, diluting parameter\nefficiency and task fidelity. We propose the LoRA-Mixer, a modular and\nlightweight MoE framework that integrates LoRA experts. Our core innovation\nlies in replacing the projection matrices of the attention module's\ninput/output linear layers with dynamically routed, task-specific LoRA experts.\nThis design ensures seamless compatibility with diverse foundation models,\nincluding transformers and state space models (SSMs), by leveraging their\ninherent linear projection structures. The framework supports two operational\nparadigms: (1) joint optimization of LoRA experts and routing mechanisms via a\nnovel hard-soft routing strategy, or (2) direct deployment of pre-trained,\nfrozen LoRA modules sourced from external repositories. To enable robust router\ntraining with limited data while ensuring stable routing decisions and\nmaximizing expert reuse, we introduce an adaptive Specialization Balance Loss\n(SBL) that jointly optimizes expert balance and task-specific alignment.\nExtensive experiments on seven benchmark datasets, including MedQA, CoLA,\nSST-2, GSM8K, ARC-E, ARC-C, and HumanEval, demonstrate the effectiveness of\nLoRA-Mixer. On datasets such as GSM8K, HumanEval, and MedQA, LoRA-Mixer\nachieves significant improvements of 7.61%, 4.88%, and 3.08% over the base\nmodels, respectively. Compared with state-of-the-art methods, LoRA-Mixer\nachieves additional improvements of 1.09%, 1.45%, and 1.68%, respectively,\nusing only 48% of the parameters, demonstrating its efficiency and strong\nperformance."}
{"id": "2507.00030", "pdf": "https://arxiv.org/pdf/2507.00030", "abs": "https://arxiv.org/abs/2507.00030", "authors": ["Abhishek Verma", "Nallarasan V", "Balaraman Ravindran"], "title": "Adaptive Action Duration with Contextual Bandits for Deep Reinforcement Learning in Dynamic Environments", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep Reinforcement Learning (DRL) has achieved remarkable success in complex\nsequential decision-making tasks, such as playing Atari 2600 games and\nmastering board games. A critical yet underexplored aspect of DRL is the\ntemporal scale of action execution. We propose a novel paradigm that integrates\ncontextual bandits with DRL to adaptively select action durations, enhancing\npolicy flexibility and computational efficiency. Our approach augments a Deep\nQ-Network (DQN) with a contextual bandit module that learns to choose optimal\naction repetition rates based on state contexts. Experiments on Atari 2600\ngames demonstrate significant performance improvements over static duration\nbaselines, highlighting the efficacy of adaptive temporal abstractions in DRL.\nThis paradigm offers a scalable solution for real-time applications like gaming\nand robotics, where dynamic action durations are critical."}
{"id": "2507.00032", "pdf": "https://arxiv.org/pdf/2507.00032", "abs": "https://arxiv.org/abs/2507.00032", "authors": ["Grey Kuling", "Marinka Zitnik"], "title": "Ken Utilization Layer: Hebbian Replay Within a Student's Ken for Adaptive Knowledge Tracing", "categories": ["cs.CY", "cs.AI", "cs.LG", "cs.NE"], "comment": null, "summary": "We introduce KUL-KT, a biologically inspired architecture for knowledge\ntracing (KT), combining Hebbian memory encoding with gradient-based\nconsolidation in a scalable, input-agnostic framework. KUL-KT adapts the\nprinciple of memory consolidation in neural systems, to student modeling by\nintroducing two key innovations: (i) a time-decaying Hebbian memory update that\nenables graceful forgetting, and (ii) a novel Loss-aligned Internal Target\n(LIT) method to compute an ideal internal state, allowing continual learning\nwithout backpropagation through time. The architecture consists of a fast\nHebbian memory that captures each learner interaction via a single associative\nupdate, and a slower linear network that consolidates recalled samples through\ngradient descent. This design enables few-shot personalization and natural\nforgetting without storing raw data or relying on large cohort training.\nOperating entirely in embedding space, KUL-KT supports both structured\n(tabular) and unstructured (short-answer) inputs. Empirically, KUL-KT\noutperforms strong baselines on ten public KT benchmarks in rank-sensitive\nmetrics such as nDCG and Recall@10. In a classroom deployment, KUL-KT\npersonalized quizzes from short-answer data, leading to improved\nlearner-perceived helpfulness and reduced difficulty (p < 0.05). Ablation\nstudies confirm that Hebbian decay and LIT are critical for continual\nadaptation. Compared to a strong graph-based KT model, KUL-KT trains 1.75x\nfaster and uses 99.01\\% less memory. These results position KUL-KT as a\nbiologically grounded, memory-efficient, and input-flexible framework for\npersonalized learning at scale."}
{"id": "2507.00033", "pdf": "https://arxiv.org/pdf/2507.00033", "abs": "https://arxiv.org/abs/2507.00033", "authors": ["Mustafa Chasmai", "Gauri Jagatap", "Gouthaman KV", "Grant Van Horn", "Subhransu Maji", "Andrea Fanelli"], "title": "Moment Sampling in Video LLMs for Long-Form Video QA", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Workshop on Video Large Language Models (VidLLMs) at CVPR 2025", "summary": "Recent advancements in video large language models (Video LLMs) have\nsignificantly advanced the field of video question answering (VideoQA). While\nexisting methods perform well on short videos, they often struggle with\nlong-range reasoning in longer videos. To scale Video LLMs for longer video\ncontent, frame sub-sampling (selecting frames at regular intervals) is commonly\nused. However, this approach is suboptimal, often leading to the loss of\ncrucial frames or the inclusion of redundant information from multiple similar\nframes. Missing key frames impairs the model's ability to answer questions\naccurately, while redundant frames lead the model to focus on irrelevant video\nsegments and increase computational resource consumption. In this paper, we\ninvestigate the use of a general-purpose text-to-video moment retrieval model\nto guide the frame sampling process. We propose \"moment sampling\", a novel,\nmodel-agnostic approach that enables the model to select the most relevant\nframes according to the context of the question. Specifically, we employ a\nlightweight moment retrieval model to prioritize frame selection. By focusing\non the frames most pertinent to the given question, our method enhances\nlong-form VideoQA performance in Video LLMs. Through extensive experiments on\nfour long-form VideoQA datasets, using four state-of-the-art Video LLMs, we\ndemonstrate the effectiveness of the proposed approach."}
{"id": "2507.00037", "pdf": "https://arxiv.org/pdf/2507.00037", "abs": "https://arxiv.org/abs/2507.00037", "authors": ["Phoomraphee Luenam", "Andreas Spanopoulos", "Amit Sant", "Thomas Hofmann", "Sotiris Anagnostidis", "Sidak Pal Singh"], "title": "Model Fusion via Neuron Interpolation", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.1"], "comment": "5 figures, 15 tables, 23 pages", "summary": "Model fusion aims to combine the knowledge of multiple models by creating one\nrepresentative model that captures the strengths of all of its parents.\nHowever, this process is non-trivial due to differences in internal\nrepresentations, which can stem from permutation invariance, random\ninitialization, or differently distributed training data. We present a novel,\nneuron-centric family of model fusion algorithms designed to integrate multiple\ntrained neural networks into a single network effectively regardless of\ntraining data distribution. Our algorithms group intermediate neurons of parent\nmodels to create target representations that the fused model approximates with\nits corresponding sub-network. Unlike prior approaches, our approach\nincorporates neuron attribution scores into the fusion process. Furthermore,\nour algorithms can generalize to arbitrary layer types. Experimental results on\nvarious benchmark datasets demonstrate that our algorithms consistently\noutperform previous fusion techniques, particularly in zero-shot and non-IID\nfusion scenarios. The code is available at\nhttps://github.com/AndrewSpano/neuron-interpolation-model-fusion."}
{"id": "2507.00038", "pdf": "https://arxiv.org/pdf/2507.00038", "abs": "https://arxiv.org/abs/2507.00038", "authors": ["Fei Chen", "Wenchi Zhou"], "title": "Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Data reduction plays a vital role in data-centric AI by identifying the most\ninformative instance within large-scale datasets to enhance model training\nefficiency. The core challenge lies in how to select the optimal\ninstances-rather than the entire datasets-to improve data quality and training\nefficiency. In this paper, we propose an effective data reduction strategy\nbased on Pointwise V-information(PVI). First, we quantify instance difficulty\nusing PVI and filter out low-difficulty instances enabling a static approach.\nExperiments demonstrate that removing 10%-30% of the data preserves the\nclassifier performance with only a 0.0001% to 0.76% loss in accuracy.Second, we\nuse a progressive learning approach to training the classifiers on instances\nsorted by ascending PVI, accelerating convergence and achieving a 0.8% accuracy\ngain over conventional training. Our results suggest that with the effective\ndata reduction strategy, training a classifier on the selected optimal subset\ncould enhance the model performance and boost training efficiency. Moreover, we\nhave transferred the PVI framework, which previously applied only to English\ndatasets, to diverse Chinese NLP tasks and base models, leading to valuable\ninsights for cross-lingual data reduction and faster training. The codes are\nreleased at https://github.com/zhouwenchi/DatasetReductionStrategy."}
{"id": "2507.00039", "pdf": "https://arxiv.org/pdf/2507.00039", "abs": "https://arxiv.org/abs/2507.00039", "authors": ["Lucas Potin", "Rosa Figueiredo", "Vincent Labatut", "Christine Largeron"], "title": "Pattern-Based Graph Classification: Comparison of Quality Measures and Importance of Preprocessing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph classification aims to categorize graphs based on their structural and\nattribute features, with applications in diverse fields such as social network\nanalysis and bioinformatics. Among the methods proposed to solve this task,\nthose relying on patterns (i.e. subgraphs) provide good explainability, as the\npatterns used for classification can be directly interpreted. To identify\nmeaningful patterns, a standard approach is to use a quality measure, i.e. a\nfunction that evaluates the discriminative power of each pattern. However, the\nliterature provides tens of such measures, making it difficult to select the\nmost appropriate for a given application. Only a handful of surveys try to\nprovide some insight by comparing these measures, and none of them specifically\nfocuses on graphs. This typically results in the systematic use of the most\nwidespread measures, without thorough evaluation. To address this issue, we\npresent a comparative analysis of 38 quality measures from the literature. We\ncharacterize them theoretically, based on four mathematical properties. We\nleverage publicly available datasets to constitute a benchmark, and propose a\nmethod to elaborate a gold standard ranking of the patterns. We exploit these\nresources to perform an empirical comparison of the measures, both in terms of\npattern ranking and classification performance. Moreover, we propose a\nclustering-based preprocessing step, which groups patterns appearing in the\nsame graphs to enhance classification performance. Our experimental results\ndemonstrate the effectiveness of this step, reducing the number of patterns to\nbe processed while achieving comparable performance. Additionally, we show that\nsome popular measures widely used in the literature are not associated with the\nbest results."}
{"id": "2507.00042", "pdf": "https://arxiv.org/pdf/2507.00042", "abs": "https://arxiv.org/abs/2507.00042", "authors": ["Xinrun Xu", "Jianwen Yang", "Qiuhong Zhang", "Zhanbiao Lian", "Zhiming Ding", "Shan Jiang"], "title": "Catastrophic Forgetting Mitigation via Discrepancy-Weighted Experience Replay", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICANN 2025", "summary": "Continually adapting edge models in cloud-edge collaborative object detection\nfor traffic monitoring suffers from catastrophic forgetting, where models lose\npreviously learned knowledge when adapting to new data distributions. This is\nespecially problematic in dynamic traffic environments characterised by\nperiodic variations (e.g., day/night, peak hours), where past knowledge remains\nvaluable. Existing approaches like experience replay and visual prompts offer\nsome mitigation, but struggle to effectively prioritize and leverage historical\ndata for optimal knowledge retention and adaptation. Specifically, simply\nstoring and replaying all historical data can be inefficient, while treating\nall historical experiences as equally important overlooks their varying\nrelevance to the current domain. This paper proposes ER-EMU, an edge model\nupdate algorithm based on adaptive experience replay, to address these\nlimitations. ER-EMU utilizes a limited-size experience buffer managed using a\nFirst-In-First-Out (FIFO) principle, and a novel Domain Distance Metric-based\nExperience Selection (DDM-ES) algorithm. DDM-ES employs the multi-kernel\nmaximum mean discrepancy (MK-MMD) to quantify the dissimilarity between target\ndomains, prioritizing the selection of historical data that is most dissimilar\nto the current target domain. This ensures training diversity and facilitates\nthe retention of knowledge from a wider range of past experiences, while also\npreventing overfitting to the new domain. The experience buffer is also updated\nusing a simple random sampling strategy to maintain a balanced representation\nof previous domains. Experiments on the Bellevue traffic video dataset,\ninvolving repeated day/night cycles, demonstrate that ER-EMU consistently\nimproves the performance of several state-of-the-art cloud-edge collaborative\nobject detection frameworks."}
{"id": "2507.00043", "pdf": "https://arxiv.org/pdf/2507.00043", "abs": "https://arxiv.org/abs/2507.00043", "authors": ["Mehmet Yigit Avci", "Pedro Borges", "Paul Wright", "Mehmet Yigitsoy", "Sebastien Ourselin", "Jorge Cardoso"], "title": "MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast Representations", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate interpretation of Magnetic Resonance Imaging scans in clinical\nsystems is based on a precise understanding of image contrast. This contrast is\nprimarily governed by acquisition parameters, such as echo time and repetition\ntime, which are stored in the DICOM metadata. To simplify contrast\nidentification, broad labels such as T1-weighted or T2-weighted are commonly\nused, but these offer only a coarse approximation of the underlying acquisition\nsettings. In many real-world datasets, such labels are entirely missing,\nleaving raw acquisition parameters as the only indicators of contrast. Adding\nto this challenge, the available metadata is often incomplete, noisy, or\ninconsistent. The lack of reliable and standardized metadata complicates tasks\nsuch as image interpretation, retrieval, and integration into clinical\nworkflows. Furthermore, robust contrast-aware representations are essential to\nenable more advanced clinical applications, such as achieving\nmodality-invariant representations and data harmonization. To address these\nchallenges, we propose MR-CLIP, a multimodal contrastive learning framework\nthat aligns MR images with their DICOM metadata to learn contrast-aware\nrepresentations, without relying on manual labels. Trained on a diverse\nclinical dataset that spans various scanners and protocols, MR-CLIP captures\ncontrast variations across acquisitions and within scans, enabling\nanatomy-invariant representations. We demonstrate its effectiveness in\ncross-modal retrieval and contrast classification, highlighting its scalability\nand potential for further clinical applications. The code and weights are\npublicly available at https://github.com/myigitavci/MR-CLIP."}
{"id": "2507.00044", "pdf": "https://arxiv.org/pdf/2507.00044", "abs": "https://arxiv.org/abs/2507.00044", "authors": ["Seyed Kahaki", "Alexander R. Webber", "Ghada Zamzmi", "Adarsh Subbaswamy", "Rucha Deshpande", "Aldo Badano"], "title": "HistoART: Histopathology Artifact Detection and Reporting Tool", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "14 pages, 5 figures", "summary": "In modern cancer diagnostics, Whole Slide Imaging (WSI) is widely used to\ndigitize tissue specimens for detailed, high-resolution examination; however,\nother diagnostic approaches, such as liquid biopsy and molecular testing, are\nalso utilized based on the cancer type and clinical context. While WSI has\nrevolutionized digital histopathology by enabling automated, precise analysis,\nit remains vulnerable to artifacts introduced during slide preparation and\nscanning. These artifacts can compromise downstream image analysis. To address\nthis challenge, we propose and compare three robust artifact detection\napproaches for WSIs: (1) a foundation model-based approach (FMA) using a\nfine-tuned Unified Neural Image (UNI) architecture, (2) a deep learning\napproach (DLA) built on a ResNet50 backbone, and (3) a knowledge-based approach\n(KBA) leveraging handcrafted features from texture, color, and frequency-based\nmetrics. The methods target six common artifact types: tissue folds,\nout-of-focus regions, air bubbles, tissue damage, marker traces, and blood\ncontamination. Evaluations were conducted on 50,000+ image patches from diverse\nscanners (Hamamatsu, Philips, Leica Aperio AT2) across multiple sites. The FMA\nachieved the highest patch-wise AUROC of 0.995 (95% CI [0.994, 0.995]),\noutperforming the ResNet50-based method (AUROC: 0.977, 95% CI [0.977, 0.978])\nand the KBA (AUROC: 0.940, 95% CI [0.933, 0.946]). To translate detection into\nactionable insights, we developed a quality report scorecard that quantifies\nhigh-quality patches and visualizes artifact distributions."}
{"id": "2507.00045", "pdf": "https://arxiv.org/pdf/2507.00045", "abs": "https://arxiv.org/abs/2507.00045", "authors": ["Ming Li", "Chenguang Wang", "Yijun Liang", "Xiyao Wang", "Yuhang Zhou", "Xiyang Wu", "Yuqing Zhang", "Ruiyi Zhang", "Tianyi Zhou"], "title": "CaughtCheating: Is Your MLLM a Good Cheating Detective? Exploring the Boundary of Visual Perception and Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent agentic Multi-Modal Large Language Models (MLLMs) such as GPT-o3 have\nachieved near-ceiling scores on various existing benchmarks, motivating a\ndemand for more challenging test tasks. These MLLMs have been reported to excel\nin a few expert-level tasks for humans, e.g., GeoGuesser, reflecting their\npotential as a detective who can notice minuscule cues in an image and weave\nthem into coherent, situational explanations, leading to a reliable answer. But\ncan they match the performance of excellent human detectives? To answer this\nquestion, we investigate some hard scenarios where GPT-o3 can still handle, and\nfind a common scenario where o3's performance drops to nearly zero, which we\nname CaughtCheating. It is inspired by the social media requests that ask\nothers to detect suspicious clues from photos shared by the poster's partner.\nWe conduct extensive experiments and analysis to understand why existing MLLMs\nlack sufficient capability to solve this kind of task. CaughtCheating provides\na class of challenging visual perception and reasoning tasks with great value\nand practical usage. Success in these tasks paves the way for MLLMs to acquire\nhuman-level detective perception and reasoning capabilities."}
{"id": "2507.00052", "pdf": "https://arxiv.org/pdf/2507.00052", "abs": "https://arxiv.org/abs/2507.00052", "authors": ["Binesh Sadanandan", "Vahid Behzadan"], "title": "VSF-Med:A Vulnerability Scoring Framework for Medical Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision Language Models (VLMs) hold great promise for streamlining\nlabour-intensive medical imaging workflows, yet systematic security evaluations\nin clinical settings remain scarce. We introduce VSF--Med, an end-to-end\nvulnerability-scoring framework for medical VLMs that unites three novel\ncomponents: (i) a rich library of sophisticated text-prompt attack templates\ntargeting emerging threat vectors; (ii) imperceptible visual perturbations\ncalibrated by structural similarity (SSIM) thresholds to preserve clinical\nrealism; and (iii) an eight-dimensional rubric evaluated by two independent\njudge LLMs, whose raw scores are consolidated via z-score normalization to\nyield a 0--32 composite risk metric. Built entirely on publicly available\ndatasets and accompanied by open-source code, VSF--Med synthesizes over 30,000\nadversarial variants from 5,000 radiology images and enables reproducible\nbenchmarking of any medical VLM with a single command. Our consolidated\nanalysis reports mean z-score shifts of $0.90\\sigma$ for\npersistence-of-attack-effects, $0.74\\sigma$ for prompt-injection effectiveness,\nand $0.63\\sigma$ for safety-bypass success across state-of-the-art VLMs.\nNotably, Llama-3.2-11B-Vision-Instruct exhibits a peak vulnerability increase\nof $1.29\\sigma$ for persistence-of-attack-effects, while GPT-4o shows increases\nof $0.69\\sigma$ for that same vector and $0.28\\sigma$ for prompt-injection\nattacks."}
{"id": "2507.00057", "pdf": "https://arxiv.org/pdf/2507.00057", "abs": "https://arxiv.org/abs/2507.00057", "authors": ["Thomas Valentin", "Ardi Madadi", "Gaetano Sapia", "Marcel Böhme"], "title": "Estimating Correctness Without Oracles in LLM-Based Code Generation", "categories": ["cs.PL", "cs.AI", "cs.LG", "cs.SE"], "comment": "8 pages + refs and appendix", "summary": "Generating code from natural language specifications is one of the most\nsuccessful applications of Large Language Models (LLMs). Yet, they hallucinate:\nLLMs produce outputs that may be grammatically correct but are factually\nincorrect. Without an existing, correct implementation (i.e., an oracle), can\nwe quantify how likely the generated program is correct?\n  In this paper, we propose a measure of incorrectness, called incoherence,\nthat can be estimated efficiently in the absence of an oracle and provides a\nlower bound on the error, i.e., the probability that the LLM-generated program\nfor that specification is incorrect. Our experiments demonstrate an\nextraordinary effectiveness. For the average code generation task, our\nincoherence-based methodology can automatically identify about two-thirds of\nincorrect programs without reports of false positives. In fact, an oracle-based\nevaluation of LLMs can be reliably replaced by an incoherence-based evaluation.\nIn particular, we find a very strong agreement between the ranking of LLMs by\nthe number of programs deemed correct via an oracle (pass@1) and the ranking of\nLLMs by the number of programs deemed correct via our incoherence."}
{"id": "2507.00061", "pdf": "https://arxiv.org/pdf/2507.00061", "abs": "https://arxiv.org/abs/2507.00061", "authors": ["Hoang-Dieu Vu", "Duc-Nghia Tran", "Quang-Tu Pham", "Hieu H. Pham", "Nicolas Vuillerme", "Duc-Tan Tran"], "title": "Smooth-Distill: A Self-distillation Framework for Multitask Learning with Wearable Sensor Data", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "This paper introduces Smooth-Distill, a novel self-distillation framework\ndesigned to simultaneously perform human activity recognition (HAR) and sensor\nplacement detection using wearable sensor data. The proposed approach utilizes\na unified CNN-based architecture, MTL-net, which processes accelerometer data\nand branches into two outputs for each respective task. Unlike conventional\ndistillation methods that require separate teacher and student models, the\nproposed framework utilizes a smoothed, historical version of the model itself\nas the teacher, significantly reducing training computational overhead while\nmaintaining performance benefits. To support this research, we developed a\ncomprehensive accelerometer-based dataset capturing 12 distinct sleep postures\nacross three different wearing positions, complementing two existing public\ndatasets (MHealth and WISDM). Experimental results show that Smooth-Distill\nconsistently outperforms alternative approaches across different evaluation\nscenarios, achieving notable improvements in both human activity recognition\nand device placement detection tasks. This method demonstrates enhanced\nstability in convergence patterns during training and exhibits reduced\noverfitting compared to traditional multitask learning baselines. This\nframework contributes to the practical implementation of knowledge distillation\nin human activity recognition systems, offering an effective solution for\nmultitask learning with accelerometer data that balances accuracy and training\nefficiency. More broadly, it reduces the computational cost of model training,\nwhich is critical for scenarios requiring frequent model updates or training on\nresource-constrained platforms. The code and model are available at\nhttps://github.com/Kuan2vn/smooth\\_distill."}
{"id": "2507.00066", "pdf": "https://arxiv.org/pdf/2507.00066", "abs": "https://arxiv.org/abs/2507.00066", "authors": ["Xingyu Xiao", "Jiejuan Tong", "Peng Chen", "Jun Sun", "Zhe Sui", "Jingang Liang", "Hongru Zhao", "Jun Zhao", "Haitao Wang"], "title": "InSight-R: A Framework for Risk-informed Human Failure Event Identification and Interface-Induced Risk Assessment Driven by AutoGraph", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Human reliability remains a critical concern in safety-critical domains such\nas nuclear power, where operational failures are often linked to human error.\nWhile conventional human reliability analysis (HRA) methods have been widely\nadopted, they rely heavily on expert judgment for identifying human failure\nevents (HFEs) and assigning performance influencing factors (PIFs). This\nreliance introduces challenges related to reproducibility, subjectivity, and\nlimited integration of interface-level data. In particular, current approaches\nlack the capacity to rigorously assess how human-machine interface design\ncontributes to operator performance variability and error susceptibility. To\naddress these limitations, this study proposes a framework for risk-informed\nhuman failure event identification and interface-induced risk assessment driven\nby AutoGraph (InSight-R). By linking empirical behavioral data to the\ninterface-embedded knowledge graph (IE-KG) constructed by the automated\ngraph-based execution framework (AutoGraph), the InSight-R framework enables\nautomated HFE identification based on both error-prone and time-deviated\noperational paths. Furthermore, we discuss the relationship between\ndesigner-user conflicts and human error. The results demonstrate that InSight-R\nnot only enhances the objectivity and interpretability of HFE identification\nbut also provides a scalable pathway toward dynamic, real-time human\nreliability assessment in digitalized control environments. This framework\noffers actionable insights for interface design optimization and contributes to\nthe advancement of mechanism-driven HRA methodologies."}
{"id": "2507.00068", "pdf": "https://arxiv.org/pdf/2507.00068", "abs": "https://arxiv.org/abs/2507.00068", "authors": ["Ziqi Zhong", "Daniel Tang"], "title": "MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "While multi-modal learning has advanced significantly, current approaches\noften treat modalities separately, creating inconsistencies in representation\nand reasoning. We introduce MANTA (Multi-modal Abstraction and Normalization\nvia Textual Alignment), a theoretically-grounded framework that unifies visual\nand auditory inputs into a structured textual space for seamless processing\nwith large language models. MANTA addresses four key challenges: (1) semantic\nalignment across modalities with information-theoretic optimization, (2)\nadaptive temporal synchronization for varying information densities, (3)\nhierarchical content representation for multi-scale understanding, and (4)\ncontext-aware retrieval of sparse information from long sequences. We formalize\nour approach within a rigorous mathematical framework, proving its optimality\nfor context selection under token constraints. Extensive experiments on the\nchallenging task of Long Video Question Answering show that MANTA improves\nstate-of-the-art models by up to 22.6% in overall accuracy, with particularly\nsignificant gains (27.3%) on videos exceeding 30 minutes. Additionally, we\ndemonstrate MANTA's superiority on temporal reasoning tasks (23.8% improvement)\nand cross-modal understanding (25.1% improvement). Our framework introduces\nnovel density estimation techniques for redundancy minimization while\npreserving rare signals, establishing new foundations for unifying multimodal\nrepresentations through structured text."}
{"id": "2507.00070", "pdf": "https://arxiv.org/pdf/2507.00070", "abs": "https://arxiv.org/abs/2507.00070", "authors": ["Bosubabu Sambana", "Hillary Sunday Nnadi", "Mohd Anas Wajid", "Nwosu Ogochukwu Fidelia", "Claudia Camacho-Zuñiga", "Henry Dozie Ajuzie", "Edeh Michael Onyema"], "title": "An efficient plant disease detection using transfer learning approach", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages , 4 figures. Scientific Reports 2025", "summary": "Plant diseases pose significant challenges to farmers and the agricultural\nsector at large. However, early detection of plant diseases is crucial to\nmitigating their effects and preventing widespread damage, as outbreaks can\nseverely impact the productivity and quality of crops. With advancements in\ntechnology, there are increasing opportunities for automating the monitoring\nand detection of disease outbreaks in plants. This study proposed a system\ndesigned to identify and monitor plant diseases using a transfer learning\napproach. Specifically, the study utilizes YOLOv7 and YOLOv8, two\nstate-ofthe-art models in the field of object detection. By fine-tuning these\nmodels on a dataset of plant leaf images, the system is able to accurately\ndetect the presence of Bacteria, Fungi and Viral diseases such as Powdery\nMildew, Angular Leaf Spot, Early blight and Tomato mosaic virus. The model's\nperformance was evaluated using several metrics, including mean Average\nPrecision (mAP), F1-score, Precision, and Recall, yielding values of 91.05,\n89.40, 91.22, and 87.66, respectively. The result demonstrates the superior\neffectiveness and efficiency of YOLOv8 compared to other object detection\nmethods, highlighting its potential for use in modern agricultural practices.\nThe approach provides a scalable, automated solution for early any plant\ndisease detection, contributing to enhanced crop yield, reduced reliance on\nmanual monitoring, and supporting sustainable agricultural practices."}
{"id": "2507.00075", "pdf": "https://arxiv.org/pdf/2507.00075", "abs": "https://arxiv.org/abs/2507.00075", "authors": ["Yifan Sun", "Yushan Liang", "Zhen Zhang", "Jiaye Teng"], "title": "Theoretical Modeling of LLM Self-Improvement Training Dynamics Through Solver-Verifier Gap", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages", "summary": "Self-improvement is among the most prominent techniques within the realm of\nlarge language models (LLM), aiming to enhance the LLM performance without\nrelying on external data. Despite its significance, generally how LLM\nperformances evolve during the self-improvement process remains underexplored.\nIn this paper, we theoretically model the training dynamics of self-improvement\nvia the concept of solver-verifier gap. This is inspired by the conjecture that\nthe performance enhancement of self-improvement stems from the gap between\nLLM's solver capability and verifier capability. Based on the theoretical\nframework, we further introduce how to predict the ultimate power of\nself-improvement using only information from the first few training epochs. We\nempirically validate the effectiveness of the theoretical model on various LLMs\nand datasets. Beyond self-improvement, we extend our analysis to investigate\nhow external data influences these dynamics within the framework. Notably, we\nfind that under limited external data regimes, such external data can be\nutilized at any stage without significantly affecting final performances, which\naccords with the empirical observations."}
{"id": "2507.00078", "pdf": "https://arxiv.org/pdf/2507.00078", "abs": "https://arxiv.org/abs/2507.00078", "authors": ["Yi Xie", "Yun Xiong", "Zejian Shi", "Hao Niu", "Zhengfu Liu"], "title": "The language of time: a language model perspective on time-series foundation models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "With the rise of large language models, the paradigm of training foundation\nmodels with massive parameter counts on vast datasets has been adopted in\nmultiple domains to achieve remarkable success. Time series foundation models\nrepresent a significant extension of this paradigm, demonstrating exceptional\nexpressive power, generalization, and cross-domain transferability. However,\nthis gives rise to a fundamental paradox: time series data reflect distinct\ndynamical systems, making cross-domain transfer intuitively implausible, yet\nthis is contradicted by the models' empirical success. To resolve this paradox,\nthis paper investigates, from both theoretical and experimental perspectives,\nthe representation learning mechanisms and generalization capabilities of\npatch-based time series foundation models. We argue that such models are not\nmerely applying a new architecture but are fundamentally generalizing the\nrepresentation paradigm of language models by extending deterministic\nvector-based representations to latent probabilistic distributional forms. Our\ntheoretical analysis supports this framework by demonstrating that continuous\ntime-series patches can be faithfully quantized into a discrete vocabulary\nwhose key statistical properties are highly consistent with those of natural\nlanguage. This generalization allows time series models to inherit the robust\nrepresentation and transfer abilities of large language models, thereby\nexplaining their superior performance in temporal tasks. Ultimately, our work\nprovides a rigorous theoretical cornerstone for understanding, evaluating, and\nimproving the safety and reliability of large-scale time series foundation\nmodels."}
{"id": "2507.00081", "pdf": "https://arxiv.org/pdf/2507.00081", "abs": "https://arxiv.org/abs/2507.00081", "authors": ["Matthew Muhoberac", "Atharva Parikh", "Nirvi Vakharia", "Saniya Virani", "Aco Radujevic", "Savannah Wood", "Meghav Verma", "Dimitri Metaxotos", "Jeyaraman Soundararajan", "Thierry Masquelin", "Alexander G. Godfrey", "Sean Gardner", "Dobrila Rudnicki", "Sam Michael", "Gaurav Chopra"], "title": "State and Memory is All You Need for Robust and Reliable AI Agents", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.ET", "physics.chem-ph"], "comment": "5 Main Figures, 10 Extended Data Figures (37 Pages) for Manuscript ;\n  9 Supplementary Tables, 40 Supplementary Figures (180 Pages) for Supporting\n  Information", "summary": "Large language models (LLMs) have enabled powerful advances in natural\nlanguage understanding and generation. Yet their application to complex,\nreal-world scientific workflows remain limited by challenges in memory,\nplanning, and tool integration. Here, we introduce SciBORG (Scientific Bespoke\nArtificial Intelligence Agents Optimized for Research Goals), a modular agentic\nframework that allows LLM-based agents to autonomously plan, reason, and\nachieve robust and reliable domain-specific task execution. Agents are\nconstructed dynamically from source code documentation and augmented with\nfinite-state automata (FSA) memory, enabling persistent state tracking and\ncontext-aware decision-making. This approach eliminates the need for manual\nprompt engineering and allows for robust, scalable deployment across diverse\napplications via maintaining context across extended workflows and to recover\nfrom tool or execution failures. We validate SciBORG through integration with\nboth physical and virtual hardware, such as microwave synthesizers for\nexecuting user-specified reactions, with context-aware decision making and\ndemonstrate its use in autonomous multi-step bioassay retrieval from the\nPubChem database utilizing multi-step planning, reasoning, agent-to-agent\ncommunication and coordination for execution of exploratory tasks. Systematic\nbenchmarking shows that SciBORG agents achieve reliable execution, adaptive\nplanning, and interpretable state transitions. Our results show that memory and\nstate awareness are critical enablers of agentic planning and reliability,\noffering a generalizable foundation for deploying AI agents in complex\nenvironments."}
{"id": "2507.00082", "pdf": "https://arxiv.org/pdf/2507.00082", "abs": "https://arxiv.org/abs/2507.00082", "authors": ["Faranaksadat Solat", "Joohyung Lee", "Mohamed Seif", "Dusit Niyato", "H. Vincent Poor"], "title": "Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "17 pages, 16 figures, IEEE Internet of Things", "summary": "Hybrid Language Models (HLMs) combine the low-latency efficiency of Small\nLanguage Models (SLMs) on edge devices with the high accuracy of Large Language\nModels (LLMs) on centralized servers. Unlike traditional end-to-end LLM\ninference, HLMs reduce latency and communication by invoking LLMs only when\nlocal SLM predictions are uncertain, i.e., when token-level confidence is low\nor entropy is high. However, ambiguous or low-confidence predictions still\nrequire frequent offloading to the LLM, leading to significant communication\noverhead in bandwidth-constrained settings. To address this, we propose FedHLM,\na communication-efficient HLM framework that integrates uncertainty-aware\ninference with Federated Learning (FL). FedHLM's key innovation lies in\ncollaboratively learning token-level uncertainty thresholds that govern when\nLLM assistance is needed. Rather than using static or manually tuned\nthresholds, FedHLM employs FL to optimize these thresholds in a\nprivacy-preserving, distributed manner. Additionally, it leverages\nembedding-based token representations for Peer-to-Peer (P2P) resolution,\nenabling clients to reuse tokens inferred by semantically similar peers without\nengaging the LLM. We further introduce hierarchical model aggregation: edge\nservers refine local routing policies through client updates, while\ncross-cluster coordination aligns global decision boundaries. This layered\ndesign captures recurring uncertainty patterns, reducing redundant LLM queries.\nExperiments on large-scale news classification tasks show that FedHLM reduces\nLLM transmissions by over 95 percent with negligible accuracy loss, making it\nwell-suited for scalable and efficient edge-AI applications."}
{"id": "2507.00083", "pdf": "https://arxiv.org/pdf/2507.00083", "abs": "https://arxiv.org/abs/2507.00083", "authors": ["Wei Meng"], "title": "Strategic Counterfactual Modeling of Deep-Target Airstrike Systems via Intervention-Aware Spatio-Causal Graph Networks", "categories": ["cs.LG", "cs.AI", "91A80, 91B62, 68T07", "I.2.6; J.7; K.4.1; C.2.4"], "comment": "This paper proposes the first closed-loop causal modeling framework\n  (IA-STGNN) that links tactical strike variables to strategic delay outcomes\n  via graph neural networks with counterfactual reasoning", "summary": "This study addresses the lack of structured causal modeling between tactical\nstrike behavior and strategic delay in current strategic-level simulations,\nparticularly the structural bottlenecks in capturing intermediate variables\nwithin the \"resilience - nodal suppression - negotiation window\" chain. We\npropose the Intervention-Aware Spatio-Temporal Graph Neural Network (IA-STGNN),\na novel framework that closes the causal loop from tactical input to strategic\ndelay output. The model integrates graph attention mechanisms, counterfactual\nsimulation units, and spatial intervention node reconstruction to enable\ndynamic simulations of strike configurations and synchronization strategies.\nTraining data are generated from a multi-physics simulation platform (GEANT4 +\nCOMSOL) under NIST SP 800-160 standards, ensuring structural traceability and\npolicy-level validation. Experimental results demonstrate that IA-STGNN\nsignificantly outperforms baseline models (ST-GNN, GCN-LSTM, XGBoost),\nachieving a 12.8 percent reduction in MAE and 18.4 percent increase in Top-5\npercent accuracy, while improving causal path consistency and intervention\nstability. IA-STGNN enables interpretable prediction of strategic delay and\nsupports applications such as nuclear deterrence simulation, diplomatic window\nassessment, and multi-strategy optimization, providing a structured and\ntransparent AI decision-support mechanism for high-level policy modeling."}
{"id": "2507.00085", "pdf": "https://arxiv.org/pdf/2507.00085", "abs": "https://arxiv.org/abs/2507.00085", "authors": ["Ruiyuan Jiang", "Dongyao Jia", "Eng Gee Lim", "Pengfei Fan", "Yuli Zhang", "Shangbo Wang"], "title": "A Joint Topology-Data Fusion Graph Network for Robust Traffic Speed Prediction with Data Anomalism", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate traffic prediction is essential for Intelligent Transportation\nSystems (ITS), yet current methods struggle with the inherent complexity and\nnon-linearity of traffic dynamics, making it difficult to integrate spatial and\ntemporal characteristics. Furthermore, existing approaches use static\ntechniques to address non-stationary and anomalous historical data, which\nlimits adaptability and undermines data smoothing. To overcome these\nchallenges, we propose the Graph Fusion Enhanced Network (GFEN), an innovative\nframework for network-level traffic speed prediction. GFEN introduces a novel\ntopological spatiotemporal graph fusion technique that meticulously extracts\nand merges spatial and temporal correlations from both data distribution and\nnetwork topology using trainable methods, enabling the modeling of multi-scale\nspatiotemporal features. Additionally, GFEN employs a hybrid methodology\ncombining a k-th order difference-based mathematical framework with an\nattention-based deep learning structure to adaptively smooth historical\nobservations and dynamically mitigate data anomalies and non-stationarity.\nExtensive experiments demonstrate that GFEN surpasses state-of-the-art methods\nby approximately 6.3% in prediction accuracy and exhibits convergence rates\nnearly twice as fast as recent hybrid models, confirming its superior\nperformance and potential to significantly enhance traffic prediction system\nefficiency."}
{"id": "2507.00087", "pdf": "https://arxiv.org/pdf/2507.00087", "abs": "https://arxiv.org/abs/2507.00087", "authors": ["Jiale Zhao", "Pengzhi Mao", "Kaifei Wang", "Yiming Li", "Yaping Peng", "Ranfei Chen", "Shuqi Lu", "Xiaohong Ji", "Jiaxiang Ding", "Xin Zhang", "Yucheng Liao", "Weinan E", "Weijie Zhang", "Han Wen", "Hao Chi"], "title": "pUniFind: a unified large pre-trained deep learning model pushing the limit of mass spectra interpretation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep learning has advanced mass spectrometry data interpretation, yet most\nmodels remain feature extractors rather than unified scoring frameworks. We\npresent pUniFind, the first large-scale multimodal pre-trained model in\nproteomics that integrates end-to-end peptide-spectrum scoring with open,\nzero-shot de novo sequencing. Trained on over 100 million open search-derived\nspectra, pUniFind aligns spectral and peptide modalities via cross modality\nprediction and outperforms traditional engines across diverse datasets,\nparticularly achieving a 42.6 percent increase in the number of identified\npeptides in immunopeptidomics. Supporting over 1,300 modifications, pUniFind\nidentifies 60 percent more PSMs than existing de novo methods despite a\n300-fold larger search space. A deep learning based quality control module\nfurther recovers 38.5 percent additional peptides including 1,891 mapped to the\ngenome but absent from reference proteomes while preserving full fragment ion\ncoverage. These results establish a unified, scalable deep learning framework\nfor proteomic analysis, offering improved sensitivity, modification coverage,\nand interpretability."}
{"id": "2507.00088", "pdf": "https://arxiv.org/pdf/2507.00088", "abs": "https://arxiv.org/abs/2507.00088", "authors": ["Alexandre S. Pires", "Laurens Samson", "Sennay Ghebreab", "Fernando P. Santos"], "title": "How large language models judge and influence human cooperation", "categories": ["physics.soc-ph", "cs.AI", "cs.SI"], "comment": null, "summary": "Humans increasingly rely on large language models (LLMs) to support decisions\nin social settings. Previous work suggests that such tools shape people's moral\nand political judgements. However, the long-term implications of LLM-based\nsocial decision-making remain unknown. How will human cooperation be affected\nwhen the assessment of social interactions relies on language models? This is a\npressing question, as human cooperation is often driven by indirect\nreciprocity, reputations, and the capacity to judge interactions of others.\nHere, we assess how state-of-the-art LLMs judge cooperative actions. We provide\n21 different LLMs with an extensive set of examples where individuals cooperate\n-- or refuse cooperating -- in a range of social contexts, and ask how these\ninteractions should be judged. Furthermore, through an evolutionary\ngame-theoretical model, we evaluate cooperation dynamics in populations where\nthe extracted LLM-driven judgements prevail, assessing the long-term impact of\nLLMs on human prosociality. We observe a remarkable agreement in evaluating\ncooperation against good opponents. On the other hand, we notice within- and\nbetween-model variance when judging cooperation with ill-reputed individuals.\nWe show that the differences revealed between models can significantly impact\nthe prevalence of cooperation. Finally, we test prompts to steer LLM norms,\nshowing that such interventions can shape LLM judgements, particularly through\ngoal-oriented prompts. Our research connects LLM-based advices and long-term\nsocial dynamics, and highlights the need to carefully align LLM norms in order\nto preserve human cooperation."}
{"id": "2507.00090", "pdf": "https://arxiv.org/pdf/2507.00090", "abs": "https://arxiv.org/abs/2507.00090", "authors": ["Corbeau Michael", "Claeys Emmanuelle", "Serrurier Mathieu", "Zaraté Pascale"], "title": "Generating Heterogeneous Multi-dimensional Data : A Comparative Study", "categories": ["cs.LG", "cs.AI"], "comment": "accepted at IEEE SMC 2025 Vienna", "summary": "Allocation of personnel and material resources is highly sensible in the case\nof firefighter interventions. This allocation relies on simulations to\nexperiment with various scenarios. The main objective of this allocation is the\nglobal optimization of the firefighters response. Data generation is then\nmandatory to study various scenarios In this study, we propose to compare\ndifferent data generation methods. Methods such as Random Sampling, Tabular\nVariational Autoencoders, standard Generative Adversarial Networks, Conditional\nTabular Generative Adversarial Networks and Diffusion Probabilistic Models are\nexamined to ascertain their efficacy in capturing the intricacies of\nfirefighter interventions. Traditional evaluation metrics often fall short in\ncapturing the nuanced requirements of synthetic datasets for real-world\nscenarios. To address this gap, an evaluation of synthetic data quality is\nconducted using a combination of domain-specific metrics tailored to the\nfirefighting domain and standard measures such as the Wasserstein distance.\nDomain-specific metrics include response time distribution, spatial-temporal\ndistribution of interventions, and accidents representation. These metrics are\ndesigned to assess data variability, the preservation of fine and complex\ncorrelations and anomalies such as event with a very low occurrence, the\nconformity with the initial statistical distribution and the operational\nrelevance of the synthetic data. The distribution has the particularity of\nbeing highly unbalanced, none of the variables following a Gaussian\ndistribution, adding complexity to the data generation process."}
{"id": "2507.00093", "pdf": "https://arxiv.org/pdf/2507.00093", "abs": "https://arxiv.org/abs/2507.00093", "authors": ["Binghua Yao", "Joris M. Mooij"], "title": "$σ$-Maximal Ancestral Graphs", "categories": ["cs.DM", "cs.AI", "cs.DS", "math.ST", "stat.TH"], "comment": "It has beee accepted by the 41st Conference on Uncertainty in\n  Artificial Intelligence (UAI)", "summary": "Maximal Ancestral Graphs (MAGs) provide an abstract representation of\nDirected Acyclic Graphs (DAGs) with latent (selection) variables. These\ngraphical objects encode information about ancestral relations and\nd-separations of the DAGs they represent. This abstract representation has been\nused amongst others to prove the soundness and completeness of the FCI\nalgorithm for causal discovery, and to derive a do-calculus for its output. One\nsignificant inherent limitation of MAGs is that they rule out the possibility\nof cyclic causal relationships. In this work, we address that limitation. We\nintroduce and study a class of graphical objects that we coin\n''$\\sigma$-Maximal Ancestral Graphs'' (''$\\sigma$-MAGs''). We show how these\ngraphs provide an abstract representation of (possibly cyclic) Directed Graphs\n(DGs) with latent (selection) variables, analogously to how MAGs represent\nDAGs. We study the properties of these objects and provide a characterization\nof their Markov equivalence classes."}
{"id": "2507.00094", "pdf": "https://arxiv.org/pdf/2507.00094", "abs": "https://arxiv.org/abs/2507.00094", "authors": ["Jacobo Casas-Ramos", "Sarah Winkler", "Alessandro Gianola", "Marco Montali", "Manuel Mucientes", "Manuel Lama"], "title": "Efficient Conformance Checking of Rich Data-Aware Declare Specifications (Extended)", "categories": ["cs.DB", "cs.AI", "cs.PL"], "comment": "Extended version of the paper of the same title accepted at the 23rd\n  International Conference on Business Process Management (BPM 2025)", "summary": "Despite growing interest in process analysis and mining for data-aware\nspecifications, alignment-based conformance checking for declarative process\nmodels has focused on pure control-flow specifications, or mild data-aware\nextensions limited to numerical data and variable-to-constant comparisons. This\nis not surprising: finding alignments is computationally hard, even more so in\nthe presence of data dependencies. In this paper, we challenge this problem in\nthe case where the reference model is captured using data-aware Declare with\ngeneral data types and data conditions. We show that, unexpectedly, it is\npossible to compute data-aware optimal alignments in this rich setting,\nenjoying at once efficiency and expressiveness. This is achieved by carefully\ncombining the two best-known approaches to deal with control flow and data\ndependencies when computing alignments, namely A* search and SMT solving.\nSpecifically, we introduce a novel algorithmic technique that efficiently\nexplores the search space, generating descendant states through the application\nof repair actions aiming at incrementally resolving constraint violations. We\nprove the correctness of our algorithm and experimentally show its efficiency.\nThe evaluation witnesses that our approach matches or surpasses the performance\nof the state of the art while also supporting significantly more expressive\ndata dependencies, showcasing its potential to support real-world applications."}
{"id": "2507.00096", "pdf": "https://arxiv.org/pdf/2507.00096", "abs": "https://arxiv.org/abs/2507.00096", "authors": ["Ailiya Borjigin", "Wei Zhou", "Cong He"], "title": "AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets", "categories": ["cs.CR", "cs.AI"], "comment": "8 Pages, 1 figure", "summary": "Alternative Assets tokenization is transforming non-traditional financial\ninstruments are represented and traded on the web. However, ensuring\ntrustworthiness in web-based tokenized ecosystems poses significant challenges,\nfrom verifying off-chain asset data to enforcing regulatory compliance. This\npaper proposes an AI-governed agent architecture that integrates intelligent\nagents with blockchain to achieve web-trustworthy tokenization of alternative\nassets. In the proposed architecture, autonomous agents orchestrate the\ntokenization process (asset verification, valuation, compliance checking, and\nlifecycle management), while an AI-driven governance layer monitors agent\nbehavior and enforces trust through adaptive policies and cryptoeconomic\nincentives. We demonstrate that this approach enhances transparency, security,\nand compliance in asset tokenization, addressing key concerns around data\nauthenticity and fraud. A case study on tokenizing real estate assets\nillustrates how the architecture mitigates risks (e.g., fraudulent listings and\nmoney laundering) through real-time AI anomaly detection and on-chain\nenforcement. Our evaluation and analysis suggest that combining AI governance\nwith multi-agent systems and blockchain can significantly bolster trust in\ntokenized asset ecosystems. This work offers a novel framework for trustworthy\nasset tokenization on the web and provides insights for practitioners aiming to\ndeploy secure, compliant tokenization platforms."}
{"id": "2507.00102", "pdf": "https://arxiv.org/pdf/2507.00102", "abs": "https://arxiv.org/abs/2507.00102", "authors": ["Bernd Hofmann", "Patrick Bruendl", "Huong Giang Nguyen", "Joerg Franke"], "title": "Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Ensuring consistent product quality in modern manufacturing is crucial,\nparticularly in safety-critical applications. Conventional quality control\napproaches, reliant on manually defined thresholds and features, lack\nadaptability to the complexity and variability inherent in production data and\nnecessitate extensive domain expertise. Conversely, data-driven methods, such\nas machine learning, demonstrate high detection performance but typically\nfunction as black-box models, thereby limiting their acceptance in industrial\nenvironments where interpretability is paramount. This paper introduces a\nmethodology for industrial fault detection, which is both data-driven and\ntransparent. The approach integrates a supervised machine learning model for\nmulti-class fault classification, Shapley Additive Explanations for post-hoc\ninterpretability, and a do-main-specific visualisation technique that maps\nmodel explanations to operator-interpretable features. Furthermore, the study\nproposes an evaluation methodology that assesses model explanations through\nquantitative perturbation analysis and evaluates visualisations by qualitative\nexpert assessment. The approach was applied to the crimping process, a\nsafety-critical joining technique, using a dataset of univariate, discrete time\nseries. The system achieves a fault detection accuracy of 95.9 %, and both\nquantitative selectivity analysis and qualitative expert evaluations confirmed\nthe relevance and inter-pretability of the generated explanations. This\nhuman-centric approach is designed to enhance trust and interpretability in\ndata-driven fault detection, thereby contributing to applied system design in\nindustrial quality control."}
{"id": "2507.00108", "pdf": "https://arxiv.org/pdf/2507.00108", "abs": "https://arxiv.org/abs/2507.00108", "authors": ["Clemente Rubio-Manzano", "Jazna Meza", "Rodolfo Fernandez-Santibanez", "Christian Vidal-Castro"], "title": "Teaching Programming in the Age of Generative AI: Insights from Literature, Pedagogical Proposals, and Student Perspectives", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.PL"], "comment": null, "summary": "Computer programming is undergoing a true transformation driven by powerful\nnew tools for automatic source code generation based on large language models.\nThis transformation is also manifesting in introductory programming courses at\nuniversities around the world, generating an in-depth debate about how\nprogramming content should be taught, learned, and assessed in the context of\ngenerative artificial intelligence.\n  This article aims, on the one hand, to review the most relevant studies on\nthis issue, highlighting the advantages and disadvantages identified in the\nspecialized literature. On the other hand, it proposes enriching teaching and\nlearning methodologies by focusing on code comprehension and execution rather\nthan on mere coding or program functionality. In particular, it advocates for\nthe use of visual representations of code and visual simulations of its\nexecution as effective tools for teaching, learning, and assessing programming,\nthus fostering a deeper understanding among students.\n  Finally, the opinions of students who took the object-oriented programming\ncourse are presented to provide preliminary context supporting the\nincorporation of visual simulations in Java (or other languages) as part of the\ntraining process."}
{"id": "2507.00145", "pdf": "https://arxiv.org/pdf/2507.00145", "abs": "https://arxiv.org/abs/2507.00145", "authors": ["Hasan Yiğit"], "title": "AI-Hybrid TRNG: Kernel-Based Deep Learning for Near-Uniform Entropy Harvesting from Physical Noise", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.IT", "eess.SP", "math.IT"], "comment": null, "summary": "AI-Hybrid TRNG is a deep-learning framework that extracts near-uniform\nentropy directly from physical noise, eliminating the need for bulky quantum\ndevices or expensive laboratory-grade RF receivers. Instead, it relies on a\nlow-cost, thumb-sized RF front end, plus CPU-timing jitter, for training, and\nthen emits 32-bit high-entropy streams without any quantization step.\n  Unlike deterministic or trained artificial intelligence random number\ngenerators (RNGs), our dynamic inner-outer network couples adaptive natural\nsources and reseeding, yielding truly unpredictable and autonomous sequences.\nGenerated numbers pass the NIST SP 800-22 battery better than a CPU-based\nmethod. It also passes nineteen bespoke statistical tests for both bit- and\ninteger-level analysis. All results satisfy cryptographic standards, while\nforward and backward prediction experiments reveal no exploitable biases. The\nmodel's footprint is below 0.5 MB, making it deployable on MCUs and FPGA soft\ncores, as well as suitable for other resource-constrained platforms.\n  By detaching randomness quality from dedicated hardware, AI-Hybrid TRNG\nbroadens the reach of high-integrity random number generators across secure\nsystems, cryptographic protocols, embedded and edge devices, stochastic\nsimulations, and server applications that need randomness."}
{"id": "2507.00161", "pdf": "https://arxiv.org/pdf/2507.00161", "abs": "https://arxiv.org/abs/2507.00161", "authors": ["Christopher M. Wegemer", "Edward Halim", "Jeff Burke"], "title": "Designing an Adaptive Storytelling Platform to Promote Civic Education in Politically Polarized Learning Environments", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Political polarization undermines democratic civic education by exacerbating\nidentity-based resistance to opposing viewpoints. Emerging AI technologies\noffer new opportunities to advance interventions that reduce polarization and\npromote political open-mindedness. We examined novel design strategies that\nleverage adaptive and emotionally-responsive civic narratives that may sustain\nstudents' emotional engagement in stories, and in turn, promote\nperspective-taking toward members of political out-groups. Drawing on theories\nfrom political psychology and narratology, we investigate how affective\ncomputing techniques can support three storytelling mechanisms: transportation\ninto a story world, identification with characters, and interaction with the\nstoryteller. Using a design-based research (DBR) approach, we iteratively\ndeveloped and refined an AI-mediated Digital Civic Storytelling (AI-DCS)\nplatform. Our prototype integrates facial emotion recognition and attention\ntracking to assess users' affective and attentional states in real time.\nNarrative content is organized around pre-structured story outlines, with\nbeat-by-beat language adaptation implemented via GPT-4, personalizing\nlinguistic tone to sustain students' emotional engagement in stories that\ncenter political perspectives different from their own. Our work offers a\nfoundation for AI-supported, emotionally-sensitive strategies that address\naffective polarization while preserving learner autonomy. We conclude with\nimplications for civic education interventions, algorithmic literacy, and HCI\nchallenges associated with AI dialogue management and affect-adaptive learning\nenvironments."}
{"id": "2507.00184", "pdf": "https://arxiv.org/pdf/2507.00184", "abs": "https://arxiv.org/abs/2507.00184", "authors": ["Jacob Schrum", "Olivia Kilday", "Emilio Salas", "Bess Hagan", "Reid Williams"], "title": "Text-to-Level Diffusion Models With Various Text Encoders for Super Mario Bros", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent research shows how diffusion models can unconditionally generate\ntile-based game levels, but use of diffusion models for text-to-level\ngeneration is underexplored. There are practical considerations for creating a\nusable model: caption/level pairs are needed, as is a text embedding model, and\na way of generating entire playable levels, rather than individual scenes. We\npresent strategies to automatically assign descriptive captions to an existing\nlevel dataset, and train diffusion models using both pretrained text encoders\nand simple transformer models trained from scratch. Captions are automatically\nassigned to generated levels so that the degree of overlap between input and\noutput captions can be compared. We also assess the diversity and playability\nof the resulting levels. Results are compared with an unconditional diffusion\nmodel and a generative adversarial network, as well as the text-to-level\napproaches Five-Dollar Model and MarioGPT. Notably, the best diffusion model\nuses a simple transformer model for text embedding, and takes less time to\ntrain than diffusion models employing more complex text encoders, indicating\nthat reliance on larger language models is not necessary. We also present a GUI\nallowing designers to construct long levels from model-generated scenes."}
{"id": "2507.00185", "pdf": "https://arxiv.org/pdf/2507.00185", "abs": "https://arxiv.org/abs/2507.00185", "authors": ["Yang Zhou", "Chrystie Wan Ning Quek", "Jun Zhou", "Yan Wang", "Yang Bai", "Yuhe Ke", "Jie Yao", "Laura Gutierrez", "Zhen Ling Teo", "Darren Shu Jeng Ting", "Brian T. Soetikno", "Christopher S. Nielsen", "Tobias Elze", "Zengxiang Li", "Linh Le Dinh", "Lionel Tim-Ee Cheng", "Tran Nguyen Tuan Anh", "Chee Leong Cheng", "Tien Yin Wong", "Nan Liu", "Iain Beehuat Tan", "Tony Kiat Hon Lim", "Rick Siow Mong Goh", "Yong Liu", "Daniel Shu Wei Ting"], "title": "Multimodal, Multi-Disease Medical Imaging Foundation Model (MerMED-FM)", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "42 pages, 3 composite figures, 4 tables", "summary": "Current artificial intelligence models for medical imaging are predominantly\nsingle modality and single disease. Attempts to create multimodal and\nmulti-disease models have resulted in inconsistent clinical accuracy.\nFurthermore, training these models typically requires large, labour-intensive,\nwell-labelled datasets. We developed MerMED-FM, a state-of-the-art multimodal,\nmulti-specialty foundation model trained using self-supervised learning and a\nmemory module. MerMED-FM was trained on 3.3 million medical images from over\nten specialties and seven modalities, including computed tomography (CT), chest\nX-rays (CXR), ultrasound (US), pathology patches, color fundus photography\n(CFP), optical coherence tomography (OCT) and dermatology images. MerMED-FM was\nevaluated across multiple diseases and compared against existing foundational\nmodels. Strong performance was achieved across all modalities, with AUROCs of\n0.988 (OCT); 0.982 (pathology); 0.951 (US); 0.943 (CT); 0.931 (skin); 0.894\n(CFP); 0.858 (CXR). MerMED-FM has the potential to be a highly adaptable,\nversatile, cross-specialty foundation model that enables robust medical imaging\ninterpretation across diverse medical disciplines."}
{"id": "2507.00191", "pdf": "https://arxiv.org/pdf/2507.00191", "abs": "https://arxiv.org/abs/2507.00191", "authors": ["Eray Erturk", "Fahad Kamran", "Salar Abbaspourazad", "Sean Jewell", "Harsh Sharma", "Yujie Li", "Sinead Williamson", "Nicholas J Foti", "Joseph Futoma"], "title": "Beyond Sensor Data: Foundation Models of Behavioral Data from Wearables Improve Health Predictions", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Wearable devices record physiological and behavioral signals that can improve\nhealth predictions. While foundation models are increasingly used for such\npredictions, they have been primarily applied to low-level sensor data, despite\nbehavioral data often being more informative due to their alignment with\nphysiologically relevant timescales and quantities. We develop foundation\nmodels of such behavioral signals using over 2.5B hours of wearable data from\n162K individuals, systematically optimizing architectures and tokenization\nstrategies for this unique dataset. Evaluated on 57 health-related tasks, our\nmodel shows strong performance across diverse real-world applications including\nindividual-level classification and time-varying health state prediction. The\nmodel excels in behavior-driven tasks like sleep prediction, and improves\nfurther when combined with representations of raw sensor data. These results\nunderscore the importance of tailoring foundation model design to wearables and\ndemonstrate the potential to enable new health applications."}
{"id": "2507.00195", "pdf": "https://arxiv.org/pdf/2507.00195", "abs": "https://arxiv.org/abs/2507.00195", "authors": ["Kumar Kshitij Patel"], "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness", "categories": ["cs.LG", "cs.AI", "cs.MA", "math.OC", "stat.ML"], "comment": null, "summary": "This thesis contributes to the theoretical understanding of local update\nalgorithms, especially Local SGD, in distributed and federated optimization\nunder realistic models of data heterogeneity. A central focus is on the bounded\nsecond-order heterogeneity assumption, which is shown to be both necessary and\nsufficient for local updates to outperform centralized or mini-batch methods in\nconvex and non-convex settings. The thesis establishes tight upper and lower\nbounds in several regimes for various local update algorithms and characterizes\nthe min-max complexity of multiple problem classes. At its core is a\nfine-grained consensus-error-based analysis framework that yields sharper\nfinite-time convergence bounds under third-order smoothness and relaxed\nheterogeneity assumptions. The thesis also extends to online federated\nlearning, providing fundamental regret bounds under both first-order and bandit\nfeedback. Together, these results clarify when and why local updates offer\nprovable advantages, and the thesis serves as a self-contained guide for\nanalyzing Local SGD in heterogeneous environments."}
{"id": "2507.00209", "pdf": "https://arxiv.org/pdf/2507.00209", "abs": "https://arxiv.org/abs/2507.00209", "authors": ["Fengyi Jiang", "Xiaorui Zhang", "Lingbo Jin", "Ruixing Liang", "Yuxin Chen", "Adi Chola Venkatesh", "Jason Culman", "Tiantian Wu", "Lirong Shao", "Wenqing Sun", "Cong Gao", "Hallie McNamara", "Jingpei Lu", "Omid Mohareri"], "title": "SurgiSR4K: A High-Resolution Endoscopic Video Dataset for Robotic-Assisted Minimally Invasive Procedures", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.RO"], "comment": null, "summary": "High-resolution imaging is crucial for enhancing visual clarity and enabling\nprecise computer-assisted guidance in minimally invasive surgery (MIS). Despite\nthe increasing adoption of 4K endoscopic systems, there remains a significant\ngap in publicly available native 4K datasets tailored specifically for\nrobotic-assisted MIS. We introduce SurgiSR4K, the first publicly accessible\nsurgical imaging and video dataset captured at a native 4K resolution,\nrepresenting realistic conditions of robotic-assisted procedures. SurgiSR4K\ncomprises diverse visual scenarios including specular reflections, tool\nocclusions, bleeding, and soft tissue deformations, meticulously designed to\nreflect common challenges faced during laparoscopic and robotic surgeries. This\ndataset opens up possibilities for a broad range of computer vision tasks that\nmight benefit from high resolution data, such as super resolution (SR), smoke\nremoval, surgical instrument detection, 3D tissue reconstruction, monocular\ndepth estimation, instance segmentation, novel view synthesis, and\nvision-language model (VLM) development. SurgiSR4K provides a robust foundation\nfor advancing research in high-resolution surgical imaging and fosters the\ndevelopment of intelligent imaging technologies aimed at enhancing performance,\nsafety, and usability in image-guided robotic surgeries."}
{"id": "2507.00214", "pdf": "https://arxiv.org/pdf/2507.00214", "abs": "https://arxiv.org/abs/2507.00214", "authors": ["Mads Henrichsen", "Rasmus Krebs"], "title": "Two-Stage Reasoning-Infused Learning: Improving Classification with LLM-Generated Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Standard classification models often map inputs directly to labels without\nexplicit reasoning, potentially limiting their performance, robustness, and\ninterpretability. This paper introduces a novel two-stage approach to enhance\ntext classification by leveraging Large Language Model (LLM)-generated\nreasonings. In the first stage, we fine-tune a Llama-3.2-1B-Instruct model\n(henceforth Llama-R-Gen) on a general-purpose reasoning dataset\n(syvai/reasoning-gen) to generate textual reasoning (R) given a question and\nits answer. In the second stage, this generally trained Llama-R-Gen is used\noffline to create an augmented training dataset for a downstream generative\nmodel. This downstream model, based on Llama-3.2-1B-Instruct, takes only the\ninput text (Q) and is trained to output the generated reasoning (R) immediately\nfollowed by the predicted emotion (A). We demonstrate this methodology on the\ndair-ai/emotion dataset for emotion classification. Our experiments show that\nthe generative model trained to output reasoning and the emotion (Classifier\nQ->RA) achieves a significant improvement of 8.7 percentage points in accuracy\n(for emotion prediction) compared to a baseline generative model trained solely\nto output the emotion (Classifier Q->A), highlighting the strong generalization\ncapabilities of the reasoning generation and the benefit of explicit reasoning\ntraining. This work underscores the potential of LLM-generated reasonings for\ncreating richer training datasets, thereby improving the performance of diverse\ndownstream NLP tasks and providing explicit explanations."}
{"id": "2507.00225", "pdf": "https://arxiv.org/pdf/2507.00225", "abs": "https://arxiv.org/abs/2507.00225", "authors": ["S. V. Chekanov", "H. Kjellerstrand"], "title": "Discovering the underlying analytic structure within Standard Model constants using artificial intelligence", "categories": ["hep-ph", "cs.AI", "physics.data-an"], "comment": "42 pages, 10 tables", "summary": "This paper presents a search for underlying analytic structures among the\nfundamental parameters of the Standard Model (SM) using symbolic regression and\ngenetic programming. We identify the simplest analytic relationships connecting\npairs of these constants and report several notable observations based on about\na thousand expressions with relative precision better than 1%. These results\nmay serve as valuable inputs for model builders and artificial intelligence\nmethods aimed at uncovering hidden patterns among the SM constants, or\npotentially used as building blocks for a deeper underlying law that connects\nall parameters of the SM through a small set of fundamental constants."}
{"id": "2507.00227", "pdf": "https://arxiv.org/pdf/2507.00227", "abs": "https://arxiv.org/abs/2507.00227", "authors": ["Paul Mayer", "Florian Lux", "Alejandro Pérez-González-de-Martos", "Angelina Elizarova", "Lindsey Vanderlyn", "Dirk Väth", "Ngoc Thang Vu"], "title": "Investigating Stochastic Methods for Prosody Modeling in Speech Synthesis", "categories": ["eess.AS", "cs.AI"], "comment": "Accepted at Interspeech 2025", "summary": "While generative methods have progressed rapidly in recent years, generating\nexpressive prosody for an utterance remains a challenging task in\ntext-to-speech synthesis. This is particularly true for systems that model\nprosody explicitly through parameters such as pitch, energy, and duration,\nwhich is commonly done for the sake of interpretability and controllability. In\nthis work, we investigate the effectiveness of stochastic methods for this\ntask, including Normalizing Flows, Conditional Flow Matching, and Rectified\nFlows. We compare these methods to a traditional deterministic baseline, as\nwell as to real human realizations. Our extensive subjective and objective\nevaluations demonstrate that stochastic methods produce natural prosody on par\nwith human speakers by capturing the variability inherent in human speech.\nFurther, they open up additional controllability options by allowing the\nsampling temperature to be tuned."}
{"id": "2507.00229", "pdf": "https://arxiv.org/pdf/2507.00229", "abs": "https://arxiv.org/abs/2507.00229", "authors": ["Tarikul Islam Tamiti", "Biraj Joshi", "Rida Hasan", "Rashedul Hasan", "Taieba Athay", "Nursad Mamun", "Anomadarshi Barua"], "title": "A High-Fidelity Speech Super Resolution Network using a Complex Global Attention Module with Spectro-Temporal Loss", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Speech super-resolution (SSR) enhances low-resolution speech by increasing\nthe sampling rate. While most SSR methods focus on magnitude reconstruction,\nrecent research highlights the importance of phase reconstruction for improved\nperceptual quality. Therefore, we introduce CTFT-Net, a Complex Time-Frequency\nTransformation Network that reconstructs both magnitude and phase in complex\ndomains for improved SSR tasks. It incorporates a complex global attention\nblock to model inter-phoneme and inter-frequency dependencies and a complex\nconformer to capture long-range and local features, improving frequency\nreconstruction and noise robustness. CTFT-Net employs time-domain and\nmulti-resolution frequency-domain loss functions for better generalization.\nExperiments show CTFT-Net outperforms state-of-the-art models (NU-Wave,\nWSRGlow, NVSR, AERO) on the VCTK dataset, particularly for extreme upsampling\n(2 kHz to 48 kHz), reconstructing high frequencies effectively without noisy\nartifacts."}
{"id": "2507.00234", "pdf": "https://arxiv.org/pdf/2507.00234", "abs": "https://arxiv.org/abs/2507.00234", "authors": ["Jiztom Kavalakkatt Francis", "Matthew J Darr"], "title": "Interpretable AI for Time-Series: Multi-Model Heatmap Fusion with Global Attention and NLP-Generated Explanations", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "13 pages", "summary": "In this paper, we present a novel framework for enhancing model\ninterpretability by integrating heatmaps produced separately by ResNet and a\nrestructured 2D Transformer with globally weighted input saliency. We address\nthe critical problem of spatial-temporal misalignment in existing\ninterpretability methods, where convolutional networks fail to capture global\ncontext and Transformers lack localized precision - a limitation that impedes\nactionable insights in safety-critical domains like healthcare and industrial\nmonitoring. Our method merges gradient-weighted activation maps (ResNet) and\nTransformer attention rollout into a unified visualization, achieving full\nspatial-temporal alignment while preserving real-time performance. Empirical\nevaluations on clinical (ECG arrhythmia detection) and industrial (energy\nconsumption prediction) datasets demonstrate significant improvements: the\nhybrid framework achieves 94.1% accuracy (F1 0.93) on the PhysioNet dataset and\nreduces regression error to RMSE = 0.28 kWh (R2 = 0.95) on the UCI Energy\nAppliance dataset-outperforming standalone ResNet, Transformer, and\nInceptionTime baselines by 3.8-12.4%. An NLP module translates fused heatmaps\ninto domain-specific narratives (e.g., \"Elevated ST-segment between 2-4 seconds\nsuggests myocardial ischemia\"), validated via BLEU-4 (0.586) and ROUGE-L\n(0.650) scores. By formalizing interpretability as causal fidelity and\nspatial-temporal alignment, our approach bridges the gap between technical\noutputs and stakeholder understanding, offering a scalable solution for\ntransparent, time-aware decision-making."}
{"id": "2507.00239", "pdf": "https://arxiv.org/pdf/2507.00239", "abs": "https://arxiv.org/abs/2507.00239", "authors": ["Aryan Shrivastava", "Ari Holtzman"], "title": "Linearly Decoding Refused Knowledge in Aligned Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Most commonly used language models (LMs) are instruction-tuned and aligned\nusing a combination of fine-tuning and reinforcement learning, causing them to\nrefuse users requests deemed harmful by the model. However, jailbreak prompts\ncan often bypass these refusal mechanisms and elicit harmful responses. In this\nwork, we study the extent to which information accessed via jailbreak prompts\nis decodable using linear probes trained on LM hidden states. We show that a\ngreat deal of initially refused information is linearly decodable. For example,\nacross models, the response of a jailbroken LM for the average IQ of a country\ncan be predicted by a linear probe with Pearson correlations exceeding $0.8$.\nSurprisingly, we find that probes trained on base models (which do not refuse)\nsometimes transfer to their instruction-tuned versions and are capable of\nrevealing information that jailbreaks decode generatively, suggesting that the\ninternal representations of many refused properties persist from base LMs\nthrough instruction-tuning. Importantly, we show that this information is not\nmerely \"leftover\" in instruction-tuned models, but is actively used by them: we\nfind that probe-predicted values correlate with LM generated pairwise\ncomparisons, indicating that the information decoded by our probes align with\nsuppressed generative behavior that may be expressed more subtly in other\ndownstream tasks. Overall, our results suggest that instruction-tuning does not\nwholly eliminate or even relocate harmful information in representation\nspace-they merely suppress its direct expression, leaving it both linearly\naccessible and indirectly influential in downstream behavior."}
{"id": "2507.00248", "pdf": "https://arxiv.org/pdf/2507.00248", "abs": "https://arxiv.org/abs/2507.00248", "authors": ["Nikita Nikitin", "Eugene Fomin"], "title": "Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "7 pages, 2 figures, 2 tables, for associated mpeg file, see\n  https://slait.app/static/Screen_Recording.mp4", "summary": "We present a novel framework for real-time sign language recognition using\nlightweight DNNs trained on limited data. Our system addresses key challenges\nin sign language recognition, including data scarcity, high computational\ncosts, and discrepancies in frame rates between training and inference\nenvironments. By encoding sign language specific parameters, such as handshape,\npalm orientation, movement, and location into vectorized inputs, and leveraging\nMediaPipe for landmark extraction, we achieve highly separable input data\nrepresentations. Our DNN architecture, optimized for sub 10MB deployment,\nenables accurate classification of 343 signs with less than 10ms latency on\nedge devices. The data annotation platform 'slait data' facilitates structured\nlabeling and vector extraction. Our model achieved 92% accuracy in isolated\nsign recognition and has been integrated into the 'slait ai' web application,\nwhere it demonstrates stable inference."}
{"id": "2507.00257", "pdf": "https://arxiv.org/pdf/2507.00257", "abs": "https://arxiv.org/abs/2507.00257", "authors": ["Davide Salaorni", "Vincenzo De Paola", "Samuele Delpero", "Giovanni Dispoto", "Paolo Bonetti", "Alessio Russo", "Giuseppe Calcagno", "Francesco Trovò", "Matteo Papini", "Alberto Maria Metelli", "Marco Mussi", "Marcello Restelli"], "title": "Gym4ReaL: A Suite for Benchmarking Real-World Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages", "summary": "In recent years, \\emph{Reinforcement Learning} (RL) has made remarkable\nprogress, achieving superhuman performance in a wide range of simulated\nenvironments. As research moves toward deploying RL in real-world applications,\nthe field faces a new set of challenges inherent to real-world settings, such\nas large state-action spaces, non-stationarity, and partial observability.\nDespite their importance, these challenges are often underexplored in current\nbenchmarks, which tend to focus on idealized, fully observable, and stationary\nenvironments, often neglecting to incorporate real-world complexities\nexplicitly. In this paper, we introduce \\texttt{Gym4ReaL}, a comprehensive\nsuite of realistic environments designed to support the development and\nevaluation of RL algorithms that can operate in real-world scenarios. The suite\nincludes a diverse set of tasks that expose algorithms to a variety of\npractical challenges. Our experimental results show that, in these settings,\nstandard RL algorithms confirm their competitiveness against rule-based\nbenchmarks, motivating the development of new methods to fully exploit the\npotential of RL to tackle the complexities of real-world tasks."}
{"id": "2507.00258", "pdf": "https://arxiv.org/pdf/2507.00258", "abs": "https://arxiv.org/abs/2507.00258", "authors": ["Jie Hou", "Chuxiong Wu", "Lannan Luo", "Qiang Zeng"], "title": "Impact of Fine-Tuning Methods on Memorization in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As the capabilities of pre-trained large language models (LLMs) continue to\nadvance, the \"pre-train and fine-tune\" paradigm has become increasingly\nmainstream, leading to the development of various fine-tuning methods. However,\nthe privacy risks arising from memorization during fine-tuning have received\nrelatively little attention. To address this gap, we categorize popular\nfine-tuning approaches and assess their impact on memorization through the lens\nof membership inference attacks (MIAs). Our results show that, compared to\nparameter-based fine-tuning, prompt-based fine-tuning achieves competitive\nperformance while exhibiting lower vulnerability to MIAs. Furthermore,\nprompt-based methods maintain low memorization regardless of model scale. These\nfindings suggest that parameter-based fine-tuning is more prone to leaking\nprivate information, whereas prompt-based fine-tuning serves as a more\nprivacy-preserving option."}
{"id": "2507.00268", "pdf": "https://arxiv.org/pdf/2507.00268", "abs": "https://arxiv.org/abs/2507.00268", "authors": ["Oren Fivel", "Matan Rudman", "Kobi Cohen"], "title": "Control-Optimized Deep Reinforcement Learning for Artificially Intelligent Autonomous Systems", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "27 pages, 10 figures", "summary": "Deep reinforcement learning (DRL) has become a powerful tool for complex\ndecision-making in machine learning and AI. However, traditional methods often\nassume perfect action execution, overlooking the uncertainties and deviations\nbetween an agent's selected actions and the actual system response. In\nreal-world applications, such as robotics, mechatronics, and communication\nnetworks, execution mismatches arising from system dynamics, hardware\nconstraints, and latency can significantly degrade performance. This work\nadvances AI by developing a novel control-optimized DRL framework that\nexplicitly models and compensates for action execution mismatches, a challenge\nlargely overlooked in existing methods. Our approach establishes a structured\ntwo-stage process: determining the desired action and selecting the appropriate\ncontrol signal to ensure proper execution. It trains the agent while accounting\nfor action mismatches and controller corrections. By incorporating these\nfactors into the training process, the AI agent optimizes the desired action\nwith respect to both the actual control signal and the intended outcome,\nexplicitly considering execution errors. This approach enhances robustness,\nensuring that decision-making remains effective under real-world uncertainties.\nOur approach offers a substantial advancement for engineering practice by\nbridging the gap between idealized learning and real-world implementation. It\nequips intelligent agents operating in engineering environments with the\nability to anticipate and adjust for actuation errors and system disturbances\nduring training. We evaluate the framework in five widely used open-source\nmechanical simulation environments we restructured and developed to reflect\nreal-world operating conditions, showcasing its robustness against\nuncertainties and offering a highly practical and efficient solution for\ncontrol-oriented applications."}
{"id": "2507.00269", "pdf": "https://arxiv.org/pdf/2507.00269", "abs": "https://arxiv.org/abs/2507.00269", "authors": ["Omar Claflin"], "title": "Feature Integration Spaces: Joint Training Reveals Dual Encoding in Neural Network Representations", "categories": ["q-bio.NC", "cs.AI"], "comment": null, "summary": "Current sparse autoencoder (SAE) approaches to neural network\ninterpretability assume that activations can be decomposed through linear\nsuperposition into sparse, interpretable features. Despite high reconstruction\nfidelity, SAEs consistently fail to eliminate polysemanticity and exhibit\npathological behavioral errors. We propose that neural networks encode\ninformation in two complementary spaces compressed into the same substrate:\nfeature identity and feature integration. To test this dual encoding\nhypothesis, we develop sequential and joint-training architectures to capture\nidentity and integration patterns simultaneously. Joint training achieves 41.3%\nreconstruction improvement and 51.6% reduction in KL divergence errors. This\narchitecture spontaneously develops bimodal feature organization: low squared\nnorm features contributing to integration pathways and the rest contributing\ndirectly to the residual. Small nonlinear components (3% of parameters) achieve\n16.5% standalone improvements, demonstrating parameter-efficient capture of\ncomputational relationships crucial for behavior. Additionally, intervention\nexperiments using 2x2 factorial stimulus designs demonstrated that integration\nfeatures exhibit selective sensitivity to experimental manipulations and\nproduce systematic behavioral effects on model outputs, including significant\ninteraction effects across semantic dimensions. This work provides systematic\nevidence for (1) dual encoding in neural representations, (2) meaningful\nnonlinearly encoded feature interactions, and (3) introduces an architectural\nparadigm shift from post-hoc feature analysis to integrated computational\ndesign, establishing foundations for next-generation SAEs."}
{"id": "2507.00275", "pdf": "https://arxiv.org/pdf/2507.00275", "abs": "https://arxiv.org/abs/2507.00275", "authors": ["Prabhat Nagarajan", "Martha White", "Marlos C. Machado"], "title": "Double Q-learning for Value-based Deep Reinforcement Learning, Revisited", "categories": ["cs.LG", "cs.AI"], "comment": "44 pages", "summary": "Overestimation is pervasive in reinforcement learning (RL), including in\nQ-learning, which forms the algorithmic basis for many value-based deep RL\nalgorithms. Double Q-learning is an algorithm introduced to address\nQ-learning's overestimation by training two Q-functions and using both to\nde-correlate action-selection and action-evaluation in bootstrap targets.\nShortly after Q-learning was adapted to deep RL in the form of deep Q-networks\n(DQN), Double Q-learning was adapted to deep RL in the form of Double DQN.\nHowever, Double DQN only loosely adapts Double Q-learning, forgoing the\ntraining of two different Q-functions that bootstrap off one another. In this\npaper, we study algorithms that adapt this core idea of Double Q-learning for\nvalue-based deep RL. We term such algorithms Deep Double Q-learning (DDQL). Our\naim is to understand whether DDQL exhibits less overestimation than Double DQN\nand whether performant instantiations of DDQL exist. We answer both questions\naffirmatively, demonstrating that DDQL reduces overestimation and outperforms\nDouble DQN in aggregate across 57 Atari 2600 games, without requiring\nadditional hyperparameters. We also study several aspects of DDQL, including\nits network architecture, replay ratio, and minibatch sampling strategy."}
{"id": "2507.00286", "pdf": "https://arxiv.org/pdf/2507.00286", "abs": "https://arxiv.org/abs/2507.00286", "authors": ["Tanusree Sharma", "Yu-Yun Tseng", "Lotus Zhang", "Ayae Ide", "Kelly Avery Mack", "Leah Findlater", "Danna Gurari", "Yang Wang"], "title": "Visual Privacy Management with Generative AI for Blind and Low-Vision People", "categories": ["cs.HC", "cs.AI", "cs.ET"], "comment": null, "summary": "Blind and low vision (BLV) individuals use Generative AI (GenAI) tools to\ninterpret and manage visual content in their daily lives. While such tools can\nenhance the accessibility of visual content and so enable greater user\nindependence, they also introduce complex challenges around visual privacy. In\nthis paper, we investigate the current practices and future design preferences\nof blind and low vision individuals through an interview study with 21\nparticipants. Our findings reveal a range of current practices with GenAI that\nbalance privacy, efficiency, and emotional agency, with users accounting for\nprivacy risks across six key scenarios, such as self-presentation,\nindoor/outdoor spatial privacy, social sharing, and handling professional\ncontent. Our findings reveal design preferences, including on-device\nprocessing, zero-retention guarantees, sensitive content redaction,\nprivacy-aware appearance indicators, and multimodal tactile mirrored\ninteraction methods. We conclude with actionable design recommendations to\nsupport user-centered visual privacy through GenAI, expanding the notion of\nprivacy and responsible handling of others data."}
{"id": "2507.00287", "pdf": "https://arxiv.org/pdf/2507.00287", "abs": "https://arxiv.org/abs/2507.00287", "authors": ["Mohamad Dabboussi", "Malo Huard", "Yann Gousseau", "Pietro Gori"], "title": "Self-Supervised Multiview Xray Matching", "categories": ["cs.CV", "cs.AI"], "comment": "MICCAI 2025", "summary": "Accurate interpretation of multi-view radiographs is crucial for diagnosing\nfractures, muscular injuries, and other anomalies. While significant advances\nhave been made in AI-based analysis of single images, current methods often\nstruggle to establish robust correspondences between different X-ray views, an\nessential capability for precise clinical evaluations. In this work, we present\na novel self-supervised pipeline that eliminates the need for manual annotation\nby automatically generating a many-to-many correspondence matrix between\nsynthetic X-ray views. This is achieved using digitally reconstructed\nradiographs (DRR), which are automatically derived from unannotated CT volumes.\nOur approach incorporates a transformer-based training phase to accurately\npredict correspondences across two or more X-ray views. Furthermore, we\ndemonstrate that learning correspondences among synthetic X-ray views can be\nleveraged as a pretraining strategy to enhance automatic multi-view fracture\ndetection on real data. Extensive evaluations on both synthetic and real X-ray\ndatasets show that incorporating correspondences improves performance in\nmulti-view fracture classification."}
{"id": "2507.00288", "pdf": "https://arxiv.org/pdf/2507.00288", "abs": "https://arxiv.org/abs/2507.00288", "authors": ["Claire Li", "David Freeborn"], "title": "Reconfiguring Digital Accountability: AI-Powered Innovations and Transnational Governance in a Postnational Accounting Context", "categories": ["econ.TH", "cs.AI", "cs.ET"], "comment": "22 pages", "summary": "This study explores how AI-powered digital innovations are reshaping\norganisational accountability in a transnational governance context. As AI\nsystems increasingly mediate decision-making in domains such as auditing and\nfinancial reporting, traditional mechanisms of accountability, based on\ncontrol, transparency, and auditability, are being destabilised. We integrate\nthe Technology Acceptance Model (TAM), Actor-Network Theory (ANT), and\ninstitutional theory to examine how organisations adopt AI technologies in\nresponse to regulatory, ethical, and cultural pressures that transcend national\nboundaries. We argue that accountability is co-constructed within global\nsocio-technical networks, shaped not only by user perceptions but also by\ngovernance logics and normative expectations. Extending TAM, we incorporate\ncompliance and legitimacy as key factors in perceived usefulness and usability.\nDrawing on ANT, we reconceptualise accountability as a relational and emergent\nproperty of networked assemblages. We propose two organisational strategies\nincluding internal governance reconfiguration and external actor-network\nengagement to foster responsible, legitimate, and globally accepted AI adoption\nin the accounting domain."}
{"id": "2507.00292", "pdf": "https://arxiv.org/pdf/2507.00292", "abs": "https://arxiv.org/abs/2507.00292", "authors": ["Ali Mammadov", "Loïc Le Folgoc", "Guillaume Hocquet", "Pietro Gori"], "title": "Reducing Variability of Multiple Instance Learning Methods for Digital Pathology", "categories": ["cs.CV", "cs.AI"], "comment": "MICCAI 2025", "summary": "Digital pathology has revolutionized the field by enabling the digitization\nof tissue samples into whole slide images (WSIs). However, the high resolution\nand large size of WSIs present significant challenges when it comes to applying\nDeep Learning models. As a solution, WSIs are often divided into smaller\npatches with a global label (\\textit{i.e., diagnostic}) per slide, instead of a\n(too) costly pixel-wise annotation. By treating each slide as a bag of patches,\nMultiple Instance Learning (MIL) methods have emerged as a suitable solution\nfor WSI classification. A major drawback of MIL methods is their high\nvariability in performance across different runs, which can reach up to 10-15\nAUC points on the test set, making it difficult to compare different MIL\nmethods reliably. This variability mainly comes from three factors: i) weight\ninitialization, ii) batch (shuffling) ordering, iii) and learning rate. To\naddress that, we introduce a Multi-Fidelity, Model Fusion strategy for MIL\nmethods. We first train multiple models for a few epochs and average the most\nstable and promising ones based on validation scores. This approach can be\napplied to any existing MIL model to reduce performance variability. It also\nsimplifies hyperparameter tuning and improves reproducibility while maintaining\ncomputational efficiency. We extensively validate our approach on WSI\nclassification tasks using 2 different datasets, 3 initialization strategies\nand 5 MIL methods, for a total of more than 2000 experiments."}
{"id": "2507.00297", "pdf": "https://arxiv.org/pdf/2507.00297", "abs": "https://arxiv.org/abs/2507.00297", "authors": ["David Ifeoluwa Adelani"], "title": "Natural language processing for African languages", "categories": ["cs.CL", "cs.AI"], "comment": "PhD thesis", "summary": "Recent advances in word embeddings and language models use large-scale,\nunlabelled data and self-supervised learning to boost NLP performance.\nMultilingual models, often trained on web-sourced data like Wikipedia, face\nchallenges: few low-resource languages are included, their data is often noisy,\nand lack of labeled datasets makes it hard to evaluate performance outside\nhigh-resource languages like English. In this dissertation, we focus on\nlanguages spoken in Sub-Saharan Africa where all the indigenous languages in\nthis region can be regarded as low-resourced in terms of the availability of\nlabelled data for NLP tasks and unlabelled data found on the web. We analyse\nthe noise in the publicly available corpora, and curate a high-quality corpus,\ndemonstrating that the quality of semantic representations learned in word\nembeddings does not only depend on the amount of data but on the quality of\npre-training data. We demonstrate empirically the limitations of word\nembeddings, and the opportunities the multilingual pre-trained language model\n(PLM) offers especially for languages unseen during pre-training and\nlow-resource scenarios. We further study how to adapt and specialize\nmultilingual PLMs to unseen African languages using a small amount of\nmonolingual texts. To address the under-representation of the African languages\nin NLP research, we developed large scale human-annotated labelled datasets for\n21 African languages in two impactful NLP tasks: named entity recognition and\nmachine translation. We conduct an extensive empirical evaluation using\nstate-of-the-art methods across supervised, weakly-supervised, and transfer\nlearning settings."}
{"id": "2507.00310", "pdf": "https://arxiv.org/pdf/2507.00310", "abs": "https://arxiv.org/abs/2507.00310", "authors": ["Dhruv Agarwal", "Bodhisattwa Prasad Majumder", "Reece Adamson", "Megha Chakravorty", "Satvika Reddy Gavireddy", "Aditya Parashar", "Harshit Surana", "Bhavana Dalvi Mishra", "Andrew McCallum", "Ashish Sabharwal", "Peter Clark"], "title": "Open-ended Scientific Discovery via Bayesian Surprise", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The promise of autonomous scientific discovery (ASD) hinges not only on\nanswering questions, but also on knowing which questions to ask. Most recent\nworks in ASD explore the use of large language models (LLMs) in goal-driven\nsettings, relying on human-specified research questions to guide hypothesis\ngeneration. However, scientific discovery may be accelerated further by\nallowing the AI system to drive exploration by its own criteria. The few\nexisting approaches in open-ended ASD select hypotheses based on diversity\nheuristics or subjective proxies for human interestingness, but the former\nstruggles to meaningfully navigate the typically vast hypothesis space, and the\nlatter suffers from imprecise definitions. This paper presents AutoDS -- a\nmethod for open-ended ASD that instead drives scientific exploration using\nBayesian surprise. Here, we quantify the epistemic shift from the LLM's prior\nbeliefs about a hypothesis to its posterior beliefs after gathering\nexperimental results. To efficiently explore the space of nested hypotheses,\nour method employs a Monte Carlo tree search (MCTS) strategy with progressive\nwidening using surprisal as the reward function. We evaluate AutoDS in the\nsetting of data-driven discovery across 21 real-world datasets spanning domains\nsuch as biology, economics, finance, and behavioral science. Our results\ndemonstrate that under a fixed budget, AutoDS substantially outperforms\ncompetitors by producing 5--29\\% more discoveries deemed surprising by the LLM.\nOur human evaluation further finds that two-thirds of AutoDS discoveries are\nsurprising to the domain experts, suggesting this is an important step forward\ntowards building open-ended ASD systems."}
{"id": "2507.00322", "pdf": "https://arxiv.org/pdf/2507.00322", "abs": "https://arxiv.org/abs/2507.00322", "authors": ["Daking Rai", "Samuel Miller", "Kevin Moran", "Ziyu Yao"], "title": "Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones", "categories": ["cs.CL", "cs.AI", "cs.SE", "I.2.7"], "comment": "23 pages, 10 figures, Preprint", "summary": "Despite remarkable advances in coding capabilities, language models (LMs)\nstill struggle with simple syntactic tasks such as generating balanced\nparentheses. In this study, we investigate the underlying mechanisms behind the\npersistence of these errors across LMs of varying sizes (124M-7B) to both\nunderstand and mitigate the errors. Our study reveals that LMs rely on a number\nof components (attention heads and FF neurons) that independently make their\nown predictions. While some components reliably promote correct answers across\na generalized range of inputs (i.e., implementing \"sound mechanisms''), others\nare less reliable and introduce noise by promoting incorrect tokens (i.e.,\nimplementing \"faulty mechanisms''). Errors occur when the faulty mechanisms\novershadow the sound ones and dominantly affect the predictions. Motivated by\nthis insight, we introduce RASteer, a steering method to systematically\nidentify and increase the contribution of reliable components for improving\nmodel performance. RASteer substantially improves performance on balanced\nparentheses tasks, boosting accuracy of some models from $0$% to around $100$%\nwithout impairing the models' general coding ability. We further demonstrate\nits broader applicability in arithmetic reasoning tasks, achieving performance\ngains of up to around $20$%."}
{"id": "2507.00339", "pdf": "https://arxiv.org/pdf/2507.00339", "abs": "https://arxiv.org/abs/2507.00339", "authors": ["Alexander Moore", "Amar Saini", "Kylie Cancilla", "Doug Poland", "Carmen Carrano"], "title": "Training for X-Ray Vision: Amodal Segmentation, Amodal Content Completion, and View-Invariant Object Representation from Multi-Camera Video", "categories": ["cs.CV", "cs.AI", "68T45, 68T07", "I.2.10; I.2.6; I.4.6"], "comment": "9 pages, 2 figures", "summary": "Amodal segmentation and amodal content completion require using object priors\nto estimate occluded masks and features of objects in complex scenes. Until\nnow, no data has provided an additional dimension for object context: the\npossibility of multiple cameras sharing a view of a scene. We introduce\nMOVi-MC-AC: Multiple Object Video with Multi-Cameras and Amodal Content, the\nlargest amodal segmentation and first amodal content dataset to date. Cluttered\nscenes of generic household objects are simulated in multi-camera video.\nMOVi-MC-AC contributes to the growing literature of object detection, tracking,\nand segmentation by including two new contributions to the deep learning for\ncomputer vision world. Multiple Camera (MC) settings where objects can be\nidentified and tracked between various unique camera perspectives are rare in\nboth synthetic and real-world video. We introduce a new complexity to synthetic\nvideo by providing consistent object ids for detections and segmentations\nbetween both frames and multiple cameras each with unique features and motion\npatterns on a single scene. Amodal Content (AC) is a reconstructive task in\nwhich models predict the appearance of target objects through occlusions. In\nthe amodal segmentation literature, some datasets have been released with\namodal detection, tracking, and segmentation labels. While other methods rely\non slow cut-and-paste schemes to generate amodal content pseudo-labels, they do\nnot account for natural occlusions present in the modal masks. MOVi-MC-AC\nprovides labels for ~5.8 million object instances, setting a new maximum in the\namodal dataset literature, along with being the first to provide ground-truth\namodal content. The full dataset is available at\nhttps://huggingface.co/datasets/Amar-S/MOVi-MC-AC ,"}
{"id": "2507.00347", "pdf": "https://arxiv.org/pdf/2507.00347", "abs": "https://arxiv.org/abs/2507.00347", "authors": ["Sun Ding", "Ude Enebeli", "Atilhan", "Manay", "Ryan Pua", "Kamal Kotak"], "title": "VTS-Guided AI Interaction Workflow for Business Insights", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Modern firms face a flood of dense, unstructured reports. Turning these\ndocuments into usable insights takes heavy effort and is far from agile when\nquick answers are needed. VTS-AI tackles this gap. It integrates Visual\nThinking Strategies, which emphasize evidence-based observation, linking, and\nthinking, into AI agents, so the agents can extract business insights from\nunstructured text, tables, and images at scale. The system works in three tiers\n(micro, meso, macro). It tags issues, links them to source pages, and rolls\nthem into clear action levers stored in a searchable YAML file. In tests on an\n18-page business report, VTS-AI matched the speed of a one-shot ChatGPT prompt\nyet produced richer findings: page locations, verbatim excerpts, severity\nscores, and causal links. Analysts can accept or adjust these outputs in the\nsame IDE, keeping human judgment in the loop. Early results show VTS-AI spots\nthe direction of key metrics and flags where deeper number-crunching is needed.\nNext steps include mapping narrative tags to financial ratios, adding\nfinance-tuned language models through a Model-Context Protocol, and building a\nRisk & Safety Layer to stress-test models and secure data. These upgrades aim\nto make VTS-AI a production-ready, audit-friendly tool for rapid business\nanalysis."}
{"id": "2507.00352", "pdf": "https://arxiv.org/pdf/2507.00352", "abs": "https://arxiv.org/abs/2507.00352", "authors": ["Abanoub E. Abdelmalak", "Mohamed A. Elsayed", "David Abercrombie", "Ilhami Torunoglu"], "title": "An AST-guided LLM Approach for SVRF Code Synthesis", "categories": ["cs.SE", "cs.AI", "cs.ET"], "comment": "9 Pages, 5 Figures, 2 Tables", "summary": "Standard Verification Rule Format (SVRF) is essential for semiconductor\napplications like Design Rule Check (DRC), Layout Versus Schematic (LVS), and\nOptical Proximity Correction (OPC) and it faces challenges as advancing nodes\ncreate complex design rules that renders traditional SVRF development\nineffective and highlight an expertise gap. This paper introduces a novel\nmethodology integrating Abstract Syntax Tree (AST) embedding and\nRetrieval-Augmented Generation (RAG) for enhanced SVRF code synthesis, ensuring\nsemantic accuracy and error minimization through structural validation with\ndomain-specific insights for precise code generation.\n  We evaluate different T5-based models and propose an innovative SVRF-specific\nscoring framework that complements standard metrics like BLEU and ROUGE-L. In\nour approach, AST provides rigorous structural validation, while RAG infuses\nrelevant domain knowledge, effectively enhancing the code generation workflow.\n  Testing on a comprehensive benchmark of 740 DRC rule implementations, our\nmethodology demonstrates up to a 40\\% improvement in code generation accuracy\ncompared to basic text-based fine-tuning process. This fusion of industry\nexpertise with advanced coding strategies not only optimizes SVRF development\nunder limited dataset constraints but also creates a more intuitive and\nefficient coding environment. Consequently, users can rapidly iterate through\ndesign cycles, reduce manual error correction, and significantly improve\noverall productivity."}
{"id": "2507.00356", "pdf": "https://arxiv.org/pdf/2507.00356", "abs": "https://arxiv.org/abs/2507.00356", "authors": ["Zhiwei Yi", "Xin Cheng", "Jingyu Ma", "Ruifei Zhu", "Junwei Tian", "Yuanxiu Zhou", "Xinge Zhao", "Hongzhe Li"], "title": "CGEarthEye:A High-Resolution Remote Sensing Vision Foundation Model Based on the Jilin-1 Satellite Constellation", "categories": ["cs.CV", "cs.AI"], "comment": "A Remote Sensing Fundation Model for Very High Resolution Images", "summary": "Deep learning methods have significantly advanced the development of\nintelligent rinterpretation in remote sensing (RS), with foundational model\nresearch based on large-scale pre-training paradigms rapidly reshaping various\ndomains of Earth Observation (EO). However, compared to the open accessibility\nand high spatiotemporal coverage of medium-resolution data, the limited\nacquisition channels for ultra-high-resolution optical RS imagery have\nconstrained the progress of high-resolution remote sensing vision foundation\nmodels (RSVFM). As the world's largest sub-meter-level commercial RS satellite\nconstellation, the Jilin-1 constellation possesses abundant sub-meter-level\nimage resources. This study proposes CGEarthEye, a RSVFM framework specifically\ndesigned for Jilin-1 satellite characteristics, comprising five backbones with\ndifferent parameter scales with totaling 2.1 billion parameters. To enhance the\nrepresentational capacity of the foundation model, we developed JLSSD, the\nfirst 15-million-scale multi-temporal self-supervised learning (SSL) dataset\nfeaturing global coverage with quarterly temporal sampling within a single\nyear, constructed through multi-level representation clustering and sampling\nstrategies. The framework integrates seasonal contrast, augmentation-based\ncontrast, and masked patch token contrastive strategies for pre-training.\nComprehensive evaluations across 10 benchmark datasets covering four typical RS\ntasks demonstrate that the CGEarthEye consistently achieves state-of-the-art\n(SOTA) performance. Further analysis reveals CGEarthEye's superior\ncharacteristics in feature visualization, model convergence, parameter\nefficiency, and practical mapping applications. This study anticipates that the\nexceptional representation capabilities of CGEarthEye will facilitate broader\nand more efficient applications of Jilin-1 data in traditional EO application."}
{"id": "2507.00358", "pdf": "https://arxiv.org/pdf/2507.00358", "abs": "https://arxiv.org/abs/2507.00358", "authors": ["Yilie Huang", "Xun Yu Zhou"], "title": "Data-Driven Exploration for a Class of Continuous-Time Linear--Quadratic Reinforcement Learning Problems", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "math.OC"], "comment": "36 pages, 10 figures", "summary": "We study reinforcement learning (RL) for the same class of continuous-time\nstochastic linear--quadratic (LQ) control problems as in\n\\cite{huang2024sublinear}, where volatilities depend on both states and\ncontrols while states are scalar-valued and running control rewards are absent.\nWe propose a model-free, data-driven exploration mechanism that adaptively\nadjusts entropy regularization by the critic and policy variance by the actor.\nUnlike the constant or deterministic exploration schedules employed in\n\\cite{huang2024sublinear}, which require extensive tuning for implementations\nand ignore learning progresses during iterations, our adaptive exploratory\napproach boosts learning efficiency with minimal tuning. Despite its\nflexibility, our method achieves a sublinear regret bound that matches the\nbest-known model-free results for this class of LQ problems, which were\npreviously derived only with fixed exploration schedules. Numerical experiments\ndemonstrate that adaptive explorations accelerate convergence and improve\nregret performance compared to the non-adaptive model-free and model-based\ncounterparts."}
{"id": "2507.00378", "pdf": "https://arxiv.org/pdf/2507.00378", "abs": "https://arxiv.org/abs/2507.00378", "authors": ["Xikai Sun", "Fan Dang", "Kebin Liu", "Xin Miao", "Zihao Yang", "Haimo Lu", "Yawen Zheng", "Yunhao Liu"], "title": "iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing", "categories": ["cs.SE", "cs.AI"], "comment": "14 pages, 6 figures", "summary": "Conformance testing is essential for ensuring that protocol implementations\ncomply with their specifications. However, traditional testing approaches\ninvolve manually creating numerous test cases and scripts, making the process\nlabor-intensive and inefficient. Recently, Large Language Models (LLMs) have\ndemonstrated impressive text comprehension and code generation abilities,\nproviding promising opportunities for automation. In this paper, we propose\niPanda, the first end-to-end framework that leverages LLMs to automate protocol\nconformance testing. Given a protocol specification document and its\nimplementation, iPanda first employs a keyword-based method to automatically\ngenerate comprehensive test cases. Then, it utilizes a code-based\nretrieval-augmented generation approach to effectively interpret the\nimplementation and produce executable test code. To further enhance code\nquality, iPanda incorporates an iterative self-correction mechanism to refine\ngenerated test scripts interactively. Finally, by executing and analyzing the\ngenerated tests, iPanda systematically verifies compliance between\nimplementations and protocol specifications. Comprehensive experiments on\nvarious protocols show that iPanda significantly outperforms pure LLM-based\napproaches, improving the success rate (Pass@1) of test-code generation by\nfactors ranging from 4.675 times to 10.751 times."}
{"id": "2507.00407", "pdf": "https://arxiv.org/pdf/2507.00407", "abs": "https://arxiv.org/abs/2507.00407", "authors": ["Cong Fu", "Yuchao Lin", "Zachary Krueger", "Haiyang Yu", "Maho Nakata", "Jianwen Xie", "Emine Kucukbenli", "Xiaofeng Qian", "Shuiwang Ji"], "title": "Augmenting Molecular Graphs with Geometries via Machine Learning Interatomic Potentials", "categories": ["physics.chem-ph", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Accurate molecular property predictions require 3D geometries, which are\ntypically obtained using expensive methods such as density functional theory\n(DFT). Here, we attempt to obtain molecular geometries by relying solely on\nmachine learning interatomic potential (MLIP) models. To this end, we first\ncurate a large-scale molecular relaxation dataset comprising 3.5 million\nmolecules and 300 million snapshots. Then MLIP foundation models are trained\nwith supervised learning to predict energy and forces given 3D molecular\nstructures. Once trained, we show that the foundation models can be used in\ndifferent ways to obtain geometries either explicitly or implicitly. First, it\ncan be used to obtain low-energy 3D geometries via geometry optimization,\nproviding relaxed 3D geometries for downstream molecular property predictions.\nTo mitigate potential biases and enhance downstream predictions, we introduce\ngeometry fine-tuning based on the relaxed 3D geometries. Second, the foundation\nmodels can be directly fine-tuned for property prediction when ground truth 3D\ngeometries are available. Our results demonstrate that MLIP foundation models\ntrained on relaxation data can provide valuable molecular geometries that\nbenefit property predictions."}
{"id": "2507.00418", "pdf": "https://arxiv.org/pdf/2507.00418", "abs": "https://arxiv.org/abs/2507.00418", "authors": ["Mohammad Firas Sada", "John J. Graham", "Elham E Khoda", "Mahidhar Tatineni", "Dmitry Mishin", "Rajesh K. Gupta", "Rick Wagner", "Larry Smarr", "Thomas A. DeFanti", "Frank Würthwein"], "title": "Serving LLMs in HPC Clusters: A Comparative Study of Qualcomm Cloud AI 100 Ultra and High-Performance GPUs", "categories": ["cs.DC", "cs.AI"], "comment": "To appear in Proceedings of the Practice and Experience in Advanced\n  Research Computing (PEARC '25)", "summary": "This study presents a benchmarking analysis of the Qualcomm Cloud AI 100\nUltra (QAic) accelerator for large language model (LLM) inference, evaluating\nits energy efficiency (throughput per watt) and performance against leading\nNVIDIA (A100, H200) and AMD (MI300A) GPUs within the National Research Platform\n(NRP) ecosystem. A total of 15 open-source LLMs, ranging from 117 million to 90\nbillion parameters, are served using the vLLM framework. The QAic inference\ncards appears to be energy efficient and performs well in the energy efficiency\nmetric in most cases. The findings offer insights into the potential of the\nQualcomm Cloud AI 100 Ultra for high-performance computing (HPC) applications\nwithin the National Research Platform (NRP)."}
{"id": "2507.00419", "pdf": "https://arxiv.org/pdf/2507.00419", "abs": "https://arxiv.org/abs/2507.00419", "authors": ["Yimin Dou", "Xinming Wu", "Nathan L Bangs", "Harpreet Singh Sethi", "Jintao Li", "Hang Gao", "Zhixiang Guo"], "title": "Geological Everything Model 3D: A Promptable Foundation Model for Unified and Zero-Shot Subsurface Understanding", "categories": ["physics.geo-ph", "cs.AI"], "comment": null, "summary": "Understanding Earth's subsurface is critical for energy transition, natural\nhazard mitigation, and planetary science. Yet subsurface analysis remains\nfragmented, with separate models required for structural interpretation,\nstratigraphic analysis, geobody segmentation, and property modeling-each\ntightly coupled to specific data distributions and task formulations. We\nintroduce the Geological Everything Model 3D (GEM), a unified generative\narchitecture that reformulates all these tasks as prompt-conditioned inference\nalong latent structural frameworks derived from subsurface imaging. This\nformulation moves beyond task-specific models by enabling a shared inference\nmechanism, where GEM propagates human-provided prompts-such as well logs,\nmasks, or structural sketches-along inferred structural frameworks to produce\ngeologically coherent outputs. Through this mechanism, GEM achieves zero-shot\ngeneralization across tasks with heterogeneous prompt types, without retraining\nfor new tasks or data sources. This capability emerges from a two-stage\ntraining process that combines self-supervised representation learning on\nlarge-scale field seismic data with adversarial fine-tuning using mixed prompts\nand labels across diverse subsurface tasks. GEM demonstrates broad\napplicability across surveys and tasks, including Martian radar stratigraphy\nanalysis, structural interpretation in subduction zones, full seismic\nstratigraphic interpretation, geobody delineation, and property modeling. By\nbridging expert knowledge with generative reasoning in a structurally aware\nmanner, GEM lays the foundation for scalable, human-in-the-loop geophysical\nAI-transitioning from fragmented pipelines to a vertically integrated,\npromptable reasoning system. Project page: https://douyimin.github.io/GEM"}
{"id": "2507.00435", "pdf": "https://arxiv.org/pdf/2507.00435", "abs": "https://arxiv.org/abs/2507.00435", "authors": ["Yi Ru Wang", "Carter Ung", "Grant Tannert", "Jiafei Duan", "Josephine Li", "Amy Le", "Rishabh Oswal", "Markus Grotz", "Wilbert Pumacay", "Yuquan Deng", "Ranjay Krishna", "Dieter Fox", "Siddhartha Srinivasa"], "title": "RoboEval: Where Robotic Manipulation Meets Structured and Scalable Evaluation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Project page: https://robo-eval.github.io", "summary": "We present RoboEval, a simulation benchmark and structured evaluation\nframework designed to reveal the limitations of current bimanual manipulation\npolicies. While prior benchmarks report only binary task success, we show that\nsuch metrics often conceal critical weaknesses in policy behavior -- such as\npoor coordination, slipping during grasping, or asymmetric arm usage. RoboEval\nintroduces a suite of tiered, semantically grounded tasks decomposed into\nskill-specific stages, with variations that systematically challenge spatial,\nphysical, and coordination capabilities. Tasks are paired with fine-grained\ndiagnostic metrics and 3000+ human demonstrations to support imitation\nlearning. Our experiments reveal that policies with similar success rates\ndiverge in how tasks are executed -- some struggle with alignment, others with\ntemporally consistent bimanual control. We find that behavioral metrics\ncorrelate with success in over half of task-metric pairs, and remain\ninformative even when binary success saturates. By pinpointing when and how\npolicies fail, RoboEval enables a deeper, more actionable understanding of\nrobotic manipulation -- and highlights the need for evaluation tools that go\nbeyond success alone."}
{"id": "2507.00440", "pdf": "https://arxiv.org/pdf/2507.00440", "abs": "https://arxiv.org/abs/2507.00440", "authors": ["Yujia Yin", "Tianyi Qu", "Zihao Wang", "Yifan Chen"], "title": "A Recipe for Causal Graph Regression: Confounding Effects Revisited", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": "ICML 2025 accepted", "summary": "Through recognizing causal subgraphs, causal graph learning (CGL) has risen\nto be a promising approach for improving the generalizability of graph neural\nnetworks under out-of-distribution (OOD) scenarios. However, the empirical\nsuccesses of CGL techniques are mostly exemplified in classification settings,\nwhile regression tasks, a more challenging setting in graph learning, are\noverlooked. We thus devote this work to tackling causal graph regression (CGR);\nto this end we reshape the processing of confounding effects in existing CGL\nstudies, which mainly deal with classification. Specifically, we reflect on the\npredictive power of confounders in graph-level regression, and generalize\nclassification-specific causal intervention techniques to regression through a\nlens of contrastive learning. Extensive experiments on graph OOD benchmarks\nvalidate the efficacy of our proposals for CGR. The model implementation and\nthe code are provided on https://github.com/causal-graph/CGR."}
{"id": "2507.00443", "pdf": "https://arxiv.org/pdf/2507.00443", "abs": "https://arxiv.org/abs/2507.00443", "authors": ["Reza Ahmadvand", "Sarah Safura Sharif", "Yaser Mike Banad"], "title": "Novel Pigeon-inspired 3D Obstacle Detection and Avoidance Maneuver for Multi-UAV Systems", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "11 Pages, 11 Pictures, 1 Table, 3 Algorithms", "summary": "Recent advances in multi-agent systems manipulation have demonstrated a\nrising demand for the implementation of multi-UAV systems in urban areas, which\nare always subjected to the presence of static and dynamic obstacles. Inspired\nby the collective behavior of tilapia fish and pigeons, the focus of the\npresented research is on the introduction of a nature-inspired collision-free\nformation control for a multi-UAV system, considering the obstacle avoidance\nmaneuvers. The developed framework in this study utilizes a semi-distributed\ncontrol approach, in which, based on a probabilistic Lloyd's algorithm, a\ncentralized guidance algorithm works for optimal positioning of the UAVs, while\na distributed control approach has been used for the intervehicle collision and\nobstacle avoidance. Further, the presented framework has been extended to the\n3D space with a novel definition of 3D maneuvers. Finally, the presented\nframework has been applied to multi-UAV systems in 2D and 3D scenarios, and the\nobtained results demonstrated the validity of the presented method in dynamic\nenvironments with stationary and moving obstacles."}
{"id": "2507.00445", "pdf": "https://arxiv.org/pdf/2507.00445", "abs": "https://arxiv.org/abs/2507.00445", "authors": ["Xingyu Su", "Xiner Li", "Masatoshi Uehara", "Sunwoo Kim", "Yulai Zhao", "Gabriele Scalia", "Ehsan Hajiramezanali", "Tommaso Biancalani", "Degui Zhi", "Shuiwang Ji"], "title": "Iterative Distillation for Reward-Guided Fine-Tuning of Diffusion Models in Biomolecular Design", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "We address the problem of fine-tuning diffusion models for reward-guided\ngeneration in biomolecular design. While diffusion models have proven highly\neffective in modeling complex, high-dimensional data distributions, real-world\napplications often demand more than high-fidelity generation, requiring\noptimization with respect to potentially non-differentiable reward functions\nsuch as physics-based simulation or rewards based on scientific knowledge.\nAlthough RL methods have been explored to fine-tune diffusion models for such\nobjectives, they often suffer from instability, low sample efficiency, and mode\ncollapse due to their on-policy nature. In this work, we propose an iterative\ndistillation-based fine-tuning framework that enables diffusion models to\noptimize for arbitrary reward functions. Our method casts the problem as policy\ndistillation: it collects off-policy data during the roll-in phase, simulates\nreward-based soft-optimal policies during roll-out, and updates the model by\nminimizing the KL divergence between the simulated soft-optimal policy and the\ncurrent model policy. Our off-policy formulation, combined with KL divergence\nminimization, enhances training stability and sample efficiency compared to\nexisting RL-based methods. Empirical results demonstrate the effectiveness and\nsuperior reward optimization of our approach across diverse tasks in protein,\nsmall molecule, and regulatory DNA design."}
{"id": "2507.00451", "pdf": "https://arxiv.org/pdf/2507.00451", "abs": "https://arxiv.org/abs/2507.00451", "authors": ["Matthew Stephenson", "Alex Newcombe", "Eric Piette", "Dennis Soemers"], "title": "Best Agent Identification for General Game Playing", "categories": ["cs.LG", "cs.AI", "cs.DS", "cs.IT", "math.IT", "stat.ML"], "comment": null, "summary": "We present an efficient and generalised procedure to accurately identify the\nbest performing algorithm for each sub-task in a multi-problem domain. Our\napproach treats this as a set of best arm identification problems for\nmulti-armed bandits, where each bandit corresponds to a specific task and each\narm corresponds to a specific algorithm or agent. We propose an optimistic\nselection process based on the Wilson score interval (Optimistic-WS) that ranks\neach arm across all bandits in terms of their potential regret reduction. We\nevaluate the performance of Optimistic-WS on two of the most popular general\ngame domains, the General Video Game AI (GVGAI) framework and the Ludii general\ngame playing system, with the goal of identifying the highest performing agent\nfor each game within a limited number of trials. Compared to previous best arm\nidentification algorithms for multi-armed bandits, our results demonstrate a\nsubstantial performance improvement in terms of average simple regret. This\nnovel approach can be used to significantly improve the quality and accuracy of\nagent evaluation procedures for general game frameworks, as well as other\nmulti-task domains with high algorithm runtimes."}
{"id": "2507.00454", "pdf": "https://arxiv.org/pdf/2507.00454", "abs": "https://arxiv.org/abs/2507.00454", "authors": ["Yihao Zhen", "Qiang Wang", "Yu Qiao", "Liangqiong Qu", "Huijie Fan"], "title": "ATSTrack: Enhancing Visual-Language Tracking by Aligning Temporal and Spatial Scales", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "A main challenge of Visual-Language Tracking (VLT) is the misalignment\nbetween visual inputs and language descriptions caused by target movement.\nPrevious trackers have explored many effective feature modification methods to\npreserve more aligned features. However, an important yet unexplored factor\nultimately hinders their capability, which is the inherent differences in the\ntemporal and spatial scale of information between visual and language inputs.\nTo address this issue, we propose a novel visual-language tracker that enhances\nthe effect of feature modification by \\textbf{A}ligning \\textbf{T}emporal and\n\\textbf{S}patial scale of different input components, named as\n\\textbf{ATSTrack}. Specifically, we decompose each language description into\nphrases with different attributes based on their temporal and spatial\ncorrespondence with visual inputs, and modify their features in a fine-grained\nmanner. Moreover, we introduce a Visual-Language token that comprises modified\nlinguistic information from the previous frame to guide the model to extract\nvisual features that are more relevant to language description, thereby\nreducing the impact caused by the differences in spatial scale. Experimental\nresults show that our proposed ATSTrack achieves performance comparable to\nexisting methods. Our code will be released."}
{"id": "2507.00459", "pdf": "https://arxiv.org/pdf/2507.00459", "abs": "https://arxiv.org/abs/2507.00459", "authors": ["Hoang Cuong Phan", "Minh Tien Tran", "Chihun Lee", "Hoheok Kim", "Sehyok Oh", "Dong-Kyu Kim", "Ho Won Lee"], "title": "Process-aware and high-fidelity microstructure generation using stable diffusion", "categories": ["cond-mat.mtrl-sci", "cs.AI"], "comment": "46 pages, 13 figures, 5 tables, 3rd Word Congress on Artificial\n  Intelligence in Materials & Manufacturing 2025", "summary": "Synthesizing realistic microstructure images conditioned on processing\nparameters is crucial for understanding process-structure relationships in\nmaterials design. However, this task remains challenging due to limited\ntraining micrographs and the continuous nature of processing variables. To\novercome these challenges, we present a novel process-aware generative modeling\napproach based on Stable Diffusion 3.5 Large (SD3.5-Large), a state-of-the-art\ntext-to-image diffusion model adapted for microstructure generation. Our method\nintroduces numeric-aware embeddings that encode continuous variables (annealing\ntemperature, time, and magnification) directly into the model's conditioning,\nenabling controlled image generation under specified process conditions and\ncapturing process-driven microstructural variations. To address data scarcity\nand computational constraints, we fine-tune only a small fraction of the\nmodel's weights via DreamBooth and Low-Rank Adaptation (LoRA), efficiently\ntransferring the pre-trained model to the materials domain. We validate realism\nusing a semantic segmentation model based on a fine-tuned U-Net with a VGG16\nencoder on 24 labeled micrographs. It achieves 97.1% accuracy and 85.7% mean\nIoU, outperforming previous methods. Quantitative analyses using physical\ndescriptors and spatial statistics show strong agreement between synthetic and\nreal microstructures. Specifically, two-point correlation and lineal-path\nerrors remain below 2.1% and 0.6%, respectively. Our method represents the\nfirst adaptation of SD3.5-Large for process-aware microstructure generation,\noffering a scalable approach for data-driven materials design."}
{"id": "2507.00461", "pdf": "https://arxiv.org/pdf/2507.00461", "abs": "https://arxiv.org/abs/2507.00461", "authors": ["Garimella Ramamurthy", "Marcos Eduardo Valle", "Tata Jagannadha Swamy"], "title": "Novel Complex-Valued Hopfield Neural Networks with Phase and Magnitude Quantization", "categories": ["cs.NE", "cs.AI"], "comment": "Paper submitted to the Fifth International Conference on Emerging\n  Techniques in Computational Intelligence (ICETCI 2025)", "summary": "This research paper introduces two novel complex-valued Hopfield neural\nnetworks (CvHNNs) that incorporate phase and magnitude quantization. The first\nCvHNN employs a ceiling-type activation function that operates on the\nrectangular coordinate representation of the complex net contribution. The\nsecond CvHNN similarly incorporates phase and magnitude quantization but\nutilizes a ceiling-type activation function based on the polar coordinate\nrepresentation of the complex net contribution. The proposed CvHNNs, with their\nphase and magnitude quantization, significantly increase the number of states\ncompared to existing models in the literature, thereby expanding the range of\npotential applications for CvHNNs."}
{"id": "2507.00467", "pdf": "https://arxiv.org/pdf/2507.00467", "abs": "https://arxiv.org/abs/2507.00467", "authors": ["Sijan Bhattarai", "Saurav Bhandari", "Girija Bhusal", "Saroj Shakya", "Tapendra Pandey"], "title": "Diversity Conscious Refined Random Forest", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Random Forest (RF) is a widely used ensemble learning technique known for its\nrobust classification performance across diverse domains. However, it often\nrelies on hundreds of trees and all input features, leading to high inference\ncost and model redundancy. In this work, our goal is to grow trees dynamically\nonly on informative features and then enforce maximal diversity by clustering\nand retaining uncorrelated trees. Therefore, we propose a Refined Random Forest\nClassifier that iteratively refines itself by first removing the least\ninformative features and then analytically determines how many new trees should\nbe grown, followed by correlation-based clustering to remove redundant trees.\nThe classification accuracy of our model was compared against the standard RF\non the same number of trees. Experiments on 8 multiple benchmark datasets,\nincluding binary and multiclass datasets, demonstrate that the proposed model\nachieves improved accuracy compared to standard RF."}
{"id": "2507.00482", "pdf": "https://arxiv.org/pdf/2507.00482", "abs": "https://arxiv.org/abs/2507.00482", "authors": ["Chanseok Lee", "Fakhriyya Mammadova", "Jiseong Barg", "Mooseok Jang"], "title": "Physics-Aware Style Transfer for Adaptive Holographic Reconstruction", "categories": ["physics.optics", "cs.AI", "cs.LG"], "comment": "Keywords: holographic imaging, style transfer, phase retrieval, deep\n  learning", "summary": "Inline holographic imaging presents an ill-posed inverse problem of\nreconstructing objects' complex amplitude from recorded diffraction patterns.\nAlthough recent deep learning approaches have shown promise over classical\nphase retrieval algorithms, they often require high-quality ground truth\ndatasets of complex amplitude maps to achieve a statistical inverse mapping\noperation between the two domains. Here, we present a physics-aware style\ntransfer approach that interprets the object-to-sensor distance as an implicit\nstyle within diffraction patterns. Using the style domain as the intermediate\ndomain to construct cyclic image translation, we show that the inverse mapping\noperation can be learned in an adaptive manner only with datasets composed of\nintensity measurements. We further demonstrate its biomedical applicability by\nreconstructing the morphology of dynamically flowing red blood cells,\nhighlighting its potential for real-time, label-free imaging. As a framework\nthat leverages physical cues inherently embedded in measurements, the presented\nmethod offers a practical learning strategy for imaging applications where\nground truth is difficult or impossible to obtain."}
{"id": "2507.00485", "pdf": "https://arxiv.org/pdf/2507.00485", "abs": "https://arxiv.org/abs/2507.00485", "authors": ["Weiran Guo", "Guanjun Liu", "Ziyuan Zhou", "Ling Wang"], "title": "PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) is widely used in tasks where agents interact\nwith an environment to maximize rewards. Building on this foundation, Safe\nReinforcement Learning (Safe RL) incorporates a cost metric alongside the\nreward metric, ensuring that agents adhere to safety constraints during\ndecision-making. In this paper, we identify that Safe RL is vulnerable to\nbackdoor attacks, which can manipulate agents into performing unsafe actions.\nFirst, we introduce the relevant concepts and evaluation metrics for backdoor\nattacks in Safe RL. It is the first attack framework in the Safe RL field that\ninvolves both Positive and Negative Action sample (PNAct) is to implant\nbackdoors, where positive action samples provide reference actions and negative\naction samples indicate actions to be avoided. We theoretically point out the\nproperties of PNAct and design an attack algorithm. Finally, we conduct\nexperiments to evaluate the effectiveness of our proposed backdoor attack\nframework, evaluating it with the established metrics. This paper highlights\nthe potential risks associated with Safe RL and underscores the feasibility of\nsuch attacks. Our code and supplementary material are available at\nhttps://github.com/azure-123/PNAct."}
{"id": "2507.00491", "pdf": "https://arxiv.org/pdf/2507.00491", "abs": "https://arxiv.org/abs/2507.00491", "authors": ["Zain Taufique", "Aman Vyas", "Antonio Miele", "Pasi Liljeberg", "Anil Kanduri"], "title": "Twill: Scheduling Compound AI Systems on Heterogeneous Mobile Edge Platforms", "categories": ["cs.MA", "cs.AI", "cs.CV", "cs.PF"], "comment": "9 Pages, 9 Figures, Accepted in International Conference on\n  Computer-Aided Design (ICCAD) 2025", "summary": "Compound AI (cAI) systems chain multiple AI models to solve complex problems.\ncAI systems are typically composed of deep neural networks (DNNs),\ntransformers, and large language models (LLMs), exhibiting a high degree of\ncomputational diversity and dynamic workload variation. Deploying cAI services\non mobile edge platforms poses a significant challenge in scheduling concurrent\nDNN-transformer inference tasks, which arrive dynamically in an unknown\nsequence. Existing mobile edge AI inference strategies manage multi-DNN or\ntransformer-only workloads, relying on design-time profiling, and cannot handle\nconcurrent inference of DNNs and transformers required by cAI systems. In this\nwork, we address the challenge of scheduling cAI systems on heterogeneous\nmobile edge platforms. We present Twill, a run-time framework to handle\nconcurrent inference requests of cAI workloads through task affinity-aware\ncluster mapping and migration, priority-aware task freezing/unfreezing, and\nDVFS, while minimizing inference latency within power budgets. We implement and\ndeploy our Twill framework on the Nvidia Jetson Orin NX platform. We evaluate\nTwill against state-of-the-art edge AI inference techniques over contemporary\nDNNs and LLMs, reducing inference latency by 54% on average, while honoring\npower budgets."}
{"id": "2507.00493", "pdf": "https://arxiv.org/pdf/2507.00493", "abs": "https://arxiv.org/abs/2507.00493", "authors": ["Fenil R. Doshi", "Thomas Fel", "Talia Konkle", "George Alvarez"], "title": "Visual Anagrams Reveal Hidden Differences in Holistic Shape Processing Across Vision Models", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://www.fenildoshi.com/configural-shape/", "summary": "Humans are able to recognize objects based on both local texture cues and the\nconfiguration of object parts, yet contemporary vision models primarily harvest\nlocal texture cues, yielding brittle, non-compositional features. Work on\nshape-vs-texture bias has pitted shape and texture representations in\nopposition, measuring shape relative to texture, ignoring the possibility that\nmodels (and humans) can simultaneously rely on both types of cues, and\nobscuring the absolute quality of both types of representation. We therefore\nrecast shape evaluation as a matter of absolute configural competence,\noperationalized by the Configural Shape Score (CSS), which (i) measures the\nability to recognize both images in Object-Anagram pairs that preserve local\ntexture while permuting global part arrangement to depict different object\ncategories. Across 86 convolutional, transformer, and hybrid models, CSS (ii)\nuncovers a broad spectrum of configural sensitivity with fully self-supervised\nand language-aligned transformers -- exemplified by DINOv2, SigLIP2 and\nEVA-CLIP -- occupying the top end of the CSS spectrum. Mechanistic probes\nreveal that (iii) high-CSS networks depend on long-range interactions:\nradius-controlled attention masks abolish performance showing a distinctive\nU-shaped integration profile, and representational-similarity analyses expose a\nmid-depth transition from local to global coding. A BagNet control remains at\nchance (iv), ruling out \"border-hacking\" strategies. Finally, (v) we show that\nconfigural shape score also predicts other shape-dependent evals. Overall, we\npropose that the path toward truly robust, generalizable, and human-like vision\nsystems may not lie in forcing an artificial choice between shape and texture,\nbut rather in architectural and learning frameworks that seamlessly integrate\nboth local-texture and global configural shape."}
{"id": "2507.00509", "pdf": "https://arxiv.org/pdf/2507.00509", "abs": "https://arxiv.org/abs/2507.00509", "authors": ["To Eun Kim", "João Coelho", "Gbemileke Onilude", "Jai Singh"], "title": "TeamCMU at Touché: Adversarial Co-Evolution for Advertisement Integration and Detection in Conversational Search", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As conversational search engines increasingly adopt generation-based\nparadigms powered by Large Language Models (LLMs) and Retrieval-Augmented\nGeneration (RAG), the integration of advertisements into generated responses\npresents both commercial opportunities and challenges for user experience.\nUnlike traditional search, where advertisements are clearly delineated,\ngenerative systems blur the boundary between informational content and\npromotional material, raising concerns around transparency and trust. In this\nwork, we propose a modular pipeline for advertisement management in RAG-based\nconversational systems, consisting of an ad-rewriter for seamless ad\nintegration and a robust ad-classifier for detection. We leverage synthetic\ndata to train high-performing classifiers, which are then used to guide two\ncomplementary ad-integration strategies: supervised fine-tuning of the\nad-rewriter and a best-of-N sampling approach that selects the least detectable\nad-integrated response among multiple candidates. Our evaluation focuses on two\ncore questions: the effectiveness of ad classifiers in detecting diverse ad\nintegration strategies, and the training methods that best support coherent,\nminimally intrusive ad insertion. Experimental results show that our\nad-classifier, trained on synthetic advertisement data inspired by marketing\nstrategies and enhanced through curriculum learning, achieves robust detection\nperformance. Additionally, we demonstrate that classifier-guided optimization,\nthrough both fine-tuning and best-of-N sampling, significantly improves ad\nstealth, enabling more seamless integration. These findings contribute an\nadversarial co-evolution framework for developing more sophisticated ad-aware\ngenerative search systems and robust ad classifiers."}
{"id": "2507.00513", "pdf": "https://arxiv.org/pdf/2507.00513", "abs": "https://arxiv.org/abs/2507.00513", "authors": ["Kai Qin", "Kexin Du", "Yimeng Chen", "Yueyan Liu", "Jie Cai", "Zhiqiang Nie", "Nan Gao", "Guohui Wei", "Shengzhu Wang", "Chun Yu"], "title": "Customer Service Representative's Perception of the AI Assistant in an Organization's Call Center", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "ACM CSCW Poster 2025", "summary": "The integration of various AI tools creates a complex socio-technical\nenvironment where employee-customer interactions form the core of work\npractices. This study investigates how customer service representatives (CSRs)\nat the power grid service customer service call center perceive AI assistance\nin their interactions with customers. Through a field visit and semi-structured\ninterviews with 13 CSRs, we found that AI can alleviate some traditional\nburdens during the call (e.g., typing and memorizing) but also introduces new\nburdens (e.g., earning, compliance, psychological burdens). This research\ncontributes to a more nuanced understanding of AI integration in organizational\nsettings and highlights the efforts and burdens undertaken by CSRs to adapt to\nthe updated system."}
{"id": "2507.00525", "pdf": "https://arxiv.org/pdf/2507.00525", "abs": "https://arxiv.org/abs/2507.00525", "authors": ["Djamahl Etchegaray", "Yuxia Fu", "Zi Huang", "Yadan Luo"], "title": "Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Interpretable communication is essential for safe and trustworthy autonomous\ndriving, yet current vision-language models (VLMs) often operate under\nidealized assumptions and struggle to capture user intent in real-world\nscenarios. Existing driving-oriented VQA datasets are limited to full-scene\ndescriptions or waypoint prediction, preventing the assessment of whether VLMs\ncan respond to localized user-driven queries. We introduce Box-QAymo, a\nbox-referring dataset and benchmark designed to both evaluate and finetune VLMs\non spatial and temporal reasoning over user-specified objects. Users express\nintent by drawing bounding boxes, offering a fast and intuitive interface for\nfocused queries in complex scenes. Specifically, we propose a hierarchical\nevaluation protocol that begins with binary sanity-check questions to assess\nbasic model capacities, and progresses to (1) attribute prediction for\nbox-referred objects, (2) motion understanding of target instances, and (3)\nspatiotemporal motion reasoning over inter-object dynamics across frames. To\nsupport this, we crowd-sourced fine-grained object classes and visual\nattributes that reflect the complexity drivers encounter, and extract object\ntrajectories to construct temporally grounded QA pairs. Rigorous quality\ncontrol through negative sampling, temporal consistency checks, and\ndifficulty-aware balancing guarantee dataset robustness and diversity. Our\ncomprehensive evaluation reveals significant limitations in current VLMs when\nqueried about perception questions, highlighting the gap in achieving\nreal-world performance. This work provides a foundation for developing more\nrobust and interpretable autonomous driving systems that can communicate\neffectively with users under real-world conditions. Project page and dataset\nare available at https://djamahl99.github.io/qaymo-pages/."}
{"id": "2507.00535", "pdf": "https://arxiv.org/pdf/2507.00535", "abs": "https://arxiv.org/abs/2507.00535", "authors": ["Dietmar Jannach", "Amra Delić", "Francesco Ricci", "Markus Zanker"], "title": "Rethinking Group Recommender Systems in the Era of Generative AI: From One-Shot Recommendations to Agentic Group Decision Support", "categories": ["cs.IR", "cs.AI"], "comment": "Submitted for publication", "summary": "More than twenty-five years ago, first ideas were developed on how to design\na system that can provide recommendations to groups of users instead of\nindividual users. Since then, a rich variety of algorithmic proposals were\npublished, e.g., on how to acquire individual preferences, how to aggregate\nthem, and how to generate recommendations for groups of users. However, despite\nthe rich literature on the topic, barely any examples of real-world group\nrecommender systems can be found. This lets us question common assumptions in\nacademic research, in particular regarding communication processes in a group\nand how recommendation-supported decisions are made. In this essay, we argue\nthat these common assumptions and corresponding system designs often may not\nmatch the needs or expectations of users. We thus call for a reorientation in\nthis research area, leveraging the capabilities of modern Generative AI\nassistants like ChatGPT. Specifically, as one promising future direction, we\nenvision group recommender systems to be systems where human group members\ninteract in a chat and an AI-based group recommendation agent assists the\ndecision-making process in an agentic way. Ultimately, this shall lead to a\nmore natural group decision-making environment and finally to wider adoption of\ngroup recommendation systems in practice."}
{"id": "2507.00537", "pdf": "https://arxiv.org/pdf/2507.00537", "abs": "https://arxiv.org/abs/2507.00537", "authors": ["Feng Lin", "Marco Chen", "Haokui Zhang", "Xiaotian Yu", "Guangming Lu", "Rong Xiao"], "title": "Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "21 pages, 7 figures", "summary": "This paper studies the role of attention heads in CLIP's image encoder. While\nCLIP has exhibited robust performance across diverse applications, we\nhypothesize that certain attention heads negatively affect final\nrepresentations and that ablating them can improve performance in downstream\ntasks. To capitalize on this insight, we propose a simple yet effective method,\ncalled Attention Ablation Technique (AAT), to suppress the contribution of\nspecific heads by manipulating attention weights. By integrating two\nalternative strategies tailored for different application scenarios, AAT\nsystematically identifies and ablates detrimental attention heads to enhance\nrepresentation quality. Experiments demonstrate that AAT consistently improves\ndownstream task performance across various domains, boosting recall rate by up\nto 11.1% on CLIP-family models for cross-modal retrieval. The results highlight\nthe potential of AAT to effectively refine large-scale vision-language models\nwith virtually no increase in inference cost."}
{"id": "2507.00546", "pdf": "https://arxiv.org/pdf/2507.00546", "abs": "https://arxiv.org/abs/2507.00546", "authors": ["Reza Marzban", "Ali Adibi", "Raphael Pestourie"], "title": "Inverse Design in Nanophotonics via Representation Learning", "categories": ["physics.app-ph", "cs.AI", "cs.LG", "physics.optics"], "comment": null, "summary": "Inverse design in nanophotonics, the computational discovery of structures\nachieving targeted electromagnetic (EM) responses, has become a key tool for\nrecent optical advances. Traditional intuition-driven or iterative optimization\nmethods struggle with the inherently high-dimensional, non-convex design spaces\nand the substantial computational demands of EM simulations. Recently, machine\nlearning (ML) has emerged to address these bottlenecks effectively. This review\nframes ML-enhanced inverse design methodologies through the lens of\nrepresentation learning, classifying them into two categories: output-side and\ninput-side approaches. Output-side methods use ML to learn a representation in\nthe solution space to create a differentiable solver that accelerates\noptimization. Conversely, input-side techniques employ ML to learn compact,\nlatent-space representations of feasible device geometries, enabling efficient\nglobal exploration through generative models. Each strategy presents unique\ntrade-offs in data requirements, generalization capacity, and novel design\ndiscovery potentials. Hybrid frameworks that combine physics-based optimization\nwith data-driven representations help escape poor local optima, improve\nscalability, and facilitate knowledge transfer. We conclude by highlighting\nopen challenges and opportunities, emphasizing complexity management,\ngeometry-independent representations, integration of fabrication constraints,\nand advancements in multiphysics co-designs."}
{"id": "2507.00577", "pdf": "https://arxiv.org/pdf/2507.00577", "abs": "https://arxiv.org/abs/2507.00577", "authors": ["Yinghao Wu", "Liyan Zhang"], "title": "BadViM: Backdoor Attack against Vision Mamba", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": null, "summary": "Vision State Space Models (SSMs), particularly architectures like Vision\nMamba (ViM), have emerged as promising alternatives to Vision Transformers\n(ViTs). However, the security implications of this novel architecture,\nespecially their vulnerability to backdoor attacks, remain critically\nunderexplored. Backdoor attacks aim to embed hidden triggers into victim\nmodels, causing the model to misclassify inputs containing these triggers while\nmaintaining normal behavior on clean inputs. This paper investigates the\nsusceptibility of ViM to backdoor attacks by introducing BadViM, a novel\nbackdoor attack framework specifically designed for Vision Mamba. The proposed\nBadViM leverages a Resonant Frequency Trigger (RFT) that exploits the frequency\nsensitivity patterns of the victim model to create stealthy, distributed\ntriggers. To maximize attack efficacy, we propose a Hidden State Alignment loss\nthat strategically manipulates the internal representations of model by\naligning the hidden states of backdoor images with those of target classes.\nExtensive experimental results demonstrate that BadViM achieves superior attack\nsuccess rates while maintaining clean data accuracy. Meanwhile, BadViM exhibits\nremarkable resilience against common defensive measures, including PatchDrop,\nPatchShuffle and JPEG compression, which typically neutralize normal backdoor\nattacks."}
{"id": "2507.00579", "pdf": "https://arxiv.org/pdf/2507.00579", "abs": "https://arxiv.org/abs/2507.00579", "authors": ["Miriam Anschütz", "Ekaterina Gikalo", "Niklas Herbster", "Georg Groh"], "title": "TUM-MiKaNi at SemEval-2025 Task 3: Towards Multilingual and Knowledge-Aware Non-factual Hallucination Identification", "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, 3 figures, SemEval-2025 Task 3, ACL", "summary": "Hallucinations are one of the major problems of LLMs, hindering their\ntrustworthiness and deployment to wider use cases. However, most of the\nresearch on hallucinations focuses on English data, neglecting the multilingual\nnature of LLMs. This paper describes our submission to the SemEval-2025 Task-3\n- Mu-SHROOM, the Multilingual Shared-task on Hallucinations and Related\nObservable Overgeneration Mistakes. We propose a two-part pipeline that\ncombines retrieval-based fact verification against Wikipedia with a BERT-based\nsystem fine-tuned to identify common hallucination patterns. Our system\nachieves competitive results across all languages, reaching top-10 results in\neight languages, including English. Moreover, it supports multiple languages\nbeyond the fourteen covered by the shared task. This multilingual hallucination\nidentifier can help to improve LLM outputs and their usefulness in the future."}
{"id": "2507.00583", "pdf": "https://arxiv.org/pdf/2507.00583", "abs": "https://arxiv.org/abs/2507.00583", "authors": ["Christian Internò", "Robert Geirhos", "Markus Olhofer", "Sunny Liu", "Barbara Hammer", "David Klindt"], "title": "AI-Generated Video Detection via Perceptual Straightening", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid advancement of generative AI enables highly realistic synthetic\nvideos, posing significant challenges for content authentication and raising\nurgent concerns about misuse. Existing detection methods often struggle with\ngeneralization and capturing subtle temporal inconsistencies. We propose\nReStraV(Representation Straightening Video), a novel approach to distinguish\nnatural from AI-generated videos. Inspired by the \"perceptual straightening\"\nhypothesis -- which suggests real-world video trajectories become more straight\nin neural representation domain -- we analyze deviations from this expected\ngeometric property. Using a pre-trained self-supervised vision transformer\n(DINOv2), we quantify the temporal curvature and stepwise distance in the\nmodel's representation domain. We aggregate statistics of these measures for\neach video and train a classifier. Our analysis shows that AI-generated videos\nexhibit significantly different curvature and distance patterns compared to\nreal videos. A lightweight classifier achieves state-of-the-art detection\nperformance (e.g., 97.17% accuracy and 98.63% AUROC on the VidProM benchmark),\nsubstantially outperforming existing image- and video-based methods. ReStraV is\ncomputationally efficient, it is offering a low-cost and effective detection\nsolution. This work provides new insights into using neural representation\ngeometry for AI-generated video detection."}
{"id": "2507.00589", "pdf": "https://arxiv.org/pdf/2507.00589", "abs": "https://arxiv.org/abs/2507.00589", "authors": ["Seok Bin Son", "Joongheon Kim"], "title": "Quantum Circuit Structure Optimization for Quantum Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) enables agents to learn optimal policies through\nenvironmental interaction. However, RL suffers from reduced learning efficiency\ndue to the curse of dimensionality in high-dimensional spaces. Quantum\nreinforcement learning (QRL) addresses this issue by leveraging superposition\nand entanglement in quantum computing, allowing efficient handling of\nhigh-dimensional problems with fewer resources. QRL combines quantum neural\nnetworks (QNNs) with RL, where the parameterized quantum circuit (PQC) acts as\nthe core computational module. The PQC performs linear and nonlinear\ntransformations through gate operations, similar to hidden layers in classical\nneural networks. Previous QRL studies, however, have used fixed PQC structures\nbased on empirical intuition without verifying their optimality. This paper\nproposes a QRL-NAS algorithm that integrates quantum neural architecture search\n(QNAS) to optimize PQC structures within QRL. Experiments demonstrate that\nQRL-NAS achieves higher rewards than QRL with fixed circuits, validating its\neffectiveness and practical utility."}
{"id": "2507.00598", "pdf": "https://arxiv.org/pdf/2507.00598", "abs": "https://arxiv.org/abs/2507.00598", "authors": ["Madison Cotteret", "Christopher J. Kymn", "Hugh Greatorex", "Martin Ziegler", "Elisabetta Chicca", "Friedrich T. Sommer"], "title": "High-resolution spatial memory requires grid-cell-like neural codes", "categories": ["cs.NE", "cs.AI", "cs.SC"], "comment": "14 pages, 4 figures. Supplementary material: 11 pages, 5 figures", "summary": "Continuous attractor networks (CANs) are widely used to model how the brain\ntemporarily retains continuous behavioural variables via persistent recurrent\nactivity, such as an animal's position in an environment. However, this memory\nmechanism is very sensitive to even small imperfections, such as noise or\nheterogeneity, which are both common in biological systems. Previous work has\nshown that discretising the continuum into a finite set of discrete attractor\nstates provides robustness to these imperfections, but necessarily reduces the\nresolution of the represented variable, creating a dilemma between stability\nand resolution. We show that this stability-resolution dilemma is most severe\nfor CANs using unimodal bump-like codes, as in traditional models. To overcome\nthis, we investigate sparse binary distributed codes based on random feature\nembeddings, in which neurons have spatially-periodic receptive fields. We\ndemonstrate theoretically and with simulations that such grid-cell-like codes\nenable CANs to achieve both high stability and high resolution simultaneously.\nThe model extends to embedding arbitrary nonlinear manifolds into a CAN, such\nas spheres or tori, and generalises linear path integration to integration\nalong freely-programmable on-manifold vector fields. Together, this work\nprovides a theory of how the brain could robustly represent continuous\nvariables with high resolution and perform flexible computations over\ntask-relevant manifolds."}
{"id": "2507.00606", "pdf": "https://arxiv.org/pdf/2507.00606", "abs": "https://arxiv.org/abs/2507.00606", "authors": ["Tao Xiong", "Xavier Hu", "Wenyan Fan", "Shengyu Zhang"], "title": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) excel in complex tasks through advanced\nprompting techniques like Chain-of-Thought (CoT) and Tree-of-Thought (ToT), but\ntheir reliance on manually crafted, task-specific prompts limits adaptability\nand efficiency. We introduce Mixture of Reasoning (MoR), a training framework\nthat embeds diverse reasoning strategies into LLMs for autonomous,\ntask-adaptive reasoning without external prompt engineering. MoR has two\nphases: Thought Generation, creating reasoning chain templates with models like\nGPT-4o, and SFT Dataset Construction, pairing templates with benchmark datasets\nfor supervised fine-tuning.Our experiments show that MoR significantly enhances\nperformance, with MoR150 achieving 0.730 (2.2% improvement) using CoT prompting\nand 0.734 (13.5% improvement) compared to baselines. MoR eliminates the need\nfor task-specific prompts, offering a generalizable solution for robust\nreasoning across diverse tasks."}
{"id": "2507.00611", "pdf": "https://arxiv.org/pdf/2507.00611", "abs": "https://arxiv.org/abs/2507.00611", "authors": ["Chenyang Cao", "Miguel Rogel-García", "Mohamed Nabail", "Xueqian Wang", "Nicholas Rhinehart"], "title": "Residual Reward Models for Preference-based Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "26 pages, 22 figures", "summary": "Preference-based Reinforcement Learning (PbRL) provides a way to learn\nhigh-performance policies in environments where the reward signal is hard to\nspecify, avoiding heuristic and time-consuming reward design. However, PbRL can\nsuffer from slow convergence speed since it requires training in a reward\nmodel. Prior work has proposed learning a reward model from demonstrations and\nfine-tuning it using preferences. However, when the model is a neural network,\nusing different loss functions for pre-training and fine-tuning can pose\nchallenges to reliable optimization. In this paper, we propose a method to\neffectively leverage prior knowledge with a Residual Reward Model (RRM). An RRM\nassumes that the true reward of the environment can be split into a sum of two\nparts: a prior reward and a learned reward. The prior reward is a term\navailable before training, for example, a user's ``best guess'' reward\nfunction, or a reward function learned from inverse reinforcement learning\n(IRL), and the learned reward is trained with preferences. We introduce\nstate-based and image-based versions of RRM and evaluate them on several tasks\nin the Meta-World environment suite. Experimental results show that our method\nsubstantially improves the performance of a common PbRL method. Our method\nachieves performance improvements for a variety of different types of prior\nrewards, including proxy rewards, a reward obtained from IRL, and even a\nnegated version of the proxy reward. We also conduct experiments with a Franka\nPanda to show that our method leads to superior performance on a real robot. It\nsignificantly accelerates policy learning for different tasks, achieving\nsuccess in fewer steps than the baseline. The videos are presented at\nhttps://sunlighted.github.io/RRM-web/."}
{"id": "2507.00613", "pdf": "https://arxiv.org/pdf/2507.00613", "abs": "https://arxiv.org/abs/2507.00613", "authors": ["Nuno Capitão", "Yi Zhang", "Yidong Zhao", "Qian Tao"], "title": "Physics-Informed Neural ODEs for Temporal Dynamics Modeling in Cardiac T1 Mapping", "categories": ["eess.IV", "cs.AI"], "comment": "Submitted version. Accepted at MICCAI 2025", "summary": "Spin-lattice relaxation time ($T_1$) is an important biomarker in cardiac\nparametric mapping for characterizing myocardial tissue and diagnosing\ncardiomyopathies. Conventional Modified Look-Locker Inversion Recovery (MOLLI)\nacquires 11 breath-hold baseline images with interleaved rest periods to ensure\nmapping accuracy. However, prolonged scanning can be challenging for patients\nwith poor breathholds, often leading to motion artifacts that degrade image\nquality. In addition, $T_1$ mapping requires voxel-wise nonlinear fitting to a\nsignal recovery model involving an iterative estimation process. Recent studies\nhave proposed deep-learning approaches for rapid $T_1$ mapping using shortened\nsequences to reduce acquisition time for patient comfort. Nevertheless,\nexisting methods overlook important physics constraints, limiting\ninterpretability and generalization. In this work, we present an accelerated,\nend-to-end $T_1$ mapping framework leveraging Physics-Informed Neural Ordinary\nDifferential Equations (ODEs) to model temporal dynamics and address these\nchallenges. Our method achieves high-accuracy $T_1$ estimation from a sparse\nsubset of baseline images and ensures efficient null index estimation at test\ntime. Specifically, we develop a continuous-time LSTM-ODE model to enable\nselective Look-Locker (LL) data acquisition with arbitrary time lags.\nExperimental results show superior performance in $T_1$ estimation for both\nnative and post-contrast sequences and demonstrate the strong benefit of our\nphysics-based formulation over direct data-driven $T_1$ priors."}
{"id": "2507.00631", "pdf": "https://arxiv.org/pdf/2507.00631", "abs": "https://arxiv.org/abs/2507.00631", "authors": ["David Shi", "Kevin Joo"], "title": "Horus: A Protocol for Trustless Delegation Under Uncertainty", "categories": ["cs.GT", "cs.AI", "cs.MA", "I.2.11; F.2.2"], "comment": "9 pages, 1 figure", "summary": "Correctness is an emergent property of systems where exposing error is\ncheaper than committing it. In dynamic, low-trust environments, autonomous AI\nagents benefit from delegating work to sub-agents, yet correctness cannot be\nassured through upfront specification or centralized oversight. We propose a\nprotocol that enforces correctness through collateralized claims in a recursive\nverification game. Tasks are published as intents, and solvers compete to\nfulfill them. Selected solvers carry out tasks under risk, with correctness\nchecked post hoc by verifiers. Any challenger can challenge a result by staking\nagainst it to trigger the verification process. Incorrect agents are slashed\nand correct opposition is rewarded, with an escalation path that penalizes\nerroneous verifiers themselves. When incentives are aligned across solvers,\nchallengers, and verifiers, falsification conditions make correctness the Nash\nequilibrium."}
{"id": "2507.00653", "pdf": "https://arxiv.org/pdf/2507.00653", "abs": "https://arxiv.org/abs/2507.00653", "authors": ["Yilun Zhang"], "title": "Cognitive Load-Aware Inference: A Neuro-Symbolic Framework for Optimizing the Token Economy of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages", "summary": "The escalating computational costs of Large Language Model (LLM) inference\nhave become a critical barrier to their widespread and sustainable deployment.\nWhile existing optimization strategies are effective, they are predominantly\nbased on statistical heuristics or architectural modifications, lacking a\nguiding cognitive theory to manage the inference process itself. This paper\naims to bridge this gap by introducing a novel paradigm: the Cognitive\nLoad-Aware Inference (CLAI) framework, which operationalizes principles from\nCognitive Load Theory (CLT) and neuroscience for LLM inference. We formalize\nthe concepts of Intrinsic Cognitive Load, Extraneous Cognitive Load, and\nGermane Cognitive Load into quantifiable LLM metrics ($ICL_{LLM}$, $ECL_{LLM}$,\nand $GCL_{LLM}$), thereby reframing the inference process as a cognitive\neconomics optimization problem: based on the intrinsic complexity of a problem\n($ICL_{LLM}$), minimize wasteful computation ($ECL_{LLM}$), and strategically\nallocate the token budget to productive reasoning ($GCL_{LLM}$). We propose two\nimplementation paths: CLAI-Prompt, a zero-shot method that guides a base LLM\nthrough cognitive control steps via a structured meta-prompt, and CLAI-Tune, a\nfine-tuned model that internalizes these principles for spontaneous cognitive\neconomy. Across a range of benchmarks in complex reasoning, long-context\nquestion answering, and code generation, our methods achieve significant\nreductions in token consumption (up to 45\\%) without sacrificing accuracy.\nFurthermore, CLAI-Tune exhibits an emergent ability to autonomously decompose\ndifficult problems, a key characteristic of human expert cognition. This work\ndemonstrates that by emulating the brain's resource management strategies, we\ncan build more efficient, robust, and capable artificial intelligence systems."}
{"id": "2507.00657", "pdf": "https://arxiv.org/pdf/2507.00657", "abs": "https://arxiv.org/abs/2507.00657", "authors": ["Jacopo Nudo", "Mario Edoardo Pandolfo", "Edoardo Loru", "Mattia Samory", "Matteo Cinelli", "Walter Quattrociocchi"], "title": "Generative Exaggeration in LLM Social Agents: Consistency, Bias, and Toxicity", "categories": ["cs.HC", "cs.AI", "cs.SI"], "comment": null, "summary": "We investigate how Large Language Models (LLMs) behave when simulating\npolitical discourse on social media. Leveraging 21 million interactions on X\nduring the 2024 U.S. presidential election, we construct LLM agents based on\n1,186 real users, prompting them to reply to politically salient tweets under\ncontrolled conditions. Agents are initialized either with minimal ideological\ncues (Zero Shot) or recent tweet history (Few Shot), allowing one-to-one\ncomparisons with human replies. We evaluate three model families (Gemini,\nMistral, and DeepSeek) across linguistic style, ideological consistency, and\ntoxicity. We find that richer contextualization improves internal consistency\nbut also amplifies polarization, stylized signals, and harmful language. We\nobserve an emergent distortion that we call \"generation exaggeration\": a\nsystematic amplification of salient traits beyond empirical baselines. Our\nanalysis shows that LLMs do not emulate users, they reconstruct them. Their\noutputs, indeed, reflect internal optimization dynamics more than observed\nbehavior, introducing structural biases that compromise their reliability as\nsocial proxies. This challenges their use in content moderation, deliberative\nsimulations, and policy modeling."}
{"id": "2507.00660", "pdf": "https://arxiv.org/pdf/2507.00660", "abs": "https://arxiv.org/abs/2507.00660", "authors": ["Rusi Chen", "Yuanting Yang", "Jiezhi Yao", "Hongning Song", "Ji Zhang", "Yongsong Zhou", "Yuhao Huang", "Ronghao Yang", "Dan Jia", "Yuhan Zhang", "Xing Tao", "Haoran Dou", "Qing Zhou", "Xin Yang", "Dong Ni"], "title": "MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted by MICCAI 2025", "summary": "Mitral regurgitation is one of the most prevalent cardiac disorders.\nFour-dimensional (4D) ultrasound has emerged as the primary imaging modality\nfor assessing dynamic valvular morphology. However, 4D mitral valve (MV)\nanalysis remains challenging due to limited phase annotations, severe motion\nartifacts, and poor imaging quality. Yet, the absence of inter-phase dependency\nin existing methods hinders 4D MV analysis. To bridge this gap, we propose a\nMotion-Topology guided consistency network (MTCNet) for accurate 4D MV\nultrasound segmentation in semi-supervised learning (SSL). MTCNet requires only\nsparse end-diastolic and end-systolic annotations. First, we design a\ncross-phase motion-guided consistency learning strategy, utilizing a\nbi-directional attention memory bank to propagate spatio-temporal features.\nThis enables MTCNet to achieve excellent performance both per- and inter-phase.\nSecond, we devise a novel topology-guided correlation regularization that\nexplores physical prior knowledge to maintain anatomically plausible.\nTherefore, MTCNet can effectively leverage structural correspondence between\nlabeled and unlabeled phases. Extensive evaluations on the first largest 4D MV\ndataset, with 1408 phases from 160 patients, show that MTCNet performs superior\ncross-phase consistency compared to other advanced methods (Dice: 87.30%, HD:\n1.75mm). Both the code and the dataset are available at\nhttps://github.com/crs524/MTCNet."}
{"id": "2507.00665", "pdf": "https://arxiv.org/pdf/2507.00665", "abs": "https://arxiv.org/abs/2507.00665", "authors": ["Sihang Li", "Wei Shi", "Ziyuan Xie", "Tao Liang", "Guojun Ma", "Xiang Wang"], "title": "SAFER: Probing Safety in Reward Models with Sparse Autoencoder", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) is a key paradigm for\naligning large language models (LLMs) with human values, yet the reward models\nat its core remain largely opaque. In this work, we present sparse Autoencoder\nFor Enhanced Reward model (\\textbf{SAFER}), a novel framework for interpreting\nand improving reward models through mechanistic analysis. Leveraging Sparse\nAutoencoders (SAEs), we uncover human-interpretable features in reward model\nactivations, enabling insight into safety-relevant decision-making. We apply\nSAFER to safety-oriented preference datasets and quantify the salience of\nindividual features by activation differences between chosen and rejected\nresponses. Using these feature-level signals, we design targeted data poisoning\nand denoising strategies. Experiments show that SAFER can precisely degrade or\nenhance safety alignment with minimal data modification, without sacrificing\ngeneral chat performance. Our approach contributes to interpreting, auditing\nand refining reward models in high-stakes LLM alignment tasks. Our codes are\navailable at https://github.com/xzy-101/SAFER-code. \\textit{This paper\ndiscusses topics related to large language model safety and may include\ndiscussions or examples that highlight potential risks or unsafe outcomes.}"}
{"id": "2507.00669", "pdf": "https://arxiv.org/pdf/2507.00669", "abs": "https://arxiv.org/abs/2507.00669", "authors": ["Duc Cao-Dinh", "Khai Le-Duc", "Anh Dao", "Bach Phan Tat", "Chris Ngo", "Duy M. H. Nguyen", "Nguyen X. Khanh", "Thanh Nguyen-Tang"], "title": "Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": "Work in progress, 42 pages", "summary": "3D Visual Grounding (3DVG) involves localizing target objects in 3D point\nclouds based on natural language. While prior work has made strides using\ntextual descriptions, leveraging spoken language-known as Audio-based 3D Visual\nGrounding-remains underexplored and challenging. Motivated by advances in\nautomatic speech recognition (ASR) and speech representation learning, we\npropose Audio-3DVG, a simple yet effective framework that integrates audio and\nspatial information for enhanced grounding. Rather than treating speech as a\nmonolithic input, we decompose the task into two complementary components.\nFirst, we introduce Object Mention Detection, a multi-label classification task\nthat explicitly identifies which objects are referred to in the audio, enabling\nmore structured audio-scene reasoning. Second, we propose an Audio-Guided\nAttention module that captures interactions between candidate objects and\nrelational speech cues, improving target discrimination in cluttered scenes. To\nsupport benchmarking, we synthesize audio descriptions for standard 3DVG\ndatasets, including ScanRefer, Sr3D, and Nr3D. Experimental results demonstrate\nthat Audio-3DVG not only achieves new state-of-the-art performance in\naudio-based grounding, but also competes with text-based methods-highlighting\nthe promise of integrating spoken language into 3D vision tasks."}
{"id": "2507.00709", "pdf": "https://arxiv.org/pdf/2507.00709", "abs": "https://arxiv.org/abs/2507.00709", "authors": ["Yiming Yang", "Yueru Luo", "Bingkun He", "Hongbin Lin", "Suzhong Fu", "Chao Yan", "Kun Tang", "Xinrui Yan", "Chao Zheng", "Shuguang Cui", "Zhen Li"], "title": "TopoStreamer: Temporal Lane Segment Topology Reasoning in Autonomous Driving", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Lane segment topology reasoning constructs a comprehensive road network by\ncapturing the topological relationships between lane segments and their\nsemantic types. This enables end-to-end autonomous driving systems to perform\nroad-dependent maneuvers such as turning and lane changing. However, the\nlimitations in consistent positional embedding and temporal multiple attribute\nlearning in existing methods hinder accurate roadnet reconstruction. To address\nthese issues, we propose TopoStreamer, an end-to-end temporal perception model\nfor lane segment topology reasoning. Specifically, TopoStreamer introduces\nthree key improvements: streaming attribute constraints, dynamic lane boundary\npositional encoding, and lane segment denoising. The streaming attribute\nconstraints enforce temporal consistency in both centerline and boundary\ncoordinates, along with their classifications. Meanwhile, dynamic lane boundary\npositional encoding enhances the learning of up-to-date positional information\nwithin queries, while lane segment denoising helps capture diverse lane segment\npatterns, ultimately improving model performance. Additionally, we assess the\naccuracy of existing models using a lane boundary classification metric, which\nserves as a crucial measure for lane-changing scenarios in autonomous driving.\nOn the OpenLane-V2 dataset, TopoStreamer demonstrates significant improvements\nover state-of-the-art methods, achieving substantial performance gains of +3.4%\nmAP in lane segment perception and +2.1% OLS in centerline perception tasks."}
{"id": "2507.00724", "pdf": "https://arxiv.org/pdf/2507.00724", "abs": "https://arxiv.org/abs/2507.00724", "authors": ["Linghui Zhu", "Yiming Li", "Haiqin Weng", "Yan Liu", "Tianwei Zhang", "Shu-Tao Xia", "Zhi Wang"], "title": "Holmes: Towards Effective and Harmless Model Ownership Verification to Personalized Large Vision Models via Decoupling Common Features", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large vision models achieve remarkable performance in various downstream\ntasks, primarily by personalizing pre-trained models through fine-tuning with\nprivate and valuable local data, which makes the personalized model a valuable\nintellectual property for its owner. Similar to the era of traditional DNNs,\nmodel stealing attacks also pose significant risks to these personalized\nmodels. However, in this paper, we reveal that most existing defense methods\n(developed for traditional DNNs), typically designed for models trained from\nscratch, either introduce additional security risks, are prone to misjudgment,\nor are even ineffective for fine-tuned models. To alleviate these problems,\nthis paper proposes a harmless model ownership verification method for\npersonalized models by decoupling similar common features. In general, our\nmethod consists of three main stages. In the first stage, we create shadow\nmodels that retain common features of the victim model while disrupting\ndataset-specific features. We represent the dataset-specific features of the\nvictim model by the output differences between the shadow and victim models.\nAfter that, a meta-classifier is trained to identify stolen models by\ndetermining whether suspicious models contain the dataset-specific features of\nthe victim. In the third stage, we conduct model ownership verification by\nhypothesis test to mitigate randomness and enhance robustness. Extensive\nexperiments on benchmark datasets verify the effectiveness of the proposed\nmethod in detecting different types of model stealing simultaneously."}
{"id": "2507.00755", "pdf": "https://arxiv.org/pdf/2507.00755", "abs": "https://arxiv.org/abs/2507.00755", "authors": ["Jinhai Hu", "Zhongyi Zhang", "Cong Sheng Leow", "Wang Ling Goh", "Yuan Gao"], "title": "LearnAFE: Circuit-Algorithm Co-design Framework for Learnable Audio Analog Front-End", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": "11 pages, 15 figures, accepted for publication on IEEE Transactions\n  on Circuits and Systems I: Regular Papers", "summary": "This paper presents a circuit-algorithm co-design framework for learnable\nanalog front-end (AFE) in audio signal classification. Designing AFE and\nbackend classifiers separately is a common practice but non-ideal, as shown in\nthis paper. Instead, this paper proposes a joint optimization of the backend\nclassifier with the AFE's transfer function to achieve system-level optimum.\nMore specifically, the transfer function parameters of an analog bandpass\nfilter (BPF) bank are tuned in a signal-to-noise ratio (SNR)-aware training\nloop for the classifier. Using a co-design loss function LBPF, this work shows\nsuperior optimization of both the filter bank and the classifier. Implemented\nin open-source SKY130 130nm CMOS process, the optimized design achieved\n90.5%-94.2% accuracy for 10-keyword classification task across a wide range of\ninput signal SNR from 5 dB to 20 dB, with only 22k classifier parameters.\nCompared to conventional approach, the proposed audio AFE achieves 8.7% and\n12.9% reduction in power and capacitor area respectively."}
{"id": "2507.00769", "pdf": "https://arxiv.org/pdf/2507.00769", "abs": "https://arxiv.org/abs/2507.00769", "authors": ["Daniel Fein", "Sebastian Russo", "Violet Xiang", "Kabir Jolly", "Rafael Rafailov", "Nick Haber"], "title": "LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative Writing", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluating creative writing generated by large language models (LLMs) remains\nchallenging because open-ended narratives lack ground truths. Without\nperformant automated evaluation methods, off-the-shelf (OTS) language models\nare employed as zero-shot judges, yet their reliability is unclear in this\ncontext. In pursuit of robust evaluation for creative writing, we introduce\nLitBench, the first standardized benchmark and paired dataset for creative\nwriting verification, comprising a held-out test set of 2,480 debiased,\nhuman-labeled story comparisons drawn from Reddit and a 43,827-pair training\ncorpus of human preference labels. Using LitBench, we (i) benchmark zero-shot\nLLM judges, (ii) train Bradley Terry and generative reward models, and (iii)\nconduct an online human study to validate reward model rankings on newly\nLLM-generated stories. Our benchmark identifies Claude-3.7-Sonnet as the\nstrongest off-the-shelf judge, reaching 73% agreement with human preferences;\namong trained reward models, Bradley-Terry and Generative reward models both\nattain an accuracy of 78%, outperforming all off-the-shelf judges. An online\nhuman study further confirms that our trained reward models consistently align\nwith human preferences in novel LLM-generated stories. We release LitBench and\nreward models at\nhttps://huggingface.co/collections/SAA-Lab/litbench-68267b5da3aafe58f9e43461,\nproviding a vetted resource for reliable, automated evaluation and optimization\nof creative writing systems."}
{"id": "2507.00788", "pdf": "https://arxiv.org/pdf/2507.00788", "abs": "https://arxiv.org/abs/2507.00788", "authors": ["Markus Borg", "Dave Hewett", "Nadim Hagatulah", "Noric Couderc", "Emma Söderberg", "Donald Graham", "Uttam Kini", "Dave Farley"], "title": "Echoes of AI: Investigating the Downstream Effects of AI Assistants on Software Maintainability", "categories": ["cs.SE", "cs.AI"], "comment": "Preprint of study preregistered at ICSME 2025 with In-Principal\n  Acceptance.\n  https://conf.researchr.org/track/icsme-2024/icsme-2024-registered-reports-track", "summary": "[Context] AI assistants, like GitHub Copilot and Cursor, are transforming\nsoftware engineering. While several studies highlight productivity\nimprovements, their impact on maintainability requires further investigation.\n[Objective] This study investigates whether co-development with AI assistants\naffects software maintainability, specifically how easily other developers can\nevolve the resulting source code. [Method] We conducted a two-phase controlled\nexperiment involving 151 participants, 95% of whom were professional\ndevelopers. In Phase 1, participants added a new feature to a Java web\napplication, with or without AI assistance. In Phase 2, a randomized controlled\ntrial, new participants evolved these solutions without AI assistance.\n[Results] AI-assisted development in Phase 1 led to a modest speedup in\nsubsequent evolution and slightly higher average CodeHealth. Although neither\ndifference was significant overall, the increase in CodeHealth was\nstatistically significant when habitual AI users completed Phase 1. For Phase\n1, we also observed a significant effect that corroborates previous\nproductivity findings: using an AI assistant yielded a 30.7% median decrease in\ntask completion time. Moreover, for habitual AI users, the mean speedup was\n55.9%. [Conclusions] Our study adds to the growing evidence that AI assistants\ncan effectively accelerate development. Moreover, we did not observe warning\nsigns of degraded code-level maintainability. We recommend that future research\nfocus on risks such as code bloat from excessive code generation and the\nbuild-up of cognitive debt as developers invest less mental effort during\nimplementation."}
{"id": "2507.00790", "pdf": "https://arxiv.org/pdf/2507.00790", "abs": "https://arxiv.org/abs/2507.00790", "authors": ["Huaqiu Li", "Yong Wang", "Tongwen Huang", "Hailang Huang", "Haoqian Wang", "Xiangxiang Chu"], "title": "LD-RPS: Zero-Shot Unified Image Restoration via Latent Diffusion Recurrent Posterior Sampling", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Unified image restoration is a significantly challenging task in low-level\nvision. Existing methods either make tailored designs for specific tasks,\nlimiting their generalizability across various types of degradation, or rely on\ntraining with paired datasets, thereby suffering from closed-set constraints.\nTo address these issues, we propose a novel, dataset-free, and unified approach\nthrough recurrent posterior sampling utilizing a pretrained latent diffusion\nmodel. Our method incorporates the multimodal understanding model to provide\nsematic priors for the generative model under a task-blind condition.\nFurthermore, it utilizes a lightweight module to align the degraded input with\nthe generated preference of the diffusion model, and employs recurrent\nrefinement for posterior sampling. Extensive experiments demonstrate that our\nmethod outperforms state-of-the-art methods, validating its effectiveness and\nrobustness. Our code and data will be available at\nhttps://github.com/AMAP-ML/LD-RPS."}
{"id": "2507.00814", "pdf": "https://arxiv.org/pdf/2507.00814", "abs": "https://arxiv.org/abs/2507.00814", "authors": ["Anita Keshmirian", "Razan Baltaji", "Babak Hemmatian", "Hadi Asghari", "Lav R. Varshney"], "title": "Many LLMs Are More Utilitarian Than One", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; I.2.11"], "comment": "9 pages, 8 Figures, 7 tables", "summary": "Moral judgment is integral to large language model (LLM) alignment and social\nreasoning. As multi-agent systems gain prominence, it becomes crucial to\nunderstand how LLMs function collectively during collaboration, compared to\nindividual agents. In human moral judgment, group deliberation leads to a\nutilitarian boost: a tendency to endorse norm violations that maximize benefits\nfor the greatest number of people despite harms. We study whether a similar\ndynamic emerges in multi-agent LLM systems. We tested six models on\nwell-established sets of moral dilemmas across two conditions: (1) Solo, where\nmodels reasoned independently, and (2) Group, where they engaged in multi-turn\ndiscussions in pairs or triads. In personal moral dilemmas, where agents must\ndecide to directly harm one individual to maximize the utility for others, all\nmodels found moral violations to be more acceptable when part of a group than\nindividually, similar to human experiments. Some models endorsed actions that\nmaximized overall well-being, even if they benefited strangers over familiar\nindividuals. Others became more willing to violate moral norms in groups.\nHowever, while human groups show a similar action bias, the mechanism for their\nutilitarian boost differs from LLMs. Whereas the human shift comes from\nheightened sensitivity to decision outcomes, LLM groups show either reduced\nnorm sensitivity or enhanced impartiality. This suggests that while the surface\nbehavior of LLM collectives mimics human group reasoning, the underlying\ndrivers differ. We discuss the implications for AI alignment, multi-agent\ndesign, and artificial moral reasoning."}
{"id": "2507.00816", "pdf": "https://arxiv.org/pdf/2507.00816", "abs": "https://arxiv.org/abs/2507.00816", "authors": ["Mengyun Wang", "Bo Wang", "Yifeng Niu", "Chang Wang"], "title": "PI-WAN: A Physics-Informed Wind-Adaptive Network for Quadrotor Dynamics Prediction in Unknown Environments", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Accurate dynamics modeling is essential for quadrotors to achieve precise\ntrajectory tracking in various applications. Traditional physical\nknowledge-driven modeling methods face substantial limitations in unknown\nenvironments characterized by variable payloads, wind disturbances, and\nexternal perturbations. On the other hand, data-driven modeling methods suffer\nfrom poor generalization when handling out-of-distribution (OoD) data,\nrestricting their effectiveness in unknown scenarios. To address these\nchallenges, we introduce the Physics-Informed Wind-Adaptive Network (PI-WAN),\nwhich combines knowledge-driven and data-driven modeling methods by embedding\nphysical constraints directly into the training process for robust quadrotor\ndynamics learning. Specifically, PI-WAN employs a Temporal Convolutional\nNetwork (TCN) architecture that efficiently captures temporal dependencies from\nhistorical flight data, while a physics-informed loss function applies physical\nprinciples to improve model generalization and robustness across previously\nunseen conditions. By incorporating real-time prediction results into a model\npredictive control (MPC) framework, we achieve improvements in closed-loop\ntracking performance. Comprehensive simulations and real-world flight\nexperiments demonstrate that our approach outperforms baseline methods in terms\nof prediction accuracy, tracking precision, and robustness to unknown\nenvironments."}
{"id": "2507.00817", "pdf": "https://arxiv.org/pdf/2507.00817", "abs": "https://arxiv.org/abs/2507.00817", "authors": ["Jiaming Zhang", "Rui Hu", "Qing Guo", "Wei Yang Bryan Lim"], "title": "CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Video Multimodal Large Language Models (V-MLLMs) have shown impressive\ncapabilities in temporal reasoning and cross-modal understanding, yet their\nvulnerability to adversarial attacks remains underexplored due to unique\nchallenges: complex cross-modal reasoning mechanisms, temporal dependencies,\nand computational constraints. We present CAVALRY-V (Cross-modal\nLanguage-Vision Adversarial Yielding for Videos), a novel framework that\ndirectly targets the critical interface between visual perception and language\ngeneration in V-MLLMs. Our approach introduces two key innovations: (1) a\ndual-objective semantic-visual loss function that simultaneously disrupts the\nmodel's text generation logits and visual representations to undermine\ncross-modal integration, and (2) a computationally efficient two-stage\ngenerator framework that combines large-scale pre-training for cross-model\ntransferability with specialized fine-tuning for spatiotemporal coherence.\nEmpirical evaluation on comprehensive video understanding benchmarks\ndemonstrates that CAVALRY-V significantly outperforms existing attack methods,\nachieving 22.8% average improvement over the best baseline attacks on both\ncommercial systems (GPT-4.1, Gemini 2.0) and open-source models (QwenVL-2.5,\nInternVL-2.5, Llava-Video, Aria, MiniCPM-o-2.6). Our framework achieves\nflexibility through implicit temporal coherence modeling rather than explicit\nregularization, enabling significant performance improvements even on image\nunderstanding (34.4% average gain). This capability demonstrates CAVALRY-V's\npotential as a foundational approach for adversarial research across multimodal\nsystems."}
{"id": "2507.00832", "pdf": "https://arxiv.org/pdf/2507.00832", "abs": "https://arxiv.org/abs/2507.00832", "authors": ["Jisoo Kim", "Chu-Hsuan Lin", "Alberto Ceballos-Arroyo", "Ping Liu", "Huaizu Jiang", "Shrikanth Yadav", "Qi Wan", "Lei Qin", "Geoffrey S Young"], "title": "Automated anatomy-based post-processing reduces false positives and improved interpretability of deep learning intracranial aneurysm detection", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Introduction: Deep learning (DL) models can help detect intracranial\naneurysms on CTA, but high false positive (FP) rates remain a barrier to\nclinical translation, despite improvement in model architectures and strategies\nlike detection threshold tuning. We employed an automated, anatomy-based,\nheuristic-learning hybrid artery-vein segmentation post-processing method to\nfurther reduce FPs. Methods: Two DL models, CPM-Net and a deformable 3D\nconvolutional neural network-transformer hybrid (3D-CNN-TR), were trained with\n1,186 open-source CTAs (1,373 annotated aneurysms), and evaluated with 143\nheld-out private CTAs (218 annotated aneurysms). Brain, artery, vein, and\ncavernous venous sinus (CVS) segmentation masks were applied to remove possible\nFPs in the DL outputs that overlapped with: (1) brain mask; (2) vein mask; (3)\nvein more than artery masks; (4) brain plus vein mask; (5) brain plus vein more\nthan artery masks. Results: CPM-Net yielded 139 true-positives (TP); 79\nfalse-negative (FN); 126 FP. 3D-CNN-TR yielded 179 TP; 39 FN; 182 FP. FPs were\ncommonly extracranial (CPM-Net 27.3%; 3D-CNN-TR 42.3%), venous (CPM-Net 56.3%;\n3D-CNN-TR 29.1%), arterial (CPM-Net 11.9%; 3D-CNN-TR 53.3%), and non-vascular\n(CPM-Net 25.4%; 3D-CNN-TR 9.3%) structures. Method 5 performed best, reducing\nCPM-Net FP by 70.6% (89/126) and 3D-CNN-TR FP by 51.6% (94/182), without\nreducing TP, lowering the FP/case rate from 0.88 to 0.26 for CPM-NET, and from\n1.27 to 0.62 for the 3D-CNN-TR. Conclusion: Anatomy-based, interpretable\npost-processing can improve DL-based aneurysm detection model performance. More\nbroadly, automated, domain-informed, hybrid heuristic-learning processing holds\npromise for improving the performance and clinical acceptance of aneurysm\ndetection models."}
{"id": "2507.00833", "pdf": "https://arxiv.org/pdf/2507.00833", "abs": "https://arxiv.org/abs/2507.00833", "authors": ["Zhi Jing", "Siyuan Yang", "Jicong Ao", "Ting Xiao", "Yugang Jiang", "Chenjia Bai"], "title": "HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning", "categories": ["cs.RO", "cs.AI"], "comment": "Project Page: https://openhumanoidgen.github.io", "summary": "For robotic manipulation, existing robotics datasets and simulation\nbenchmarks predominantly cater to robot-arm platforms. However, for humanoid\nrobots equipped with dual arms and dexterous hands, simulation tasks and\nhigh-quality demonstrations are notably lacking. Bimanual dexterous\nmanipulation is inherently more complex, as it requires coordinated arm\nmovements and hand operations, making autonomous data collection challenging.\nThis paper presents HumanoidGen, an automated task creation and demonstration\ncollection framework that leverages atomic dexterous operations and LLM\nreasoning to generate relational constraints. Specifically, we provide spatial\nannotations for both assets and dexterous hands based on the atomic operations,\nand perform an LLM planner to generate a chain of actionable spatial\nconstraints for arm movements based on object affordances and scenes. To\nfurther improve planning ability, we employ a variant of Monte Carlo tree\nsearch to enhance LLM reasoning for long-horizon tasks and insufficient\nannotation. In experiments, we create a novel benchmark with augmented\nscenarios to evaluate the quality of the collected data. The results show that\nthe performance of the 2D and 3D diffusion policies can scale with the\ngenerated dataset. Project page is https://openhumanoidgen.github.io."}
{"id": "2507.00838", "pdf": "https://arxiv.org/pdf/2507.00838", "abs": "https://arxiv.org/abs/2507.00838", "authors": ["Karol Przystalski", "Jan K. Argasiński", "Iwona Grabska-Gradzińska", "Jeremi K. Ochab"], "title": "Stylometry recognizes human and LLM-generated texts in short samples", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The paper explores stylometry as a method to distinguish between texts\ncreated by Large Language Models (LLMs) and humans, addressing issues of model\nattribution, intellectual property, and ethical AI use. Stylometry has been\nused extensively to characterise the style and attribute authorship of texts.\nBy applying it to LLM-generated texts, we identify their emergent writing\npatterns. The paper involves creating a benchmark dataset based on Wikipedia,\nwith (a) human-written term summaries, (b) texts generated purely by LLMs\n(GPT-3.5/4, LLaMa 2/3, Orca, and Falcon), (c) processed through multiple text\nsummarisation methods (T5, BART, Gensim, and Sumy), and (d) rephrasing methods\n(Dipper, T5). The 10-sentence long texts were classified by tree-based models\n(decision trees and LightGBM) using human-designed (StyloMetrix) and\nn-gram-based (our own pipeline) stylometric features that encode lexical,\ngrammatical, syntactic, and punctuation patterns. The cross-validated results\nreached a performance of up to .87 Matthews correlation coefficient in the\nmulticlass scenario with 7 classes, and accuracy between .79 and 1. in binary\nclassification, with the particular example of Wikipedia and GPT-4 reaching up\nto .98 accuracy on a balanced dataset. Shapley Additive Explanations pinpointed\nfeatures characteristic of the encyclopaedic text type, individual overused\nwords, as well as a greater grammatical standardisation of LLMs with respect to\nhuman-written texts. These results show -- crucially, in the context of the\nincreasingly sophisticated LLMs -- that it is possible to distinguish machine-\nfrom human-generated texts at least for a well-defined text type."}
{"id": "2507.00880", "pdf": "https://arxiv.org/pdf/2507.00880", "abs": "https://arxiv.org/abs/2507.00880", "authors": ["Ruihan Xu", "Haokui Zhang", "Yaowei Wang", "Wei Zeng", "Shiliang Zhang"], "title": "NN-Former: Rethinking Graph Structure in Neural Architecture Representation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to CVPR 2025. Code is avaiable at\n  https://github.com/XuRuihan/NNFormer", "summary": "The growing use of deep learning necessitates efficient network design and\ndeployment, making neural predictors vital for estimating attributes such as\naccuracy and latency. Recently, Graph Neural Networks (GNNs) and transformers\nhave shown promising performance in representing neural architectures. However,\neach of both methods has its disadvantages. GNNs lack the capabilities to\nrepresent complicated features, while transformers face poor generalization\nwhen the depth of architecture grows. To mitigate the above issues, we rethink\nneural architecture topology and show that sibling nodes are pivotal while\noverlooked in previous research. We thus propose a novel predictor leveraging\nthe strengths of GNNs and transformers to learn the enhanced topology. We\nintroduce a novel token mixer that considers siblings, and a new channel mixer\nnamed bidirectional graph isomorphism feed-forward network. Our approach\nconsistently achieves promising performance in both accuracy and latency\nprediction, providing valuable insights for learning Directed Acyclic Graph\n(DAG) topology. The code is available at https://github.com/XuRuihan/NNFormer."}
{"id": "2507.00891", "pdf": "https://arxiv.org/pdf/2507.00891", "abs": "https://arxiv.org/abs/2507.00891", "authors": ["Yuheng Wang", "Xianhe Tang", "Pufeng Huang"], "title": "MemeCMD: An Automatically Generated Chinese Multi-turn Dialogue Dataset with Contextually Retrieved Memes", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Memes are widely used in online social interactions, providing vivid,\nintuitive, and often humorous means to express intentions and emotions.\nExisting dialogue datasets are predominantly limited to either manually\nannotated or pure-text conversations, lacking the expressiveness and contextual\nnuance that multimodal interactions provide.To address these challenges, we\nintroduce MemeCMD, an automatically generated Chinese Multi-turn Dialogue\ndataset with contextually retrieved memes. Our dataset combines a large-scale,\nMLLM-annotated meme library with dialogues auto-generated by dual agents across\ndiverse scenarios. We introduce a retrieval framework and adaptive threshold to\nensure contextually relevant, naturally spaced meme usage. Experiments\ndemonstrate the effectiveness of our approach in generating contextually\nappropriate and diverse meme-incorporated dialogues, offering a scalable and\nprivacy-preserving resource for advancing multimodal conversational AI."}
{"id": "2507.00902", "pdf": "https://arxiv.org/pdf/2507.00902", "abs": "https://arxiv.org/abs/2507.00902", "authors": ["Feng Wang", "Shengyu Zhang", "Een-Kee Hong", "Tony Q. S. Quek"], "title": "Constellation as a Service: Tailored Connectivity Management in Direct-Satellite-to-Device Networks", "categories": ["eess.SY", "cs.AI", "cs.SY", "eess.SP"], "comment": "To appear in IEEE Communications Magazine", "summary": "Direct-satellite-to-device (DS2D) communication is emerging as a promising\nsolution for global mobile service extension, leveraging the deployment of\nsatellite constellations. However, the challenge of managing DS2D connectivity\nfor multi-constellations becomes outstanding, including high interference and\nfrequent handovers caused by multi-coverage overlap and rapid satellite\nmovement. Moreover, existing approaches primarily operate within\nsingle-constellation shell, which inherently limits the ability to exploit the\nvast potential of multi-constellation connectivity provision, resulting in\nsuboptimal DS2D service performances. To address these challenges, this article\nproposes a Constellation as a Service (CaaS) framework, which treats the entire\nmulti-constellation infrastructure as a shared resource pool and dynamically\nforms optimal sub-constellations (SCs) for each DS2D service region. The\nformation of each SC integrates satellites from various orbits to provide\ntailored connectivity based on user demands, guided by two innovative\nstrategies: predictive satellite beamforming using generative artificial\nintelligence (GenAI) and pre-configured handover path for efficient satellite\naccess and mobility management. Simulation results demonstrate that CaaS\nsignificantly improves satellite service rates while reducing handover\noverhead, making it an efficient and continuable solution for managing DS2D\nconnectivity in multi-constellation environments."}
{"id": "2507.00903", "pdf": "https://arxiv.org/pdf/2507.00903", "abs": "https://arxiv.org/abs/2507.00903", "authors": ["Andreea Bianca Popescu", "Andreas Seitz", "Heiko Mahrholdt", "Jens Wetzl", "Athira Jacob", "Lucian Mihai Itu", "Constantin Suciu", "Teodora Chitiboi"], "title": "Deep learning-based segmentation of T1 and T2 cardiac MRI maps for automated disease detection", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "This work has been submitted for consideration at European Radiology\n  (Springer). Upon acceptance, this preprint will be updated with the journal\n  reference", "summary": "Objectives Parametric tissue mapping enables quantitative cardiac tissue\ncharacterization but is limited by inter-observer variability during manual\ndelineation. Traditional approaches relying on average relaxation values and\nsingle cutoffs may oversimplify myocardial complexity. This study evaluates\nwhether deep learning (DL) can achieve segmentation accuracy comparable to\ninter-observer variability, explores the utility of statistical features beyond\nmean T1/T2 values, and assesses whether machine learning (ML) combining\nmultiple features enhances disease detection. Materials & Methods T1 and T2\nmaps were manually segmented. The test subset was independently annotated by\ntwo observers, and inter-observer variability was assessed. A DL model was\ntrained to segment left ventricle blood pool and myocardium. Average (A), lower\nquartile (LQ), median (M), and upper quartile (UQ) were computed for the\nmyocardial pixels and employed in classification by applying cutoffs or in ML.\nDice similarity coefficient (DICE) and mean absolute percentage error evaluated\nsegmentation performance. Bland-Altman plots assessed inter-user and\nmodel-observer agreement. Receiver operating characteristic analysis determined\noptimal cutoffs. Pearson correlation compared features from model and manual\nsegmentations. F1-score, precision, and recall evaluated classification\nperformance. Wilcoxon test assessed differences between classification methods,\nwith p < 0.05 considered statistically significant. Results 144 subjects were\nsplit into training (100), validation (15) and evaluation (29) subsets.\nSegmentation model achieved a DICE of 85.4%, surpassing inter-observer\nagreement. Random forest applied to all features increased F1-score (92.7%, p <\n0.001). Conclusion DL facilitates segmentation of T1/ T2 maps. Combining\nmultiple features with ML improves disease detection."}
{"id": "2507.00907", "pdf": "https://arxiv.org/pdf/2507.00907", "abs": "https://arxiv.org/abs/2507.00907", "authors": ["Fabio Correa Xavier"], "title": "The Age of Sensorial Zero Trust: Why We Can No Longer Trust Our Senses", "categories": ["cs.CR", "cs.AI", "68T07, 68T45, 94A60", "K.6.5; D.4.6; I.2.6"], "comment": "14 pages", "summary": "In a world where deepfakes and cloned voices are emerging as sophisticated\nattack vectors, organizations require a new security mindset: Sensorial Zero\nTrust [9]. This article presents a scientific analysis of the need to\nsystematically doubt information perceived through the senses, establishing\nrigorous verification protocols to mitigate the risks of fraud based on\ngenerative artificial intelligence. Key concepts, such as Out-of-Band\nverification, Vision-Language Models (VLMs) as forensic collaborators,\ncryptographic provenance, and human training, are integrated into a framework\nthat extends Zero Trust principles to human sensory information. The approach\nis grounded in empirical findings and academic research, emphasizing that in an\nera of AI-generated realities, even our eyes and ears can no longer be\nimplicitly trusted without verification. Leaders are called to foster a culture\nof methodological skepticism to protect organizational integrity in this new\nthreat landscape."}
{"id": "2507.00909", "pdf": "https://arxiv.org/pdf/2507.00909", "abs": "https://arxiv.org/abs/2507.00909", "authors": ["Philip Colangelo", "Ayse K. Coskun", "Jack Megrue", "Ciaran Roberts", "Shayan Sengupta", "Varun Sivaram", "Ethan Tiao", "Aroon Vijaykar", "Chris Williams", "Daniel C. Wilson", "Zack MacFarland", "Daniel Dreiling", "Nathan Morey", "Anuja Ratnayake", "Baskar Vairamohan"], "title": "Turning AI Data Centers into Grid-Interactive Assets: Results from a Field Demonstration in Phoenix, Arizona", "categories": ["cs.DC", "cs.AI", "cs.PF", "cs.SY", "eess.SY"], "comment": "10 pages, 6 figures, 1 table", "summary": "Artificial intelligence (AI) is fueling exponential electricity demand\ngrowth, threatening grid reliability, raising prices for communities paying for\nnew energy infrastructure, and stunting AI innovation as data centers wait for\ninterconnection to constrained grids. This paper presents the first field\ndemonstration, in collaboration with major corporate partners, of a\nsoftware-only approach--Emerald Conductor--that transforms AI data centers into\nflexible grid resources that can efficiently and immediately harness existing\npower systems without massive infrastructure buildout. Conducted at a 256-GPU\ncluster running representative AI workloads within a commercial, hyperscale\ncloud data center in Phoenix, Arizona, the trial achieved a 25% reduction in\ncluster power usage for three hours during peak grid events while maintaining\nAI quality of service (QoS) guarantees. By orchestrating AI workloads based on\nreal-time grid signals without hardware modifications or energy storage, this\nplatform reimagines data centers as grid-interactive assets that enhance grid\nreliability, advance affordability, and accelerate AI's development."}
{"id": "2507.00914", "pdf": "https://arxiv.org/pdf/2507.00914", "abs": "https://arxiv.org/abs/2507.00914", "authors": ["Jindong Han", "Yansong Ning", "Zirui Yuan", "Hang Ni", "Fan Liu", "Tengfei Lyu", "Hao Liu"], "title": "Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "The long-standing vision of intelligent cities is to create efficient,\nlivable, and sustainable urban environments using big data and artificial\nintelligence technologies. Recently, the advent of Large Language Models (LLMs)\nhas opened new ways toward realizing this vision. With powerful semantic\nunderstanding and reasoning capabilities, LLMs can be deployed as intelligent\nagents capable of autonomously solving complex problems across domains. In this\narticle, we focus on Urban LLM Agents, which are LLM-powered agents that are\nsemi-embodied within the hybrid cyber-physical-social space of cities and used\nfor system-level urban decision-making. First, we introduce the concept of\nurban LLM agents, discussing their unique capabilities and features. Second, we\nsurvey the current research landscape from the perspective of agent workflows,\nencompassing urban sensing, memory management, reasoning, execution, and\nlearning. Third, we categorize the application domains of urban LLM agents into\nfive groups: urban planning, transportation, environment, public safety, and\nurban society, presenting representative works in each group. Finally, we\ndiscuss trustworthiness and evaluation issues that are critical for real-world\ndeployment, and identify several open problems for future research. This survey\naims to establish a foundation for the emerging field of urban LLM agents and\nto provide a roadmap for advancing the intersection of LLMs and urban\nintelligence. A curated list of relevant papers and open-source resources is\nmaintained and continuously updated at\nhttps://github.com/usail-hkust/Awesome-Urban-LLM-Agents."}
{"id": "2507.00938", "pdf": "https://arxiv.org/pdf/2507.00938", "abs": "https://arxiv.org/abs/2507.00938", "authors": ["Zihao Sun", "Meng Fang", "Ling Chen"], "title": "WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks", "categories": ["cs.IR", "cs.AI", "cs.DB", "F.2.2; I.2.7"], "comment": "10 pages, 9 figures, 4 tables", "summary": "Recent progress in large language models (LLMs) has enabled the development\nof autonomous web agents capable of navigating and interacting with real\nwebsites. However, evaluating such agents remains challenging due to the\ninstability and inconsistency of existing benchmarks, which often rely on\ndynamic content or oversimplified simulations. In this work, we introduce\nWebArXiv, a static and time-invariant benchmark comprising 275 web-based tasks\ngrounded in the arXiv platform. WebArXiv ensures reproducible and reliable\nevaluation by anchoring tasks in fixed web snapshots with deterministic ground\ntruths and standardized action trajectories. Through behavioral analysis, we\nidentify a common failure mode, Rigid History Reflection, where agents\nover-rely on fixed interaction histories. To address this, we propose a\nlightweight dynamic reflection mechanism that allows agents to selectively\nretrieve relevant past steps during decision-making. We evaluate ten\nstate-of-the-art web agents on WebArXiv. Results demonstrate clear performance\ndifferences across agents and validate the effectiveness of our proposed\nreflection strategy."}
{"id": "2507.00953", "pdf": "https://arxiv.org/pdf/2507.00953", "abs": "https://arxiv.org/abs/2507.00953", "authors": ["Ke Liu", "Shuanke Shen", "Hao Chen"], "title": "From Sentences to Sequences: Rethinking Languages in Biological System", "categories": ["q-bio.BM", "cs.AI"], "comment": null, "summary": "The paradigm of large language models in natural language processing (NLP)\nhas also shown promise in modeling biological languages, including proteins,\nRNA, and DNA. Both the auto-regressive generation paradigm and evaluation\nmetrics have been transferred from NLP to biological sequence modeling.\nHowever, the intrinsic structural correlations in natural and biological\nlanguages differ fundamentally. Therefore, we revisit the notion of language in\nbiological systems to better understand how NLP successes can be effectively\ntranslated to biological domains. By treating the 3D structure of biomolecules\nas the semantic content of a sentence and accounting for the strong\ncorrelations between residues or bases, we highlight the importance of\nstructural evaluation and demonstrate the applicability of the auto-regressive\nparadigm in biological language modeling. Code can be found at\n\\href{https://github.com/zjuKeLiu/RiFold}{github.com/zjuKeLiu/RiFold}"}
{"id": "2507.00966", "pdf": "https://arxiv.org/pdf/2507.00966", "abs": "https://arxiv.org/abs/2507.00966", "authors": ["Nikolai Lund Kühne", "Jesper Jensen", "Jan Østergaard", "Zheng-Hua Tan"], "title": "MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Submitted to IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing for possible publication", "summary": "With the advent of new sequence models like Mamba and xLSTM, several studies\nhave shown that these models match or outperform state-of-the-art models in\nsingle-channel speech enhancement, automatic speech recognition, and\nself-supervised audio representation learning. However, prior research has\ndemonstrated that sequence models like LSTM and Mamba tend to overfit to the\ntraining set. To address this issue, previous works have shown that adding\nself-attention to LSTMs substantially improves generalization performance for\nsingle-channel speech enhancement. Nevertheless, neither the concept of hybrid\nMamba and time-frequency attention models nor their generalization performance\nhave been explored for speech enhancement. In this paper, we propose a novel\nhybrid architecture, MambAttention, which combines Mamba and shared time- and\nfrequency-multi-head attention modules for generalizable single-channel speech\nenhancement. To train our model, we introduce VoiceBank+Demand Extended\n(VB-DemandEx), a dataset inspired by VoiceBank+Demand but with more challenging\nnoise types and lower signal-to-noise ratios. Trained on VB-DemandEx, our\nproposed MambAttention model significantly outperforms existing\nstate-of-the-art LSTM-, xLSTM-, Mamba-, and Conformer-based systems of similar\ncomplexity across all reported metrics on two out-of-domain datasets: DNS 2020\nand EARS-WHAM_v2, while matching their performance on the in-domain dataset\nVB-DemandEx. Ablation studies highlight the role of weight sharing between the\ntime- and frequency-multi-head attention modules for generalization\nperformance. Finally, we explore integrating the shared time- and\nfrequency-multi-head attention modules with LSTM and xLSTM, which yields a\nnotable performance improvement on the out-of-domain datasets. However, our\nMambAttention model remains superior on both out-of-domain datasets across all\nreported evaluation metrics."}
{"id": "2507.00969", "pdf": "https://arxiv.org/pdf/2507.00969", "abs": "https://arxiv.org/abs/2507.00969", "authors": ["Alberto Neri", "Maximilan Fehrentz", "Veronica Penza", "Leonardo S. Mattos", "Nazim Haouchine"], "title": "Surgical Neural Radiance Fields from One Image", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Purpose: Neural Radiance Fields (NeRF) offer exceptional capabilities for 3D\nreconstruction and view synthesis, yet their reliance on extensive multi-view\ndata limits their application in surgical intraoperative settings where only\nlimited data is available. In particular, collecting such extensive data\nintraoperatively is impractical due to time constraints. This work addresses\nthis challenge by leveraging a single intraoperative image and preoperative\ndata to train NeRF efficiently for surgical scenarios.\n  Methods: We leverage preoperative MRI data to define the set of camera\nviewpoints and images needed for robust and unobstructed training.\nIntraoperatively, the appearance of the surgical image is transferred to the\npre-constructed training set through neural style transfer, specifically\ncombining WTC2 and STROTSS to prevent over-stylization. This process enables\nthe creation of a dataset for instant and fast single-image NeRF training.\n  Results: The method is evaluated with four clinical neurosurgical cases.\nQuantitative comparisons to NeRF models trained on real surgical microscope\nimages demonstrate strong synthesis agreement, with similarity metrics\nindicating high reconstruction fidelity and stylistic alignment. When compared\nwith ground truth, our method demonstrates high structural similarity,\nconfirming good reconstruction quality and texture preservation.\n  Conclusion: Our approach demonstrates the feasibility of single-image NeRF\ntraining in surgical settings, overcoming the limitations of traditional\nmulti-view methods."}
{"id": "2507.00971", "pdf": "https://arxiv.org/pdf/2507.00971", "abs": "https://arxiv.org/abs/2507.00971", "authors": ["Taeyoun Kim", "Fahim Tajwar", "Aditi Raghunathan", "Aviral Kumar"], "title": "Reasoning as an Adaptive Defense for Safety", "categories": ["cs.LG", "cs.AI"], "comment": "42 pages, 11 Figures, 7 Tables", "summary": "Reasoning methods that adaptively allocate test-time compute have advanced\nLLM performance on easy to verify domains such as math and code. In this work,\nwe study how to utilize this approach to train models that exhibit a degree of\nrobustness to safety vulnerabilities, and show that doing so can provide\nbenefits. We build a recipe called $\\textit{TARS}$ (Training Adaptive Reasoners\nfor Safety), a reinforcement learning (RL) approach that trains models to\nreason about safety using chain-of-thought traces and a reward signal that\nbalances safety with task completion. To build TARS, we identify three critical\ndesign choices: (1) a \"lightweight\" warmstart SFT stage, (2) a mix of harmful,\nharmless, and ambiguous prompts to prevent shortcut behaviors such as too many\nrefusals, and (3) a reward function to prevent degeneration of reasoning\ncapabilities during training. Models trained with TARS exhibit adaptive\nbehaviors by spending more compute on ambiguous queries, leading to better\nsafety-refusal trade-offs. They also internally learn to better distinguish\nbetween safe and unsafe prompts and attain greater robustness to both white-box\n(e.g., GCG) and black-box attacks (e.g., PAIR). Overall, our work provides an\neffective, open recipe for training LLMs against jailbreaks and harmful\nrequests by reasoning per prompt."}
{"id": "2507.00990", "pdf": "https://arxiv.org/pdf/2507.00990", "abs": "https://arxiv.org/abs/2507.00990", "authors": ["Shivansh Patel", "Shraddhaa Mohan", "Hanlin Mai", "Unnat Jain", "Svetlana Lazebnik", "Yunzhu Li"], "title": "Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Project Page: https://rigvid-robot.github.io/", "summary": "This work introduces Robots Imitating Generated Videos (RIGVid), a system\nthat enables robots to perform complex manipulation tasks--such as pouring,\nwiping, and mixing--purely by imitating AI-generated videos, without requiring\nany physical demonstrations or robot-specific training. Given a language\ncommand and an initial scene image, a video diffusion model generates potential\ndemonstration videos, and a vision-language model (VLM) automatically filters\nout results that do not follow the command. A 6D pose tracker then extracts\nobject trajectories from the video, and the trajectories are retargeted to the\nrobot in an embodiment-agnostic fashion. Through extensive real-world\nevaluations, we show that filtered generated videos are as effective as real\ndemonstrations, and that performance improves with generation quality. We also\nshow that relying on generated videos outperforms more compact alternatives\nsuch as keypoint prediction using VLMs, and that strong 6D pose tracking\noutperforms other ways to extract trajectories, such as dense feature point\ntracking. These findings suggest that videos produced by a state-of-the-art\noff-the-shelf model can offer an effective source of supervision for robotic\nmanipulation."}
{"id": "2507.01001", "pdf": "https://arxiv.org/pdf/2507.01001", "abs": "https://arxiv.org/abs/2507.01001", "authors": ["Yilun Zhao", "Kaiyan Zhang", "Tiansheng Hu", "Sihong Wu", "Ronan Le Bras", "Taira Anderson", "Jonathan Bragg", "Joseph Chee Chang", "Jesse Dodge", "Matt Latzke", "Yixin Liu", "Charles McGrady", "Xiangru Tang", "Zihang Wang", "Chen Zhao", "Hannaneh Hajishirzi", "Doug Downey", "Arman Cohan"], "title": "SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present SciArena, an open and collaborative platform for evaluating\nfoundation models on scientific literature tasks. Unlike traditional benchmarks\nfor scientific literature understanding and synthesis, SciArena engages the\nresearch community directly, following the Chatbot Arena evaluation approach of\ncommunity voting on model comparisons. By leveraging collective intelligence,\nSciArena offers a community-driven evaluation of model performance on\nopen-ended scientific tasks that demand literature-grounded, long-form\nresponses. The platform currently supports 23 open-source and proprietary\nfoundation models and has collected over 13,000 votes from trusted researchers\nacross diverse scientific domains. We analyze the data collected so far and\nconfirm that the submitted questions are diverse, aligned with real-world\nliterature needs, and that participating researchers demonstrate strong\nself-consistency and inter-annotator agreement in their evaluations. We discuss\nthe results and insights based on the model ranking leaderboard. To further\npromote research in building model-based automated evaluation systems for\nliterature tasks, we release SciArena-Eval, a meta-evaluation benchmark based\non our collected preference data. The benchmark measures the accuracy of models\nin judging answer quality by comparing their pairwise assessments with human\nvotes. Our experiments highlight the benchmark's challenges and emphasize the\nneed for more reliable automated evaluation methods."}
{"id": "2507.01003", "pdf": "https://arxiv.org/pdf/2507.01003", "abs": "https://arxiv.org/abs/2507.01003", "authors": ["Eun-Ji Park", "Sangwon Yun"], "title": "Description of the Training Process of Neural Networks via Ergodic Theorem : Ghost nodes", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 2 figures", "summary": "Recent studies have proposed interpreting the training process from an\nergodic perspective. Building on this foundation we present a unified framework\nfor understanding and accelerating the training of deep neural networks via\nstochastic gradient descent. By analyzing the geometric landscape of the\nobjective function we introduce a practical diagnostic, the running estimate of\nthe largest Lyapunov exponent, which provably distinguishes genuine convergence\ntoward stable minimizers from mere statistical stabilization near saddle\npoints. We then propose a ghost category extension for standard classifiers\nthat adds auxiliary ghost output nodes so the model gains extra descent\ndirections that open a lateral corridor around narrow loss barriers and enable\nthe optimizer to bypass poor basins during the early training phase. We show\nthat this extension strictly reduces approximation error and that after\nsufficient convergence the ghost dimensions collapse and the extended model's\ninvariant law coincides with that of the original and there exists a path in\nthe enlarged parameter space along which the total loss does not increase while\nthe original loss decreases by an arbitrary margin. Taken together these\nresults provide a principled architecture level intervention that accelerates\nearly stage trainability while preserving asymptotic behavior."}
{"id": "2507.01006", "pdf": "https://arxiv.org/pdf/2507.01006", "abs": "https://arxiv.org/abs/2507.01006", "authors": ["Wenyi Hong", "Wenmeng Yu", "Xiaotao Gu", "Guo Wang", "Guobing Gan", "Haomiao Tang", "Jiale Cheng", "Ji Qi", "Junhui Ji", "Lihang Pan", "Shuaiqi Duan", "Weihan Wang", "Yan Wang", "Yean Cheng", "Zehai He", "Zhe Su", "Zhen Yang", "Ziyang Pan", "Aohan Zeng", "Baoxu Wang", "Boyan Shi", "Changyu Pang", "Chenhui Zhang", "Da Yin", "Fan Yang", "Guoqing Chen", "Jiazheng Xu", "Jiali Chen", "Jing Chen", "Jinhao Chen", "Jinghao Lin", "Jinjiang Wang", "Junjie Chen", "Leqi Lei", "Leyi Pan", "Mingzhi Zhang", "Qinkai Zheng", "Sheng Yang", "Shi Zhong", "Shiyu Huang", "Shuyuan Zhao", "Siyan Xue", "Shangqin Tu", "Shengbiao Meng", "Tianshu Zhang", "Tianwei Luo", "Tianxiang Hao", "Tianle Gong", "Wenkai Li", "Wei Jia", "Xin Lyu", "Xuancheng Huang", "Yanling Wang", "Yadong Xue", "Yanfeng Wang", "Yifan An", "Yifan Du", "Yiming Shi", "Yiheng Huang", "Yilin Niu", "Yuan Wang", "Yuanchang Yue", "Yuchen Li", "Yutao Zhang", "Yuxuan Zhang", "Zhanxiao Du", "Zhenyu Hou", "Zhao Xue", "Zhengxiao Du", "Zihan Wang", "Peng Zhang", "Debing Liu", "Bin Xu", "Juanzi Li", "Minlie Huang", "Yuxiao Dong", "Jie Tang"], "title": "GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We present GLM-4.1V-Thinking, a vision-language model (VLM) designed to\nadvance general-purpose multimodal reasoning. In this report, we share our key\nfindings in the development of the reasoning-centric training framework. We\nfirst develop a capable vision foundation model with significant potential\nthrough large-scale pre-training, which arguably sets the upper bound for the\nfinal performance. Reinforcement Learning with Curriculum Sampling (RLCS) then\nunlocks the full potential of the model, leading to comprehensive capability\nenhancement across a diverse range of tasks, including STEM problem solving,\nvideo understanding, content recognition, coding, grounding, GUI-based agents,\nand long document understanding, among others. To facilitate research in this\nfield, we open-source GLM-4.1V-9B-Thinking, which achieves state-of-the-art\nperformance among models of comparable size. In a comprehensive evaluation\nacross 28 public benchmarks, our model outperforms Qwen2.5-VL-7B on nearly all\ntasks and achieves comparable or even superior performance on 18 benchmarks\nrelative to the significantly larger Qwen2.5-VL-72B. Notably,\nGLM-4.1V-9B-Thinking also demonstrates competitive or superior performance\ncompared to closed-source models such as GPT-4o on challenging tasks including\nlong document understanding and STEM reasoning, further underscoring its strong\ncapabilities. Code, models and more information are released at\nhttps://github.com/THUDM/GLM-4.1V-Thinking."}
